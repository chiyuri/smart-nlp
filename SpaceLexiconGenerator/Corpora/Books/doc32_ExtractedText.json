{"content": "\nIntroduction to Satellite\nRemote Sensing\n\nAtmosphere, Ocean, Land and\n\nCryosphere Applications\n\nWilliam Emery\nUniversity of Colorado at Boulder,\n\nColorado, United States\n\nAdriano Camps\nUniversitat Polite?cnica de Catalunya,\n\nBarcelona, Spain\n\n\n\nAdriano Camps\nDedicated to my parents, siblings, wife, and daughters\n\nWilliam Emery\nDedicated to my wife and children\n\n\n\nElsevier\nRadarweg 29, PO Box 211, 1000 AE Amsterdam, Netherlands\nThe Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, United Kingdom\n50 Hampshire Street, 5th Floor, Cambridge, MA 02139, United States\n\nCopyright \u00a9 2017 Elsevier Inc. All rights reserved.\n\nNo part of this publication may be reproduced or transmitted in any form or by any means, electronic or\nmechanical, including photocopying, recording, or any information storage and retrieval system, without\npermission in writing from the publisher. Details on how to seek permission, further information about the\nPublisher\u2019s permissions policies and our arrangements with organizations such as the Copyright Clearance\nCenter and the Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions.\n\nThis book and the individual contributions contained in it are protected under copyright by the Publisher\n(other than as may be noted herein).\n\nNotices\nKnowledge and best practice in this field are constantly changing. As new research and experience broaden our\nunderstanding, changes in research methods, professional practices, or medical treatment may become\nnecessary.\n\nPractitioners and researchers must always rely on their own experience and knowledge in evaluating and using\nany information, methods, compounds, or experiments described herein. In using such information or methods\nthey should be mindful of their own safety and the safety of others, including parties for whom they have a\nprofessional responsibility.\n\nTo the fullest extent of the law, neither the Publisher nor the authors, contributors, or editors, assume any\nliability for any injury and/or damage to persons or property as a matter of products liability, negligence or\notherwise, or from any use or operation of any methods, products, instructions, or ideas contained in the\nmaterial herein.\n\nLibrary of Congress Cataloging-in-Publication Data\nA catalog record for this book is available from the Library of Congress\n\nBritish Library Cataloguing-in-Publication Data\nA catalogue record for this book is available from the British Library\n\nISBN: 978-0-12-809254-5\n\nFor information on all Academic Press publications visit our\nwebsite at https://www.elsevier.com/books-and-journals\n\nPublisher: Candice G. Janco\nAcquisition Editor: Louisa Hutchins\nEditorial Project Manager: Emily Thomson\nProduction Project Manager: Mohana Priyan Rajendran\nDesigner: Christian J. Bilbow\n\nTypeset by TNQ Books and Journals\n\nhttp://www.elsevier.com/permissions\nhttps://www.elsevier.com/books-and-journals\n\n\nTHE HISTORY OF SATELLITE\nREMOTE SENSING 1\n1.1 THE DEFINITION OF REMOTE SENSING\nEvelyn Pruitt coined the term \u201cremote sensing\u201d in the 1960s when she was working at the US Office of\nNaval Research. The term was intended to imply a measurement made by some indirect or \u201cremote\u201d\nmeans rather than by a contact sensor. In its application to satellite and aircraft instrumentation, remote\nsensing relied primarily upon either reflected or emitted electromagnetic radiation (optical and mi-\ncrowave) from the Earth to infer changes on the Earth\u2019s surface or in the overlying atmosphere. The\nfact that these inferences must be made from a by-product (either the reflected or the emitted radiation)\nof the surface or atmospheric process qualifies satellite data collection as \u201cremote sensing.\u201d\n\nOther applications such as the use of acoustic signals to map the internal character of the ocean and\nthe solid Earth are often also considered as a remote sensing. In the past few decades, however, satellite\nand aircraft data analyses have become even more closely associated with the term remote sensing.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING\n1.2.1 THE NATURE OF LIGHT AND THE DEVELOPMENT OF AERIAL PHOTOGRAPHY\nAerial photography depends mainly on the use of reflected solar radiation to image the Earth\u2019s surface.\nMany developments in optics needed to take place before optical systems could be developed. Sir Isaac\nNewton conducted some of the earliest work on the nature of light during his time as the Lucasian\nProfessor at the University of Cambridge.\n\nHe had reached the conclusion that white light is not a single entity. Every scientist since Aristotle\nhad believed that white light was a basic single element, but the chromatic aberration in a telescope\nlens convinced Newton otherwise. When he passed a thin beam of sunlight through a glass prism,\nNewton noted the spectrum of colors that was formed. Newton argued that white light is really a\nmixture of many different types of rays, which are refracted at slightly different angles, and that each\ndifferent type of ray produces a different spectral color. Newton was led by this reasoning to the\nerroneous conclusion that telescopes using refracting lenses would always suffer chromatic aberration.\nHe therefore proposed and constructed a reflecting telescope (i.e., using mirrors).\n\nIn London, around 1862, Maxwell (Fig. 1.1) calculated that the speed of propagation of electro-\nmagnetic fields is that of the speed of light. He proposed that the phenomenon of light is therefore an\nelectromagnetic phenomenon. Maxwell wrote the truly remarkable words:\n\nCHAPTER\n\nIntroduction to Satellite Remote Sensing. http://dx.doi.org/10.1016/B978-0-12-809254-5.00001-4\n\nCopyright \u00a9 2017 Elsevier Inc. All rights reserved.\n1\n\nhttp://dx.doi.org/10.1016/B978-0-12-809254-5.00001-4\n\n\nWe can scarcely avoid the conclusion that light consists in the transverse undulations of the same\n\nmedium, which is the cause of electric and magnetic phenomena.\n\nIn the early part of the 19th century, Daguerre created the first photographic plate, which consisted\nof a thin film of polished silver on a copper base. Putting it into a container with iodine in it sensitized\nthe surface of the silver; the iodine vapors reacted with the polished silver surface and formed a thin\nyellow layer of silver iodide. After a photograph was taken on the plate, it was developed by exposing\nthe plate to magnesium vapor at 339 K. The vapor would only stick to the parts of the plate, which had\nbeen exposed to the light. The plate was then dipped in sodium thiosulfate to dissolve the unused silver\niodide, and then rinsed in hot water to get rid of any remaining chemicals. Daguerreotypes, as these\nimages came to be known, had the ability to capture fine detail, but due to their long exposure time they\nwere constrained to motionless subjects.\n\nOn January 4, 1829, Nie?pce agreed to go into partnership with Louis Daguerre. Nie?pce died only\n4 years later, but Daguerre continued to experiment. Soon he had discovered a way of developing\nphotographic plates, a process, which greatly reduced the exposure time from 8 h down to half an hour.\nHe also discovered that an image could be made permanent by immersing it in salt. Following a report\non this invention by Paul Delaroche, a leading scholar of the day, the French government bought the\nrights to it in July 1839. Details of the process were made public on August 19, 1839, and Daguerre\nnamed it the daguerreotype (Fig. 1.2).\n\nFIGURE 1.1\n\nJames Clerk Maxwell. Born: June 13, 1831 in Edinburgh, Scotland. Died: November 5, 1879 in Cambridge,\n\nCambridgeshire, England.\n\n2 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nThe application to topographic mapping was first suggested in 1849, and balloonist F. Tournachon\nundertook initial attempts in 1858 from a captive balloon a few hundred meters over Petit Bicetre in\nFrance using large silver plates as the camera (Fig. 1.3). Balloon photographs of Confederate positions\nduring the American Civil War represent the first practical use of aerial photography. This is a good\nexample of how war strongly motivates the rapid development of a new technology that could be used\nto gain an advantage over the enemy.\n\nThe invention of gelatin dry plates (film) byMaddox, in 1871, eliminated the need for transporting an\nentire darkroom on the balloon platform. Triboulet used dry plates in 1879 to photograph Paris from a\nfree balloon. The size of the camera was also reduced which opened more opportunities for photography.\n\nThe English meteorologist E. Archibald took the first kite photographs in 1882. In 1889, R. Thiele,\nfrom Russia, mounted cameras on seven unmanned kites to produce a \u201cpanaramograph.\u201d In 1885, W.\nA. Eddy, an American meteorologist in New Jersey, reported the first kite photograph taken in the\nwestern hemisphere. He also developed a kite-camera system, which proved a useful supplement to\nballoon photography during the Spanish-American war. G. R. Lawrence, referred to as the \u201cKing of\nKite Photography,\u201d used kite systems with cameras weighing up to 454 kg and negatives as large as\n1.35 m ? 2.4 m. He is particularly noted for his photograph of San Francisco just after the earthquake\nof 1906 (Fig. 1.4).\n\nAn innovative application of aerial photography was the attachment of cameras to carrier pigeons\nat the 1909 world\u2019s fair in Dresden, Germany (Fig. 1.5). These pigeons would fly over the fair and take\n\nFIGURE 1.2\n\nAn early daguerreotype by John Plumbe of the east front elevation of the United States Capitol.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 3\n\n\n\nan exposure, which would then be developed and printed for sale to the attendees at the fair that can see\nthemselves and the overall fairgrounds.\n\nIn 1908 a passenger appropriately collected the first aircraft still photographs with Wilbur Wright\nflying on a test flight in France (Fig. 1.6), while another passenger took the first aerial movies with\nWilbur in the following year.\n\nSimilarly, Samuel Goddard collected the first rocket photos in 1926 during his experiments with\nrocketry.\n\nFIGURE 1.4\n\nKite photograph of San Francisco after 1906 earthquake; the camera weighed 49 lbs and was held up by\n\nseven kites.\n\nFIGURE 1.3\n\nFelix Tournachon takes a picture of Petit Bicetre, France, in 1858.\n\n4 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nFIGURE 1.5\n\nCameras on carrier pigeons took pictures at the 1909 Dresden World\u2019s Fair.\n\nFIGURE 1.6\n\nFirst aircraft photo by Wilbur Wright\u2019s passenger in France in 1908. In 1909, he made the first aerial movies.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 5\n\n\n\n1.2.2 THE BIRTH OF EARTH-ORBITING SATELLITES\nIn 1903, Konstantin Tsiolkovsky (1857e1935) published Exploring Space Using Jet Propulsion\nDevices (in Russian: Jssmfepcaojf njrpc9y Vrpstraostc rfaltjco9nj Vrjbpranj), which\nis the first academic treatise on the use of rocketry to launch spacecraft. He calculated the orbital speed\nrequired for a minimal orbit around the Earth at 8 km/s, and that a multistage rocket fueled by liquid\npropellants could be used to achieve this. He proposed the use of liquid hydrogen and liquid oxygen,\nthough other combinations can be used.\n\nIn 1928, Slovenian Herman Potocnik (1892e1929) published his sole book, The Problem of Space\nTraveldThe Rocket Motor (German: Das Problem der Befahrung des Weltraumsdder Raketen-\nMotor), a plan for a breakthrough into space and a permanent human presence there. He conceived\na space station in detail and calculated its geostationary orbit. He described the use of orbiting\nspacecraft for detailed peaceful and military observation of the ground and described how the special\nconditions of space could be useful for scientific experiments. The book described geostationary\nsatellites (first put forward by Tsiolkovsky) and discussed communication between them and the\nground using radio, but fell short of the idea of using satellites for mass broadcasting and as tele-\ncommunications relays.\n\nIn a 1945 Wireless World article, the English science fiction writer Arthur C. Clarke (1917e2008)\ndescribed in detail the possible use of communications satellites for mass communications. Clarke\nexamined the logistics of satellite launch, possible orbits, and other aspects of the creation of a network\nof world-circling satellites, pointing to the benefits of high-speed global communications. He also\nsuggested that three geostationary satellites would provide coverage over the entire planet.\n\nThe world changed dramatically on October 4, 1957 with the successful launch and operation of\nthe Russian Sputnik satellite, which was the first human created instrument to orbit the Earth. About\nthe size of a basketball, it weighed only 183 pounds, and took about 98 min to orbit the Earth on its\nelliptical path. That launch ushered in new political, military, technological, and scientific de-\nvelopments. While the Sputnik launch was a single event, it marked the start of the space age and the\nUSeUSSR space race. This satellite carried no Earth-oriented sensors and only really sent out radio\nsignals that were used to communicate with the satellite. It did demonstrate, however, that satellites\ncould be launched from the Earth and operated on a continuous basis. The Sputnik launch changed\neverything. As a technical achievement, Sputnik caught the world\u2019s attention and the American public\noff-guard. Its size was more impressive than Vanguard\u2019s intended 3.5-pound payload. In addition, the\npublic feared that the Soviets\u2019 ability to launch satellites also translated into the capability to launch\nballistic missiles that could carry nuclear weapons from Europe to the United States. Then the Soviets\nstruck again; on November 3, Sputnik II was launched, carrying a much heavier payload, including a\ndog named Laika. Table 1.1 lists all of the first satellites launched by 12 different countries starting\nwith the Soviet Union launch of Sputnik-1 in 1957.\n\nThere were also a number of attempted first launches by many of these same countries before they\nwere successful at launching a satellite and inserting it in to Earth orbit. Several other countries,\nincluding Brazil, Argentina, Pakistan, Romania, Taiwan, Indonesia, Australia, New Zealand,\nMalaysia, Turkey, Spain, Japan, India, Israel, France, Germany, and Switzerland (and others) are at\nvarious stages of development of their own small-scale launcher capabilities. This list grows a lot\nlonger when you include nations and satellites that were launched by the capabilities of other nations.\n\n6 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nToday with the advent of small satellites such as \u201cCubeSats\u201d almost anyone can get a satellite payload\ninto space. It is something the commercial remote sensing companies are taking a very close look at.\n\nIn the United States there had been studies going on as to how Earth-orbiting satellites could benefit\nthe meteorological forecasting community in monitoring conditions on the Earth. These studies led to\nprojects to create new satellites that would monitor the atmosphere. Some early launch failures in the\nUnited States delayed the launch of these new satellites, but eventually the first TIROS (Television and\nInfrared Observation Satellite) was launched and made operational in April of 1960. This satellite was\nspin stabilized which led to the fact that the Earth-oriented sensor (aligned with the spin access) could\nview only a limited portion of the Earth\u2019s latitude (Fig. 1.7).\n\nThis picture shows the location of the solar power panels on the outside of the satellite, which is\ntypical of a spinning satellite.\n\nFig. 1.8 shows all of the different equipment on the first TIROS satellite and their roles in the\noperation of the satellite. The primary sensor was the wide-angle TV camera, which collected images\nof the Earth at approximately 750 km orbital altitude. A small infrared (IR) system was also used to\ncollect some limited measurements through the narrow angle TV camera that also collected radiation\nin visible wavelengths. The receiving and transmitting antennas are shown, and all data collected were\ntransmitted as analog signals down to the ground. A tape recorder on board was used to store these\nanalog data so that they could be downlinked to the ground when the satellite was in view of a tracking\nground station.\n\nThe solar cells and magnetic orientation coils were used to power and control the orientation of the\nspacecraft. Since it was spinning the spin axis would remain fixed in orientation, but the satellite was\ndeployed in a moderate inclination orbit and it passed in and out of the Earth\u2019s magnetic poles and the\nmagnetic coils were needed to unloaded torquing stresses that built up over time. The pointing of the\nmain cameras was controlled by the spin stabilization and the camera pointed only to the latitudes from\n\nTable 1.1 First Successful Satellite Launches by Country\n\nOrder Country Date Rocket Satellite\n\n1 Soviet Union October 4, 1957 Sputnik-PS Sputnik-1\n\n2 United States February 1, 1958 Juno I Explorer 1\n\n3 France November 26, 1965 Diamant-A Aste?rix\n\n4 Japan February 11, 1970 Lambda-4S Osumi\n\n5 China April 24, 1970 Long March 1 Dong Fang Hong I\n\n6 United Kingdom October 28, 1971 Black Arrow Prospero\n\n7 India July 18, 1980 SLV Rohini D1\n\n8 Israel September 19, 1988 Shavit Ofeg 1\n\n9 Russia January 21, 1992 Soyuz-U Kosmos 2175\n\n10 Ukraine July 13, 1992 Tsyklon-3 Strela\n\n11 Iran February 2, 2009 Safir-1 Omid\n\n12 North Korea December 12, 2012 Unha-3 Kwangmyongsong-3,\nunit 2\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 7\n\n\n\nnorthern North America to South America. The rest of the time the camera pointed out into space\nproviding no information on the rest of the Earth\u2019s surface. Thus, the TIROS satellites were incapable\nof observing the entire globe. This was a limitation of the spin stabilization at least as it was deployed\nin this fashion.\n\nThe TIROS camera was designed to depict the Earth\u2019s cloud cover as an indication of the weather\nsystems over the Earth. Thus, these early satellite designs were driven primarily by meteorological\nconsiderations and the need for improved forecasting. An example of a TIROS image of an Atlantic\nstorm is presented here in Fig. 1.9. Note the distortion of the latitude, longitude lines, which is caused\nby the curvature and rotation of the Earth as well as the pointing orientation of the satellite camera.\nSince all of the TIROS imagery were analog the correction of these geometric distortions was not\npossible using digital methods and mapping was done by overlaying \u201cwarped grids\u201d that best matched\nthe orientation of the global features. This type of mapping approach determined the lines on Fig. 1.9.\n\nViewing these early satellite, TV images became a method of discovery where images were located\nthat depicted various important atmospheric processes. Another example is presented in Fig. 1.10,\nwhich shows a cloud streak that represents the jet stream over the land on the left as it passes over the\nocean at the east coast of North America just south of Cape Blanco. The image shows the spreading of\nthe jet stream over the central United States and thinning as it moves east. The cloud stream thickens\nonce again as it moves eastward from the coast.\n\nOne of the big benefits of satellite imagery was the ability to view hurricanes from space. The thick\ncloud cover associated with a hurricane along with the characteristic eye of the storm made these\n\nFIGURE 1.7\n\nTIROS I prototype on display at the Smithsonian National Air and Space Museum.\n\n8 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nfeatures easy to see as shown here in the distorted image of Fig. 1.11. Here the geometric distortion due\nto Earth\u2019s curvature and rotation are seen in the shape of the Earth\u2019s surface and the features. No\nlatitude, longitude lines have been added to this image to further depict these distortions. As with\nFig. 1.10, there are some dark lines showing boundaries of the central part of the image and a plus sign\nto show the center of the image. In this case, hurricane Betsy is in the southwestern corner of the\n\nFIGURE 1.8\n\nTIROS satellite equipment and instruments.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 9\n\n\n\nFIGURE 1.9\n\nTIROS image of an Atlantic storm.\n\nFIGURE 1.10\n\nTIROS image of the jet stream south of Cape Blanco; the dark lines and cross in the middle of the image have\n\nbeen added to identify the jet stream. The data were collected on November 11, 1964, at 13:00 GMT.\n\n10 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nimage. The slant view of the storm leads to an \u201capparent\u201d closure of the eye of the storm due to the\norientation.\n\nLand surface features were also apparent in the early TIROS imagery when cloud cover was\nsufficiently low to make it possible to view the surface. As an example Fig. 1.12 presents an image of\nLake Erie, which clearly shows some of the limitations to this type of imagery. Here the lake covers a\nnumber of satellite passes each of which has a slightly different exposures. This produces artificial\nstriping in the image. Earth surface distortion continues to be a problem as shown by the elongated part\nof the lake in the southwest portion of the image. The presence of clouds in this same portion of the\nimage also obscures the surface of the lake. Discontinuities in the cloud cover are introduced by the\nfact that the image is made up of sequential passes, which are not truly synoptic in coverage.\n\nIt is important to recognize that in this era of analog data relay all image processing was done using\na collage of pictures printed with conventional means as shown in Fig. 1.13.\n\nThe initial TIROS satellites were relatively short-lived with satellites lasting only a few months\neach. By the end of the series, however, the satellites were lasting approximately a year and continuing\nto report data over this entire period.\n\nTo overcome the viewing limitations of the original TIROS series of satellites the next generation\nof spinning satellites was changed to have the camera pointing radially outward and the spin axis of the\nsatellite turned 90 degrees relative to the original TIROS satellites. This new configuration was called\nthe \u201cwheel\u201d satellite and a consequence of this change was the ability to collect a series of circular\nimages that over the period of a day covered the entire surface of the Earth (Fig. 1.14). Operated by the\n\nFIGURE 1.11\n\nHurricane Betsy north of the Bahamas from TIROS VII on September 4, 1965.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 11\n\n\n\nFIGURE 1.12\n\nTIROS first satellite image of sea ice over the Gulf of St. Lawrence and St. Lawrence River, May 1960.\n\nFIGURE 1.13\n\nTIROS image data handling by photographic methods.\n\n12 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nnewly formed Earth Satellite Science Administration (ESSA), these satellites were identified as ESSA\nsatellites a practice that was followed when the agency evolved into the National Oceanic and At-\nmospheric Administration (NOAA).\n\nThe daily circular images of the Earth were pasted together to comprise a global image of the Earth\nand its atmosphere. While the resultant global image did not represent a synoptic picture of the Earth, it\ndid represent a first look at daily images of the entire Earth (Fig. 1.15). Note how the edges of the\n\nFIGURE 1.14\n\nThe scan operation of the Earth Satellite Science Administration wheel satellites (NOAA Photo Library).\n\nFIGURE 1.15\n\nFirst global image from the Earth Satellite Science Administration wheel satellite (NOAA Photo Library),\n\nFebruary 13, 1965.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 13\n\n\n\nvarious component images are quite marked both by changes in brightness and in the expression of the\nindividual features. Clouds in particular are not continuous, and major cloud features appear broken up\ndue to the temporal discontinuities in the collection of the individual images.\n\nIn spite of these limitations, these global images became the standard to study atmospheric cloud\nconditions and to infer their connections to global weather patterns. These patterns could then be used\nto improve weather forecasting by being able to \u201csee\u201d the weather before it crossed the US coastline.\nSince the images were global similar forecasting improvements were possible for other parts of the\nworld as well as the United States. This was a big improvement over the earlier TIROS program and\nthere were a number of ESSA wheel satellites that operated between 1966 and 1971.\n\nThe next development in the evolution of operational weather satellites was the incorporation of\nspacecraft stability control. Developed as part of the ballistic missile program during the \u201ccold war,\u201d\nthree-axes stability systems were now available to control the pointing of the spacecraft without the\nneed to spin the spacecraft. With this three-axes stabilization, it was possible to keep the Earth sensors\nalways pointing at the Earth regardless of its position in the orbit. This made it possible to collect\nimagery over the entire Earth\u2019s surface from the same sensors at the same resolution Fig. 1.16.\n\nCalled the Improved TIROS Observing Satellite, or ITOS, this family of satellites brought in a new\nera of remote sensing. In addition to the three-axes stabilization, these satellites carried a new suite of\noptical radiometers which were scanning systems that collected reflected and emitted radiation from\nthe Earth\u2019s surface line by line as the satellite moved along in its polar orbit. These first radiometers\n(Fig. 1.17) ushered in the new era of improved capabilities that became a standard approach to viewing\nthe Earth.\n\nTo ensure data continuity, this satellite also carried cameras that could provide the same kind of\ndata that had been previously available through its predecessor satellites. There were cameras\n\nFIGURE 1.16\n\nThree-axes stabilized ITOS satellite.\n\n14 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\ncollecting data for two types of data relay: (1) the highest possible spatial resolution of the camera and\n(2) a lower resolution applied picture transmission (APT) that supplied lower resolution data to field\nstations using an omnidirectional antenna. The highest resolution required the use of a \u201ctracking\u201d\nantenna system that followed the spacecraft as it crossed over the receiving site. Such systems were at\nthe time too complex and expensive for many field offices and ships at sea. The APT broadcast was set\nup to make it possible to broadcast a lower resolution version of the data using a VHF omnidirectional\nbeacon that could easily be picked up by low-cost antenna systems. This tradition has been continued\nup to today and there are still APT transmissions providing lower resolution real-time imagery to these\nremote sites. The ITOS scanning radiometers were those that became the primary instruments for\nfuture satellites. Unlike cameras, these radiometers collected radiation one line at a time thus building\nup an image as the satellite continued forward in its orbit. These radiometers could also collect ra-\ndiation in various spectral bands.\n\nThe first ITOS satellite demonstrated the utility of these new technologies and began a longer time\nseries of polar-orbiting spacecraft, which were now called NOAA satellites after the name of the\nagency that operated them. A series of eight satellites with approximately the same suite of equipment\nfilled in the years between 1970 and 1976. The practice was to designate the satellites as NOAA a, b, c,\netc. when they were built, and then transition them to NOAA 1, 2, 3.etc. once they were operating on\norbit. The fact that not all of the NOAA satellites achieved orbit or failed early on orbit led to the fact\nthat alpha and numeric designations do not map one to one.\n\nThe details of the ITOS orbit are shown here in Fig. 1.18, which shows the satellite polar orbit\nrelative to day/night and lists all of the sensor capabilities and gives the details of the orbit. Now the\norbital altitude is about 1271 km and the orbit is Sun-synchronous with an 80-degree inclination in a\nretrograde orbit with a period of about 111 min.\n\nA big change over this evolution of satellite capabilities was the size and weight of the spacecraft.\nThe original TIROS satellites weighed about 150 kg, which increased to 250 kg with the change to the\n\nFIGURE 1.17\n\nThe ITOS satellite with its sensors and other equipment; note the introduction of solar panels. APT, applied\n\npicture transmission; AVCS, advanced vidicon camera system.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 15\n\n\n\nESSAwheel satellites. The shift to three-axes stabilization increased the ITOS satellite up to 400 kg,\nwhich then increased by over a factor of three to the modern NOAA and Defense Meteorological\nSatellite Program (DMSP) satellites that weigh about 1500 kg.\n\nThe analog radiometer data from the NOAA satellites were digitized on the ground so that the\nimages could be digitally processed and enhanced to geometrically correct the image geolocation and\nbring out various features in the atmosphere and on the ground. The geometric corrections for Earth\ncurvature and rotation compensated for the distortions of satellite viewing. Additional corrections were\nalso needed for satellite attitude and time, which influences the viewing angle.\n\nRadiance enhancement was needed to bring out the weaker gradients in some of the radiometer\nchannels such as the thermal IR patterns in the ocean. An example is shown here in Fig. 1.19, which is\nan image of the Gulf of Mexico and the east coast of Florida, which shows the warm water (dark gray\nshades) associated with the loop current in the Gulf of Mexico and the subsequent Gulf Stream off the\neast of Florida. The colder water closer to the shore off Florida represents the colder \u201cshelf water\u201d that\nflows southward inshore of the Gulf Stream. Colder waters also bound the dark pattern of the loop\ncurrent in the center of the Gulf of Mexico.\n\nThis image has been remapped to correct for geometric distortion, which can be seen in the\nappearance of Florida at the edge of the image, which would be highly distorted if seen in satellite\nperspective. It is very difficult to quantitatively study features in satellite imagery without being able to\n\u201cnavigate\u201d the imagery, which includes the geometric corrections for Earth curvature and rotation as\nwell as corrections for spacecraft attitude and timing errors.\n\nThe ITOS and NOAA satellites carried two different radiometers. The primary instrument was the\nscanning radiometer (SR), which had an 8 km resolution and was limited to only three channels: (1) a\n\nFIGURE 1.18\n\nITOS satellite operation. APT, applied picture transmission; AVCS, advanced vidicon camera system.\n\n16 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nwide band visible, (2) a near-IR channel (0.7e1.1 mm), and (3) a thermal IR (11 mm) channel. The\ninstrument was used to map clouds and later applied to the mapping of sea surface temperature (SST)\nusing the 11 mm channel. A sophisticated processing system was developed that used a histogram\nmethod to filter out pixels dominated by clouds to produce SST over large 50 km boxes. This system\nwas found to introduce a lot of errors by letting some cloudy pixels slip through and used an objective\nanalysis (Cressman, 1959) routine that \u201cfilled\u201d in erroneous data.\n\nAnother instrument flown on the NOAA satellites was the very high resolution radiometer\n(VHRR), which was the first instrument to demonstrate a real capability for being able to map SST. It\nhad channels in the visible, the near-IR wavelengths, and the midrange IR and the thermal IR\nwavelengths (again 11 mm). Using the visible and near-IR channels for cloud clearing the VHRR data\nwere then used to produce a 1 km resolution SST, which was the native resolution of the instrument.\nThe image in Fig. 1.19 is from the VHRR sensor.\n\nThe biggest change in satellites and sensors came in the fall of 1978 with the advent of TIROS-N\n(\u201cN\u201d for new). An advanced version of this series of NOAA polar-orbiting satellites the last of which is\nstill operating as this text is being written. These are the 1500 kg spacecraft referred to earlier where\nthe added weight reflects greatly increased capabilities with these new spacecraft. They were fully\ndigital systems that downlinked their data digitally. A new imager called the advanced very high\nresolution radiometer (AVHRR) became the workhorse radiometer on this spacecraft. With its basic\n1 km footprint in four channels the AVHRR data have been used for a wide range of studies of ocean,\nland, and atmospheric processes. Over the subsequent three decades, this instrument has evolved from\n\nFIGURE 1.19\n\nVery high-resolution radiometer thermal infrared image of the Gulf of Mexico, March 31, 1974 (NOAA Photo\n\nLibrary).\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 17\n\n\n\nhaving only four channels to one that now has six different channels, is called AVHRR-3, and has the\ncharacteristics as described in Table 1.2.\n\nThe original four channels covered the visible (channel 1), the near-IR (channel 2), the mid-\nrange IR (channel 3 only at 3.7 mm), and the 11 mm (channel 4) thermal IR. The first improvement in\nthis sensor led to the AVHRR-2, which added the fifth channel at 12 mm. This channel was added to\nprovide a \u201csplit-window\u201d in the thermal IR to make it possible to correct for atmospheric water\nvapor attenuation of the thermal IR signal in computing SST. The nominal sensor spatial\nresolution of 1.09 km meant that all of the channels delivered images with essentially the same\nresolution.\n\nChannel 3 is now broken into two parts. The approximately 3.7 mm channel (now called channel\n3B) is continued at night, but during the day this channel shifts over to 1.6 mm to better resolve at-\nmospheric aerosols and clouds. The visible and near-IR channels are widely used for mapping\nvegetation, snow cover, and atmospheric aerosols. These channels are also used for mapping snow and\nice cover. The thermal IR channels are also used to compute land surface temperature in addition to\nSST.\n\nThe TIROS-N satellites also carried a variety of other instruments. The high-resolution IR sounder\nis the primary sensor in the TIROS operational sounder system that also includes data from the British\nstratospheric sounding unit , and the microwave sounding unit (MSU). Together these three in-\nstruments are used to retrieve atmospheric temperature and water vapor profiles for use in numerical\nmodel assimilation. Actually it was learned that it was better to directly assimilate satellite instrument\nradiances from this system into the numerical weather forecast models than it would be to retrieve\ntemperature and water vapor profiles to be assimilated into the models.\n\nOther instruments on TIROS-N (Fig. 1.20) are the search and rescue (SAR in Fig. 1.20B) and\nArgos data collection system (UHF data collection system antenna in Fig. 1.20A). Both of these\nsystems collect data transmitted from the Earth\u2019s surface and use the Doppler shift of these signals to\naccurately locate these platforms. The Argos system also has the capability of collecting a limited\namount (approximately 256 data words) of geophysical data collected on the platform.\n\nThis diagram shows how this spacecraft has considerable extra capacity and other sensors of\nopportunity have been flown on this satellite such as the Earth Radiation Budget Experiment in-\nstruments that flew only on NOAA-9. These TIROS-N satellites continued to carry the name of NOAA\n\nTable 1.2 AVHRR-3 Channel Characteristics\n\nCh. 1 Ch. 2 Ch. 3A Ch. 3B Ch. 4 Ch. 5\n\nSpc Rg (mm) 0.58e0.68 0.7e1.0 1.58e1.64 3.55e3.93 10.3e11.3 11.5e12.5\n\nDetector Silicon Silicon InGaAs InSb HgCdTe HgCdTe\n\nResolution (km) 1.09 1.09 1.09 1.09 1.09 1.09\n\nS/N at 5% 9:1 9:1 20:1 e e e\n\nNedT at 300 K e e e 0.12 K 0.12 K 0.12 K\n\nTemperature Range (K) e e e 180e335 180e335 180e335\n\nCh., channel; NedT, noise equivalent delta temperature; Spc Rg, spectral range; S/N, signal-to-noise ratio. The S/N ratio is given at\n5% reflectivity.\n\n18 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nFIGURE 1.20\n\nTIROS-N and ATIROS-N satellites schematic diagrams.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 19\n\n\n\nsatellites. A picture of a TIROS-N satellite being worked on in storage is shown in Fig. 1.21, to give the\nreader a better appreciation of the size of these satellites.\n\nA summary of the evolution of polar-orbiting environmental satellite (POES) weather satellites is\ngiven here in Fig. 1.22, which contains pictures of the important satellites and the relevant\ncharacteristics.\n\n1.2.3 THE FUTURE OF POLAR-ORBITING SATELLITES\nPrior to 2011 there were three separate US polar-orbiting satellite systems. The one that has been\ndiscussed most up to now is the one operated by NOAA. Originally these systems were developed by\nNASA, and then turned over to NOAA for operations and data analysis. More recently NOAA has\ngotten involved with the design and acquisition of these systems, and only uses NASA in a most formal\nbasis to contract for these systems. There is also a parallel system operated by the US Department of\nDefense (DoD) known as the DMSP, which uses spacecraft very similar to the NOAA satellites, but\nflying a different suite of sensors. Finally, there is a set of NASA research polar-orbiting satellites that\nalso provide data from similar Sun-synchronous orbits.\n\nFIGURE 1.21\n\nA TIROS-N satellite being worked on.\n\n20 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nIn mid-1994 a US presidential directive dictated the convergence of these three systems into a\nsingle polar-orbiting satellite system that would fulfill the needs of the DoD, NOAA, and NASA. To be\nled by NOAA, an Integrated Project Office (IPO) was created that would be staffed by people seconded\nfrom each of the three component agencies. Each of these three agencies was given specific roles and\nresponsibilities within this new National Polar-orbiting Operational Environmental Satellite System\n(NPOESS). These assignments are described below.\n\nThe Department of Commerce (NOAA) was designated to be the lead agency that will appoint the\nsystem program director who will be an NOAA employee who will act as the head of the executive\ncommittee (EXCOM) of the IPO/NPOESS program. NOAAwill also have the lead responsibility for\n\nFIGURE 1.22\n\nThe evolution of polar-orbiting environmental satellite weather satellites.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 21\n\n\n\ninterfacing with national and international civil user communities, consistent with national security,\nand foreign policy requirements.\n\nThe DoD will have the lead agency responsibility to support the IPO in major system acquisitions\nnecessary to the NPOESS. DoD will nominate the principal deputy system program director who will\nbe approved by the NOAA system program director.\n\nNASAwill have the lead agency responsibility to support the IPO in facilitating the development\nand insertion of new cost-effective technologies that enhance the ability of the converged system to\nmeet its operational requirements.\n\nOriginally all of the contracts were let for all of the NPOESS sensors before the contract was let for\nthe spacecraft and ground systems to Northrop Grumman Corp. It was then decided to place all of the\nsensor contracts under Northrop Grumman Corp. as well. These sensors were all designed by the\ncommercial contractors in response to a list of Environmental Data Records (EDRs) that were created\nby the NPOESS IPO. This EDR list contained a list of observables along with requirements such as\nresolution, precision, and accuracy as defined by the IPO.\n\nThe original schedule for the NPOESS program was seriously delayed and budgets overrun by\nexploding sensor budgets and inabilities to meet planned time schedules. The combined overruns led\nto a DoD mandated congressional review that led to a revision in scope agreed upon by the principals\nof NOAA, the DoD, and NASA. A dramatically scaled down and delayed program emerged with plans\nfor an interim NASA sponsored NPOESS preparatory program satellite originally scheduled to be\nlaunched in 2006 was finally launched on October 28, 2011. Fortunately, most systems seem to be\nworking properly.\n\nIn 2010 the program was completely reorganized by separating it into two parts; one funded via\nNOAA, but controlled by NASA employees at the Goddard Space Flight Center (GSFC). This segment\nis referred to as the Joint Polar Satellite System (JPSS) with a primary responsibility to the civilian part\nof the polar-orbiting satellite requirements. The other half was returned to the DoD and it is called the\nDefense Weather Satellite System. Each program has taken a very different path for the near future\nwith the JPSS program using essentially a copy of the NPOESS Preparatory Project (NPP) satellite for\nits first satellite while the DoD has kept the larger satellite bus of the original NPOESS program. In\n2011 the DoD decided to cancel its component of this program leaving only the JPSS program to fly a\npolar-orbiting weather satellite.\n\nMore recently the entire NPOESS program was canceled and reorganized as the JPSS. NOAA\ncontinued to lead the effort but contractural activists were carried out by NASA at the GSFC in\nGreenbelt, MD. The only satellite presently carrying some of the earlier NPOESS sensors was pre-\nviously known as the NASA Preparatory Platform but now has been renamed in honor of Vern Suomi\nand is the Suomi satellite. JPSS-1 is scheduled to be launched sometime in 2017. It will be a copy of the\nSuomi satellite and carry the same suite of sensors [Visible/Infrared Radiometer Suite (VIIRS),\nAdvanced Technology Microwave Sounder (ATMS), Cross-track Infrared Sounder (CrIS), Ozone\nMapping and Profiler Suite (OMPS), and Cloud and Earth Radiant Energy System (CERES)].\n\nThe primary imager for NPOESS will continue on and is known as the VIIRS. It contributes to 23\nEDRs and it is the primary instrument for 18 EDRs. VIIRS will combine a simple scan mechanism and\nradiometric fidelity of the earlier AVHRR with the high spatial resolution (0.65 km) of the Operational\nLine Scanner (OLS) operating on the DMSP satellites. VIIRS provides imagery of clouds in sunlit\nconditions in about a dozen visible channels as well as provide imagery in a number of IR channels for\nnight and day cloud imaging products and a low-light sensing capability as was carried on DMSP.\n\nVIIRS has multichannel imaging capabilities to support the acquisition of high-resolution atmo-\nspheric imagery and the generation of a variety of applied products including visible and IR imaging of\n\n22 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nhurricanes, detection of wildfires, smoke, and atmospheric aerosols. VIIRS will have capabilities to\nproduce higher resolution and more accurate measurements of SST then was possible from the her-\nitage AVHRR instrument. VIIRS also has channels to measure ocean color products. The channels for\nVIIRS are shown here in Table 1.3.\n\nHere we can see that VIIRS supplies a lot more data than the AVHRR and data processing systems\nmust be increased in capacity and capability if they are going to be able to process and reduce all of\nthese data. New algorithms had to be developed to take best advantage of the many new channels\navailable with VIIRS that were not available with AVHRR. Fortunately, NASA\u2019s moderate resolution\nimaging spectrometer had most of these channels making it possible to gain a lot of experience with the\nuse of these channels for computing various geophysical quantities.\n\nThe operation of the VIIRS radiometer is shown here as a flow chart in Fig. 1.23, which starts with\nthe scanning telescope of the VIIRS instrument.\n\nTable 1.3 Channel Characteristics for the Visible/Infrared Radiometer Suite\n\nBand\nName\n\nWavelength\n(nm)\n\nSpatial Resolution\n(km)\n\nWavelength\nType\n\nRadiance\nType\n\nFocal Plane\nType\n\nM1 412 20 Visible Reflective VISNIR\n\nM2 445 18 Visible Reflective VISNIR\n\nM3 488 20 Visible Reflective VISNIR\n\nM4 555 20 Visible Reflective VISNIR\n\nM5 672 20 Visible Reflective VISNIR\n\nM6 746 15 Near-infrared\n(IR)\n\nReflective VISNIR\n\nM7 865 39 Near-IR Reflective VISNIR\n\nM8 1240 20 Shortwave IR Reflective SMWIR\n\nM9 1378 15 Shortwave IR Reflective SMWIR\n\nM10 1610 60 Shortwave IR Reflective SMWIR\n\nM11 2250 50 Shortwave IR Reflective SMWIR\n\nM12 3700 180 Midwave IR Emissive SMWIR\n\nM13 4050 155 Midwave IR Emissive SMWIR\n\nM14 8550 300 Longwave IR Emissive LWIR\n\nM15 10,763 1000 Longwave IR Emissive LWIR\n\nM16 12,013 950 Longwave IR Emissive LWIR\n\nDNB 700 400 Visible Reflective\nimaging\n\nDNB\n\nI1 640 80 Visible Reflective\nimaging\n\nVISNIR\n\nI2 865 39 Near IR Reflective\nimaging\n\nVISNIR\n\nI3 1610 60 Shortwave IR Reflective\nimaging\n\nSMWIR\n\nI4 37,403 80 Midwave IR Emissive\nimaging\n\nSMWIR\n\nI5 11,450 1900 Longwave IR Emissive\nimaging\n\nLWIR\n\nDNB, day night band; LWIR, longwave infrared; SMWIR, short- and mid-wavelength infrared; VISNIR, visible/near infrared.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 23\n\n\n\nThe rotating telescope views the Earth\u2019s surface, the blackbody assembly is used for thermal\ncalibration, the solar diffuser for visible/near-infrared (VISNIR) calibration, deep space for additional\nthermal calibration information, and finally the Moon for additional visible calibration. After\ncollection by the telescope the data pass through some relay optics before being split by a dichroic\nbeam splitter into the different wavelengths. The visible and near-IR energy goes to the VISNIR focal\nplane assembly (FPA), while the short and midrange IR go to one FPA and the longwave to another.\nAnother beam splitter is employed to separate out the longwave infrared (LWIR) and the shortwave\ninfrared (SWIR). Both of these two FPAs must be cooled with a radiative cooler to improve the\nperformance of the FPA. The outputs from the FPAs are recorded electronically and converted to\ndigital representations. These data are then further processed and reduced in volume.\n\n1.2.3.1 The Cross-Track Infrared Sounder\nAnother instrument on the NPP satellite is the Cross-track Infrared Sounder (CrIS), which is an IR-\nbased radiation sounder based on a Fourier transform interferometer. It has an 18.5 km resolution at\nnadir for the temperature profile, 15 km for the moisture profile, and 55 km for the atmospheric\npressure profile, with a temperature accuracy of 1 K. CrIS is an interferometer that provides over 1000\nspectral channels in the thermal IR with an improved spatial resolution, and it will be able to measure\nvertical temperature profiles with an accuracy approaching 1 K.\n\nAlong with the CrIS, the ATMS collects atmospheric information to measure temperature and\nmoisture profiles at high (wdaily) temporal resolution. ATMS is the only instrument not being\ndeveloped by a contractor, but by NASA\u2019s GSFC. A conceptual picture of CrIS is shown here in\nFig. 1.24.\n\nSun\nSDSM\n\nSolar\nDiffuser\n\nRelay\nOptics\n\nDichroic\nBeamsplitter\n\nDichroic\nBeamsplitter\n\nRadiative\nCooler\n\nCold\nStage\n\nAssembly\nSWIR/MWIR\n\nFPA\n\nLWIR FPA\n\nPower, Command,\nControl, Telemetry\n\nElectronics\n\nVIS/NIR\nFPA\n\nIncludes\nDNB\n\nFocal Plane\nElectronics\n\nand A/D\nConversion\n\nFormatter\nData\n\nCompression\nand Buffer\n\nData\nOutput\n\nBlackbody\nAssembly\n\nSpace\nView\n\nMoon\n\nEarth\n\nRotating\nTelescope\nAssembly\n\nFIGURE 1.23\n\nFlow chart of the Visible/Infrared Radiometer Suite.\n\n24 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\n1.2.4 OTHER HISTORICAL SATELLITE PROGRAMS\n1.2.4.1 The NIMBUS Program\nOne of the most important historical satellite programs was NASA\u2019s NIMBUS program that was a test\nplatform for testing new instruments in space. Built as an early three-axes stabilized platform, the\nNIMBUS (raincloud) satellite, the first NIMBUS satellite (Fig. 1.25), was used to test the meteoro-\nlogical sensors that were later carried by the TIROS, ESSAwheel, and ITOS/NOAA satellites. Unlike\n\nFIGURE 1.24\n\nThe Cross-track Infrared Sounder instrument conceptual diagram.\n\nFIGURE 1.25\n\nNIMBUS 1 satellite for testing meteorological sensors.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 25\n\n\n\nthe ITOS satellites NIMBUS used a gravity gradient to maintain Earth orientation for all of the\nNIMBUS satellite instruments.\n\nOne of the most important NIMBUS purposes was the test of the multispectral scanner (MSS) that\nbecame the primary instrument of the Landsat satellites. In fact, the first three Landsat satellites used\nthe NIMBUS bus to deploy these instruments.\n\nThe last of the NIMBUS series was NIMBUS 7 launched in late 1978 and was finally decom-\nmissioned in 1986. It carried the first ocean color imager the coastal zone color scanner (CZCS), and a\nquickly refurbished engineering model of the scanning multichannel microwave radiometer that flew\nearlier on the short-lived Seasat satellite. Unfortunately, NASA decided it would be too expensive to\ncontinue the NIMBUS program, which would need a new satellite platform, and this mechanism for\nroutinely testing new satellite instrumentation was lost.\n\n1.2.4.2 The Landsat Program\nLandsat represents the world\u2019s longest continuously acquired collection of spaced-based, moderate\nresolution land remote sensing data. Four decades of Landsat imagery provides a unique resource for\nthose who work in agriculture, geology, forestry, regional planning, education, mapping, and global\nchange research. As mentioned above the land surface sensors were first launched and tested as part of\nthe NIMBUS program. The Hughes Santa Barbara Research Center designed and built the first three\nMSSs. These first three Landsat satellites used the NIMBUS bus to simplify development and get the\nMSS imager into space as quickly as possible. At this stage this was called the Earth Resources\nTechnology Satellites Program (1966), but this was changed to Landsat in 1975.\n\nIn 1979 by Presidential Directive 54, President Jimmy Carter transferred the Landsat operations\nfrom NASA to NOAA and recommended of a long-term operational system with four additional\nsatellites beyond Landsat 3. At this time, it was also recommended that the Landsat program be\ntransitioned to the private sector. This occurred in 1985 when the Earth Observation Satellite Company\n(EOSAT) was formed as a partnership between Hughes Aircraft and RCA. NOAA transferred the\nLandsat program to EOSAT with an agreement to operate the system for 10 years. EOSAT operated\nLandsat 4 and 5, had exclusive right to market Landsat data, and was to build Landsat 6 and 7.\n\nA new and unique bus was developed for Landsat 4 and 5 (Fig. 1.26). Also a new instrument called\nthe Thematic Mapper (TM) was developed for these two spacecraft. Thus, Landsat 4 and 5 carried both\ntheMSS and TM imagers. The TM instrument added a thermal IR channel to the existingMSS channels.\n\nThey had completed the construction of Landsat 6, which had a new design and an improved sensor\ncalled the Extended Thematic Mapper (ETM). Landsat 6 was finally launched on October 5, 1993, but\nwas lost in a launch failure. Processing of Landsat four and five data was resumed by EOSAT in 1994.\nIt should be noted that in an effort to recover their costs EOSAT charges for the Landsat images was\nvery high and basically cut out the majority of science users other than oil companies and the insurance\nindustry.\n\nLandsat 7 was a copy of Landsat 6, but by the time it was ready for launch the program had been\ntransferred back to NASAwho launched it on April 15, 1999. The value of the Landsat program was\nrecognized by Congress in October, 1992 when it passed the Land Remote Sensing Policy Act (Public\nLaw 102-555) authorizing the procurement of Landsat 7 and assuring the continued availability of\nLandsat digital data and images, at the lowest possible cost, to both traditional and new users of these\ndata. This satellite continues to operate, but problems with the scan system led to the implementation\nof a scan line corrector in May of 2003.\n\n26 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nCalled the Landsat Data Continuity Mission (LDCM) Landsat 8 was launched February 11, 2013.\nLike the previous Landsat satellites, Landsat 8 represents a collaboration between NASA and the US\nGeological Survey (USGS). Landsat 8 represents a departure from previous Landsat satellites in that it\ncarries two instruments that cover very different parts of the electromagnetic spectrum. Built by Ball\nAerospace the Operational Land Imager (OLI) continues the long time series of land surface mea-\nsurements, but using up-to-date technologies. The Thermal Infrared Sensor (TIRS) will provide unique\nthermal IR sensing capability for a Landsat satellite. The satellite bus was built by the Orbital Sciences\nCorp. and has a design life of 5 years, but carries enough fuel for 10 years of operations. The NASA\ncontract for the LDCM satellite bus was originally awarded to the General Dynamics Advanced In-\nformation Systems (GDAIS) in April, 2008. Orbital Sciences subsequently acquired the spacecraft\nmanufacturing division of GDAIS and therefore assumed the responsibility for the Landsat 8 satellite\nbus. The bus was built at Orbital\u2019s spacecraft manufacturing facility in Gilbert, Arizona.\n\nThe OLI was built by Ball Aerospace and Technologies Corp. and measures in the visible, near-IR,\nand shortwave IR portions of the electromagnetic spectrum. The images have a 15-m panchromatic\nand a 30-m multispectral spatial resolutions along a 185 km wide swath (Fig. 1.27).\n\nOLI represents a real advancement in Landsat sensor technology and uses a technical approach\ndemonstrated by the Advanced Land Imager Sensor flown on NASA experimental EO-1 satellite.\nEarlier Landsat instruments all used scan mirrors that stopped and started with each scan (see the\noptical instrument chapter). OLI instead uses long detector arrays with over 7000 detectors per spectral\nband, aligned across its focal plane to view across the swath. This \u201cpush-broom\u201d scan approach results\nin a much more sensitive instrument providing improved land surface sensing with fewer moving parts.\nIn addition, OLI has an improved signal-to-noise ratio as compared to previous Landsat instruments.\n\nFIGURE 1.26\n\nLandsat 5 satellite.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 27\n\n\n\nThe TIRS is designed to measure land surface temperature in two thermal bands using a new\ntechnology to detect heat. The motivation behind the TIRS instrument is a realization that state hy-\ndrology managers relied on the LDCM\u2019s predecessors, Landsat 5 (TM) and Landsat 7 (ETM), to track\nhow land and water are being used in their state. Since nearly 80% of the freshwater in the western\nUnited States is used to irrigate crops, TIRS will become an invaluable tool for managing water\nconsumption.\n\nTIRS uses Quantum Well Infrared Photodetectors (QWIPs) to detect long wavelength radiation\nemitted by the Earth whose intensity depends on surface temperature. In these thermal IR portions\nof the spectrum, QWIPs are a new, lower-cost alternative to conventional longwave IR technolo-\ngies. The QWIPs were developed at NASA\u2019s GSFC in Greenbelt, Maryland. The QWIPs are\nsensitive to two thermal IR wavelength bands, helping users separate the temperature of the Earth\u2019s\nsurface from that of the atmosphere. Their design depends on quantum mechanics where gallium\narsenide semiconductor chips trap electrons in an energy state \u201cwell\u201d until the electrons are\nelevated to a higher state by thermal IR radiation of a certain wavelength is incident on it. The\nelevated electrons create an electrical signal that can be readout to form a digital image.\n\nAn overview of this sequence of satellites is best given by Table 1.4, which shows all of the Landsat\nsatellites up to Landsat 8.\n\nAll of the Landsat satellites operate in a Sun-synchronous orbit with a 9:42 a.m. local equator\ncrossing time. The swath width of the TMwas 150 km, and the ground track separation at the equator\nwas 2875 km. The OLI has increased the swath width to 185 km. Thus, any spot on the Earth is only\ncovered approximately every 15 days. This low frequency of repeat coverage meant that cloud cover\ncould dramatically reduce the amount of coverage of the Landsat instruments. The TM instrument\nadded a number of channels to the MSS including a new thermal IR channel. In addition, the TM\nspatial resolution increased from 80 m with the MSS to about 30 m for the TM. Landsat 8 further\nimproves on this spectral resolution by adding an independent TIRS instrument to cover the thermal\nIR channels while preserving the visible and near-IR channels with the OLI.\n\nFIGURE 1.27\n\nThe data collection pattern of the Operational Land Imager (OLI) on Landsat 8.\n\n28 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nTable 1.4 Sequence of Landsat Satellites up to Landsat 8\n\nInstrument Picture Launched Terminated Duration Notes\n\nLandsat 1 July 23,\n1972\n\nJanuary 6,\n1978\n\n2 years,\n11 months and\n15 days\n\nOriginally named\nEarth resources\ntechnology\nsatellite 1\n\nLandsat 2 January\n22, 1975\n\nFebruary\n25, 1982\n\n2 years,\n10 months and\n17 days\n\nNearly identical\ncopy of Landsat 1\n\nLandsat 3 March 5,\n1978\n\nMarch 31,\n1983\n\n5 years and\n26 days\n\nNearly identical\ncopy of Landsat 1\nand Landsat 2\n\nLandsat 4 July 16,\n1982\n\nDecember\n14, 1993\n\n11 years,\n4 months\n28 days\n\nLandsat 5 March 1,\n1984\n\nJune 5, 2013 29 years,\n3 months and\n4 days\n\nNearly identical\ncopy of Landsat\n4. Longest\nEarth-observing\nsatellite mission\nin history\n\nLandsat 6 October 5,\n1993\n\nOctober 5,\n1993\n\n0 days Failed to reach\norbit\n\nLandsat 7 April 15,\n1999\n\nStill active 16 years,\n1 month and\n8 days\n\nOperating with scan\nline\ncorrector disabled\nsince May 2003\n\nLandsat 8 February\n11, 2013\n\nStill active 2 years,\n3 months and\n12 days\n\nOriginally named\nLandsat data\n\nContinuity Mission\nfrom launch until\nMay 30, 2013,\nwhen NASA\noperations were\nturned over\nto USGS\n\n\n\n1.2.4.3 The Defense Meteorological Satellite Program\nSmaller and lighter than the original TIROS, the 100-pound TIROS-derived RCA satellite was shaped\nlike a 10-sided polyhedron, 0.58 m across, and 0.53 m high. A spinning motion, introduced on\ninjection into orbit, was maintained on the early National Reconnaissance Office (NRO) weather\nsatellites at about 12 rpm by small spin rockets. However, the spin axis was maintained\nperpendicular to the orbit plane by torquing the satellite against the Earth\u2019s magnetic field, the\nforces supplied through a direct-current loop around the satellite\u2019s perimeter. A ground command\nwould cause the electric current to flow in the desired direction to generate the torque. Those few\nNASA officials who knew about it viewed the Air Force program as a no-risk test of a modified four-\nstage Scout with an \u201cEarth-referenced\u201d wheel-mode weather satellite. If it operated correctly, the RCA\nshuttered television camera (a photosensitive vidicon tube) would be pointed directly at the Earth once\neach time the satellite rotated. At the programmed interval, when IR horizon sensors indicated the lens\nwas vertical to the Earth, the vidicon would take a picture of an 800-mile-square area of the surface\nbelow, with the image recorded on tape as an analog signal for later transmission to the ground.\nLaunched into a Sun-synchronous 833 km height, circular polar orbit, the RCA television system\nwould provide 100% daily coverage of the northern hemisphere at latitudes above 60 degrees, and 55%\ncoverage at the equator. Readout of the tape-recorded pictures was planned to occur on each pass over\nthe western hemisphere; at the ground stations, the video pictures of cloud cover over the Eurasian\nlandmass would be relayed to the Air Weather Service\u2019s Air Force Global Weather Central collocated\nwith Headquarters Strategic Air Command at Offutt AFB, near Omaha, Nebraska.\n\nThe second DMSP launch on August 23, 1962, resulted in success, although the Lockheed ground-\ncontrol team failed at first to track the weather satellite. Each day at high noon the vehicle took pictures\nas it transited the Soviet Union. Weather pictures of the Caribbean returned by this vehicle 2 months\nlater in October also proved crucial during the \u201cCuban Missile Crisis,\u201d permitting effective aerial\nreconnaissance missions and reducing the number of aerial weather reconnaissance sorties in the region.\n\nThe first DMSP weather satellite to be controlled at the ground stations manned by Air Force\npersonnel was flight number three launched on February 19, 1963. At Vandenberg AFB, another Air\nForce team, the Systems Command 6595th Aerospace Test Wing, conducted launch operations. In this\ninstance, the Scout booster upper stages again malfunctioned and placed the satellite in an orbit ill\nsuited to strategic weather reconnaissance operations for more than a few months at best. In late April,\nthe satellite\u2019s primary tape recorder control circuit failed and with it the storage of primary data for\nlater commanded transmission, although direct vidicon readout continued for a few weeks more. A\nnew experiment, however, continued to function nicely for many months: an IR radiometer that\nregistered the Earth\u2019s background radiation and indicated the extent of nighttime cloud cover. At\nGlobal Weather Central, the 3rd Weather Wing used computer programs written by Air Weather\nService personnel to produce crude operational maps of the cloud cover at night over the regions\nobserved until January 1964. Indeed, the IR experiment proved so successful that it was mounted on all\nDMSP satellites through Block 4, eventually also providing measurements of cloud height and the\nEarth\u2019s heat balance.\n\nStrategic weather reconnaissance might command the primary mission of the DMSP, but American\nmilitary services wanted tactical weather data to meet a variety of operational needs. By 1963 it was\nplain that NASA\u2019s sophisticated, three-axes stabilized, low-altitude Nimbus-NOMSS (National\nOperational Meteorological Satellite System) satellite would be extensively delayed and, when\nfinished, likely too complex and expensive to satisfy Defense Department meteorological\nrequirementsdtactical or strategic.\n\n30 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nHowever, the political and bureaucratic climate in 1963 did not favor an all-military tactical\nweather satellite system. All of the military meteorological satellite requirements would continue to be\nfurnished to NASA and the Department of Commerce. To assess and combine those requirements, in\nearly 1964 the Defense Department established in the Air Staff a Joint Meteorological Satellite\nProgram Office. After further agitation by the military services, however, the Defense Department\napproved a test of the defense meteorological satellite applied to tactical operations in the 1964 Strike\nCommand Goldfire exercise at Fort Leonard Wood in southwest Missouri. Air Force Global Weather\nCentral at Offutt AFB relayed weather reconnaissance pictures directly to the Army and Air Force\nusers supporting ground and paratroop exercises at the fort, and for the deployment of fighter aircraft\non a transatlantic flight. Later in the year, between November 24 and 26, Global Weather Central\nfurnished tactical weather data over Central Africa to the Military Airlift Command, which proved\ncrucial in the successful airlift of Belgian paratroopers from Europe to Stanleyville in the Congo,\nwhere hostages seized in an uprising were freed. The weather data proved to be of considerable value\nin these tactical operations, analysis revealed, but improvements were needed. Coverage had to be\nreceived daily at local ground stations before meteorologists could depend on a satellite as a primary\nsource of data, and a resolution at the surface better than the three nautical miles provided by the\nDMSP Block-I satellites was judged \u201cextremely desirable.\u201d\n\nWhen US air strikes against North Vietnam commenced in February 1965, Det-14 personnel found\nthemselves unable to meet the demand for weather information from the second Air Division and the\nStudies and Observation Group of the Military Assistance Command Vietnam, which conducted\nclandestine operations against North Vietnam. In response, the Air Force, with Defense Department\napproval, launched on March 18, 1965, a noontime military meteorological satellite that could be\nprogrammed to record and readout specific weather data in Southeast Asia to support tactical oper-\nations in the theater. In one of his last official acts in support of that effort, in January, US Army\nColonel Haig planned and laid out the DMSP ground station at Tan Son Nhut Air Base, Saigon, in\nSouth Vietnam. The new station was erected and began operating in time to support the satellite\nlaunched in March. It furnished to military users, within 30 min of receipt, complete cloud cover data\nfor North Vietnam, South Vietnam, and parts of Laos, China, and the Gulf of Tonkin.\n\nThese impressive results were enough to prompt action from Defense Department officials who\nnow sought to break the NASA/Department of Commerce franchise and pursue openly a separate\nmilitary weather satellite program for strategic and tactical applications. The DMSP program office in\nEl Segundo, California would move from the Air Force Special Projects Office, to the Space Systems\nDivision next door, in Air Force Systems Command, with Headquarters USAF and Systems Command\nassuming overall management responsibility for what was termed an \u201congoing development/opera-\ntional program.\u201d The Strategic Air Command would continue to launch the satellites and operate the\nDMSP control center and ground terminals in the continental United States; Air Weather Service\nwould man the direct readout terminals overseas, while continuing to operate Air Force Global\nWeather Central and process DMSP strategic weather data at Offutt AFB. Perhaps anticipating an\nexcess of public affairs enthusiasm on the Air Staff, he regretted to say that security restrictions\nprecluded any public recognition of DMSP accomplishments.\n\nBack in 1964, when tests of the meteorological satellite applied to tactical military operations at\nhome and abroad began, the NRO approved modification of three additional satellites for direct readout.\nThese 160-pound vehicles, identical in size and shape to their 45e54 kg Block 1 predecessors, also\nmounted improved IR radiometers and were known collectively as Block 2. Launched during 1965 and\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 31\n\n\n\n1966, two of them attained Earth orbit and provided tactical meteorological data for operations in\nSoutheast Asia. A fourth satellite, the one equipped and launched expressly for tactical uses on May 20,\n1965, came to be called Block 3. The reason for this curiosity, a \u201cone-vehicle block,\u201d involved efforts to\ndistinguish it from its Block 2 cousins that also supported the primary strategic cloud cover mission.\nShortly before he stepped down as DMSP director and control of the DMSP passed to the Air Force\nSystems Command, in early 1965 Colonel Haig secured permission to begin the design of a more\npowerful military meteorological satellite that met more completely the demands of its customers.\n\nThe Block 4 satellite, slightly larger than those in Blocks 1 and 2, was 76 cm. in diameter, 74 in\nheight, and weighed 79.4 kg (Fig. 1.28). Still spin stabilized, the satellite nonetheless provided\nimproved weather coverage. Previously, the single 0.013 m focal length RCA vidicon television\ncamera in Block 1 and 2 satellites furnished a nadir resolution of 5.5e7.4 km along a 2778 km swath.\nThe resolution varied from 1.5 km at nadir to 5.5 km at the picture\u2019s edge. Besides a multisensor IR\nsubsystem, Block 4 also incorporated a high-resolution radiometer that furnished cloudeheight\nprofiles. A tape recorder of increased capacity stored pictures of the entire northern hemisphere each\nday, while the satellite furnished real-time, direct local tactical weather coverage to small mobile\nground or shipboard terminals.\n\nThe revolutionary Block 5 spacecraft (Fig. 1.29) took the form of an integrated system; it departed\nentirely from the TIROS-derived technology of its predecessors. The Block 5 design was based on the\nusers\u2019 wish to receive a product in a form that approached as closely as possible the weather charts and\nmaps that the meteorologists employed. Moreover, the product furnished the albedo of each scene, not its\nbrightness, which varied enormously from full sunlight to partial moonlight. A survey of the industry and\nnew technologies revealed line scanning sensors and advances in highly sensitive visible light and IR\npoint (as opposed to array) detectors. Instead of using complicated electronics to scan the raster of a TV\n\nFIGURE 1.28\n\nDefense Meteorological Satellite Program Block 4 Satellite.\n\n32 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\ncamera, one now could let the motion of the satellite provide the scanning along the line of flight. That\nwould require a spacecraft that always \u201clooked down,\u201d rather than one that wheeled along its orbit. But a\nsatellite stabilized on three axes would make possible acquiring a strip of imagery of indefinite length,\nimagery that could be rectified at will.\n\nTheWestinghouse \u201cOperational Line Scanner\u201d (OLS), as it came to be called, provided images of the\nEarth and its cloud cover in both thevisual and IR spectral regions.With this system, nadir visualeimaging\nresolution at the Earth\u2019s surface improved to 0.56 km during daytime and 3.7 km at night through quarter-\nmoonlight illumination levels. The higher resolution (less than 0.93 km) now satisfied the requirements of\ntactical users. The IR subsystem furnished 3.7 km resolution at the surface day and night, as well as\ncloudeheight profile and identification of all clouds above or below a selected altitude, and heat-balance\ndata. Complete global coverage was transmitted over encrypted S-Band digital data links. Block 5\nsimultaneously satisfied the meteorological needs of the military commander in the field for tactical\nsupport, while it met completely the \u201cstrategic\u201d requirements of the NRO.\n\nTo achieve the pointing accuracy required for the Block 5 line scan sensor, the spacecraft employed a\nnovel momentum-bias attitude-control system. It consisted of a momentum wheel and horizon scanner,\nand magnetic coils. The wheel and scanner controlled the pitch axis, while the magnetic coils controlled\nthe roll and yaw axes, replacing the momentum dissipated by friction in the bearing between the\nmomentum wheel and the main body of the spacecraft. The slab-sided, tube-shaped Block 5 satellite\nremained 0.76 m in diameter, but its height increased to 1.22 m and its weight rose to 104.3 kg. Three\n\nFIGURE 1.29\n\nDefense Meteorological Satellite Program Block 5A Satellite.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 33\n\n\n\nBlock 5A spacecrafts were built before military demands for greater tactical meteorological support\ndictated further change.\n\nThe DMSP program office, however, had introduced a requirement for an Earth-oriented pointing\naccuracy much greater than the one imposed on its predecessor Block 5C. In the design competition for\nthe new spacecraft conducted between Boeing and RCA, only the latter firm was judged able to meet\ncompletely that requirement. A contract for five Block 5D satellites, signed with RCA in the fall of\n1972, set a required launch date for the first of them in the fall of 1974. But the greater pointing\naccuracy and a complement of additional instruments also had increased the projected cost of these\nspacecraft as compared to their predecessors, and it introduced the risk of delays in development.\n\nWhatever its pointing accuracy, and the numerical sleight-of-hand for \u201cBlock 5D\u201d notwithstanding,\nin November 1972 the Office of Management and Budget (OMB) requested that the Departments of\nCommerce and Defense reexamine a consolidated civil and military polar-orbiting meteorological\nsatellite program, and the possibility of using a single spacecraft to satisfy the demands of both. Either\naction could be expected to result in substantial dollar savings, and a steering group composed of\nrepresentatives from NOAA, DoD, and NASA was formed once again to consider these questions.\nSince the technical capability of the existing Block 5C already exceeded the capability of a planned\nNOAA successor, TIROS-N, the group\u2019s report, issued in mid-1973, concluded that the greatest\nsavings would be realized in a single national meteorological satellite system managed by the Air\nForce, using a standard DMSP Block 5D satellite. This military solution was quickly rejected by Henry\nKissinger, President Nixon\u2019s National Security Advisor, who argued that it would violate the National\nAeronautics and Space Act, which dictated a separation of military and civil spacefaring, and by\nofficials made uneasy in the Department of State, who warned of adverse international repercussions.\nSubsequent interagency deliberations led by Air Force Under Secretary James W. Plummer, the di-\nrector of the NRO, resulted in an agreement in July 1974 to achieve major cost savings by adopting a\nvariant of the DMSP Block 5D military satellite for use in both the civil (replacing TIROS-N) and\nmilitary polar-orbiting, low-altitude, meteorological space programs. The larger, joint-use version\nneeded by the NOAA to support additional sensors, was identified as Block 5D-2. The five original Air\nForce-RCA spacecraft thus became DMSP Block 5D-1.\n\nThe Block 5D-1 design that had emerged back in the early 1970s resembled in appearance\nconventional Earth-oriented satellites of this period (Fig. 1.30). Sized to fit the space taken by the Burner\nIIA solid-propellant upper stage on the Thor, it was 1.5 m in diameter and 6 m long. The 5D satellite\nbuilt by RCA consisted of three sections: a square precision-mounting platform on the forward end\nsupported the sensors and other equipment required for precise alignment; in the center, a five-sided\nequipment-support module contained the bulk of the electronics and featured one or two pinwheel\nlouvers on four sides for thermal control; and, at the aft end, a circular reaction and control-equipment\nsupport structure housed the spent third stage solid-propellant rocket motor and contained reaction-\ncontrol equipment. A deployable, 1.83-by-4.88 m Sun-tracking solar array was also mounted aft, on\nthis section. With its complement of additional sensors, the spacecraft weighed 522 kg, making it more\nthan twice as massive as its Block 5C predecessors. To heft the additional weight into orbit, the program\noffice contracted with Boeing for a new, larger, solid-propellant second stage. The original Burner IIA\nsecond stage, now adapted as a third stage and fixed to the satellite, was used during ascent to inject the\nvehicle into its circular, Sun-synchronous 724 km Earth orbit.\n\nThe electronic components of the follow-on satellites remained essentially the same as those in\n5D-1, but the 5D-2 structure increased in length from 6 to 6.8 m. The extension increased the\n\n34 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\ndownward-facing sensor-mounting area and lengthened the equipment-support module amidships.\nThat module now contained a second 25.5 Ah battery and sported two or three pinwheel temperature\ncontrol louvers on four of its five sides. The solar array mounted on the aft reaction control\nequipment-support structure also increased in size to 3 ? 5 m, furnishing increased electrical power.\nTwo important sensors were added to those in the 5D-1 complement: a topside ionospheric sounder\nprovided detailed global measurements of the electron distribution in the Earth\u2019s ionosphere, and a\nmicrowave imager (flown on the last few 5D-2 satellites) defined the extent of sea ice and sea-state\nconditions (wave height and patterns) on the world\u2019s oceans. Withal, these changes increased the\nweight of the Block 5D-2 spacecraft to 813 kg a sum too great for the Thor/Burner booster\ncombination.\n\nHeated debates took place between officials in the program office and Aerospace Defense Command,\nthe launch agency at that time, about adapting Thrust Augmented Thors to the task, just to keep a \u201cblue\nsuit\u201d launch squadron. Ultimately, however, the launch vehicle selected for the 5D-2 meteorological\nsatellite in 1980dafter 16 months of vacillationdwas the General Dynamics Atlas E, an improved\nversion of the liquid-propellant intercontinental ballistic missile deployed briefly in the early 1960s.\n\nOne unique capability of the OLS was a \u201clow-light\u201d sensing capability. This requirement was to\nmake it possible to view the Earth under moonlight lighting conditions. This capability has been used\nto study the lights of cities and other population centers as well as the progression of wildfires and\nanthropogenic burning of forests. One unique application was the capture of the Aurora Borealis in\nFig. 1.31.\n\nAvariety of secondary sensors, some judged as \u201cnice to have,\u201d appeared in different combinations on\nBlock 5D-1 missions. Five of them frequently appeared on the spacecraft. An atmospheric density sensor\nmeasured the major atmospheric constituents (nitrogen, oxygen, and ozone) in the Earth\u2019s thermosphere\non the daylight portion of each orbit. A precipitating electron spectrometer counted ambient electrons at\nvarious energies. A scanning IR radiometer furnished vertical temperature profiles, vertical water vapor\nprofiles, and the total ozone concentration. A passive microwave-scanning radiometer profiled global\natmospheric temperatures from the Earth\u2019s surface to altitudes above 30 km. Known as the Special\nSensor Microwave/Imager (SSM/I) this instrument has been the source of a lot of science investigations.\n\nFIGURE 1.30\n\nDefense Meteorological Satellite Program Block 5D-1 satellite.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 35\n\n\n\nEarly in its operation the DoD worked out with NOAA an agreement known as \u201cshared processing\u201d\nwhere the SSM/I data were decrypted and made freely available through NASA and NOAA data centers.\nFinally, a gamma-radiation sensor furnished by the Air Force Technical Applications Center detected\nnuclear detonations as part of the ongoing Integrated Operations NUDET Detection System.\n\nDesign studies of a still larger and heavier Block 5D-3 satellite began in the late 1970s, but funds for\nthe military version were not appropriated until mid-1980. The 5D-3 satellites, though initially designed\nto be compatible for launch on NASA\u2019s Space Shuttle and be laser-hardened, ultimately would be\nlaunched on an unmanned expendable rocket. This satellite mounted an improved Westinghouse OLS\nand a larger combination of secondary sensors. The length of the satellite increased from 6.7 to 7.3 m,\nwhile the weight rose to 1033 kg. The RCA spacecraft consisted of the same basic components as its\nimmediate predecessors, but included a larger solar array, three 50-Ah batteries, and a redesigned\nsunshade. The center section now sported four pinwheel temperature control louvers on four of its five\nsides. These and other design improvements combined to give the 5D-3 an anticipated mean mission\nlifetime on orbit of 5 years (60 months).\n\n1.2.4.4 Geostationary Weather Satellites\nIn 1966 the first Advanced Technology Satellite (ATS1) was launched into a geostationary orbit and used\na new instrument the \u201cspin-scan camera\u201d to sense radiative properties of a hemisphere under the satellite.\nAs geostationary orbit dictated an increase in altitude from about 800 to 36,000 km the spin-scan camera\nhad to be considerably more sensitive than the low Earth orbiter instruments. Also, since these early\ngeostationary satellites were all spin stabilized the scanner had only a very limited time to collect the\nradiation from the Earth\u2019s surface.\n\nAn image from the spin-scan camera on ATS1 is presented here in Fig. 1.32, which clearly shows\nthe cloud cover over this hemisphere. While the spin-scan camera was limited to visible imagery later\nversions of this instrument were extended to add IR images to provide night imagery of the Earth\nalthough at a lower spatial resolution than the polar orbiters.\n\nFIGURE 1.31\n\nDefense Meteorological Satellite Program nighttime image of the Aurora Borealis taken by the first Block 5A\n\nsatellite in 1971 (Note the lighted cities from Canada through Central America).\n\n36 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nIn spite of the sampling limitations imposed by the geostationary orbit, it was demonstrated that the\ngeostationary orbits were very useful for measuring the Earth due to the high frequency of temporal\ncoverage. Since the satellite was stationary relative to the Earth a new scan mechanism was developed\nthat stepped a mirror across the hemisphere making it possible to measure the Earth in a very rapid\nfashion. No longer were samples limited by the approximately 90 min repeat orbits of low Earth\norbiting satellites, but scans could be collected every 30 min or hourly. This made it possible to\nexamine a host of new atmospheric processes and geostationary satellites soon became the standard\nmeasurement method for meteorological studies and weather forecasting. All of the sides of this\nspinning satellite were covered with solar panels that would get equal amounts of solar illumination.\n\nA typical spinning geostationary satellite is shown here in Fig. 1.33.\nThe first operational geostationary weather satellites were known as the Stationary Meteorological\n\nSatellites, which then evolved into the Geostationary Observing Environmental Satellites (GOES).\nThe imager progressed from the limited channel spin-scan camera to a visible IR spin-scan radiometer,\nwhich collected hemispherical images in a variety of spectral bands. The final configuration of the\nGOES spinner satellites is shown here in Fig. 1.34, which differs from the earlier satellite in that the\nlower portion of the spacecraft was \u201cdespun\u201d making communications with the ground a lot easier and\nallowing directive antennas and higher rates of data delivery to the ground.\n\nA desire to improve the sensing capabilities of the geostationary satellites led to the development of\na three-axes stabilized satellite that could \u201cstare\u201d at the Earth\u2019s surface collecting more radiation than\nwould be possible during the limited time imposed by a spinning geostationary satellite. A despun\nsatellite, however, introduced new problems. The thermal equilibrium provided by the spinning\nsatellite was no longer available and the satellite had to be designed to withstand the thermal gradients\nimposed by a satellite being heated by the Sun on one side and cooled on the opposite side. This led to\nthe satellite configuration seen here in Fig. 1.35, which is an artist\u2019s conception of GOES-8 the first of\nthe operational US three-axes stabilized geostationary satellites.\n\nFIGURE 1.32\n\nVisible image from the spin-scan camera on ATS1.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 37\n\n\n\nFIGURE 1.33\n\nEarly Geostationary Observing Environmental Satellites spinner geostationary weather satellite.\n\nFIGURE 1.34\n\nGOES satellite showing the despun communications antennas at the bottom.\n\n38 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nNow the solar panels are now only on the sunlit side of the satellite while on the other side there is a\n\u201csolar sail\u201d to help with the stability of the platform. The new GOES imager was able to take advantage\nof the \u201cstarting\u201d capability of this satellite and provided much improved radiative fidelity and\naccuracy.\n\nAs part of the weather forecast system the GOES satellites were used to collect the radiation from\nthe Earth\u2019s surface and process it on the ground. The early spinner satellites relayed analog only data\nwhile the three-axes stabilized satellites provided digital data streams. The earlier data were digitized\non the ground and an analyzed weather facsimile product was generated. This product was then\nuplinked to the same GOES satellite and broadcast as a low-resolution image to be used for forecast\nactivities by remote forecasting locations. Known as WEFAX this product has continued to be\navailable from geostationary satellites.\n\nIt is important to realize that the geostationary satellites were and are used to collect both imagery\nand data transmitted from platforms on the surface. In this way they acted as standard communications\nsatellites providing the relay of data from the surface. They could handle a much larger data stream\nthan the polar low Earth orbiters making it possible to collect both data and more recently accurate\ngeolocation information from GPS receivers.\n\nToday geostationary satellites are the primary observing platforms for all weather forecasting\noperations. In the United States, one GOES satellite orbits at 135?Woff the United States. West coast to\nmonitor storms and weather fronts approaching from their traditional position west of the United States,\nand the other satellite is located at 75?Woff the eastern coast of the United States to monitor hurricane\nformation and their progression toward the US mainland. The European EUMETSAT organization\noperates METEOSAT at 0? as their primary weather satellite, while Japan operates the Geostationary\n\nFIGURE 1.35\n\nArtist\u2019s impression of the GOES-8 satellite superimposed on a GOES west image.\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 39\n\n\n\nMeteorological Satellite at 145?E for severe weather in the Asian region. India operates INSAT at 83?E\nin the Indian Ocean, but the data are restricted to Indian weather operations. Japanese and European\nsatellites are still spin stabilized, while the Indian and American satellites are three-axes stabilized. The\nEuropean Space Agency claims that the spin stabilization provides (1) better geometric correction\nquality, (2) better spectral and geometric resolution, (3) better inversion availability, (4) moderate\ninversion availability, and (5) the same NEDT as that of a slight larger aperture.\n\n1.2.4.4.1 GOES-R\nThe next generation of geostationary satellites is already built and the first launch was November 19,\n2016. GOES-R is a collaborative mission between NOAA and NASA and the satellite was built by\nLockheed-Martin Corp. in Denver, CO. GOES-R will provide continuous imagery and atmospheric\nmeasurements of the Earth\u2019s western hemisphere and space weather measurements. It will carry six\ndifferent instruments to measure both land and space parameters. The primary instrument is the\nAdvanced Baseline Imager (ABI), which replaces the GOES imager and will image Earth\u2019s weather\noceans and atmospheric environment (Fig. 1.36). ABI will view the Earth with 16 spectral bands\n(compared to the five on the GOES), including two visible channels, four near-IR channels, and 10 mid\nto thermal IR channels. It will deliver three times more spectral information, four times the spatial\nresolution and more than five times faster temporal coverage than the present system. ABI will deliver\nmore than 65% of all the GOES-R mission data products.\n\nABI is designed to be used for a wide variety of applications that will utilize the 16 spectral bands\nand its higher spaceetime resolution. The instrument operates in two scan modes: one where it\ncontinuously takes an image of the entire full disk of the planet every 5 min, and a second one called\nthe flex mode where it takes a full disk image every 15 min, an image of the continental United States\nevery 5 min and smaller, more detailed images of areas where storm activity is present as often as\nevery 30 s. This latter sampling is designed to see the formation of tornadoes as their cloud tops rise\nabove the line of thunderstorm clouds.\n\nFIGURE 1.36\n\nThe Advanced Baseline Imager.\n\n40 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nThe ABI provides a dramatic improvement over present GOES imagery with an increase from 5 to\n16 bands, visible spatial resolution going from 1 to 0.5 km and the thermal IR bands improving their\nspatial resolution from 4 to 2 km. All of these channels will have on-orbit calibration capabilities\nunlike the present GOES imager. These capabilities will be valuable in a number of nonweather\napplications as well. The rapid temporal sampling will be useful in mapping forest fires, volcanoes,\nfloods, hurricanes, and storms that spawn tornadoes. It is estimated that benefits from the ABI may be\nas much as $4.6 billion over the lifetime of the series due to improved tropical cyclone forecasts, fewer\nweather related flight delays, airline incidences with volcanic plumes, improved production and dis-\ntribution of electricity and natural gas, increased efficiency in irrigation, and higher protection rates for\nrecreational boaters in the event of storms or hurricanes.\n\nAnother Earth-sensing instrument is the Geostationary Lightning Mapper (GLM), which is a\nsingle-channel, near-IR optical transient detector that can detect the rapid changes in an optical scene\nindicating the presence of lightning (Fig. 1.37). GLM measures total lightning activity continuously\nover the Americas and adjacent ocean regions with a near uniform spatial resolution of 10 km. GLM\nwill provide early predictions of intensifying storms and severe weather events. GLM is unique in the\ncollection of lightning measurement systems in that ground systems only provide cloud-to-ground\nlightning coverage, GLM includes both cloud-to-ground and cloud-to-cloud coverage of lightning\nevents. In addition, ground-based systems are limited to land while GLMwill operate over the ocean as\nwell.\n\nAnother GOES-R instrument known as the extreme ultraviolet and X-ray Irradiance Sensors\n(EXIS) are designed to monitor solar irradiance in the upper atmosphere as the power and effect of the\nSun\u2019s electromagnetic radiation per unit area of the atmosphere. EXIS will be able to detect solar flares\nthat could disrupt communications and reduce satellite-based navigation accuracy by affecting\nsatellites, high altitude aircrafts, and power grids on the Earth. EXIS is made up of two main sensors:\nthe extreme ultraviolet sensor and the X-ray sensor. EXIS will be mounted on the Sun pointing\n\nFIGURE 1.37\n\nThe Geostationary Lightning Mapper (http://www.goes-r.gov/spacesegment/glm-lightning-detect.html).\n\n1.2 THE HISTORY OF SATELLITE REMOTE SENSING 41\n\nhttp://www.goes-r.gov/spacesegment/glm-lightning-detect.html\n\n\nplatform which is on the yoke of the solar array. NOAA\u2019s Space Weather Prediction Center in Boulder,\nColorado, will rely on products from EXIS to improve their warning of radio blackouts to improve\ncommunications and navigation systems.\n\nThe other three instruments on GOES-R are designed to measure the space rather than the Earth\u2019s\nenvironment. The magnetometer provides measurements of the space environment magnetic field that\ncontrols charged particle dynamics in the outer region of the magnetosphere. The geomagnetic field\nmeasurements provide important alerts and warnings to satellite operators and power utilities. The Solar\nUltraviolet Imager (SUVI) is a telescope that monitors the Sun in the extreme ultraviolet portion of the\nelectromagnetic spectrum. SUVI will provide full disk solar images around the clock. It replaces the\ncurrent GOES Solar X-ray Imager (SXI) instrument and represents a change in both spectral coverage\nand spatial resolution over the SXI. Finally, the Space Environment In Situ Suite (SEISS) is comprised of\nfour sensors that will monitor proton, electron, and heavy ion fluxes at geostationary orbit (35,786 km\naltitude). These four instruments are the Energetic Heavy Ion Sensor (EHIS), the Magnetospheric\nParticle Sensors-High and Low, and the Solar and Galactic Proton Sensor. The instrument suite also\nincludes the data processing unit. Data from SEISS will drive the solar radiation storm portion of the\nNOAA\u2019s space weather forecast system.\n\n1.3 STUDY QUESTIONS\n\n1. What were the fundamental observational methods that needed to be developed before satellite\nremote sensing could become a reality?\n\n2. Why were the first polar-orbiting weather satellites only able to view a small portion of the\nEarth\u2019s surface?\n\n3. What change in the stabilization of the polar-orbiting weather satellites needed to be made to\nmake it possible to observe the entire Earth?\n\n4. What NASA satellite program was used to test new instruments designed for atmospheric, land,\nand ocean studies.\n\n5. What satellite control system was needed to make it possible to continuously view the Earth\u2019s\nsurface?\n\n6. What is the difference between an early television image of the Earth and the image collected by\na radiometer?\n\n7. What is the difference between a radiometer and a spectrometer?\n8. How do orbiting (polar and geostationary) satellites profile the atmospheric temperature and\n\nmoisture?\n9. How did the Landsat program begin?\n\n10. What is the succession of instruments used in the Landsat program?\n\n42 CHAPTER 1 THE HISTORY OF SATELLITE REMOTE SENSING\n\n\n\nBASIC ELECTROMAGNETIC\nCONCEPTS AND APPLICATIONS\nTO OPTICAL SENSORS\n\n2\n2.1 MAXWELL\u2019S EQUATIONS\nJames Clerk Maxwell was the first one to formally postulate the existence of electromagnetic (EM)\nwaves. Maxwell combined ideas from other earlier researchers to formulate a set of partial differential\nequations that describe the properties of the electric and magnetic fields, and relate them to their\nsources. Maxwell derived a waveform of the electric and magnetic equations, revealing the wavelike\nnature of the electric and magnetic fields and demonstrating their symmetry. Since the speed of the EM\nwaves predicted by the wave theory coincided with the measured speed of light, Maxwell concluded\nthat light itself is an EM wave. The electric and magnetic waves are linked together, but one does not\ncause the other. They are linked together in the same way that time and space changes are linked in the\ntheory of special relativity. Together, these fields form a propagating EM wave, which moves out into\nspace. Individually the equations are known as Gauss\u2019s law, Gauss\u2019s law for magnetism, Faraday\u2019s law\nof induction, and Ampe?re\u2019s law with Maxwell\u2019s correction.\n\nThese equations together with the Lorentz force law constitute the complete set of classical\nelectromagnetism. The Lorentz force law was actually derived by Maxwell under the name of\n\u201cequation for electromotive force\u201d and was one of an earlier set of eight Maxwell\u2019s equations.\n\nIn symbols these equations are given in Table 2.1.\nIn 1864 Maxwell derived the EM wave equation by linking the displacement current to the time-\n\nvarying electric field associated with EM induction thus linking some earlier ideas. He commented\nthat, \u201clight and magnetism are affections of the same substance, and that light is an electromagnetic\ndisturbance propagated through the field according to electromagnetic laws.\u201d Today this theory has\nbeen adapted to light propagation in a vacuum where one can have stable, self-perpetuating waves of\noscillating electric and magnetic fields driving each other. The speed calculated for EM radiation\nexactly matches the speed of light since light is indeed one form of EM radiation bringing together the\ntwo fields of electromagnetism and optics.\n\n2.2 THE BASICS OF ELECTROMAGNETIC RADIATION\nEM radiation is a form of energy with the properties of a wave. The waves propagate through time and\nspace in a manner rather like water waves, but (except for polarized light) oscillate in all directions\nperpendicular to their direction of travel (the wave front of a transverse wave).\n\nSuch a wave is characterized by two principal measures: wavelength and frequency (or period).\nThe wavelength (l) is the distance between two successive crests of the waves. The frequency (n or f )\n\nCHAPTER\n\nIntroduction to Satellite Remote Sensing. http://dx.doi.org/10.1016/B978-0-12-809254-5.00002-6\n\nCopyright \u00a9 2017 Elsevier Inc. All rights reserved.\n43\n\nhttp://dx.doi.org/10.1016/B978-0-12-809254-5.00002-6\n\n\nis the number of oscillations (cycles) completed per 1 s period. The period (T) of the wave is T \u00bc 1/f\nwith the frequency f in cycles/s.\n\nIn a vacuum, EM waves travel at a constant speed c, the speed of light (c \u00bc 299,792,458 m/s),\nwhich is the product of frequency and wavelength:\n\nl$nz 300:000 km=s; (2.5)\n\nso the frequency and wavelength are inversely proportional to each other for an EM wave. These\nrelationships are displayed here in Fig. 2.1.\n\nNote in Fig. 2.1 that the electric and magnetic fields are in phase, and perpendicular to each other in\norientation. Both are transverse waves with the same wave frequency and wavelength.\n\n2.3 THE REMOTE SENSING PROCESS\nThe underlying basis for most remote sensing methods and systems is simply that of measuring the\nvarying energy and/or frequency levels of a single entity, the fundamental unit in the EM force field\nknown as the photon. As will be shown later, variations in photon energies are tied to the parameter\nwavelength or its inverse, frequency. Radiation from specific parts of the EM spectrum contains\nphotons of different wavelengths whose energy levels fall within a discrete range of values. When\nany target material is excited by internal processes or by interaction with incoming EM radiation,\nit will emit photons of varying wavelengths whose radiometric quantities differ at different\nwavelengths in a way that can be used to diagnose the material. Photons may also be introduced by\nreflection and absorption. Photon energy received at detectors is commonly stated in power units\nsuch as Watts per square meter per wavelength unit (W/m2 mm). The plot of variation of power with\nwavelength gives rise to a specific pattern or curve that is the spectral signature for the substance or\nfeature being sensed.\n\nTable 2.1 Summary of Maxwell\u2019s Equations in Differential and Integral Forms\n\nName Differential Form Integral Form\n\nGauss\u2019s law V$E\n!\u00bc r\n\n?0\n(2.1a) %vv E\n\n!\n$dA\n!\u00bc Q\u00f0V\u00de\n\n?0\n(2.1b)\n\nGauss\u2019s law for\nmagnetism\n\nV$B\n!\u00bc 0 (2.2a) %vV B\n\n!\n$dA\n!\u00bc 0 (2.2b)\n\nMaxwelleFaraday\nequation (Faraday\u2019s law\nof induction)\n\nV? E!\u00bc ?vB\n!\nvt (2.3a)\n\nH\nvS E\n!\n$d l\n!\u00bc ?vQB;S\n\nvt (2.3b)\n\nAmpe?re\u2019s circuital law\n(with Maxwell\u2019s\ncorrection)\n\nV? B!\u00bc\n \n\nJ\n!\u00fe vE\n\n!\nvt\n\n!\n(2.4a)\n\nH\nvS B\n!\n$d l\n\n. \u00bc m0Is\u00fe m0?0vFE;Svt (2.4b)\n\nwhereE\n!\n\nis the electric field vector, B\n!\n\nis the magnetic field vector, V$ is the divergence operator, Vx is the curl operator, v/vt is the\npartial derivative with respect to time, dA\n\n!\nis the differential vector element of a surface A\n\n!\nwith an infinitesimally small magnitude\n\nand direction normal to the surface S, d l\n!\n\nis the differential vector element of path length tangential to the path, ?0 is the dielectric\npermittivity of free space (8.854 ? 10?12 F/m), m0 is the magnetic permeability of free space ( 4p ? 10?6 H/m), r is the total\ncharge density, and J\n\n!\nis the total current density. Q(V) is the total charge contained in the volume vV, and Is,FB,S, andFE,S are the\n\nflux of the volumetric current density (J), magnetic field (B), and electric field (E) passing through a closed surface vS.\n\n44 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nThe photon is the physical form of a quantum, the basic particle of QuantumMechanics, the part of\nPhysics dealing with the very small, at atomic and subatomic levels. It is also described as the\nmessenger particle for EM force or as the smallest bundle of light. This subatomic massless particle\ncontains radiation reflected, absorbed or emitted either by matter when it is excited thermally, or by\nnuclear processes (fusion, fission), or by bombardment with other radiation. Photons move at the speed\nof light as waves and hence, have a \u201cdual\u201d nature. These waves follow a pattern that we described in\nterms of a sine (trigonometric) function, as shown in two dimensions in Fig. 2.1.\n\nA photon is said to be quantized, in that any given one possesses a certain quantity of energy. Some\nother photons can have a different energy value. Photons as quanta thus show a wide range of\ndiscrete energies. The amount of energy characterizing a photon is determined using Planck\u2019s general\nequation:\n\nE \u00bc h$n; (2.6)\nwhere h is the Planck\u2019s constant (h \u00bc 6.62607 ? 10?34 J$s) and v represents frequency. Photons\ntraveling at higher frequencies are therefore more energetic. If an electron experiences a change in\nenergy level from a higher-level E2 to a lower-level E1, a photon is emitted at a frequency given by:\n\nDE \u00bc E2 ? E1 \u00bc h$n; (2.7)\n\nMagnetic field\n\nElectric field\n\nElectromagnetic Waves\n\n(?)\nWavelength\n\nDistance between\nsuccessive crests\n\nDirection of\npropagation\n\nFrequency (?) :\nCycles per secondCycle\n\n?\n?\n\n?\n\n?\n\n? t 2?\n?\n\nyy\nA\n\nP\n\nO'\n\n? ? ? =  c\n\nmetres\ncycles\n\u2014\u2014\u2014\n\ncycles\nseconds\n\u2014\u2014\u2014\u2014 metres\n\nseconds\n\u2014\u2014\u2014\u2014? =\n\nE. L.\n\nE. L.\n\n? ?\n\nFIGURE 2.1\n\nElectromagnetic wave showing both the magnetic and electric fields along with definitions of frequency and\n\nwavelength.\n\n2.3 THE REMOTE SENSING PROCESS 45\n\n\n\nAlternatively, the passage of an electron from E1 to E2 requires the absorption of a photon where v\nhas some discrete value determined by n2 ? n1 \u00bc (E2 ? E1)/h. In other words, a particular energy\nchange is characterized by emitting radiation (photons) at a specific frequency v and a corresponding\nwavelength at a value dependent on the magnitude of the change of energy.\n\nThe distribution of all photon energies over the range of observed frequencies is embodied in the\nterm spectrum (a concept developed later). A photon with some specific energy level occupies a\nposition somewhere within this range, i.e., lies at some specific point in the spectrum.\n\nThe remote sensing of color is a particular example of the remote sensing process since these wave-\nlengths are restricted to the small portion of the EMspectrum that contains the visible bands (Fig. 2.2). All\nof this radiation is reflected radiation excited by incoming solar radiation as indicated in Fig. 2.3.\n\n2.4 THE CHARACTER OF ELECTROMAGNETIC WAVES\n2.4.1 DEFINITION OF RADIOMETRIC TERMS\nRadiant energy (Q), transferred as photons, is said to emanate in short bursts (wave trains) from a\nsource in an excited state. This stream of photons moves along lines of flow (also called rays) as a flux\n(f), which is defined as the temporal rate at which the energy Q passes a spatial reference (dQ/dt). The\nflux concept is related to that of power, defined as the temporal rate of doing work or spending energy.\nThe nature of the work that can be done is a combination of these: changes in motion of particles acted\nupon by force fields; heating; physical or chemical change of state. Depending on circumstances, the\nenergy spreading from a point source may be limited to a specific direction (a beam) or can disperse in\ndifferent directions.\n\nRadiant flux density is the power per unit surface (W/m2). The flux density is proportional to the\nsquares of the amplitudes of the component waves. Flux density as applied to radiation coming from an\nexternal source to the surface of a body is referred to as irradiance (E); if the flux comes out of that\n\nFIGURE 2.2\n\nHeuristic diagram of visible wavelengths showing the breakdown of colors.\n\n46 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nbody; its nomenclature is exitance (M) (see below for a further description). Mathematically the\nirradiance can be written as\n\nE\u00f0x; y\u00de \u00bc dF\ndA\n\n?\nW=m2\n\n?\n; (2.8)\n\nand depicted in Fig. 2.4.\nThe radiant exitance is the flux per unit area radiated, transmitted, or reflected by a surface and it\n\ncan be written mathematically as\n\nM\u00f0x; y\u00de \u00bc dF\ndA\n\n?\nW=m2\n\n?\n; (2.9)\n\nand displayed in Fig. 2.5.\n\nFIGURE 2.4\n\nDefinition of irradiance (Schott, 2007).\n\nReflection of colours\n\nVisible\nspectrum\n\nWhite light\nSun\n\nReflected\npart\n\nEye\n\nE. L.\n\nFIGURE 2.3\n\nIllustration of the reflection of colors by an Earth target.\n\n2.4 THE CHARACTER OF ELECTROMAGNETIC WAVES 47\n\n\n\nThe notion of radiant intensity is given by the radiant flux per unit of solid angle (Fig. 2.6) in\nsteradians (sr). Hence the radiant intensity is the power per unit solid angle and is given in (W/sr) and\nindicated by the symbol I. Thus, for a surface at a distance R from a point source, the radiant intensity I\nis the flux F [W/m2] flowing through a cone of solid angle U on to the area A at a distance\n\nR, is given by I \u00bc F/(A/R2). Note that the radiation is moving in some direction or pathway relative to\na reference line as defined by the angle q.\n\nThe radiant intensity can be written as\n\nI\u00f0q;4\u00de \u00bc dF\ndA\n\n?\nW=m2\n\n?\n; (2.10)\n\nand shown graphically in Fig. 2.6.\n\nFlux, ?\n\nArea, A\n\nSource Intensity, I\n\nI = ?/(A/R2)\n\nReference\nLine\n\nRa\nng\n\ne, \nR\n\n?\n\nFIGURE 2.6\n\nThe definition of a solid angle for incoming radiation.\n\nFIGURE 2.5\n\nDefinition of radiant exitance (Schott, 2007).\n\n48 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nFrom this, a fundamental EM radiation entity known as radiance (commonly noted as \u201cL\u201d) can be\nderived. Radiance is defined as the radiant flux per unit solid angle leaving an extended source (of\narea A) in a given direction per unit projected surface area in that direction [W/(m2 sr)].\n\nL\u00f0x; y; q;4\u00de \u00bc d\n2F\n\ndA $ dU $ cosq\n\u00bc dE\n\ndU $ cosq\n\u00bc dM\n\ndU $ cosq\n\n?\nW\n??\n\nm2 sr\n??\n. (2.11)\n\nRadiance is closely related to the concept of brightness as associated with luminous bodies. The\nmagnitudes actually measured by remote sensing detectors are the radiances at different wavelengths\nleaving extended areas (which can \u201cshrink\u201d to point sources under certain conditions). Radiant fluxes\nthat come out of sources (internal origin) are referred to as radiant exitance (M) or sometimes as\n\u201cemittance\u201d (now obsolete). Radiant fluxes that reach or \u201cshine upon\u201d any surface (external origin) are\ncalled irradiance. Thus, the Sun, a source, irradiates the Earth\u2019s atmosphere and surface.\n\nThe above radiometric quantities Q, F, I, E, L, andM apply to the entire EM spectrum. Most wave\ntrains are polychromatic, meaning that they consist of numerous sinusoidal wave components of\ndifferent frequencies. The bundle of varying frequencies (either continuous within the spectral range\ninvolved or a mix of discrete, but discontinuous monochromatic frequencies or wavelengths) con-\nstitutes a complex or composite wave. Any complex wave can be broken into its components by\nFourier analysis, which extracts a series of simple harmonic sinusoidal waves each with a charac-\nteristic frequency, amplitude, and phase.\n\nEM radiation can be incoherent or coherent. Waves whose amplitudes are irregular or randomly\nrelated are said to be incoherent; polychromatic light fits this state. If two waves of different wave-\nlengths can be combined so as to develop a regular, systematic relationship between their amplitudes,\nthey are said to be coherent; monochromatic light generated by lasers meets this condition. The\nabove, rather abstract, set of ideas and terminology are important to the theorist. This synopsis is\nincluded mainly to familiarize the reader with these radiometric quantities in the event they are\nencountered in other reading.\n\nS3\n\nS2\n\nS1\n\n2?\n\n2\n\nIp\n\n?\n\nFIGURE 2.7\n\nThe Poincare? sphere is the parameterization of the last three Stokes\u2019 parameters in spherical coordinates.\n\n2.4 THE CHARACTER OF ELECTROMAGNETIC WAVES 49\n\n\n\nIf Eq. (2.4) is dot multiplied by E\n!\n\nand Eq. (2.3) by B\n!\n, and subtracted, the following equation can\n\nbe obtained:\n\nE\n!\n$B\n!? B!$E!\u00bc s??E!??2 \u00fe ?0 vE!2\n\nvt\n? m0\n\nvB\n!2\nvt\n\n\u00bc s??E!??2 \u00fe v\nvt\n\n?\n?0 E\n!2 \u00fe m0 B!2\n\n\t\n; (2.12)\n\nthat can be reduced using vector calculus and the divergence theorem to\n\n? v\nvt\n\nZ\nV\n\n?\n?0 E\n!2 \u00fe m0 B!2\n\n\t\ndV \u00bc\n\nZ\nS\n\n?\nE\n!? B!?d S!\u00fe Z\n\nV\n\nj\n!\n$E\n!\ndV ; (2.13)\n\nThis equation shows that the rate of decrease of energy in a volume equals the rate of energy\ncrossing the surface of that volume plus the energy dissipated in the volume (which is a measure of\nwork done by the field).\n\nThe Poynting vector P\n!\n\ncan be written as\n\nP\n\n!\n\n\u00bc E!? B!. (2.14)\nFrom Eq. (2.13), it can be seen that the integral of the Poynting vector over a closed surface has a\n\nphysical significance. For a rapidly alternating field the Poynting vector does represent the flow across\nan isolated area.\n\nOne important consequence of Eq. (2.13) follows from the fact that the Poynting vector is parallel\nto E\n\n!? B!; thus, the EM wave travels perpendicularly to the magnetic and electric field oscillations.\nWhile E\n\n!\nand B\n\n!\nare sinusoidal changing direction over time the Poynting vector is unidirectional, but\n\nvaries from a maximum when E\n!\n\nand B\n!\n\nare at a maximum, to a value of zero when E\n!\n\norB\n!\n\nare zero.\n\n2.4.2 POLARIZATION AND THE STOKES VECTOR\nPolarization describes the orientation of the oscillations in an EM wave. For typical transverse EM\nwaves the polarization is the orientation of the oscillations perpendicular to the direction of wave\ntravel. Most typical are linear polarizations where the oscillations are oriented in a single direction\n(either vertical or horizontal). Oscillations may also rotate as the wave travels (circular or elliptical\npolarizations1). These rotational polarizations can rotate either to the right (right-hand criterium) or\nleft (left-hand criterium).2\n\nThe polarization of an EM wave is described by specifying the direction of the wave\u2019s electric\nfield. According to Maxwell\u2019s equations, the direction of the magnetic field is uniquely determined\nfor a specific electric field distribution and polarization. The Stokes parameters are a set of\nvalues that describe the polarization of EM radiation. George Gabriel Stokes first defined them in\n1852 as a simpler approach to the description of incoherent or partially polarized radiation in terms\n\n1Circular/elliptical polarization refers to the fact that the amplitude is constant or not as the wave propagates.\n2Right/left-hand criteria refer to the sense of rotation as given by the fingers of the right/left hand, when the thumb points in\nthe direction of propagation of the wave.\n\n50 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nof its total intensity (I), (fractional) degree of polarization (p), and the shape parameters of the\npolarization ellipse.\n\nThe relationship of the Stokes parameters to intensity and polarization ellipse parameters is shown\nin the equations below and Fig. 2.7.\n\nS0 \u00bc I; (2.15a)\nS1 \u00bc I $ p $ cos\u00f02j\u00de $ cos\u00f02c\u00de; (2.15b)\nS2 \u00bc I $ p $ sin\u00f02j\u00de $ cos\u00f02c\u00de; (2.15c)\nS3 \u00bc I $ p $ sin\u00f02c\u00de; (2.15d)\n\nHere I$p, 2j and 2c are the spherical coordinates of the polarization state in the three-dimensional\nspace of the last three Stokes parameters. The factor of two before j represents the fact that any\npolarization ellipse is indistinguishable from one rotated by 180 degree, while the factor of two before\nc indicates that an ellipse is indistinguishable from one with the semiaxes lengths swapped accom-\npanied by a 90 degree rotation. Alternatively, the following relationships can be derived from\nEq. (2.15):\n\nI \u00bc S0; (2.16a)\n\np \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nS21 \u00fe S22 \u00fe S23\n\nq\nS0\n\n; (2.16b)\n\n2j \u00bc atan\n?\nS3\nS1\n\n\n; (2.16c)\n\n2c \u00bc atan\n\n0\nB@ S3ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\nS21 \u00fe S22\nq\n\n1\nCA; (2.16d)\n\nand are often combined into a vector, known as the Stokes vector:\n\nS\n!\u00bc\n\n2\n66664\nS0\n\nS1\n\nS2\n\nS3\n\n3\n77775 \u00bc\n\n2\n66664\n\nI\n\nQ\n\nU\n\nV\n\n3\n77775. (2.17)\n\nThe Stokes vector operates on intensities and spans the space of unpolarized, partially polarized,\nand fully polarized light. For comparison, consider the Jones vector (Yeh and Gu, 1999) that represents\nthe relative amplitude and phase of the electric field in the x and y directions. It spans the space of fully\npolarized light, but is more useful for problems involving coherent light such as interference or\ndiffraction. The four Stokes parameters do not form a preferred basis of the space, but rather were\nchosen because they can be easily measured or calculated.\n\n2.4 THE CHARACTER OF ELECTROMAGNETIC WAVES 51\n\n\n\nThe effect of an optical system on the polarization of light can be determined by constructing the\nStokes vector for the input light and applying Mueller calculus, to obtain the Stokes vector of the light\nleaving the system.\n\nS\n!\n\n0 \u00bc M $ S!i. (2.18)\nSimilarly, when the light passes through a series of optical systems characterized by the Mueller\n\nmatrices M1;M2;M3, the Stokes vector of the light at the system output is given by:\n\nS\n!\n\n0 \u00bc M3 $ M2 $ M1 $ S!2. (2.19)\nAny Mueller matrix M can be derived from the so-called Jones matrix J by the following\n\nrelationship:\n\nM \u00bc A $ ?J5J?? $ A?1; (2.20)\nwhere * is the complex conjugate, 5 is the Kronecker product, and\n\nA \u00bc\n\n2\n66664\n1 0\n\n1 0\n\n0 1\n\n0 ?1\n0 1\n\n0 1\n\n1 0\n\n?1 0\n\n3\n77775. (2.21)\n\nBelow are shown some Stokes vectors for common states of polarization of light. Superscript \u201cT\u201d\nstands for transposed.\n\n2.4.3 REFLECTION AND REFRACTION AT THE INTERFACE OF TWO FLAT MEDIA\nWhenever an EM wave passes from one medium to another one and the interface is flat there is both\nreflection and refraction as illustrated in Fig. 2.8.\n\n2.4.4 BREWSTER\u2019S ANGLE\nBrewster\u2019s angle is also known as the polarization angle, and it is the angle of incidence at which an\nunpolarized EM wave (containing equal amounts of vertical and horizontal polarization, Fig. 2.9)\nseparates into a vertically polarized EM wave that is transmitted through a surface, leaving the surface\n\nPolarization State Stokes Vector Jones Vector\n\nLinearly polarized (horizontal) \u00bd 1 1 0 0 ?T \u00bd 1 0 ?T\nLinearly polarized (vertical) \u00bd 1 ?1 0 0 ?T \u00bd 0 1 ?T\nRight-hand circularly polarized \u00bd 1 0 0 ?1 ?T 1ffiffi\n\n2\np \u00bd 1 ?j ?T\n\nLeft-hand circularly polarized \u00bd 1 0 0 1 ?T 1ffiffi\n2\n\np \u00bd 1 j ?T\nUnpolarized \u00bd 1 0 0 0 ?T NA\n\n52 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nreflection with only the horizontal components of the incoming radiation. For an incoming vertically\npolarized EM wave there is no reflection. This angle is named after a Scottish physicist Sir David\nBrewster (1781e1868). At this angle the light with this particular polarization cannot be reflected as\nshown here in Fig. 2.9.\n\nThe condition for the Brewster\u2019s angle can be derived by forcing the reflection to be zero, which in\nterms of Snell\u2019s law can be written as\n\nn1$sin\u00f0qi\u00de \u00bc n2$sin\u00f0qt\u00de; (2.22)\nwith qi \u00bc qB and qi \u00fe qt \u00bc 90?.\n\nn1$sin\u00f0qB\u00de \u00bc n2$sin\u00f090? ? qB\u00de \u00bc n2$cos\u00f0qB\u00de. (2.23)\nFrom this, the following expression can be derived:\n\nqB \u00bc arctan\n?\nn2\nn1\n\n\n. (2.24)\n\nThus, a dielectric (or a stack of dielectrics) placed at the Brewster\u2019s angle can be used as a\npolarizer.\n\n? i ? r\n\n? t\n\n? t\n\n? r? i =\n\nair\n\nglass\n\nn = 1.00\n\nn = 1.52\n\nsin\n\n? isin\n\u2014\u2014\n\nnair\nnglass\n\u2014\u2014=\n\nreflected\n\nwave\n\nincident\n\nwave\n\nrefracted\n\nwave\n\nFIGURE 2.8\n\nReflection and refraction at a simple air/glass interface.\n\nAdapted from http://www.mellesgriot.com/products/optics/oc_2_1.htm.\n\n2.4 THE CHARACTER OF ELECTROMAGNETIC WAVES 53\n\nhttp://www.mellesgriot.com/products/optics/oc_2_1.htm\n\n\nFor glass (n2 \u00bc 1.5) in air (n1 \u00bc 1), Brewster\u2019s angle for visible light is approximately 50 degree\nto the normal while for an airewater interface (n2 \u00bc 1.33), it is approximately 53 degree.3 Since\nrefractive index for a given medium changes depending on the EM wavelength, as the Brewster\u2019s\nangle also varies with wavelength. If one desires to view the thermal emission from the sea surface\nthe Brewster\u2019s angle is an optimal viewing angle for this application since a minimum of\nthe longwave solar radiation will be reflected back into the viewing thermal infrared (TIR)\nradiometer.\n\n2.4.5 CRITICAL ANGLE\nIf instead of going from a less dense to a more dense medium, our light ray travels from a medium\nwith a greater density to one with lesser density, then the ray is bent away from the normal\n(Fig. 2.10).\n\nFor an EMwave at the critical incidence angle qc, the exit angle approaches 90 degree. This critical\nangle can be computed using Snell\u2019s law by setting the refraction exit angle to 90 degree and solving\nfor qc, it can be obtained: qc \u00bc arcsin(n2/n1). Under this condition the EM wave does not exit the\nincident medium, thus it is called total internal reflection. For any angle of incidence less than the\ncritical, part of the incident light will be transmitted and part will be reflected.\n\npolarized lightUnpolarized light\n\nAir\n\nGlass\n\nPartially polarized\nlight\n\nPerpendicular \nto plane of paper\n\nFIGURE 2.9\n\nIllustration of the polarization of unpolarized light passing through and reflected off of glass.\n\n3This is a typical incidence angle used by many optical and passive microwave sensors, since it makes vertical polarization\nless sensitive to surface roughness effects.\n\n54 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\n2.4.6 ALBEDO VERSUS REFLECTANCE\nIt is important to discriminate between \u201calbedo\u201d and reflectance. The former is defined as the ratio of\nthe amount of EM energy reflected by a surface to the amount of energy incident upon it. It differs from\n\u201cspectral reflectance\u201d since albedo is usually averaged over the visible range of the EM spectrum while\nspectral reflectance applies only to a specific region of the EM spectrum. Originally, the albedo\n(derived from the Latin albedo or whiteness) refers to reflected sunlight containing a full range of\nwavelengths. So, unless the albedo is restricted to some particular wavelength it refers to some average\nacross the wavelength range of visible light.\n\nAlbedo also depends on the directional distribution of the incident radiation with the exception of\nLambertian surfaces, which by their nature scatter radiation in all directions and therefore have an albedo\nthat is independent of the incident angle of the irradiance. For other surfaces, it is most appropriate to\nspecify a bidirectional reflectance distribution function (BDRF) to accurately characterize the scattering\nproperties of a surface. It is common, however, to use albedo as a first approximation to the scattering.\n\nReflectance is the fraction of incident EM radiation that is reflected off a surface. This is in contrast\nto reflectivity, which is a property of the surface material itself. The spectral reflectance is a plot of the\nreflectance as a function of wavelength. Reflectivity is a directional property and most surfaces can be\ndivided into those that give specular reflection and those that give diffuse reflection. For a specular\nsurface such as a glass or a metal, the reflectivity will be nearly zero for all angles except for those\nnormal to the surface. For diffuse surfaces such as flat white paint the reflectivity is uniform, and\nradiation is reflected at all angles equally or nearly equally. Such surfaces are said to be Lambertian. Few\nsurfaces are solely Lambertian or specular and instead have a mixture of these properties (Fig. 2.11).\n\n2.5 ELECTROMAGNETIC SPECTRUM: DISTRIBUTION OF RADIANT\nENERGIES\n\nAs noted in the previous chapter, EM radiation (EMR) extends over a wide range of energies and\nwavelengths (frequencies). A narrow range of EMR extending from 0.4 to 0.7 mm, the interval\n\nReflected\nray\n\nRefracted\nray\n\nNormal\nline\n\nIncident\nray\n\nAir (n1)\nWater (n2)\n\n?1\n\n?2 Reflected\nray\n\nRefracted\nray\n\nNormal\nline\n\nIncident\nray\n\nAir (n2)\nWater (n1)\n\n?2\n\n?1\n\nFIGURE 2.10\n\nCondition of an electromagnetic wave traveling to a medium of lesser index of refraction (n).\n\n2.5 ELECTROMAGNETIC SPECTRUM: DISTRIBUTION OF RADIANT ENERGIES 55\n\n\n\ndetected by the human eye, is known as the visible region (also referred to as visible light but physicists\noften use that term to include radiation beyond the visible). White light contains a mix of all wave-\nlengths in the visible region. It was Sir Isaac Newton who first in 1666 carried out an experiment that\nshowed visible light to be a continuous sequence of wavelengths that represented the different colors\nthe eye can see. He passed white light through a glass prism and found that as the radiation passes from\none medium to another, it is bent according to what is known today as Snell\u2019s law. The index of\nrefraction is dependent on the wavelength, so that the bending angle varies systematically from red\n(longer wavelength; lower frequency) to blue (shorter wavelength; higher frequency). The process of\nseparating the constituent colors in white light is known as dispersion (Fig. 2.12). These phenomena\napply to radiation of wavelengths outside the visible (e.g., a crystal\u2019s atomic lattice serves as a\ndiffraction device that bends X-rays in different directions). The distribution of the continuum of all\nradiant energies can be plotted either as a function of wavelength or of frequency in a chart known as\nthe electromagnetic spectrum (Fig. 2.13).\n\nThe EM spectral chart in Fig. 2.13 also indicates the atomic or molecular mechanisms for forming\nthese different types of radiation; it also depicts the spectral ranges covered by many of the detector\nsystems in common use today. This figure indicates that EMR, i.e., photon release, is produced in a\nvariety of ways. Most involve actions within the electronic structure of atoms or in movements of\natoms within molecular structures (as affected by the type of bonding). The fundamental physics\ninvolves changing the direction and/or magnitude of electric and magnetic fields in the source of the\nEMR in short time intervals.\n\nOne common mechanism is to excite an atom by heating or by electron bombardment, which\ncauses electrons in specific orbital levels to momentarily move to higher energy levels; upon dropping\nback to the original level the energy gained is emitted as radiation at discrete frequencies given by\n\nspecular\nreflectiondiffuse\n\nreflection\n\nincident light\n\nFIGURE 2.11\n\nLambertian scattering mixed with specular reflection.\n\n56 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nEq. (2.9). EM waves are given off whenever such charged particles are accelerated, and these waves\ncan interact with any other charged particles. Such EM waves carry energy, momentum, and angular\nmomentum away from their source particle and can transfer these properties to matter with which they\ninteract. The EMwaves are \u201cmassless,\u201d but they are still affected by gravity. These EMwaves continue\nto \u201cradiate\u201d without the continuing influence of their moving source particles that created them since\nthey have achieved sufficient distance from their original source. This is often referred to as the \u201cfar\nfield\u201d as opposed to the \u201cnear field\u201d which is still within the radius of influence of the source particle.\n\nIn the quantum theory of electromagnetism, EM radiation consists of photons: the elementary\nparticles responsible for all EM interactions. Quantum processes provide additional sources of EM\nradiation, as mentioned earlier the transition of electrons to lower energy levels in an atom. The energy\nof an individual photon is quantized and is greater for photons of higher frequency. This relationship is\ngiven by Planck\u2019s law E \u00bc h$n, where E is the energy per proton, n is the frequency of the photon, and\nh is Planck\u2019s constant. Thus, a gamma ray photon could carry as much as w200,000 times the energy\nof a single photon of visible light. At high energies even the atom itself can be dissociated, releasing\nphotons of short wavelengths. Photons themselves, in an irradiation mode, are capable of causing\natomic or molecular responses in target materials that generate emitted photons (in the reflected light\nprocess, the incoming photons that produce the response are not necessarily the same photons that\nleave the target).\n\n2.5.1 GAMMA, X-RAY, AND ULTRAVIOLET PORTIONS OF THE ELECTROMAGNETIC\nSPECTRUM\n\nThe shortest wavelengths are in the gamma, X-ray, and ultraviolet (UV) parts of the EM spectrum,\nwhile the near-infrared (NIR: 0.7e2.5 mm) covers the wavelengths just longer than the visible portion\nof the EM spectrum. As it will become apparent when explaining Planck\u2019s radiation law in\n\nFIGURE 2.12\n\nPrism showing the dispersion of white sunlight.\n\n2.5 ELECTROMAGNETIC SPECTRUM: DISTRIBUTION OF RADIANT ENERGIES 57\n\n\n\nSection 2.6.6, in the UVand in the NIR, the radiation received by the sensors is largely dominated by\nreflected solar radiation, which also dominates the visible wavelengths. They do not contain any\nthermal emissions, which distinguishes them from the mid- and longwave portions of the infrared (IR)\nregion of the EM spectrum.\n\nNIR radiation was discovered in 1800 by William Herschel, a musician and amateur astronomer\nwho discovered the planet Uranus, because he wanted to know if any particular color was associated\nwith heat from sunlight. He found that the heat maximum was beyond the red end of the spectrum.\nHerschel could not believe that light and his \u201cradiant heat\u201d were related, but here he was wrong. By\n1835, Ampere had demonstrated that the only difference between light and what he named \u201cinfrared\nradiation\u201d was their wavelength. This all came together with James Maxwell in 1864 who wrote.\n\n\u201cThis velocity (of electromagnetic force) is so nearly that of light that it seems we have strong\nreason to conclude that light itself (including radiant heat and other types of radiation) is an elec-\ntromagnetic disturbance in the form of waves propagated through the electromagnetic field according\nto electromagnetic laws.\u201d\n\nAbsorptions in the NIR are generated from fundamental vibrations by two processes: overtones and\ncombinations. Overtones can be thought of as harmonics, so that every fundamental overtone will\nproduce a series of absorptions at integer multiples of the wavelength. Combinations are a bit more\ncomplicated and NIR absorptions are at a higher state of excitement so that they require more energy\nthan a fundamental absorption. These combinations arise from the sharing of NIR energy between two\nor more fundamental absorptions. While the number of possible overtones from a group of funda-\nmental absorptions is limited to a few, a very large number of combinations will be observed.\n\nFIGURE 2.13\n\nElectromagnetic spectrum.\n\n58 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nOne of the primary uses of NIR is to sense the health of the leaves in vegetation. While the visible\nchannels respond to the green of the surface vegetation (response to chlorophyll), the NIR responds to\nthe water carried in the mesophyll structure of the leaves. Thus, in the NIR wavelengths large peaks are\nobserved where the NIR responds to the presence of water (Fig. 2.14). For comparison this plot shows\nthe dry matter (Jacquemoud et al., 1999).\n\n2.5.2 VISIBLE SPECTRUM\nThe visible portion of the spectrum (Fig. 2.15) includes an extremely limited number of wavelengths\nthat are very important for remote sensing since they are the range of wavelengths viewed by human\neyesight and hence the source of a lot of information for mankind. These wavelengths correspond\nto those of the maximum radiation coming from the Sun, and an atmospheric transmission window,\nso this radiation can reach the surface of the Earth, and be reflected back to outer space. Most\nof optical remote sensing is focused on the use of reflected radiation in these relatively few\nwavelengths. There is a lot of energy in these narrow bands, which are frequently divided into narrow\nchannels to sense the different colors and their responses to radiation reflected by different features\non the Earth\u2019s surface.\n\nVisible remote sensing ranges from land surface geology and vegetation studies to ocean color\nimaging of ocean productivity. Each of these applications requires slightly different slices of the\nvisible spectrum and each requires its own level of sensitivity. These various applications and their\nrequirements will be discussed later.\n\n0.08\n\n0.07\n\n0.06\n\n0.05\n\n0.04\n\n0.03\n\n0.02\n\n0.01\n\n0\n400 800 1200 1600 2000 2400\n\nWavelength  (nm) \n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\nS\npecific absorption coefficientS\n\npe\nci\n\nfic\n a\n\nbs\nor\n\npt\nio\n\nn \nco\n\nef\nfic\n\nie\nnt\n\nWater\n\nChlorophyll\n\nDry matter\n\nFIGURE 2.14\n\nSpecific absorption coefficient of chlorophyll a \u00fe b (cm2/mg) on the left axis, water (cm?1), and dry matter\n(cm2/g) on the right axis (Jacquemoud et al., 2000).\n\n2.5 ELECTROMAGNETIC SPECTRUM: DISTRIBUTION OF RADIANT ENERGIES 59\n\n\n\n2.5.3 THERMAL INFRARED SPECTRUM\nThe TIR portion of the EM spectrum covers wavelengths from 10?5 to 10?3 m and as shown in\nFig. 2.16 includes both reflective and emissive channels. The shortest wavelengths have both reflected\nand emitted radiation while the longer wavelength channels represent only emitted radiation. One\ncommon practice to sort out the combination of reflected and emitted radiation in the shorter wave-\nlength TIR channels is to use nighttime only data which then represents only emitted radiation for\ncomparison with the longer wavelength thermally emitted only data (e.g., channels 3A and 3B in\nAVHRR3, Table 1.2, Section 1.2.1).\n\n2.5.4 MICROWAVE SPECTRUM\nThe microwave portion of the EM spectrum refers to those wavelengths longer than those at the IR\nfrequencies typically from 1 to 100 GHz although there are applications for frequencies beyond\n\nFIGURE 2.15\n\nVisible spectrum.\n\n60 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\n100 GHz (millimeter wave frequencies). As shown in Fig. 2.17 the microwave frequencies are\nseparated into a strange assortment of unevenly spaced channels with nonsequential titles. This odd\ndesignation of naming and bandwidth size was selected during the Second World War to conceal the\nidentity of this information. While one might think this strange designation would have been dropped\nafter this conflict was over, this naming convention appears to have taken root and lives on in spite of\nthe apparent wisdom to change it. Wavelengths range from 1 mm to 1.0 m. Another characteristic of\nmicrowave sensors is that the channels are typically dual-polarized, which corresponds to the first two\nStokes elements thus taking advantage of differences seen in the polarization signatures of some land\nsurface features. Other instruments may be fully polarimetric measuring the full Stokes vector. This is\nuseful in discriminating vegetation, snow cover, surface roughness, ocean wave direction, or atmo-\nspheric hydrometer shape and orientation.\n\n1016\n\n1012\n\n1014\n\nM\nic\n\nro\nw\n\nav\ne\n\n1 km?\n\nWavelength (m)Wavelength (m)\nLongerLonger\n\nShorterShorter\n\n104104 10\n4\n\n106\n\n108\n\n1010\n\n1018\n\n1020\n\n102102\n\n10-210-2\n\n10-410-4\n\n10-610-6\n\n10-810-8\n\n10-1010-10\n\n10-1210-12\n\n1.01.0\n\nLower\n\nHigherG\nam\n\nm\na\n\nR\nay\n\ns\nX\n\n-R\nay\n\ns\n\nU\nltr\n\nav\nio\n\nle\nt I\n\nnf\nra\n\nre\nd\n\nR\nad\n\nio\n W\n\nav\nes\n\nVi\nsi\n\nbl\ne\n\nFrequency (Hz)\n\n1 m?\n\n1cm?\n\n1 ?m?\n\n1 nm?\n?1 EHI\n\n?1 PHI\n\n?1 THI\n\n?1 GHI\n\n?1 MHI\n\n?1 KHI\n\n?\n\nInfrared\n\nfa\nr\n\nm\nid\n\nne\nar re\nfle\n\nct\niv\n\ne\nem\n\nis\nsi\n\nve\nra\n\ndi\nat\n\niv\ne\n\nth\ner\n\nm\nal\n\nsh\nor\n\nt w\nav\n\ne\n\n10-7\n\n10-6\n\n10-5\n\n10-4\n\n10-3\n\nWavelength\n(metres)\n\nFIGURE 2.16\n\nInfrared spectrum.\n\n2.5 ELECTROMAGNETIC SPECTRUM: DISTRIBUTION OF RADIANT ENERGIES 61\n\n\n\n2.6 ATMOSPHERIC TRANSMISSION\nMost remote sensing is conducted above the Earth either within or above the atmosphere. The gases in\nthe atmosphere interact with solar irradiation, with radiation from the Earth\u2019s surface and with natural\nor artificial microwave radiation (often considered as radio frequency interference). The atmosphere\nitself is excited by EMR so as to become another source of released photons. Fig. 2.18 is a generic\ndiagram showing relative atmospheric radiation transmission at different wavelengths.\n\nBlue zones mark the minimal passage of incoming and/or outgoing radiation, whereas, white areas\ndenote atmospheric transmission windows, in which the radiation does not interact much with air\nmolecules and hence, is not absorbed or scattered by the atmosphere. Note the narrow \u201cwindow\u201d\nchannels in the thermal and midrange IR. Also it should be pointed out that for most of the microwave\nchannels the atmosphere is nearly transparent to the microwave radiation except at about 22 and\n183 GHz where microwave absorption peaks due to water vapor and 55e60 GHz and 118 GHz where\noxygen absorption bands exist.\n\n1016\n\n1014\n\n1012\n\n?1 GHI\n\n?1 THI\n\n?1 EHI\n\n?1 PHI\n\n?1 MHI\n\n?1 KHI\n\nM\nic\n\nro\nw\n\nav\ne\n\n1 km?\n\nWavelength (m)\nLonger\n\nShorter\n\n104 10\n4\n\n106\n\n108\n\n1018\n\n1020\n\n102\n\n10-2\n\n10-4\n\n10-6\n\n10-8\n\n10-10\n\n10-12\n\n1.0\n\nLower\n\nHigherG\nam\n\nm\na\n\nR\nay\n\ns X\n-R\n\nay\ns\n\nU\nltr\n\nav\nio\n\nle\nt I\n\nnf\nra\n\nre\nd\n\nR\nad\n\nio\n W\n\nav\nes\n\nV\nis\n\nib\nle\n\nFrequency (Hz)\n\n1 m?\n\n1cm?\n\n1 ?m?\n\n1 nm?\n\n?\n\nMicrowaves\n\nFrequency\n(GHz)\n\nWavelength\n(metres)\n\n10\u20133\n\n10\u20132\n\n10\u20131\n\n1.0\n\nP-band\n\nL-band\n\nS-band\n\nC-band\nX-band\nKu-band\nK-band\n\nKa-band\n\n30-100 cm\n\n15-30 cm\n\n7.5-15 cm\n\n3.75-7.5 cm\n2.4-3.75 cm\n1.67-2.4 cm\n1.1-1.67 cm\n\n0.75 -1.1 cm\n\nmillimetre band\n\nsub-millimetre band\n\n40\n\n26.5\n18\n12.5\n8\n4\n\n2\n\n1\n\n0.3\n\nFIGURE 2.17\n\nMicrowave spectrum.\n\n62 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nIt is also useful to view the atmospheric transmission windows relative to the solar emissions as\npresented here in Fig. 2.19.\n\nAs it can be seen energy in the UV, visible, and NIR is mostly transmitted through the atmosphere.\nHowever, in the midrange IR there are rather narrow windows in which the radiation passes through\nthe atmosphere. As shown in Fig. 2.18, these narrow windows are due to the presence of different gases\nin the atmosphere. Most of the windows in the midrange and longer wavelength TIR portions of the\nspectrum are due to water vapor and carbon dioxide in the atmosphere.\n\nIn particular, there is a rather large window at about 10 mm, which passes the longer wavelength\nTIR energy through the atmosphere. This is the primary channel used to remotely sense both sea and\nland surface temperatures by the IR emissions from the Earth\u2019s surface. Due to the nature of IR\nradiation these emissions are necessarily from the skin of the land and ocean surfaces.\n\n1014\n\nv\nI\nS\nI\nB\nL\nE 1013 1012 1011 1010 109 FREQUENCY(Hz)\n\nWAVE\nLENGTH\n\n100 cm10 cm1.0 cm0.1 cm100 ?m1.0 ?m\n\nTr\nan\n\nsm\nis\n\nsi\nvi\n\nty\n\n10\n\nRADAR BANDS\nK X\n\nMICROWAVEINFRARED\nC S L PTRANSMISSION\n\nFOR 1 KM PATH\nH2O\n\nH2O\n\nH2OH2O\nH2O H2O\n\nH2O\n\nH2O\nH2O N2O\n\nCO2\nCO2\n\nCO2\n\nCO2H2O O3\n\nO2\nO2\n\nO3\n\n1.0\n\n.5\n\nMOSTLY OPAQUE\nDUE TO H2O\n\nFIGURE 2.18\n\nAtmospheric transmission spectrum.\n\n0.3\n?m\n\n1\n?m\n\n10\n?m\n\n100\n?m\n\nWavelength\n\nSun\n\n0\n\n100\n\nEarth\n\nAbsorbed\n\nM\nIC\n\nR\nO\n\nW\nAV\n\nE\n\nIN\nFR\n\nA\nR\n\nE\nD\n\nU\nV\n\nV\nIS\n\nIB\nLE\n\nE\nne\n\nrg\ny\n\nTr\nan\n\nsm\nis\n\nsi\non\n\n (%\n)\n\n1\nmm\n\n1\nm\n\nFIGURE 2.19\n\nAtmospheric transmission windows and solar emission spectra.\n\n2.6 ATMOSPHERIC TRANSMISSION 63\n\n\n\nThis next plot (Fig. 2.20), made with the Airborne Visible/Infrared Imaging Spectrometer\nhyperspectral spectrometer, gives a more detailed spectrum, made in the field looking up into the\natmosphere, for the interval 0.4e2.5 mm (converted in the diagram to 400e2500 nm).\n\nMost remote sensing instruments on airborne or space platforms operate in one or more of these\nwindows by making their measurements with optics and detectors tuned to specific frequencies\n(wavelengths) that pass through the atmosphere. However, some sensors, especially those on mete-\norological satellites, directly measure absorption phenomena, such as those associated with carbon\ndioxide, CO2, and other gaseous molecules. Note that the atmosphere is nearly opaque to EM radiation\nin part of the mid-IR and all of the far-IR regions. In the microwave region, by contrast, most of this\nradiation moves unimpeded through the atmosphere, so radar waves may reach the surface and EM\nemitted from the Earth\u2019s surface in the microwave portion of the spectrum can reach the top of the\natmosphere and be sensed by satellite radiometers, except for the scattering and attenuation (caused by\nraindrops) that blocks the transport through the atmosphere and allows the rain to be detected by radars\nand microwave radiometers.\n\nBackscattering refers to scattering of photons in all directions above the target in the hemisphere\nthat lies on the source side. Mie scattering refers to directional scatting of radiation by atmospheric\nconstituents (e.g., smoke aerosols, dust) whose dimensions are of the order of the EM wavelengths.\nRayleigh scattering is quite isotropic and results from scattering by atmospheric constituents (e.g.,\nmolecular gases such as O2, N2 as well as other nitrogen compounds, and CO2, together with water\nvapor) that are much smaller than the EM wavelengths. Rayleigh scattering increases with decreasing\n\nAVIRIS 224 Contiguous Spectral Channels\n\n1\n\n0.9\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0\n400.0 700.0 1000.0 1300.0 1600.0 1900.0 2200.0 2500.0\n\nWavelength (nm)\n\nAtmosphere TransmittanceT\nra\n\nns\nm\n\nitt\nan\n\nce\n\nLandsat Thematic Mapper 6 Multispectral Bands\n\nAtmospheric\nScattering\n\nO3\n\nO2\n\nO2\n\nO2 CO2\n\nCO2\n\nCO2\nCH4\n\nH2O\n\nH2O\n\nH2O\nH2O\n\nH2O\n\nH2O\n\nH2O\n\nFIGURE 2.20\n\nAtmospheric transmission spectrum for Airborne Visible/Infrared Imaging Spectrometer (blue); and the\n\nLandsat Thematic Mapper bands (green).\n\n64 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\n(shorter) wavelengths, causing the preferential scattering of blue light (blue sky effect); however, the\nred sky tones at sunset and sunrise result from significant absorption of shorter wavelength visible light\nowing to greater \u201cdepth\u201d of the atmospheric path as the Sun is near the horizon. Particles much larger\nthan the irradiation wavelengths give rise to nonselective (wavelength-independent) scattering.\nAtmospheric backscatter can, under certain conditions, account for 80%e90% of the radiant flux\nobserved by a spacecraft sensor.\n\nRemote sensing of the Earth traditionally has used reflected energy in the visible and NIR as well as\nemitted energy in the TIR and microwave regions to gather radiation that can be analyzed numerically\nor used to generate images whose variations represent different intensities of photons associated with a\nrange of wavelengths that are received at the sensor. This gathering of a (continuous or discontinuous)\nrange(s) of wavelengths is the essence of what is usually termed multispectral remote sensing. A\nhyperspectral imaging sensor has many more spectral channels (typically >10) than a multispectral\nsensor. The bands have narrower bandwidths, enabling the finer spectral characteristics of the targets to\nbe captured by the sensor.\n\nA hyperspectral imaging system is also known as an \u201cimaging spectrometer.\u201d It acquires images in\nabout 100 or more contiguous spectral bands. The precise spectral information contained in a\nhyperspectral image enables better characterization and identification of targets. Hyperspectral images\nhave potential applications in fields such as precision agriculture (e.g. monitoring the types, health,\nmoisture status and maturity of crops), coastal management (e.g. monitoring of phytoplankton,\npollution, bathymetry changes).\n\nIn the reflected bands, it is also common practice to have a band that integrates radiation over all of\nthe wavelengths, which is referred to as the panchromatic band. The advantage of this channel is that\nby integrating all of the wavelengths together it responds to a much stronger radiative signal and can\nhave a greater spatial resolution due to the greater intensity of the radiometric signal.\n\nImages made from the varying wavelength/intensity signals will show variations in gray tones in\nblack and white versions or colors (in terms of hue, saturation, and intensity) in colored versions (also\ncalled \u201cfalse color\u201d as these colors are selected to emphasize the gradients and not reflect any true color\non the Earth\u2019s surface). A pictorial (image) representation of target objects and features in different\nspectral regions and/or polarizations, usually using different sensors (commonly with band-pass filters)\neach tuned to accept and process the wave frequencies (wavelengths) that characterize each region,\nwill normally show significant differences in the distribution (patterns) of color or gray tones.\n\n2.6.1 SPECTRAL WINDOWS\nThe atmosphere has a strong influence on EM radiation, through the phenomena of absorption and\nscattering. The amount of radiation that fails to penetrate is due to the opacity of the atmosphere, and\nvaries for radiation at different wavelengths. At certain wavelengths the atmosphere is transparent (or\nmostly transparent): these wavelengths define \u201cwindows\u201d that can be used by space-borne imaging\nsensors (Fig. 2.21). Wavelengths at which the atmosphere is opaque (or mostly opaque) are used by\nspace-borne sounding sensors to infer vertical properties in the atmosphere.\n\nIn practice, a range of atmospheric conditions such as weather (clouds), and dust particles affect the\nsensors \u201cvision,\u201d particularly in tropical and polar regions. In recent years, new sensors have been\ndeveloped, using microwaves with wavelengths between 1 cm and 1 m that can penetrate the atmo-\nsphere in almost all atmospheric conditions.\n\n2.6 ATMOSPHERIC TRANSMISSION 65\n\n\n\n2.6.2 ATMOSPHERIC EFFECTS\nThe atmosphere exerts two principal effects on the radiation passing through it from either direction\n(down from space or up from the Earth\u2019s surface); absorption and scattering. Absorption is the process\nby which radiation is picked up by atmospheric molecules and atoms increasing the energy in the\natmosphere. Scattering is the process by which radiative energy disperses off of atmospheric particles.\nThese particles include gas molecules and atoms along with suspended aerosols and water droplets and\nice particles in the atmosphere.\n\n2.6.2.1 BeereLambert Absorption Law\nAbsorption attenuates the radiative signal depending on the constituent gases and aerosols compo-\nnents. The interaction between these atmospheric components and the radiation is expressed by:\n\na \u00bc\nX\ni\n\nmi$Ca;i \u00bc\nX\ni\n\nmi$Cgeom;i$xi; (2.25)\n\nwhere mi is volumetric density, Ca,i and Cgeom,i are the absorption coefficients (dependent on the ith\nspecies) and the geometric coefficient respectively, and xi is the absorption efficiency, which can be\nlarger than one.\n\nThe processes contributing to this absorption are atomic and molecular processes within the\natmospheric gases and aerosol constituents. The atmospheric uptake of photons by shifts in electron\nenergy states generally leads to a fairly rapid reemission of the equivalent energy, but at a different\nwavelength consistent with the temperature of the gas. Another energy absorption mechanism is the\nuptake of energy by crystalline processes at the molecular level. The amount of energy absorbed by the\nmechanism depends on the concentration and types of ions.\n\nFIGURE 2.21\n\nAtmospheric transmission windows (marked in yellow).\n\n66 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nThe atmospheric effects on the radiant energy transiting it include transmission, reflection,\nabsorption (Fig. 2.21), and scattering. Transmission results only in refraction of the transmission lines,\nbut absorption, as just explained, leads to the attenuation and eventual reemission of the energy.\n\n2.6.2.2 BeereLambert Absorption Law: Opacity\nAlso known as the BeereLamberteBouguer law, this is an empirical relationship that relates the\nabsorption of light to the properties of the material through which the light is traveling. This law states\nthat there is a logarithmic dependence between the transmission (or transmissivity), T, of light through\na substance and the product of the absorption coefficient of the substance, and the distance the light\ntravels through the material (i.e., the path length), l (Fig. 2.22).\n\nFor a nondispersive medium, the transmissivity can be written as:\n\nT \u00bc I\nI0\n\n\u00bc 10?k$l; (2.26)\n\nwhere a is the absorption coefficient (Nep/m), and which can be expressed in terms of the absorptance,\nA, defined as\n\nA \u00bc ?log10\n?\nI\n\nI0\n\n\n. (2.27)\n\nHistorically the BeereLambert law states that absorption is proportional to the light path length,\nand the concentration of the absorbing species in the medium.\n\nThe absorption coefficient A is one of the ways to express the absorption of EM waves. There are\nmany other ways of writing the same relationship. For example, A can be expressed as the imaginary\npart of the refractive index, k, and the wavelength of the light in free space, l0 as;\n\nA \u00bc 4pk\nl0\n\n; (2.28)\n\nFIGURE 2.22\n\nDiagram of BeereLambert absorption of light as it travels through a medium of width l.\n\n2.6 ATMOSPHERIC TRANSMISSION 67\n\n\n\nThere are five conditions that must be met for the BeereLambert law to be valid:\n\n1. The absorbers must act independently of each other;\n2. The absorbing medium must be homogeneously distributed in the interaction volume and must\n\nnot scatter the radiation;\n3. The incident radiation must consist of parallel rays, each traversing the same length in the\n\nabsorbing medium;\n4. The incident radiation should preferably be monochromatic, or have at least a width that is\n\nnarrower than the absorbing transition; and\n5. The incident flux must not influence the atoms or molecules; it should only act as a noninvasive\n\nprobe of the species under study. In particular, this implies that the light should not cause optical\nsaturation or optical pumping, since such effects will deplete the lower level and possibly give rise\nto stimulated emission.\n\n2.6.2.3 Atmospheric Scattering\nFig. 2.23 summarizes the atmospheric effects on radiation. Scattering is represented by an isotropic\ndistribution of the incoming radiation over the upper hemisphere. Depending on the particle size the\nthree different scattering mechanisms mentioned previously must be considered.\n\nRayleigh scattering occurs when particles are very small as compared to the wavelength of the\nradiation. These could be particles such as small specks of dust or nitrogen and oxygen molecules.\nRayleigh scattering causes shorter wavelengths of energy to be scattered much more than longer\nwavelengths. Rayleigh scattering is the dominant scattering mechanism in the upper atmosphere. The\nfact that the sky appears \u201cblue\u201d during the day is because of this phenomenon. As sunlight passes\n\nMedium 1\n\n?1\n?1  >  ?2\n\nTransmission Reflection\n\nMedium 2\n\nMedium 1\n\n?1 ?2\n?1  =  ?2\n\nScattering Absorption\n\nEmission\n\nEmission\n\n?2\n\n?1\n\nFIGURE 2.23\n\nSummary of atmospheric effects on radiation.\n\n68 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nthrough the atmosphere, the shorter wavelengths (i.e., blue) of the visible spectrum are scattered more\nthan the other (longer) visible wavelengths. At sunrise and sunset, the light has to travel farther through\nthe atmosphere than at midday and the scattering of the shorter wavelengths is more complete; this\nleaves a greater proportion of the longer wavelengths to penetrate the atmosphere and are less\nattenuated resulting in the yellow and red colors of sunrise and sunset.\n\nRadiances associated with Rayleigh scattering are proportional to the inverse of the radiation\nwavelength to the fourth power and exhibit a wide scattering pattern as shown in Eq. (2.29):\n\nbr\u00f0q; l\u00def\n1\n\nl4\n\n?\n1\u00fe cos2q?. (2.29)\n\nHere br is the Rayleigh scattering coefficient, q is the angle with respect to a reference line\n(Fig. 2.6), and l is the wavelength of the radiation.\n\nMie scattering occurs when the particles are just about the same size as the wavelength of the\nradiation. Dust, pollen, smoke, and clouds are common causes of Mie scattering, which tends to affect\nlonger wavelengths than those affected by Rayleigh scattering. Mie scattering occurs mostly in the\nlower portions of the atmosphere where larger particles are more abundant, and dominates when cloud\nconditions are overcast. Mie scattering is mostly forward scattering and the radiance associated with\nthis scattering mechanism is highly variable as given here in Eq. (2.30):\n\nbr\u00f0q; l\u00deflmf \u00f0q\u00de; m \u00bc 0:6.? 2: (2.30)\nThe final form of scattering is referred to as nonselective scattering and it holds for particles\n\nthat are much larger than the wavelength of the radiation. Water droplets, ice, and large dust\nparticles can cause this type of scattering. Nonselective scattering gets its name from the fact that\nall wavelengths are scattered about equally. This type of scattering causes fog and clouds to appear\nwhite to our eyes because blue, green, and red light are all wavelengths scattered in approximately\nequal quantities (blue \u00fe green \u00fe red light \u00bc white light). This type of scattering is generally\nisotropic.\n\nThese atmospheric scattering processes are summarized in Fig. 2.24 as a function of EM wave-\nlength and particle radius.\n\n2.7 SENSORS TO MEASURE PARAMETERS OF THE EARTH\u2019S SURFACE\nThe mechanisms of radiation leaving the Earth\u2019s surface are summarized here in Fig. 2.25 that covers\nboth the radiation stimulated by incoming solar insolation (reflected radiation) and that in response to\nEarth\u2019s surface temperature (emitted radiation). These reflections and emissions are summarized by\ncolored arrows that represent the various processes. Here the colors are only intended to discriminate\nthe processes and do not refer to any color of visible radiation.\n\nThe incoming solar radiation transmitted through the atmosphere may reach the sensor after a\ndirect reflection (scattering) from the Earth\u2019s surface such as on a clear day (A), or after being diffused\nin the atmosphere (B) such as in a foggy or cloudy sky. Under these conditions, solar radiation is also\nreflected (scattered) in the atmosphere (C), such as from the tops of the clouds, or after multiple re-\nflections in the environment (G). On the other hand, the Earth\u2019s surface emits radiation according to the\nabsolute surface temperature that can reach the sensor directly (D), or after several reflections (H).\n\n2.7 SENSORS TO MEASURE PARAMETERS OF THE EARTH\u2019S SURFACE 69\n\n\n\nSimilarly, the atmosphere also emits, and this radiation may reach the sensor directly (F), or after a\nreflection on the surface of the Earth (E).\n\nThis set of mechanisms maps into remote sensing instrumentation in Eq. (2.31) where L indicates\nradiance and the subscripts refer to the mechanisms in Fig. 2.25.\n\nVIS/NIR L LA LB LC LG? + + + (2.31a)\n\nLWIR L LD LE LF LH? + + + (2.31b)\n\nMWIR L LA LB LC LD LE LF LG LH? + + + + + + + (2.31c)\n\nMicrowaves L LA LD LE LF? + + (2.31d)\n\nAs it will be shown later, under the RayleigheJeans approximation, at microwave frequencies, L is\nproportional to the physical temperature T of the emitting body and therefore:\n\nT z TA \u00fe TD \u00fe TE \u00fe TF; (2.32a)\nTAPz TSun \u00fe TB \u00fe TSC \u00fe TUP. (2.32b)\n\nHere VIS/NIR refers to visible and near-infrared radiation dominated by the direct, reflect, and\nscattered radiation from the Sun. MWIR is the midrange thermal infrared where both solar and Earth\nemissions are comparable; LWIR refers to the longwave thermal infrared channels in which the Earth\u2019s\n\n1\n\nS\nO\n\nLA\nR\n\n \nR\n\nA\nD\n\nIA\nTI\n\nO\nN\n\nTE\nR\n\nR\nE\n\nS\nTR\n\nIA\nL\n\nR\nA\n\nD\nIA\n\nTI\nO\n\nN\n\nW\nE\n\nAT\nH\n\nE\nR\n\nR\nA\n\nD\nA\n\nR\n\n10-3\n\n102\n\n103\n104\n\n10-1\n\n10-2\n\n1\n\nSIZE PARAMETER AS A FUNCTION OF INCIDENT \n RADIATION AND PARTICLE RADIUS\n\n10 GE\nOM\n\nETR\nIC O\n\nPTI\nCS\n\nMIE\n SC\n\nATT\nER\n\nING\n\nRAY\nLEI\n\nGH\n SC\n\nATT\nER\n\nING\n\nNE\nGL\n\nIGI\nBLE\n\n SC\nATT\n\nER\nING?=\n\n1\n\n10 102 103 104 105\n\nRAINDROPS\n\nDRIZZLE\n\nCLOUD DROPLETS\n\nSMOKE, DUST, HAZE\n\nAIR MOLECULES\n\nr (\n  m\n\n)\n?\n\n? (  m)?\n\nFIGURE 2.24\n\nSummary of the atmospheric scattering mechanisms as a function of radiation wavelength and atmospheric\n\nsize parameter. Also shown are the atmospheric constituents that contribute to these scattering processes.\n\n70 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nsurface emissiondominates, and themicrowave regionoverwhich there a radiation components fromboth\nthe Earth and the Sun. In Eq. (2.32) the radiances at microwave frequencies are related to temperatures\n(T) where the subscript AP refers now to \u201capparent\u201d antenna temperature due to radiation reaching the\nradiometer antenna, Sun refers to the radiation coming from the Sun, B refers to the \u201cbrightness\u201d\ntemperature of the surface, SC refers to the downwelling (DN) radiation coming from the atmosphere\nand the Galactic and cosmic background that are \u201cscattered\u201d on the Earth\u2019s surface and attenuated by the\natmosphere in the upwelling path, and UP refers to the upwelling atmospheric radiation.\n\n2.8 INCOMING SOLAR RADIATION\nThe radiative energy coming from the Sun to the Earth is the ultimate source of energy for all natural\nprocesses that will be considered. The spectrum of the Sun\u2019s emissions is compared to the atmospheric\nwindows we introduced earlier (Fig. 2.26) and we see that the highest energy windows are located at\nthe shorter wavelengths while the wider windows, in terms of wavelength band, are located in the\nlonger TIR wavelengths.\n\nIt is important to realize that even the very narrow windows in the shortwave part of the spectrum\ntransmit a lot of solar radiation to the Earth\u2019s surface where about 50% of this shortwave radiation\nmakes it to the Earth\u2019s surface. Here the radiation is converted into heat or biomass or some other form\n\nA B C G D E F H\n\n(A) Solar irradiance transmitted through the atmosphere and reflected by Earth\u2019s surface\n\n(B) Solar radiation diffused by the atmosphere reflected by the Earth\u2019s surface\n\n(C) Upwelling solar radiance diffused by the atmosphere\n\n(D) Spontaneous thermal emission of the Earth\u2019s surface\n\n(E) Downwelling atmospheric radiance (spontaneous emission) reflected at the Earth\u2019s surface\n\n(F) Upwelling atmospheric radiation (spontaneous emission)\n\n(G) Reflected solar irradiance reaching the sensor through multiple scattering\n\n   Spontaneous thermal emission of bodies reaching the sensor through multiple scattering (H)\n\nFIGURE 2.25\n\nContributions to the radiance reaching a space sensor (Schott, 2007).\n\n2.8 INCOMING SOLAR RADIATION 71\n\n\n\nof energy equivalent. A much smaller amount is reradiated by the Earth (surface temperature of 300K)\nback into the atmosphere and up into space (Fig. 2.26).\n\n2.9 INFRARED EMISSIONS\nThe radiation emitted by a surface is governed by Planck\u2019s law, which applies to theoretical black\nbodies which are ideal materials that absorb all the incident radiation at all frequencies and polari-\nzations, and in thermodynamic equilibrium reemits it following Planck\u2019s law which is:\n\nMl;BB \u00bc 2$p$h$c\n2\n\nl5\n$\n\n1\n\ne\nh$c\n\nl$kB$T ? 1\nW\n?\n\nm2 mm\n? ?? ?\n\n; (2.33)\n\nwhere kB is the Boltzmann\u2019s constant (1.3806 ? 10?23 m2 kg s?2 K?1). The spectral curves for\nPlanck\u2019s law for the Sun and Earth (considered as black bodies at 6000K and 288K, respectively) are\npresented here in Fig. 2.27.\n\nIn reality, no bodies are actually black bodies, and despite there are close approximations to\nreference black bodies, the reality is that all bodies are really \u201cgray bodies\u201d and do not emit all of the\nradiation consistently with their absolute temperature. The emissivity (e) of a body represents how\nwell a real body approximates a blackbody. It is expressed as the ratio of the actual radiation at a given\nwavelength to that of a blackbody with the same absolute temperature:\n\n0 ? e\u00f0q;4; l\u00de \u00bc Ml\u00f0q;4; l; T\u00de\nMl;BB\u00f0l; T\u00de ? 1; (2.34)\n\nwhere q is the elevation angle and 4 is the azimuth angle.\nThe wavelength of the maximum in Fig. 2.28 is a function of the absolute temperature and it\n\nexpressed by Wien\u2019s Displacement law:\n\nlmax$T \u00bc 2898 \u00f0mm K\u00de. (2.35)\n\n0\n\n300\n\n600\n\n900\n\n1200\nS\n\nO\nLA\n\nR\n S\n\nP\nE\n\nC\nTR\n\nA\nL \n\nIR\nR\n\nA\nD\n\nIA\nN\n\nC\nE\n\n (W\nm\n\n-2\n?m\n\n-1\n)\n\n1500\n\n1800\n\n2100\n\n46\n9\n\n55\n5\n\n64\n5\n\n85\n8\n\n12\n40\n\n16\n40\n\n21\n80 260020001500\n\nWAVELENGTH (nm)\n\n200\n\nO3\n\nO3\n\nMODIS BANDS\n\nAIRMASS = 1.5\nWATER VAPOR = 2.0 cm\n\nOZONE = 0.34 cm\n?' aerosol 550nm = 0.126\n\n\u00c5 exponent = 0.66\n\nSOLAR IRRADIANCE OUTSIDE \nATMOSPHERE\n\nDIRECT SOLAR IRRADIANCE AT  SEA LEVEL \n\nH2O & CO2\nH2O & CO2\n\nH2O & CO2H2O\nH 2\n\nO O\n2\n\nH 2\nO\n\n1000 2700\n\nFIGURE 2.26\n\nTop of the atmosphere solar irradiance spectrum outside the atmosphere (blue line) compared with atmo-\n\nspheric transmission windows (yellow line, https://objectivistindividualist.blogspot.com/2013/02/infrared-\n\nabsorbing-gases-and-earths.html).\n\n72 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\nhttps://objectivistindividualist.blogspot.com/2013/02/infrared-absorbing-gases-and-earths.html\nhttps://objectivistindividualist.blogspot.com/2013/02/infrared-absorbing-gases-and-earths.html\n\n\nFIGURE 2.27\n\nPlanck emission curves for the Sun and Earth (solid black).\n\nFIGURE 2.28\n\nEmission curves illustrating Wien\u2019s displacement law.\n\n2.9 INFRARED EMISSIONS 73\n\n\n\nThis relationship is expressed graphically in Fig. 2.28 where the different curves represent different\nsurface covers at various absolute temperatures ranging from Arctic ice at 220K to the Sun at 6000K.\nAt the top of this diagram are the designations to those portions of the wavelength spectrum. Notice the\nlarge range of TIR wavelengths particularly as compared to the fairly narrow range of visible\nwavelengths.\n\nEmissivity is a characteristic of the surface of the material. Emissivity is a measure of a material to\nboth radiate and absorb energy. Recall that a blackbody is by definition a perfect emitter and a perfect\nabsorber. High emissivities indicate materials that absorb and emit large proportions on incident\nradiation. Some emissivities are given here for various materials in Table 2.2 for the 8e12 mm region\nof EM spectrum, which covers the TIR portion of the spectrum.\n\nHence two surfaces with the same kinetic temperature, but different emissivities will have different\nradiant temperatures. Since remote sensing instrumentation can only observe the emitted temperature\nthe emissivity of the surface material must be known to derive the kinetic temperature of the surface.\nWhen looking at the ocean\u2019s surface it is common to assume a very high emissivity, as suggested by\nTable 2.2.\n\nTwo other approximations to Planck\u2019s law that are important in remote sensing are the\nStephaneBoltzmann\u2019s law and the RayleigheJeans approximation. The latter applies to the micro-\nwave portion of the spectrum, which corresponds to the longer wavelengths shown in Figs. 2.21 and\n2.22 as discussed earlier in this chapter (Eq. 2.32). This approximation is written as:\n\nMl;BBz 2p\nc\n\nl4\n$kB$T\n\n?\nW\n??\n\nm2 mm\n??\n; (2.36)\n\nwhere kB is the Boltzmann\u2019s constant as given earlier. This equation is accurate to within 1% for\nfrequencies f ? 112 GHz and temperatures T ? 300K. This equation makes it possible to compute\nmicrowave emissions from the knowledge of the absolute temperature (T). Similarly, for the TIR\nportion of the EM spectrum we can use the StephaneBoltzmann\u2019s law:\n\nMBB \u00bc 2p\n5$k4B\n\n15$c2$h3\n$T4 \u00bc s$T4 ?W?m2?; (2.37)\n\nwhere s \u00bc 5.6698 ? 10?8 [W/(m2 K4)] is StefaneBoltzmann\u2019s constant.\n\nTable 2.2 Emissivities for the 8e12 mm Portion of the\nElectromagnetic Spectrum\n\nMaterial Emissivity, e\n\nPolished metal surface 0.006\n\nGranite 0.815\n\nQuartz sand, large grains 0.914\n\nDolomite, polished 0.929\n\nBasalt, rough 0.934\n\nAsphalt paving 0.959\n\nConcrete walkway 0.966\n\nA coat of flat black paint 0.970\n\nWater, with a thin film of\npetroleum\n\n0.972\n\nWater, pure 0.993\n\n74 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\nOver the annual cycle the incoming solar energy that makes it to the Earth\u2019s surface (about 50%) is\nbalanced by the outgoing TIR energy emitted from the Earth\u2019s surface. While this emitted energy is at\na much lower temperature than the incoming solar radiation it should be remembered that the\nincoming solar radiation only illuminates at a time (Fig. 2.29) while the Earth emits radiation over its\nwhole surface. Thus, the thermal equilibrium is maintained between this incoming shorter wave solar\nradiation and the longer wavelength thermal emission from the Earth\u2019s surface.\n\nThe atmosphere transmits, absorbs (mainly by H2O, dust, O3), reflects (by clouds), and scatters\nradiation (by aerosols and gases); the Earth\u2019s surface reflects and absorbs radiation both short and long\nwaves. The Earth reemits longwave radiation, which is selectively transmitted, reflected or absorbed\nby the atmosphere.\n\nExamples of surface and atmospheric components are shown here in Fig. 2.30 which are composite\nimages taken from geostationary satellite imagers. On the right is the \u201coutgoing longwave radiation\u201d\nwhich is the longwave radiation emitted by the Earth\u2019s surface while at the left is the higher peak\nrepresenting the shorter wavelength incoming energy from the Sun.\n\nThe hemispherical image on the right has been separated in half with the right half showing the\natmospheric water vapor content and the left half the outgoing longwave radiation. Land surface,\nclouds and water vapor have been individually labeled along with their average constituencies of the\natmosphere on the right side. On the left clouds, surface and air (atmosphere) have been labeled to\ndemonstrate the appearance of these features in reflected visible satellite imagery.\n\nThere are a few other radiative transfer terms that need to be defined in working with satellite data\nand atmospheric effects. The first is transmittance, which is the amount of radiant energy that is\ntransmitted through the atmosphere\n\ns\u00f0l\u00de \u00bc Ms\nEi\n\n; (2.38)\n\nOutgoing longwave\n\nradiation radiates out\n\nover the entire surface\n\nof the earth at all times.\n\nIncoming shortwave solar radiation shines on only hone-half of the earth at a time.\n\nThis area if found as ?R2 where R is the radius of the earth.  Thus, the heat flux\nreceived by the earth is 1.9 cal/cm2min \u2022?R2. The longwave radiation emitted from\nthe earth is over the entire  surface of the \u201csphere\u201d with an area of 4?R2 the area of\nthe sphere. Thus, the heat flux out is 0.49 cal/cm2min \u20224?R2 which is approximately\nequal to the incoming heat flux and the temperature of the earth remains constant.   \n\nFIGURE 2.29\n\nRadiative thermal equilibrium of the Earth\u2019s surface.\n\n2.9 INFRARED EMISSIONS 75\n\n\n\nwhere Ms is the radiant energy transferred by the atmosphere and the Ei represents the incoming\nradiation at the top of the atmosphere. Likewise, reflectivity, which represents the amount of radiant\nenergy reflected, is expressed as\n\nr\u00f0l\u00de \u00bc Mr\nEi\n\n; (2.39)\n\nwhere the subscript \u201cr\u201d represents the reflected portion of the incoming radiation. Finally, the ab-\nsorptivity is the amount of radiant energy absorbed by the atmosphere\n\na\u00f0l\u00de \u00bc Ml\nEi\n\n; (2.40)\n\nKirchhoff\u2019s law states that the absorptivity and emissivity are equal (a \u00bc e), while in thermody-\nnamic equilibrium the conservation of energy requires that\n\ne\u00fe s\u00fe r \u00bc 1: (2.41)\nReal emission spectra show some variations from Planck\u2019s law that represent the different atmo-\n\nspheric constituent contributions. An example is presented here in Fig. 2.31 for a typical surface\nemission.\n\nThe CO2 window is fairly wide revealing that it is rather well spread in the atmosphere as is water\nvapor. The ozone line is much narrower reflecting its variability in time and space.\n\nFIGURE 2.30\n\nReflected solar and outgoing longwave (infrared) radiation from the GOES satellite imager.\n\n76 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\n2.10 SURFACE REFLECTANCE: LAND TARGETS\nThe primary remote sensing signal from the land surface takes the form of reflected visible energy. The\namount and wavelength of reflectance depends on the character of the surface in terms of material and\nthe amount of water content. Some examples of this reflectance as a function of wavelength are\npresented here in Fig. 2.32 where different curves represent different surface features displaying\ndiffering reflectances as a function of wavelength.\n\nReflectivity depends on absorption and scattering mechanisms that take place within the material.\nThe absorption processes are electronic processes (absorption of a photon and reemission at a longer\nwavelength, i.e., heating), crystalline effects (atomic energy levels splitting the crystalline net, which\nalso depends on the concentration of a given type of ion), and absorptions by charge transfer (inter-\nelement transitions when a photon absorption causes the movement of an electron among ions).\nScattering depends on the type of mixture between the reflecting materials, and also on the grain size\nwhere the larger the grain size, the larger the light absorption, and the lower the reflectance.\n\nNotice that water bodies, either turbid or clear have relatively small reflectance in the shorter\nvisible wavelengths and no reflectance at the longer wavelengths. As it is clear in Fig. 2.32 the amount\nof reflectance from a water surface is restricted to the shorter visible and NIR wavelengths. This\nreflectance is also a function of the amount of suspended matter in the water with clear water having\nless reflectance than turbid waters. The reflectance also depends on the phase of the water with a\nmeasurable increase in reflectance with the presence of ice and the actual crystalline form of the ice.\n\nFIGURE 2.31\n\nEarth surface emissions spectrum showing water vapor, ozone and carbon dioxide windows (http://acmg.\n\nseas.harvard.edu/people/faculty/djj/book/bookchap7.html).\n\n2.10 SURFACE REFLECTANCE: LAND TARGETS 77\n\nhttp://acmg.seas.harvard.edu/people/faculty/djj/book/bookchap7.html\nhttp://acmg.seas.harvard.edu/people/faculty/djj/book/bookchap7.html\n\n\nTurbid waters lead to an increase in the visible reflectance which is the source of ocean color\nreflectance which has led to a whole new area of remote sensing of ocean color as an indicator of ocean\nprimary productivity. The color largely reflects the presence of chlorophyll in the ocean as represented\nby the green reflectance from the upper ocean. Other biologically active substances have different\nsignatures that complicate the ocean color signatures. Coastal waters with their sediment loads and\nfrequent ice components further complicate the mapping of ocean color signatures in the coastal\ndomain where the biological activity is generally most important.\n\nThis reflectance represents the characteristics of the upper few meters of the ocean rather than just\nthe upper few microns as is reflected by the thermal emissions responsible for the remote sensing of IR\nsea surface temperatures. Another element that strongly alters the reflectance in the visible range is the\namount of sediment content in the water. These features are only found in coastal regions usually\nassociated with river discharges.\n\nDry bare soil has a relatively high reflectance in the visible, which increases going to the longer\nwavelengths. Green vegetation has a small peak in the green portions of the visible band, but shows the\ngreatest reflectance in the NIR and midrange IR wavelengths.\n\nThe NIR reflectance can be used to discriminate between different types of vegetation such as\nconiferous and deciduous trees (Fig. 2.33). While both types of trees have very similar visible\nreflectances the coniferous trees do not attain as high values in the NIR beyond 0.7 mm as do the\ndeciduous trees. This is because the coniferous trees simply maintain the same level of leaf health\nthroughout the year while the deciduous trees go from a leaf-off stage in winter to a new and healthy leaf\nstage in summer. This increase in NIR reflectance dominates at the longer wavelengths near 0.9 mm.\n\nReflectance due to the presence of soil and rocks is moderate (r ? 0.3) depending on the amount of\nvegetation covering it. Soil grain size and surface roughness also influence the amount of reflectance\nand shift the reflectance to the longer midrange IR channels. The relative constancy of the soil\nsignature as compared to the two types of vegetation is seen in Fig. 2.34, which plots the spectral\nresponse of soil, dry and green vegetation reflectances as functions of wavelength.\n\nDry Bare Soil (Gray/Brown)\n\nVegetation (Green)\n\nWater (Clear)\n\nWater (Turbid)\n\nWAVELENGTH, ?m\n0.4\n0\n\n20\n\n40\n\n60\n\nR\nE\n\nF\nL\nE\n\nC\nT\nA\n\nN\nC\n\nE\n, \n%\n\n80\n\n100\n\n0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6\n\nAdapted from Remote Sensing \nand Image Interpretation. Lillesand\nand Kiefer. Reprinted with permission.\n\ncopyright  \u00a9 1987 by John Wiley\n\nand Sons. Inc.\n\nTM BANDS (?m)\n1 = .45-.52\n\n2 = .52-.60\n\n3 = .63-.69\n\n4 = .76-.90\n\n5 = 1.55-1.75\n\n7 = 2.08-2.35\n\n6 = 10.4-12.5\n\nFIGURE 2.32\n\nReflectance of various surfaces as a function of wavelength.\n\nFrom Hanel, R.A., Conrath, B.J., Kunde, V.G., Prabhakara, C., Revah, I., Salomonson, V.V., Wolford, G., 1972.\n\nThe Nimbus 4 infrared spectroscopy experiment: 1. Calibrated thermal emission spectra. J. Geophys. Res.\n\n77 (15), 2629e2641. http://dx.doi.org/doi:10.1029/JC077i015p02629.\n\n78 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\nhttp://dx.doi.org/10.1029/JC077i015p02629\n\n\n50\n\n40\n\n30\n\n20\n\n10\n\n0\n0.4 0.5 0.6 0.7 0.8 0.9\n\nWavelength (?m)\n\nDeciduous\ntrees\n\nConiferous\ntrees\n\nR\nef\n\nle\nct\n\nan\nce\n\n (%\n)\n\nFIGURE 2.33\n\nCanopy reflectance for coniferous and deciduous trees.\n\nGreen\nVegetation\n\nDry\nVegetation\n\nSoil\n\nWAVELENGTH (?m)\n\nR\nE\n\nFL\nE\n\nC\nTA\n\nN\nC\n\nE\n\n0.5\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n1.0 1.5 2.0 2.5\n\nFIGURE 2.34\n\nVegetation and soil reflectance spectra.\n\nAfter Clark, R.N., 1999. Spectroscopy of rocks and mineral, and principles of spectroscopy. In: Chapter 1: Manual of Remote\n\nSensing. U.S. Geological Survey, MS 964, Fig. 1.18.\n\n2.10 SURFACE REFLECTANCE: LAND TARGETS 79\n\n\n\nSoil and dry vegetation show similar linear increases with wavelength at the shorter wavelengths up\nto about 0.65 mm. At this point the soil reflectance curve begins to flatten out at about 0.25, while the\ndry vegetation continues to increase to a maximum of about 0.4 at 1.3 mm before it begins a gradual\ndecrease marked by a few minor subsequent maxima and minima, associated to the presence of water.\n\nOne of these at about 1.4 mm coincides with a major drop in the reflectance spectrum for green\nvegetation that has a maximum at about 0.8 mm. This peak follows a strong increase in reflectivity at\nabout 0.7 mm. The peak in green vegetation reflectivity is rather broad covering the wavelength range\nfrom 0.7 to 1.2 mm. This represents a response to the health of the mesophyll structure in the leaves.\nFollowing the drop at 1.4 mm the green vegetation curve has a secondary maximum between 1.7 and\n1.8 mm followed by a minimum at 1.9 mm. All three spectral curves exhibit a fall off towards the longer\nwavelengths.\n\nIce leads to a greater reflectance in the slightly longer wavelengths as shown here in Fig. 2.35. In\nthis figure the different curves correspond to different wavelengths of the EM spectrum that would be\nused to sense the surface properties.\n\nIce types in Fig. 2.35 range from ice blocks to fine frost and the reflectance exhibits a rather large\nrange. In curves aec there is a sharp drop-off in reflectance at about 1.5 and 2.0 mm due to the water\nabsorption.\n\n2.10.1 LAND SURFACE MIXTURES\nWhile it is nice to think of the surface as composite of various orthogonal surface types, that is again an\nabstraction. In reality the surface types are very mixed in space and time and any one scene needs to be\n\nFIGURE 2.35\n\nReflectance of ice as a function of wavelength, ice type and electromagnetic wavelength (grain sizes:\n\na \u00bc 50 mm, b \u00bc 200 mm, c \u00bc 400e2000 mm; http://speclab.cr.usgs.gov/PAPERS.refl-mrs/refl4.html).\n\n80 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\nhttp://speclab.cr.usgs.gov/PAPERS.refl-mrs/refl4.html\n\n\nthought of as a mixture of individual land cover types. In general, there are four types of mixtures.\nLinear mixtures where individual materials can be optically distinguished and there is no multiple\nscattering between components. Intimate mixtures where different materials are in close contact on a\nscattering surface. Depending on the optical properties of each component the resulting reflected\nsignal is a highly nonlinear combination of the end-member spectra. Coating occurs when one material\nlies over another. Both coatings are scattering/transmitting depending on the optical properties of the\nmaterial and the wavelength of radiation. Molecular mixtures occur on a molecular level such as a\ncombination of two liquids or a liquid and a solid mixed together. Examples are water absorbed onto a\nmineral or gasoline spilled onto soil.\n\nOne of the most challenging set of spectral features to distinguish between is those of various plant\nspecies. Fig. 2.36 shows four plant spectra (offset for clarity) with shapes that are very similar. If the\ncommon background (often called the continuum) is removed, the chlorophyll absorption spectra for\nthese and other plants can be seen in Fig. 2.37. Spectral shape matching algorithms such as those\ndiscussed in Clark et al. (1990) can discriminate between these spectra and compare them to spectral\nlibraries.\n\n2.11 STUDY QUESTIONS\n\n1. A blackbody at 350K emits radiation.\na. Determine the total radiance emitted by the object.\nb. Determine the radiance given off at a wavelength of 12 mm.\nc. Determine the wavelength and frequency of maximum emitted radiance.\nd. In which portion of the EM spectrum is this radiation?\n\n0.4\n\n0.6\n\nNugget Potato\n\nCanola\n\nOat Hay\n\nAlfalfa\n\n0.2\n\n0.0\n0.5 1.0\n\nWAVELENGTH (?m)\n\nR\nE\n\nFL\nE\n\nC\nTA\n\nN\nC\n\nE\n\n1.5 2.0 2.5\n\nFIGURE 2.36\n\nReflectance spectra of four types of vegetation. Each curve is offset by 0.05 from the one below.\n\nFrom Clark, R.N., 1999. Chapter 1: Spectroscopy of rocks and minerals, and principles of spectroscopy. In: Rencz, A.N. (Ed.),\n\nManual of Remote Sensing, Volume 3, Remote Sensing for the Earth Sciences, John Wiley and Sons, New York, pp. 3e58.\n\n2.11 STUDY QUESTIONS 81\n\n\n\n2. Another object at a temperature of 350K has an absorptance of 0.90. How much radiance is it\ngiving off at a wavelength of 12 mm?\n\n3. A disk of radius \u201ca\u201d is emitting radiation with intensity I0. The disk is observed from a point at a\ndistance \u201cz\u201d from the disk (the distance is measured from the center of the disk in a direction\nnormal to the plane of the disk). Show that in the case of a large distance \u201cz,\u201d the flux density to\nthe disk at the observation point is given by\n\nF \u00bc p$I0$a\n2\n\nz2\n.\n\n4. The atmosphere is found to have an absorption coefficient of 5 ? 106 m?1 and a scattering\ncoefficient equal to 1 ? 106 m?1. If the intensity of radiation entering a 10 km long section of\nthe atmosphere is given by I0, determine\na. The optical depth of the section of the atmosphere.\nb. The transmissivity of the section of the atmosphere.\nc. The intensity of radiation leaving the section of the atmosphere.\n\n5. A patch of ocean has a temperature of 25?C and an emissivity of 0.97 for radiation at a\nwavelength of 10 mm. Scattering may be neglected at this wavelength, but the atmosphere is\nconsidered to have an absorption coefficient of 5 ? 106 m?1. If the atmosphere is isothermal\nwith a temperature of 20?C, determine the brightness temperature measured by a radiometer\nflying in an airplane at an altitude of 5 km above the surface. Consider absorption and emission\nin the atmosphere, assume the atmosphere emits as a blackbody, and assume the radiometer\nsenses radiation only at a wavelength of 10 mm.\n\n0.55\n\nNugget Potato\n\nWAVELENGTH (?m)\n\nC\nO\n\nN\nTI\n\nN\nU\n\nU\nM\n\n R\nE\n\nM\nO\n\nV\nE\n\nD\n R\n\nE\nFL\n\nE\nC\n\nTA\nN\n\nC\nE\n\nOat Hay\n\nAlfalfa\n\nCanola\n\nNorkotah Potato\n\nPasture (Chico)\n\nPasture\n\nSpinach\n\n0.60 0.65 0.70 0.75\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nFIGURE 2.37\n\nContinuum-removed chlorophyll absorption for eight vegetation types (including the four from Fig. 2.36)\n\nshowing that the continuum-removed features can show subtle spectral differences.\n\nFrom Clark, T.L., 1995. Marshall Space Flight Center Electromagnetic Compatibility Design & Interference Control (MEDIC)\n\nHandbook. CDDF Final Report, Project No. 93e15.\n\n82 CHAPTER 2 BASIC ELECTROMAGNETIC CONCEPTS\n\n\n\n6. Which type of imager provides better sensitivity and why: a whisk-broom scanner or a push-\nbroom? Are there other advantages of one type in front of the other? Please provide examples of\nmissions using these types of scanners.\n\n7. A lidar transmits laser pulses and measures the light radiation scattered back, and collected by a\ntelescope. If the scattering is elastic (scattered radiation has the same wavelength as the\ntransmitted one), and the wavelength of operation is green, to which type of atmospheric\nconstituents it will respond? Why?\n\n8. In a lidar, if the received signal is too weak, the signal-to-noise ratio can be increased by (mark\nall that apply):\na. Increasing the transmitted power.\nb. Increasing the duration of the transmitted pulses.\nc. Increasing the aperture of the optical system (typically a telescope).\nd. Using a more sensitive photodetector.\n\n9. The microwave part of the spectrum is nearly transparent, except for some resonances around 22\nand 183 GHz, and 55e60 and 118 GHz, which are due to water vapor and oxygen. Will these\nbands be used for radar systems? Why?\n\n10. In the abovementioned bands the increased atmospheric attenuation translates into an increased\natmospheric emission. Which parameters can be inferred from?\n\n2.11 STUDY QUESTIONS 83\n\n\n\nOPTICAL IMAGING SYSTEMS 3\n3.1 PHYSICAL MEASUREMENT PRINCIPLES\nOptical remote sensing spans the range of electromagnetic wavelengths from the visible to the thermal\ninfrared (IR) making images from both reflected and emitted radiation from the Earth\u2019s surface and\noverlying atmosphere. The various types of surface and atmospheric targets that both reflect and emit\nradiation are summarized here in Fig. 3.1. Note that the arrows going to the spacecraft represent both\nreflected and emitted radiation.\n\nIn many cases the characteristics of the surface targets are such that they can be discriminated by\ntheir optical spectral signatures. Land surface targets are generally imaged with reflected radiation from\nvisible and near-IR wavelengths while the ocean\u2019s surface is usually imaged with the thermal IR since\nthe interest is more in the ocean\u2019s surface temperature which is related to the thermally emitted radi-\nation. In addition, the land does not retain heat the way the ocean does, so thermal imaging of the land\nsurface is not as meaningful as that from the ocean\u2019s surface. Since the 1980s the measurement of ocean\ncolor features has made it possible to use the narrow reflected bands to estimate chlorophyll and other\nrelated substances in the ocean. It should be emphasized here that the ocean biological parameters are so\n\nCHAPTER\n\nSatellite Incident\nSolar Radiation\n\nAtmosphere\n\nForest Grass Bare Soil\nPaved\nRoad Built-up Area\n\nSun\n\nReflected\nSolar Radiation\n\nFIGURE 3.1\n\nEarth surface targets for optical remote sensing (http://www.crisp.nus.edu.sg/wresearch/tutorial/optical.htm).\nLiew, S.C. Principles of Remote Sensing, Centre for Remote Imaging, Sensing and Processing, National University of Singapore.\n\nhttp://www.crisp.nus.edu.sg/~research/tutorial/rsmain.htm\n\nIntroduction to Satellite Remote Sensing. http://dx.doi.org/10.1016/B978-0-12-809254-5.00003-8\n\nCopyright \u00a9 2017 Elsevier Inc. All rights reserved.\n85\n\nhttp://www.crisp.nus.edu.sg/%7Eresearch/tutorial/optical.htm\nhttp://www.crisp.nus.edu.sg/%7Eresearch/tutorial/optical.htm\nhttp://www.crisp.nus.edu.sg/~research/tutorial/rsmain.htm\nhttp://dx.doi.org/10.1016/B978-0-12-809254-5.00003-8\n\n\nweak that a typical land sensor would \u201csee\u201d no gradients in the ocean. Also the ocean color signals are\nso weak that the measurements must be corrected for atmospheric attenuation, which is actually greater\nthan the ocean color signal itself, and is even made worse for increased surface roughness.\n\nLand targets range from bright surfaces such as roads, buildings, and parking areas to dark targets\nsuch as forests and crop fields ripe for harvest. In addition, land targets comprise bare soil, short grass,\nand shrubs. These surface subjects are again sensed by the reflected optical bands and require a high\nspatial resolution to discriminate important spatial changes in the nature of surface cover. Considerable\neffort has been spent in developing techniques to analyze images of the Earth\u2019s surface for different\ntypes of land cover and land use changes.\n\nVisible channel sensing of the ocean\u2019s surface has been restricted to the study of biological\nproductivity, which can only be sensed with narrowbands in the visible range of the EM spectrum.\nEven given these narrowbands the ocean primary productivity signal is so weak that it is masked by the\natmospheric attenuation of these reflected signals from the ocean\u2019s surface. To compensate for this\nattenuation a global reference is used to correct for the atmospheric component. This works quite well\nin the low-productivity waters of the open ocean, but fails in the complex waters of the productive\ncoastal regions known as case 2 waters. Here even the derived \u201cocean-color\u201d algorithms fail to perform\nwell against in situ calibration sources (Morel and Prieur, 1977).\n\nOne problem unique to ocean color measurements is \u201cSun glitter\u201d which is caused by sunlight\nreflecting in a specular fashion from certain ocean waves to the sensor. This direct specular reflection is\nmuch stronger than the normally reflected signal and it easily blots out the ocean color signal of\ninterest to the remote sensor. Since most of this Sun glitter is caused by the shortest ocean capillary\nwaves caused by winds, it can be estimated from the knowledge of the local wind field.\n\nOptical satellite sensors measure electromagnetic radiation in the visible through thermal IR\nportion of the spectrum as functions of location (x,y), time (t), and wavelength (l). There are two types\nof radiation sensors: (1) imagers and (2) nonimagers. The first make two- and three-dimensional\nimages of the target at a fixed wavelength or wavelength range. Nonimagers measure along the\nnadir, subsatellite track and stress wavelength and time resolution. This text focuses more on the\nimaging sensors and the images created.\n\nThese imaging sensors are generally referred to as \u201cradiometers,\u201d1 which are instruments that collect\nradiant energy using a variety of techniques. These radiometers have some methods to separate wave-\nlength contributions and quantify these various contributions with matched detectors. Some general\ndispersion methods used by radiometers to separate out the wavelengths are (1) prisms, (2) filter wheels,\n(3) grating spectrometers, and (4) interferometers. There are advantages and disadvantages associated\nwith each approach, which will be discussed individually.\n\n3.2 BASIC OPTICAL SYSTEMS\n3.2.1 PRISMS\nAs introduced in Chapter 1, Sir Issac Newton was the first to use a prism to separate white light into the\nvarious colors of the visible spectrum. This dispersion effect is attributed to the wavelength-dependent\nrefraction experienced by the light rays entering and exiting the prism (Fig. 3.2). The primary\n\n1Optical radiometers, as opposed to microwave radiometers. Usually the distinction optical versus microwave is dropped, as\nit is implicit by the context.\n\n86 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nadvantages of the prism as a dispersing element are its relative simplicity, synopticity, and reliability.\nThese advantages must be measured against the fact that prisms are heavy and cause a significant\nattenuation in radiative signal strength. Still for some applications the simplicity of operation along\nwith the reliability of function lead to the choice of a prism as the means of radiation dispersion in the\ndesign of a remote sensing instrument. These applications are generally infrequent as the weight\nlimitation of most spaceborne instruments precludes the use of prisms for wavelength dispersion.\n\n3.2.2 FILTER-WHEEL RADIOMETERS\nThe next simplest andmostwidely usedmethod ofwavelength separation is the filter-wheel radiometer. In\nthis type of radiometer, a \u201cwheel\u201d of radiative filters (Fig. 3.3) is cycled through the radiation path to\nseparate out the different wavelengths. In this diagram, optical lenses have been used while in most\nremote sensing applications radiometers are constructed with mirrors to save space and weight.\n\nMost of the other critical elements of filter-wheel radiometers are also shown in Fig. 3.3. This\nparticular filter-wheel radiometer makes precise measurements of radiometric temperature in the mid-\nand longwave IR bands. The reference blackbodies are traceable back to National Institute of Standards\nand Technology (NIST) standards. First there is a collector for the radiation, which is usually known as\nthe \u201cscan mirror\u201d which views the Earth target. Next comes the \u201cchopper\u201d which switches between the\nincoming radiation and the emitted radiation. The reference blackbody constitutes an internal calibration\nof the thermal IR channels. Next is a series of mirrors to focus the radiation and pass it through the filters\nfor further optical processing before it reaches the detectors where it is converted into an electrical signal.\nThis signal is amplified in a preamplifier before being transmitted further down the system. This diagram\nserves to demonstrate the positions and roles of most of the elements of a filter-wheel radiometer.\n\nAs a comparison a diagram of the scanning radiometer (SR), an early filter-wheel radiometer used\non the US polar orbiting Earth satellites is presented in Fig. 3.4. Here mirrors are used for all of the\noptical processing steps. The optical design uses a Cassegrain mirror arrangement to focus the\nradiation on the dichroic filter that separates out the longwave radiation from the shorter visible\nwavelengths. This Cassegrain mirror arrangement requires the radiation from the secondary mirror to\npass through a hole in the center of the primary mirror before going to the dichroic filter and detectors.\n\nCondenser\nEntrance Slit\n\nExit Slit\n\nFocal Plane\nfor SpectrumSource\n\nB\n\nA\n\nFe\nd E\n\nC t1\n\nt2\n\nD\n\nF\n\nF f\n\nB\n\nB?\n\nB?\n\nA?\n\nA?\n\nA?\n\nA?\n\n(n)\n\n?\n\n?+d?\n\nd?\n\nd?\n\n?\u2013??\n\n?\n\nd\n\nFIGURE 3.2\n\nA prism as a radiative dispersion element (Slater, 1980).\n\n3.2 BASIC OPTICAL SYSTEMS 87\n\n\n\nThe large scan mirror rotates at a constant angular speed collecting radiation from the Earth\u2019s surface\nover a portion of this scan. Radiation from this scan mirror is focused by the primary mirror onto the\nsecondary mirror, which then focuses the radiation through the dichroic on to the detector. A limit to\nthis amount of radiation hitting the detector is the field stop, which restricts the amount of radiation\nthat can hit the detector. This measured space allows only the wanted radiation in the center of the\nbeam to reach the detectors cutting off the weaker \u201cstray radiance\u201d surrounding the stronger central\ncore of the radiation.\n\nAlignment\nMirror\n\nPrimary\nMirror\n\nPhotodiode\n(Visible Light)\n\nField Stop\n\nDichronic\n\nField Stop\n\nBack Optics\nModule\n\nBolometer\n(Infrared)\n\nBottle\nTelescope\nHousing\n\nSecondary\nMirror\n\nAxis of\nRotation\n\nScan\nMirror\n\nFIGURE 3.4\n\nThe scanning radiometer, an early filter-wheel radiometer.\n\nCollimated\ninput beam\n\nVerification\nsource\n\nInterchangeable\nobjective lens\n\nFlip mirror Reflecting\nchopper wheel\n\nFilter wheel\n\nMirror\n\nLiquid nitrogen\ncooled\n\ndetector\n\nReference source\n\nFIGURE 3.3\n\nFilter-wheel radiometer (RAD-900 radiometer, http://www.optikos.com/products/rad-900/).\n\n88 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\nhttp://www.optikos.com/products/rad-900/\n\n\nIn this case the filter wheel is the dichroic. This uses an optical glass substrate over which 20e50 thin\n(typically, 1 mm thick) layers of a special refractive index dielectric material (or materials in certain\ncombinations) are deposited in a vacuum setup. This optical filter then selectively transmits a specific\nrange or band of wavelengths, while reflecting the rest with nearly zero absorptivity. These dichroic\nfilters can be either additive or subtractive color filters when operating in the visible range. Here a\nbolometer serves as the IR reference target instead of a pair of blackbodies usually used in higher\nprecision IR radiometers. A bolometer measures IR radiation using the thermal electric effect whereby\nthe incident thermal IR radiation increases the temperature which is then measured to estimate the value\nof the radiation. Again there is a field stop that limits the amount of the reference target that is viewed by\nthe radiometer.\n\nNote how the use of mirrors instead of lenses makes the optical \u201ctelescope\u201d a lot more compact.\nLenses require longer focal lengths, which can only be accommodated with longer optical bodies\nwhile mirrors can be located within close proximity to each other.\n\nThese two types of filter-wheel systems are shown here side-by-side in Fig. 3.5.\nIn addition to layer attenuation and chromatic aberration due to the wavelength dependence of the\n\nindex of refraction, lenses also suffer from spherical aberration when parallel light rays focus at\ndifferent points, depending on their distance to the optical axis of a spherical lens or mirror resulting in\na blurry image. Positive/negative spherical aberration occurs when the outer light rays bend too much/\nlittle and focus at shorter/larger distances than the focal length. This aberration can be reduced by\neither reducing the optical system aperture and/or increasing the focal length (Fig. 3.6).\n\n3.2.2.1 An Example: The Cloud Absorption Radiometer\nSince filter-wheel radiometers are so widely used a more detailed example of one such system is\ngiven here. The cloud absorption radiometer (CAR, http://car.gsfc.nasa.gov/subpages/index.php?\nsection\u00bcInstrument&content\u00bcSchematics) is designed to measure light scattered by clouds in 14\nspectral bands between 0.34 and 2.3 mm. The scan mirror, rotating at 100 rpm, directs the light into a\nDalleKirkham telescope where the beam is split into nine paths. Eight light beams pass through beam\nsplitters, dichroics, and lenses to individual detectors (0.34e1.27 mm), and finally are registered by\neight data channels, which are sampled simultaneously, and continuously. The ninth beam passes\nthrough a spinning filter wheel to a Stirling cycle cooler. Signals registered by the ninth data channel\nare selected from among six spectral bands (1.55e2.30 mm). The filter wheel can either cycle through\nall six spectral bands at a prescribed interval (usually changing filters every fifth scan line), or lock onto\nany one of the six spectral bands and sample it continuously.\n\nTheCARisacross-trackscannerwithascanmirror that rotates360 degrees in a plane perpendicular to\nthe direction of flight and the data are collected through a 190 degree field of view (FOV). In the normal\nmode of operation onboard the CV-580 aircraft, the CAR views 190 degrees of Earth-atmosphere scene\naround the starboard horizon. This configuration permits observations of both local zenith and nadir with\nas much as a 5 degree aircraft roll. In addition to the starboard viewing mode, the CAR instrument can\nnow be rotated in-flight into three other viewing positions: downward-looking imaging mode, upward-\nlooking imaging mode, and a dedicated bidirectional reflectance distribution function viewing mode.\n\nThe instrument incorporates several innovative features:\n\n1. Since it is sometimes flown through clouds, there is the possibility that moisture may be deposited\non optical surfaces, especially the scan mirror, producing large errors. The instrument is mounted\noutside the airplane and cannot be observed in flight. To check for water on the mirror, a unique\ndetection system was devised. A thin beam of light is shone on the edge of the mirror, and the\n\n3.2 BASIC OPTICAL SYSTEMS 89\n\nhttp://car.gsfc.nasa.gov/subpages/index.php%3Fsection%BCInstrument&amp;content%BCSchematics\nhttp://car.gsfc.nasa.gov/subpages/index.php%3Fsection%BCInstrument&amp;content%BCSchematics\n\n\nreflected beam is monitored by a photodiode. If any condensation appears on the mirror the\nreflected light scatters, reducing the photodiode\u2019s output and flagging data likely to be in error.\n\n2. Another novel feature maintains low offset (ensuring that zero volts at the output always\ncorrespond to a zero-radiance input) by using the scan mirror as a type of radiation chopper. It\nworks by forcing the electrical output to zero during each back scan while the detectors are all\ncompletely darkened by means of a scanner-synchronized moveable shutter. Long time constant\ncoupling in the amplifier then ensures that data measured during the active part of the scan\nremains accurately related to this zero reference level.\n\nA cutaway diagram of the CAR instrument in Fig. 3.7 shows the location of the filter-wheel\nhousing relative to the scan mirror, the primary and secondary mirrors. This instrument uses the\nsame Cassegrain optical design discussed earlier for the SR in Fig. 3.4. In this particular configuration,\nthis design is referred to as a DalleKirkham telescope (King et al., 1986).\n\nCollector\n\nSCAN MIRROR\n\n\u00b1 2.9\u00b0\n\nSECONDARY\n\nMIRROR\n\nFIBER BUNDLE\n\nENDS AT FOCUS\n\nDETECTORS\n\n(1 TO 24)\n\n24 VIDEO\n\nOUTPUTS\n\nSHUTTER\n\nWHEELPRIMARY\n\nMIRROR\n\n11.6\u00b0 VIEW\n\nTO EARTH\n\nReflective\n\nchopper\n\nFilter\n\nField stop\n\nField lens\n\nDetector\n\nPre-amp\n\nCalibration source\n\nElectronics\n\nDisplay\n\nrecord\n\n(A)\n\n(B)\n\nFIGURE 3.5\n\nExample lens (A) and mirror (B) filter-wheel radiometer systems.\n\n90 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nA blow-up of the optical system in Fig. 3.8 clearly shows the complexity of the filter-wheel with its\nsix positions and corresponding wavelengths.\n\nThe radiation having left the secondary mirror first passes through the defining field stop and then\nthrough a pair of specially designed dichroic beam splitters. The radiation reflected by the first dichroic\n(D1) enters branch I and is of wavelength range 0.34e0.87 mm. The radiation transmitted by D1 and\nreflected by D2 enters branch II where it is separated into three channels in a similar manner for filters\nin the 1.03e1.27 mm interval. The radiation transmitted by D2 enters branch III, where it is further\ndefined spectrally by a filter wheel containing six narrowband interference filters in the wavelength\nrange 1.55e2.30 mm.\n\n3.2.2.2 Filters\nThere are essentially two types of filters: (1) absorption or (2) interference. For filter wheels only\nabsorption lenses come into question. Filters can be designed to pass either long or short wavelengths,\nbut most filters for satellite sensors are band-pass filters and pass radiation only in relatively narrow-\nbands. These filters are characterized by their central wavelength and the short and long wavelength\ncutoff limits. The shape of the filter is also important and it is generally described by the half-width of the\ntransmission bandwidth that defines the spectral resolution of the filter and hence the radiometer. The\n\nFIGURE 3.6\n\nA perfect lens (top) focuses all incoming rays to a single point on the optic axis, but a real lens with spherical\n\nsurfaces (bottom) focuses different rays to different locations on the optic axis. This is known as spherical\n\naberration (https://commons.wikimedia.org/wiki/File:Spherical_aberration_2.svg).\n\n3.2 BASIC OPTICAL SYSTEMS 91\n\nhttps://commons.wikimedia.org/wiki/File:Spherical_aberration_2.svg\n\n\nfilter also attenuates the radiation passing through it, so some knowledge of its radiative efficiency is\nneeded to evaluate the filter\u2019s characteristics. This is usually given as the signal-to-noise ratio (SNR) for\nthe filter, which equals the band-pass energy/total energy outside the bandpass.\n\nThe colored absorption filters are either colored glass or dyed gelatin. The former has seen the\nwidest application due to their advantages of (1) freedom from strictions, (2) they are optically flat, and\n(3) the ease of laying out parallel surfaces. In this design, all layers are deposited on one substrate.\nTypically, the absorption filters are broader in shape as opposed to the interference filters that can be\ndesigned to be narrower (Fig. 3.9).\n\nThese filters may be either broad or narrow band-pass filters. These filters may also be high\nbandpass (selectively removes longer wavelengths) or low bandpass (absorbs shorter wavelengths).\n\n3.2.3 GRATING SPECTROMETER\nWhile the term spectrometer accurately applies to any system that separates radiation by wavelength, it\nhas been generally applied to the use of a grating to generate the interference pattern that separates the\nwavelengths (Fig. 3.10). Like the prism, this has the disadvantage that an array of detectors is needed\n\n41 \nCM\n\nELE\nCTR\n\nON\nICS\n\nCO\nMP\n\nAR\nTM\n\nEN\nT\n\nFILTER WHEEL\nHOUSING\n\nTELESCOPE\nPRIMARY\nMIRROR\n\nTELESCOPE\nSECONDARY\nMIRROR\n\nUP\nFORWARD\n\n72 CM\n\nInSb DETECTORASSEMBLY\n\n39 CM\n\nSCAN MIRROR\n\nFIGURE 3.7\n\nCutaway diagram of the cloud absorption radiometer instrument.\n\nImage modified by Gatebe and Gammage from King, M.D., Strange, M.G., Leone, P., Blaine, L.R., 1986. Multiwavelength\n\nscanning radiometer for airborne measurements of scattered radiation within clouds. J. Atmos. Oceanic Technol. 3, 513e522.\n\n92 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nto measure the radiation from the separated rays. As a result, grating spectrometers are generally large\nand expensive. While a slit grating is depicted in Fig. 3.10 a spaceborne system Fig. 3.11 generally\nuses a serrated mirror to generate the spectral dispersion. The amount of dispersion depends on the\nspacing of these angular serrations. The vast majority of master gratings are formed in one of two\nways: by mechanical ruling, in which a diamond is dragged across a metalized substrate to produce a\nseries of parallel grooves, or by interference methods, in which the fringe pattern formed by two\ncoincident laser beams exposed on a photosensitive blank, creating all grooves at once. The latter\nmethod produces gratings commonly termed \u201cholographic.\u201d Since making one high-quality master\ngrating can take weeks, without a replication process grating-based spectrometers would be\ncommercially available.\n\nLENS #31\nIR\n\nMIRROR\n\nBEAMSPLITTER\n\nBEAMSPLITTER\n\nBEAMSPLITTER\n\nBEAMSPLITTER\n\nBEAMSPLITTER\n\nPRIMARY MIRROR\n\nSECONDARY\nMIRROR\n\nFILTER\nLENS #23\n\nLENS #21\n\nLENS #22\n\nCONCENTRATOR LENS DETECTOR #1\n340nm\n\nDETECTOR #5\n872nm\n\nDETECTOR #7\n1219nm\n\nDETECTOR #8\n1273nm\n\nDETECTOR #6\n1036nm\n\nDETECTOR #4\n672nm\n\nDETECTOR #2\n380nm\n\nDETECTOR #3\n472nm\n\nLENS #14\n\nLENS #13\n\nLENS #2\n\nLENS #10\n\nLENS #15\n\nLENS #10\n\nLENS #30\n\nD2\n\nD1\n\nLENS #20\n\nDICHROIC\n\nAPERATURE\n5mm\n\nBRANCH I\n\nBRANCH II\n\nFILTER\n\nMIRROR M1\n\nINDIUM ANTIMONIDE\nDETECTOR ASSEMBLY\n(DETECTOR #9)\n\nMIRROR\nM2\n\nBRANCH III\n\nFILTER WHEEL\n1556nm\n1656nm\n1737nm\n2103nm\n2205nm\n2302nm\n\nSCHEMATIC ILLUSTRATION OF THE\nCLOUD ABSORPTION RADIOMETER OPTICAL SYSTEM\n\nFIGURE 3.8\n\nOptical system of the cloud absorption radiometer instrument.\n\nImage modified by Gatebe and Gammage from King, M.D., Strange, M.G., Leone, P., Blaine, L.R., 1986. Multiwavelength\n\nscanning radiometer for airborne measurements of scattered radiation within clouds. J. Atmos. Oceanic Technol. 3, 513e522.\n\n3.2 BASIC OPTICAL SYSTEMS 93\n\n\n\n400\n0\n\n20\n\n40\n\n60\n\n80\n\nTr\nan\n\nsm\nis\n\nsi\non\n\n (P\ner\n\nce\nnt\n\nag\ne)\n\nTr\nan\n\nsm\nis\n\nsi\non\n\n (P\ner\n\nce\nnt\n\nag\ne)\n\n100\n(A)\n\n(B)\n\nInterference Filter Characteristics and Nomenclature \n\nBroad Band Absorption Filter Spectra\n\nCenter Wavelength (CWL)\n\n500\n\nWavelength (Nanometers)\n\nWavelength (Nanometers)\n350\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n450 550 650 750\n\n600\n\nRed\nRegion\n\nFigure 1\n\nGreen\nRegion\n\nBlue\nRegion\n\nBlocking\nRange\n\nFigure 6\n\nFWHM\n\nPeak\nTransmittance\n\nLongpass\n\nAverage\nTransmittance\n\n50%\nCut-On\n\n50%\nCut-Off\n\nShortpass\n\n700\n\nFIGURE 3.9\n\nSpectral properties of interference (A) and absorption filters (B) (http://micro.magnet.fsu.edu/primer/java/\n\nfilters/absorption/).\n\nFrom OLYMPUS CORPORATION, http://www.olympus-lifescience.com/de/microscope-resource/primer/techniques/confocal/\n\ninterferencefilters/.\n\nENTRANCE\nSLIT\n\nSOURCE\nEMITTING\n3 LINES:\n?1,?2,?3\n\nZERO ORDER\n?1,?2,?3\n\n1ST ORDER\nSPECTRUM\n\n1ST ORDER\nSPECTRUM\n\n2ND ORDER\nSPECTRUM\n\nCOLLIMATOR\nLENS\n\nGRATING\nSPACING\n\nd\nFOCUSING\n\nLENS\n\n?1\n\n?i ?d\n?1\n\n?1\n\n?2\n\n?2\n\n?2\n\n?3\n\n?3\n\n?3\n\nFIGURE 3.10\n\nGrating spectrometer dispersion system (Slater, 1980).\n\nhttp://micro.magnet.fsu.edu/primer/java/filters/absorption/\nhttp://micro.magnet.fsu.edu/primer/java/filters/absorption/\nhttp://www.olympus-lifescience.com/de/microscope-resource/primer/techniques/confocal/interferencefilters/\nhttp://www.olympus-lifescience.com/de/microscope-resource/primer/techniques/confocal/interferencefilters/\n\n\nThe primary advantage of this type of a spectrometer is the truly synoptic separation of the\nradiation wavelengths also with a very precise definition of the wavelength separation set by the\ngrating spacing (Fig. 3.11). The primary disadvantage of this system is the complex detector array\nrequired to sense this synoptic picture. This complex detector array also leads to the reality that a\nfailure of any element of the detector array eliminates the radiation that belonged to this part of the\nspectrum. This fact together with the high-cost, complexity, and weight are often reasons that this\noption is not selected for satellite instrumentation applications.\n\n3.2.4 INTERFEROMETER\nA final technical approach to dispersion of the radiation wavelengths is in terms of an interferometer\nsuch as the FabryePerot system depicted here in Fig. 3.12 (Slater, 1980). In this instrument the\ndispersion mechanism is created by the spacing between the two \u201cFabryePerot\u201d mirrors. This spacing\nis stepped through a variety of intervals to separate out the desired wavelength signals.\n\nThe advantages of this type of wavelength dispersion system are that it has a very simple operation\nwhere only the spacing between the mirrors needs to be changed. This allows for a semi-infinite\nwavelength separation at the expense of a finite time between the wavelength samples. It also\nrequires a simple detector system with a detector located only at the aperture point.\n\nFIGURE 3.11\n\nTwo common groove patterns used for\n\ngratings.\n\nEXTENDED\nSOURCE\n\nCOLLI-\nMATOR\n\nFABRY-PEROT\nMIRRORS FOCUSING\n\nLENS FRINGE\nPATTERN\n\nAPERTURE\n\np+1\np\n\np+2\n\nFIGURE 3.12\n\nA FabryePerot interferometer (Slater, 1980).\n\n3.2 BASIC OPTICAL SYSTEMS 95\n\n\n\nThe main disadvantage of this technique is the finite amount of time it takes to sample each\nwavelength, resulting in less than a truly synoptic sample of all of the wavelengths of interest, and the\nsignal attenuation since it involves a number of mirrors and lenses. Additionally, the detector must be\ncapable of responding to a wide range of wavelengths rather than being optimized for a particular\nwavelength as in the spectrometer. The relative simplicity of this system makes it attractive relative to\nthe spectrometer, but it is much more complex than the filter-wheel radiometer.\n\n3.3 SPECTRAL RESOLVING POWER; THE RAYLEIGH CRITERION\nSpectral resolving power is given by l/dl, where l is the wavelength and dl is the minimum wave-\nlength separation. The \u201cRayleigh criterion\u201d is satisfied when a minimum of the diffraction pattern of\none image coincides with the maximum of another. Thus, the maximum spectral resolving power is\nproportional to the maximum optical path difference introduced in the beam or simply said the\nRayleigh criterion specifies the minimum separation between two light sources for them to be resolved\ninto two distinct objects. If the distance is greater, the two points are well resolved and if it is smaller\nthey are regarded as not resolved (Fig. 3.13).\n\nThe central region of the profile, from the peak to the first minimum, is called the Airy disk and its\nangular radius is given by:\n\nD$sinqz 1:22$l; (3.1)\n\nwhere D \u00bc 2$a is the diameter of the aperture and l is the electromagnetic wavelength. Using the\nsmall angle approximation that sinqz q (where q is measured in radians):\n\nqz 1:22l=D.\n\nFor the grating spectrometer the diffraction limit for a diffraction grating is given by:\n\nR \u00bc N$m; (3.2)\nwhere N is the number of ruled lines (or slits) being illuminated in a grating (or grooves in a space\nborne instrument), andm is the order of diffraction (m \u00bc 0, 1, 2, 3.). For the grating, the total widthW\nis effectively limited to the width of the ruled region of the diffraction grating, since this is fully\nilluminated by the optical beam.\n\nFIGURE 3.13\n\nResolved and unresolved wavelengths versus the Rayleigh criterion.\n\n96 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nFor a prism this diffraction limit is the base length times the refractive index, which can be written\nas:\n\nRprism \u00bc B$\n????dmdl\n\n????; (3.3)\nwhere B is the length of the base of the prism (the side opposite the apex) and dm/dl the rate of change\nof the refractive index m with respect to wavelength l. The refractive index of a prism at a given\nwavelength may be found by geometrical considerations from the angle of minimum deviation dmin for\nthat wavelength:\n\nn \u00bc\nsin\n\n?\n1\n\n2\n\u00f0A\u00fe dmin\u00de\n\n?\n\nsin\n\n?\n1\n\n2\nA\n\n? (3.4)\nwhere A is the apex angle of the prism. It is not possible to write a simple relationship between dmin and\nl as this depends on the precise material the prism is made of and how it is cut.\n\nFor the interferometer the distance between the reflecting surfaces gives this resolving power.\nfound in modern satellite sensors with an increasing trend to achieve an increased spectral resolution\nusing spectrometer and interferometers in spite of the increase in complexity of the optical systems.\nThere is also a trend to require more channels than those that can easily be accomplished with the\nsimple filter-wheel radiometer.\n\nA nice summary of the role of the diffraction limit as applied to spatial resolution is given in\nFig. 3.14, which is a logelog plot of aperture diameter versus angular resolution at various wave-\nlengths. Also shown are various astronomical instruments at their operational wavelengths. It is\ninteresting to note that the Hubble Space Telescope is almost diffraction limited at 0.1 arcsec as\nindicated by the blue star in the figure. The colored bands correspond to different wavelength bands\nused for remote sensing of various targets. The various apertures of different telescope systems are also\nincluded in this figure. Please note the change in units used to describe the different apertures since\nsome earlier instruments were built to inch specifications rather than meters.\n\n3.4 DETECTING THE SIGNAL\nThe next step is to get the spectrally separated radiation to appropriate detectors. This can be done\nthrough lenses or by detector positioning or, in the case of the multispectral scanner (MSS) and other\nsensors, by channeling radiation in specific ranges to fiber optics bundles that carry the focused\nradiation to an array of individual detectors. For the MSS, this involves six fiber optic leads for the six\nlines scanned simultaneously to six detectors for each of the four spectral bands, or a total of 24\ndetectors in all.\n\nOnce the radiation reaches the photodetector, assuming that all variables are constant within the\nspectral width (Dl), the output voltage (V0) is given by:\n\nV0 \u00bc Li\nG#\n\n$Adet$?l$R; (3.5)\n\nwhere Li is the incoming radiance reaching the sensor, Adet is the area of the photodetector which is\nrelated to the photodetectors\u2019 dimension (Adet \u00bc l2det), ?l is the spectral width, R is the photodetector\u2019s\n\n3.4 DETECTING THE SIGNAL 97\n\n\n\nresponsivity, that relates the output voltage and the input optical power (units [V/W]), G# is the \u201cG\nnumber\u201d (units of [strad?1]) which is related to the inverse of the FOVof the optical system,2 and it is\ndefined as:\n\nG# z\n1\u00fe 4$F2#\nsopt$p\n\n; (3.6)\n\nFIGURE 3.14\n\nLogelog plot of aperture diameter versus angular resolution at the diffraction limit for various light wavelengths\n\nfor various astronomical instruments. For example, the blue star shows that the Hubble Space Telescope is\n\nalmost diffraction limited in the visible spectrum at 0.1 arcsec.\n\n2Not to be confused with the instantaneous field of view as seen by the photodetector that depends on its physical size (Idet),\nand it is approximately given by IFOVzIdet=f .\n\n98 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nwhere sopt is the transmissivity of the optical system, and F# is the \u201cF number\u201d defined as the ratio of\nthe focal length (f) and the aperture (D) of the optical system:\n\nF# \u00bc f\nD\n. (3.7)\n\nMost detectors are made of solid-state semiconductors, metals, or alloys. A semiconductor has a\nconductivity intermediate between a metal and an insulator. Under certain conditions, such as the\ninteraction with photons, electrons in the semiconductor are excited and moved from a filled energy\nlevel (in the electron orbital configuration around an atomic nucleus) to another level called the\nconduction band, which is deficient in electrons in the unexcited state. The resistance to flow varies\ninversely with the number of incident photons. The process is best understood by quantum theory.\nDifferent materials respond to different wavelengths and are thus spectrally selective.\n\nIn the visible light range, silicon and PbO are common detector materials. Photoconductor material\nin the near-IR includes PbS (lead sulfide) and InAs (indium-arsenic). In the mid-IR (3e6 mm), InSb\n(indium-antimony) is responsive. The most common detector material for the 8e14 mm range is\nHg-Cd-Te (mercury-cadmium-tellurium). When the infrared sensors are operating it is necessary to\ncool the detectors to optimize the efficiency of electron release. Other detector materials are also used\nand perform under specific conditions. In Fig. 3.15 we show the photodetector specific detectivity (D*)\nas a function of the wavelength, which is defined as:\n\nD?\u00f0l\u00de \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nAphotodetector$B\n\np\nNEP\u00f0l\u00de\n\n?\ncm\n\nffiffiffiffiffiffi\nHz\n\np \t\nW\n\n\n. (3.8)\n\nThe specific detectivity is a figure of merit of the photodetectors\u2019 noise performance that allows us\nto compare them independently of their area (Aphotodetector) and bandwidth (B). The NEP is the\n\nFIGURE 3.15\n\nThe sensitivity of various detector materials as functions of wavelength.\n\nImage courtesy of Teledyne Judson technologies. http://www2.chem.uic.edu/tak/chem52413/notes8/notes8_13.pdf.\n\n3.4 DETECTING THE SIGNAL 99\n\nhttp://www2.chem.uic.edu/tak/chem52413/notes8/notes8_13.pdf\n\n\nso-called noise equivalent power and it is defined as the ratio of the noise at the output, divided by the\nphotodetector\u2019s responsivity R.\n\nFor the typically used photodiodes, the NEP can be computed as the ratio of the standard deviation\nof the dark current and the intrinsic responsivity:\n\nNEP \u00bc sdarkness\nRi\n\n\u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2q\u00f0Ids \u00fe F$M2$Idb\u00de$B\n\np\nh$\n\nq$l\n\nc$h\n$M\n\n; (3.9)\n\nwhich depends on a number of physical parameters of the device. These are the dark current3 that\ncirculates through the surface (Ids) or through the volume (Idb), h is the quantum efficiency (ratio of\nelectrons reaching the output of the semiconductor divided by the number of electroneholes pairs\ngenerated by the incoming photons), and the multiplication factor (M), which is equal to M \u00bc 1 for a\nphotodiode, andM > 1 for an avalanche photodiode. The term F is called the excess noise factor and it\nis equal to\n\nF \u00bc k$M \u00fe\n?\n2? 1\n\nM\n\n?\n$\u00f01? k\u00de; (3.10)\n\nwith k z 0.0033, and accounts for the extra noise generated during the avalanche process that\nproduces the amplification (M).\n\nOther detector systems are less commonly used in remote sensing function in different ways. The\nlist includes photoemissive, photodiode, photovoltaic, and thermal (absorption of radiation) detectors.\n\n3.5 VIGNETTING\nVignetting is a \u201cfact of life\u201d for all optical systems and consists of a darkening of the corners of an\nimage relative to the center of the image (Fig. 3.16). There are three types of vignetting that are\ncharacteristic of any optical systems, which are mechanical vignetting, optical vignetting, and natural\nvignetting. For digital systems there is an additional pixel vignetting.\n\nMechanical vignetting occurs when light beams emanating from object points located off-axis are\npartially blocked by external objects such as thick or stacked filters, secondary lenses, and improper\nlens hoods. The corner darkening can be gradual or abrupt, depending on the lens aperture (Fig. 3.17).\nComplete blackening is possible with mechanical vignetting.\n\nOptical vignetting is caused by the physical dimensions of a multiple element lens. Rear elements\nare shaded by elements in front of them, which reduces the effective lens opening for off-axis incident\nlight. The result is a gradual decrease of the light intensity towards the image periphery. Optical\nvignetting is sensitive to the aperture and can be completely cured by stopping down the lens. Two or\nthree stops are usually sufficient.\n\nUnlike the previous types, natural vignetting (also known as natural illumination falloff) is not due\nto the blocking of light rays. The falloff is approximated by the cos4 or \u201ccosine fourth\u201d law of\nillumination falloff. Here, the light falloff is proportional to the fourth power of the cosine of the angle\n\n3Dark current refers to the current that circulates in the absence of incoming light to generate pairs of electroneholes.\n\n100 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nat which the light impinges on the film or sensor array. Wide-angle rangefinder designs and the lens\ndesigns used in compact cameras are particularly prone to natural vignetting. Telephoto lenses, retro\nfocus wide-angle lenses used on SLR cameras, and telecentric designs in general are less troubled by\nnatural vignetting. A gradual gray filter or postprocessing techniques may be used to compensate for\nnatural vignetting, as stopping down the lens cannot cure it.\n\nFIGURE 3.16\n\nAn example of vignetting in a photograph.\n\nFIGURE 3.17\n\nAn example of mechanical vignetting.\n\n3.5 VIGNETTING 101\n\n\n\nPixel vignetting only affects digital systems and is caused by angle dependence of the digital\nsensors. Light incident on the sensor at a right angle produces a stronger signal than light hitting it at an\noblique angle. Most digital cameras use built-in image processing to compensate for optical vignetting\nand pixel vignetting when converting raw sensor data to standard image formats such as JPEG or TIFF.\nThe use of microlenses over the image sensor can also reduce the effect of pixel vignetting.\n\n3.6 SCAN GEOMETRIES\nVarious kinds of scan geometries have been used to collect the radiation in these optical instruments.\nThe simplest is a cross-track scanner, which consists of a rotating mirror (Fig. 3.18A) that rotates at a\nconstant rate synchronized with the orbit of the satellite so that it increments the image each scan line.\n\nHere the angular FOV represents the cross-track scan across the ground. As it will be discussed\nlater, the rest of the mirror rotation is used to measure reference values such as a cold-space reference\ntemperature as well as two blackbody targets one at ambient temperature and one at a controlled\ntemperature for calibration purposes.\n\nThere are two types of mirror cross-track scanners: one that uses a mirror constantly rotating mirror\n(in the same sense) as depicted in Fig. 3.18A, while the other uses an optical system that oscillates back\n\nScan\nDirection\n\nScan\nDirection\n\nLens\n\nFocal\nPlane\n\nDetector\nArray\n\nGround\nResolution\n\nCell\n\nGround\nResolution\n\nCells\n\nAngular\nField\n\nof View\n\nDetector\n\nInstantaneous\nField\n\nof View\n\nRotating\nScan\nMirror\n\nMotor\n\n CROSS\u2013TRACK SCANNER.  ALONG\u2013TRACK SCANNER.\n\n(A) (B)\n\nFIGURE 3.18\n\n(A) Cross-track rotating mirror scanner. (B) Push-broom along-track scanner.\n\n102 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nand forth across the scan line. The latter is called a whisk-broom scanner and these cross-track\nscanners all rely on the forward motion of the spacecraft to increment the image one line at a time.\n\nAnother type of scanner samples the entire line at the same time using a cross-track array, which is\ncalled a \u201cpush-broom\u201d scanner (Fig. 3.18B). This configuration has the advantage that the samples are\ntruly synoptic across the track. This has become a very popular method for optical sensor design. The\ntype of cross-track scanner that oscillates back and forth across the track (Fig. 3.19) is the type of\nscanning mechanism using by the MSS, which flew on the Landsat series of satellites.\n\nThe more recent imager on Landsat is called the \u201cThematic Mapper (TM)\u201d and produces a \u201cbow-\ntie\u201d effect on the scan as the satellite progresses along its track (Fig. 3.20). This effect compensates\nfor the satellite movement as the line is scanned so that all lines are parallel, and perpendicular to the\nsatellite ground track. While this effect requires additional image correction, it has the added benefit\nthat this system increases the integration time since the mirrors do not have to rotate as fast as they did\nin the MSS.\n\nFinally, there is a conical along-track scan configuration (Fig. 3.21).\nThis scan mechanism has the advantage of viewing the same spot on the Earth twice in rapid\n\nsuccession if the scan axis is not oriented strictly perpendicular to the ground track of the satellite. This\nis the scan method used in the along-track scanning radiometereinfrared radiometer on board the\nEuropean Space Agency\u2019s (ESA) ERS-1/2 satellites (ATSR-IRR; Fig. 3.22). The principle of removing\natmospheric effects in measurements by viewing the sea surface from two angles is the basis of the\n\nFIGURE 3.19\n\nWhisk-broom scanning on Landsat multispectral scanner (from Fig. 6.10 of [Schott, 2007]).\n\n3.6 SCAN GEOMETRIES 103\n\n\n\nfamily of (A)ATSR instruments. The sea surface temperature (SST) objectives are met through the use\nof thermal IR channels (centered on 1.6, 3.7, 10.85, and 12 mm), identical to those on ATSR 1 and 2.\nAtmospheric modeling for ERS-1 has shown that ATSR, with its thermal IR channels and two-angle\nviewing geometry (55 and 0 degree incidence angles in the fore and aft swaths), can achieve a global\naccuracy in SST better than 0.5K.\n\nThis same scan geometry is also being widely used in passive microwave imagers as it will be\ndiscussed later.\n\nAs an example of the Landsat series, we will look at the TM instrument as shown here in Fig. 3.23.\n\nFIGURE 3.20\n\nBow-tie scanner Landsat Thematic Mapper (from Fig. 6.11, 6.12 and 6.13 of [Schott, 2007]).\n\n104 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nThis sensor is mounted in the Landsat spacecraft in a horizontal position with the sunshade pointing\ntoward the Earth. Directly above the sunshade is the scan mirror surrounded by its drive mechanisms,\ncontrol electronics, and scan mirror hardware. The TM IFOV is 42.5 mrad, which equates to a ground\nresolution of 30 m. The band ranges and their science applications are given here in Table 3.1.\n\nThe temporal resolution of the TM, which has been flying since 1983, is approximately 15 days. As\nshown in Table 3.1 the TM has seven spectral bands including a rather broad thermal IR channel\nbetween 10.4 and 12.5 mm. The higher spatial resolution (w30 m) makes it possible to more accu-\nrately map surface features such as vegetation cover. Landsat TM has proven to be particularly useful\nin the study of surface expressions of geologic formations which do not change significantly within the\n15-day repeat sample of the TM.\n\nDirection of\nmovement\n\nSwath\nwidth\n\nArea\nscanned\n\nFIGURE 3.21\n\nConical scan.\n\n47\u00b0\n\n50\n0 k\n\nm\n8 \n\nkm\n\nSub\n-Sat\n\nellite\n Tra\n\nck\n\n500 km\n\nFlight\nDirection\n\nFIGURE 3.22\n\nScan geometry of the conical along-track scanning radiometer.\n\n3.6 SCAN GEOMETRIES 105\n\n\n\nThe latest in the Landsat series is Landsat 8 also known as the Landsat Data Continuity Mission\n(LDCM). Unlike its predecessors it carries the Operational Land Imager (OLI), a new instrument built\nby Ball Aerospace. The OLI is a push-broom scanner that has a focal plane with long arrays of\nphotodetectors (Irons and Dwyer, 2010). A four-mirror anastigmatic telescope focuses incident\n\nFIGURE 3.23\n\nThe Landsat Thematic Mapper sensor (https://eoportal.org/documents/163813/2855045/LS4-5_Auto2.jpeg).\n\nTable 3.1 Landsat Thematic Mapper Bands and Their Applications\n\nBand Number Pixel Size Spectral Range NEDr Application\n\n1 30 ? 30 m 0.45e0.52 mm 0.8% Shore water mapping\nBare soil-vegetation mapping\n\nDeciduous-coniferous vegetation\nmapping\n\n2 30 ? 30 m 0.52e0.60 mm 0.5% Vegetation health\n3 30 ? 30 m 0.63e0.69 mm 0.5% Vegetation classification\n4 30 ? 30 m 0.76e0.90 mm 0.5% Biomass studies\n\nWater contours delimitation\n\n5 30 ? 30 m 1.55e1.75 mm 1.0% Cloudsesnow differentiation\nWater content determination\n(vegetation, soil)\n\n6 120 ? 120 m 10.40e12.50 mm 0.5K Temperature\nVegetation health\n\n7 30 ? 30 m 2.08e2.35 mm 2.4% Water temperature\nMineral and oil geology\n\n106 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\nhttps://eoportal.org/documents/163813/2855045/LS4-5_Auto2.jpeg\n\n\nradiation onto the focal plane while providing a 15 degree FOV covering a 185 km across-track ground\nswath from the nominal LDCM observatory altitude (Fig. 3.24). Periodic sampling of the across-track\ndetectors as the observatory flies forward along a ground track forms the multispectral digital images.\n\nThe detectors are divided into 14 modules arranged in an alternating pattern along the centerline of\nthe focal plane (Fig. 3.25). Data are acquired from nearly 7000 across-track detectors for each spectral\nband with the exception of the 15 m panchromatic band that requires over 13,000 detectors. The\nspectral differentiation is achieved by interference filters arranged in a \u201cbutcher-block\u201d pattern over the\n\nFIGURE 3.24\n\nDrawing of the Operational Land Imager.\n\nCourtesy of Ball Aerospace.\n\nFIGURE 3.25\n\nDrawing of the Operational Land Imager focal plane.\n\nCourtesy of Ball Aerospace.\n\n3.6 SCAN GEOMETRIES 107\n\n\n\ndetector arrays in each module. Silicon PIN (SiPIN) detectors collect the data for the visible and near-\nIR spectral bands (Bands 1e4 and 8) while magnesiumecadmiumetelluride (MgCdTe) detectors are\nused for the shortwave IR bands (bands 6, 7, and 9).\n\nThe OLI telescope views the Earth through a baffle extending beyond the aperture stop. A shutter\nwheel assembly sits between the baffle and the aperture stop. A hole in the shutter wheel allows light to\nenter the telescope during nominal observations and the wheel rotates when commanded to a closed\nposition and acts as a shutter preventing light from entering the instrument. A second baffle, for solar\nviews, intersects the Earth-view baffle at a 90-degree angle and a three-position diffuser wheel\nassembly dissects the angle. A hole in the diffuser wheel allows light to enter the telescope for nominal\nEarth observations. Each of the other two wheel positions introduces one of two solar diffuser panels to\nblock the optical path through the Earth-view baffle. When the wheel is in either of these two positions,\nthe solar-view baffle points at the Sun and a diffuser panel reflects solar illumination into the telescope.\nOne position will hold a \u201cworking\u201d panel that is exposed regularly to sunlight while the other position\nholds a \u201cpristine\u201d panel that is exposed infrequently and used to detect changes in the \u201cworking\u201d panel\nspectral reflectance due to solar exposure. Additionally, two stimulation lamp assemblies are located\njust inside the telescope on the aperture stop. Each of the two assemblies holds six small lamps inside\nan integrating hemisphere and is capable of illuminating the full OLI focal plane through the telescope\nwith the shutter closed. These assemblies, the shutter wheel, diffuser wheel, and stimulation lamp\nassemblies, constitute the OLI calibration subsystem.\n\n3.7 FIELD OF VIEW\nThe FOVof an optical instrument is dictated by the wavelength of interest, and the angular resolution\nof the sensor optics. In terms of a digital camera, the FOV refers to the projection of the image on to the\ncamera\u2019s detector array, which also depends on the camera lens\u2019 focal length. Hence the FOV (also\ncalled the field of view) is the angular extent of the observable world that is seen at any given moment.\nHumans have an almost 180 degree forward-facing FOV, while some birds have a complete or nearly\ncomplete 360 degree FOV. In addition, the vertical range of the FOV may vary. The range of visual\nabilities is not uniform across an FOVand varies from animal to animal. For example, binocular vision,\nwhich is important for depth perception, only covers 140 degrees of the field of vision in humans; the\nremaining peripheral 40 degrees have no binocular vision (because of the lack of overlap in the images\nfrom either eye for those parts of the FOV). The aforementioned birds would have a scant 10 or\n20 degrees of binocular vision.\n\nAngular FOV is typically specified in degrees, while linear FOV is a ratio of lengths. For example,\nbinoculars with a 5.8 degree FOV might be advertised as having a (linear) FOV of 305 ft per 1000\nyards or 102 mm per meter.\n\nIn terms of satellite remote sensing the instantaneous FOV (IFOV) angular resolution has a lower\nlimit set by the diffraction limit which is l/D, where l is the wavelength and D is the diameter of the\nfirst target (lens or in the case of most satellite instruments the primary sensor mirror). Hence translated\nto ground resolution, assuming a flat Earth, the minimum IFOV at normal incidence is:\n\nIFOVminz l$\nH\n\nD\n; (3.11)\n\nwhere H is the satellite height above the surface or the altitude. There is of course a relationship\nbetween the ground resolution, the satellite velocity, and the sampling time of the sensor. Thus, for a\n\n108 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nscanning sensor this limits the sampling time as a function of the satellite\u2019s orbit. For a push-broom\nconfiguration the scan line is collected simultaneously thus increasing the exposure time, but with\nthe disadvantage that each sensor must be calibrated separately.\n\n3.8 OPTICAL SENSOR CALIBRATION\nThere are two types of calibration that are important for optical and other types of satellite sensors.\nFirst there is an intensive prelaunch calibration and characterization intended to give the users of these\ndata the best possible connection between the sensor radiation measurements and the FOV. Second,\nsince all sensors degrade and drift with time and temperature, there is a need for a periodic calibration\nafter the sensor has been launched in to orbit.\n\nHere it is impossible to carry out the laboratory and controlled experiments used in the prelaunch\nconfiguration so a system referred to as \u201cvicarious calibration\u201d has been introduced. In this type of\ncalibration, very uniform Earth targets are identified and field campaigns are conducted to measure and\nmonitor the surface conditions that are coincident with the radiative measurements made by the satellite\nsensors. This assumes, of course, that the atmosphere is very clear and does not introduce any additional\nerrors to this type of vicarious calibration.\n\nPrelaunch calibration procedures and methods are first discussed, and then vicarious calibration\napproaches are introduced and discussed. The goal of all calibration efforts is to set and maintain over\ntime the relationship between the satellite radiances and the in situ property being measured. Without a\nproper calibration, sensor radiance measurements are just numbers without any meaningful relationship\nto an in situ property or parameter.\n\n3.8.1 VISIBLE WAVELENGTHS CALIBRATION\nShort visible wavelengths are calibrated with an \u201cintegrating sphere\u201d which is designed to create a\nhollow cavity with very high diffuse reflectivity, which generates a known uniform light condition that\ncan be measured with the radiometer as part of its calibration (http://www.electro-optical.com/\ndatashts/visible/ivs400.html). Also known as an Ulbricht sphere, the integrating sphere usually\nmounts a number of different light sources around its surface, which can be turned on or off to control\nthe light intensity and frequency. The interior surface of the sphere is coated with white material that is\nnearly a Lambertian reflector creating a uniform diffuse reflectance of the interior lights that is then\nviewed by the radiometer through a view port through the sphere.\n\nAs an example the ISV400 is presented here, which is a compact, reliable, and easy to operate\nsystem specifically designed for test and calibration of detectors and sensor systems which respond in\nthe visible light spectrum. It incorporates a 1200 diameter integrating sphere with a 400 diameter exit port\n(Fig. 3.26). The interior is coated with barium sulfate to provide a uniform and Lambertian luminance\nwithin the sphere. Illumination is provided by four quartz halogen lamps whose variable output uses a\nclosed loop control sensor and output attenuator to provide ease of use and stability. All four lamps are\ncalibrated to a NIST traceable color temperature of 2950 ? 25K.\n\nA silicon detector continuously monitors the output of the lamps and provides feedback to the\nattenuator, providing a very stable and repeatable performance. Control electronics and lamp power\nsupplies are built in to a 5.2500 high, 1900 rack mount unit. Operation of the unit is from the front panel\nkeypad or via the built-in IEEE-488 and RS-232 computer interfaces.\n\n3.8 OPTICAL SENSOR CALIBRATION 109\n\nhttp://www.electro-optical.com/datashts/visible/ivs400.html\nhttp://www.electro-optical.com/datashts/visible/ivs400.html\n\n\nIntegrating spheres have played fundamental roles in the prelaunch calibration of a number of\nsensors such as the advanced very high resolution radiometer (AVHRR), the ATSR, Moderate Res-\nolution Imaging Spectroradiometer, Sea-viewing Wide Field-of-view Sensor, Landsat TM, and\nextended TM, and many others. As discussed in Gatebe et al. (2007), there are known problems\ninherent in the use of integrating spheres for instrument calibration. Quoting Hovis and Knoll (1983),\nthe spectral irradiance from the sphere and the Sun peaks at different wavelengths (w805 and 550 nm,\nrespectively). This causes a problem for instruments designed to look at the Earth in that calibration\nbetween these two wavelengths is done with different radiance shapes from the sphere and the Sun.\n\nIn the calibration of the CAR discussed earlier a series of integrating sphere sources (ISSs) were\nused at different light levels as determined by the number of lamps used (from 0 to 16). This test helped\nto establish the linearity of the instrument over its performance range and to give the full range of\nconversion from digital counts to radiance (Fig. 3.27).\n\nA second test involved measuring the responsivity of the CAR (defined here as detector output per\nunit if incident power at a particular wavelength) at more than nine distances from the ISS aperture.\nThis test ascertained the sensitivity of the calibration to the distance of separation between the CAR\nand the ISS. A third test involved determining the CAR responsivity across its angular scan range.\n\nThe ATSR (Fig. 3.28) calibration (Bachmann et al., 2014) was carried out with a Labsphere Uni-\nsource 2000, 500 mm diameter, integrating sphere with a 200 mm exit aperture (Smith et al., 1999a).\n\nThis unit provided eight distinct output levels of uniform illuminance of the exit port. These were\nachieved with four lamps, two with 45 W, and two with 150 W equally spaced about the exit port. All\nlamps had a color temperature of 3000K and hence the spectral profile was independent of the lamp\n\nFIGURE 3.26\n\nThe ISV400 integrating sphere (http://www.electro-optical.com/html/datashts/visible/isv400.asp).\n\n110 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\nhttp://www.electro-optical.com/html/datashts/visible/isv400.asp\n\n\n(B)(A)\n\nFIGURE 3.27\n\nSetup for slick sphere and cloud absorption radiometer (CAR) for determining (A) responsivity across the scan\n\nrange and (B) change in radiance with distance of separation, with the CAR at the closest distance from the\n\nslick sphere.\n\nClosed\ncycle\ncooler\n\nFocal\nplane\nassembly\n\nScan\nmirror\n\nIR optical\nbench\n\nMW antenna\n\nMW chassis\n\nBlack body\non-board calibration\ntarget\n\nForward baffle\n\nnadir view\n\nIR chassis\n\nFIGURE 3.28\n\nThe along-track scanning radiometer sensor.\n\n3.8 OPTICAL SENSOR CALIBRATION 111\n\n\n\ncombination used in the test. Additional output levels were obtained by varying the area of the output\naperture. This was done by inserting a blackened aluminum plate with a hole of the required diameter\nin front of the main aperture. A total of 27 apertures were used including the main aperture.\n\nFor the calibration, the radiometer detector was positioned on the sphere axis 1096 mm from the\nmain aperture as shown in Fig. 3.29. Two detectors were used: a silicon detector with a 1 cm2 active\narea for the 0.4e1.9 mm range, and a germanium detector with an active area of 0.2 cm2 covering\n0.8e1.8 mm. To eliminate any possible stray light from the calibration a tight enclosure was built and\nbaffles inserted between the radiometer and the integrating sphere. The internal surface of the radi-\nometer was blackened to minimize any stray light from the source. This arrangement reduced the\nbackground signal to the noise level of the radiometer.\n\nIn a similar calibration, narrowband filters were inserted in front of the detector to get the calibration\nat each ATSR wavelength. The filters were from the same batch as were used in the construction of the\nATSR-2 and AATSR visible focal plane assemblies. For the 1.6 mm channel a commercial filter was used\nas no \u201cwitness\u201d filter was available for this test. The spectral responses of these filters were measured at\nBentham Instruments immediately after the sphere calibration was performed. The center wavelength,\nbandwidth, and peak transmissions of these filters are given here in Table 3.2. Here the \u201cwitness\u201d version\nrefers to the AATSR flight model filter as does the same connotation for ATSR-2.\n\nThe full aperture spectral radiances from the National Physical Lab (NPL) calibration and that\ncarried out at Rutherford Appleton Lab (RAL) are compared in Table 3.3. The table shows very good\nagreement between RAL and NPL for 0.87 and 0.56 mm, respectively, but at 0.66 mm the RAL\nreadings are consistently 6.5% lower than those from NPL which was later traced to a slight\nmisalignment of the witness filter in the RAL setup. Better agreement (<2%) was achieved when the\nmeasurements were repeated at RAL taking care to make sure that the filters were optimally aligned.\n\nAt 1.6 mm, there is a significant difference between the RAL and NPL measurements. The\ndifferences and the lower accuracy of the NPL calibration highlight the difficulty in measuring radiances\nin the near-IR. The differences can be attributed to a combination of effects, errors in the filter\ntransmission, area of the detector aperture and, more significantly, radiometric leaks and stray light.\n\nFIGURE 3.29\n\nExperimental layout for the calibration with the Labsphere Unisource 2000 integrating sphere.\n\n112 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\n3.8.2 POLARIZATION FILTERS\nIntegrating spheres can also be used to test polarization filters that have been incorporated into a\nsensor. Such a test arrangement is shown here in Fig. 3.30, which was used for the ATSR 1, 2 and the\nAATSR. For this test a smaller 30 W integrating sphere was used. Two standard Ealing polarization\nfilters were used, one for the visible range from 0.2 to 0.8 mm and the other to cover the near-IR range\nfrom 0.8 to 2.2 mm. The polarizers were mounted in rotatable mounts so that their variation in response\ncould be measured as a function of polarization angle. A calcite polarizer was used to determine the\norientation of the filters in the test setup (Fig. 3.30).\n\nBefore establishing the relative orientation of the polarizers, it was necessary to measure any\npolarization introduced by the integrating sphere. Radiometer readings were taken for all filter and\ndetector combinations. The variation in measured signal, relative to the mean sphere output, was less\nthan ?0.5% for all wavelengths (Fig. 3.31).\n\nThe polarization sensitivity of the radiometer was removed by performing the measurements with\nthe detector set at orthogonal orientations. The variation at 1.6 mm in Fig. 3.31 is mainly due to sensor\ndrift. The calcite polarizer was inserted into the light path and oriented so that the plane of the\n\nTable 3.3 Main Aperture Calibration Measurements by National Physical Lab and Rutherford\nAppleton Lab (in Parentheses)\n\nPower Level (W)\n\nIntegrating Sphere Radiance (mW/cm2 sr)\n\n1.6 mm 0.87 mm 0.66 mm 0.56 mm\n\n390 7.55 (9.94) 7.41 (7.46) 5.73 (5.26) 3.43 (3.42)\n\n240 4.51 (6.01) 4.43 (4.45) 3.41 (3.16) 2.05 (2.05)\n\n150 3.09 (4.04) 3.04 (3.03) 2.34 (2.13) 1.40 (1.38)\n\n90 1.51 (1.95) 1.48 (1.48) 1.14 (1.06) 0.68 (0.69)\n\n45 0.77 (0.98) 0.75 (0.74) 0.58 (0.53) 0.35 (0.35)\n\nTable 3.2 Along-Track Scanning Radiometer (ATSR) Channel Filter Characteristics\n\nChannel (mm) Filter Set Mid Wavelength Bandwidth (nm) Transmission\n\n0.56 AATSR flight 0.560 20.79\n\nAATSR witness 0.560 20.09 0.4624\n\nATSR-2 witness 0.558 21.22 0.8560\n\n0.66 AATSR flight 0.660 20.13\n\nAATSR witness 0.659 20.69 0.6771\n\nATSR-2 witness 0.657 20.41 0.8275\n\n0.87 AATSR flight 0.863 20.14\n\nAATSR witness 0.863 20.25 0.7301\n\nATSR-2 witness 0.863 21.65 0.8859\n\n1.6 AATSR flight 1.594 62.88\n\nNorthern optics 1.610 166.79 0.6130\n\n3.8 OPTICAL SENSOR CALIBRATION 113\n\n\n\npolarized light was perpendicular to the optical bench. Radiometer readings were again taken for each\ndetector and filter combination. The results showed that the visible filter was well set up in the rotating\nmount and required no correction. The data for the IR filter showed that it was offset by?60 degrees in\nthe mount and therefore a corresponding correction was required.\n\nFIGURE 3.30\n\nTest arrangement for calibrating the orientation of the thin film polarizing filters.\n\nFIGURE 3.31\n\nMeasured variation of 30 W integrating sphere output with polarization angle.\n\n114 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\n3.9 LIGHT DETECTION AND RANGING\nLight detection and ranging (LIDAR) is sometimes called \u201claser radar\u201d in an abuse of language because\nits principles are similar to those of the radar systems that will be discussed later in this text. LIDAR is an\noptical remote sensing technique that measures the properties of scattered light to find the range or speed\nof distant targets, or the backscattering and attenuation of volume targets such as the atmosphere or the\nsea water. As in radar systems, the range to an object is determined by measuring the time delay between\ntransmission of a (light) pulse and the detection of the reflected signal. LIDAR technology was first used\nin 1962 by Fiocco and Smultin reflecting a laser beam off the surface of the Moon and studying the\nturbidity in upper atmospheric layers. Later, in 1963 it was used by Ligda to perform the first cloud\nheight and aerosols measurements. LIDAR has seen applications in archeology, geography, geology,\ngeomorphology, seismology, remote sensing, and atmospheric physics.\n\n3.9.1 PHYSICS OF THE MEASUREMENT\nThemain difference between LIDAR and radar is that LIDAR operates withmuch shorter wavelengths of\nthe EM spectrum, in atmospheric transmissionwindows in the ultraviolet (UV), visible, and near-IR (e.g.,\n0.4e0.7, 0.7e1.5, 3e5, and 9e13 mm) (http://en.wikipedia.org/wiki/lidar). Thus, in general it is possible\nto detect a feature or object, which is about the size of the wavelength or larger. Thus, LIDAR is very\nsensitive to atmospheric aerosols and cloud particles and has many applications in atmosphere research\nand meteorology. However, an object needs to produce a dielectric discontinuity to reflect the transmitted\nwave. At radar (microwave or radio) frequencies, a metallic object produces a significant reflection.\nHowever nonmetallic objects, such as rain and rocks produce weaker reflections and somematerials may\nproduce nondetectable reflection at all, meaning some objects or features are effectively invisible at radar\nfrequencies. This is especially true for very small objects (such as single molecules and aerosols).\n\nLasers provide one solution to these problems. The beam densities and coherency are excellent,\nand the wavelengths are much smaller. The basic atmospheric LIDAR equation (volumetric target) is\ngiven by Eq. (3.12):\n\nP\u00f0l;R\u00de \u00bc P0$c$s\n2\n$b\u00f0l;R\u00de$Ar\n\nR2\n$exp\n\n8<\n:?2\n\nZ R\n0\n\na\u00f0l;R\u00dedr\n9=\n;$x\u00f0l\u00de$x\u00f0R\u00de; (3.12)\n\nwhere P(l,R) is the received power at a wavelength l from a range R, which is associated with a time\ndelay t \u00bc 2$R=c, P0 is the transmitted pulse power, s is the pulse duration, c$s=2 is the pulse \u201cduration\u201d\nin the range direction, b(l,R) is the backscattering coefficient, Ar is the effective area of the receiving\nsystem (typically a telescope), a(l,R) is the absorption coefficient of the atmosphere, x\u00f0l\u00de is the trans-\nmissivity of the receiver optics, and x\u00f0R\u00de is the so-called overlapping factor, which accounts for the\nvolume intersection between the transmitted laser beam and the receiving cone, as illustrated in Fig. 3.32.\n\nThe detected output voltage of the LIDAR returns at each range gate is proportional to the received\npower (Eq. 3.12):\n\nV0 \u00bc GT$R$Ps \u00fe GT\u00f0Ids \u00feM$Idb\u00de\n\u00bc GT$RfP\u00f0R\u00de \u00fe x\u00f0l\u00de$Pbackg \u00fe GT\u00f0Ids \u00feM$Idb\u00de\n\u00bc GT$R$P\u00f0R\u00de|fflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflffl}\n\ns\n\n\u00feGT$R$x\u00f0l\u00de$Pback \u00fe GT\u00f0Ids \u00feM$Idb\u00de|fflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl}\nVoff\n\n;\n(3.13)\n\n3.9 LIGHT DETECTION AND RANGING 115\n\nhttp://en.wikipedia.org/wiki/lidar\n\n\nwhere GT is the amplifier\u2019s voltage gain, Pback is the background power (power collected from the\nambient light), S stands for the signal term, Voff stands for the offset term (to be compensated for), and\nall other terms have been previously defined.\n\nThe noise associated to the LIDAR measurements has three different contributions: the \u201cshot\u201d\nnoise associated with the signal power (P), the \u201cshot\u201d noise associated to the background power, and\nthe thermal noise\n\n?\ns2thermal\n\n\n\n4:\n\nN \u00bc sV \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2q$G2T$F$M\n\n2$R$PS$B\u00fe 2q$G2T\u00f0Ids \u00fe F$M2$Idb\u00de$B\u00fe s2thermal\nq\n\n; (3.14)\n\nSince the SNR is typically very low, long incoherent averaging is required to increase it as in radar\nsystems.\n\nDifferent types of scattering are used for different LIDAR applications, most common are Rayleigh\nscattering, Mie scattering, and Raman scattering as well as fluorescence. The wavelengths are ideal for\nmaking measurements of smoke and other airborne particles (aerosols), clouds, and air molecules. A\nlaser typically has a very narrow beam, which allows the mapping of physical features with very high\nresolution compared with radar. In addition, many chemical compounds interact more strongly at\nvisible wavelengths than at microwaves, resulting in a stronger image of these materials. Suitable\ncombinations of lasers can allow for remote mapping of atmospheric contents by looking for\nwavelength-dependent changes in the intensity of the returned signal.\n\nLIDAR has been used extensively for atmospheric research and meteorology. With the deployment\nof the global positioning systems (GPS) in the 1980s precision positioning of aircraft became possible.\n\nTELESCOPE\n\nd = do - R?\n\nLASER\n\nR\n\nwo\n\ndo\n\nco\n\n?\n\n?\n\n?\n\nA\n\nW\n\nd\n\nGT\n\nFIGURE 3.32\n\nGraphical description of the overlapping factor as the intersection between the transmitted beam and receiver\n\ncone.\n\nCredits: F. Rocadenbosch (UPC)\n\n4Since the output voltage is proportional to the input power, the noise is proportional to the standard deviation of the output\nvoltage, and not to the variance.\n\n116 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nGPS-based surveying technology has made airborne surveying and mapping applications possible and\npractical. Many have been developed, using downward-looking LIDAR instruments mounted in\naircraft or satellites.\n\n3.9.2 OPTICAL AND TECHNOLOGICAL CONSIDERATIONS\nThere are in general two kinds of LIDARs: \u201cincoherent\u201d or direct detection of the power return, mainly\nan amplitude measurement, and \u201ccoherent\u201d which uses the Doppler shift and must keep track of the\nphase information in each laser pulse. Coherent systems generally use optical heterodyne detection\nwhich is more sensitive than direct detection and allows operation at a much lower power levels, but at\nthe expense of having more complex transceiver requirements.\n\nIn both coherent and incoherent LIDARs, there are two types of pulse models: micropulse and\nhigh-energy LIDARs. Micropulse systems have been developed as a result of the ever-increasing\ncomputer power available to process the sensor data combined with marked advances in laser tech-\nnology. Micropulse systems typically operate at power levels that are \u201ceye safe\u201d meaning that they can\noperate without any additional safety precautions. High-power systems are common in atmospheric\nresearch where they are widely used for measuring atmospheric parameters such as cloud height,\nlayering and densities of clouds, cloud particle properties, temperature, pressure, wind, humidity, trace\ngas concentrations (ozone, methane, nitrous oxide, etc.), aerosols.\n\nThe components of a typical LIDAR are as follows:\n\n1. Laser. 600e1000 nm lasers are most common for nonscientific applications. They are\ninexpensive, but since they can be focused and easily absorbed by the eye the maximum power is\nlimited by the need to make them eye-safe. Eye safety is often a requirement for most\napplications. A common alternative, the 1550 nm lasers are eye-safe at much higher power levels\nsince this wavelength is not focused by the eye, but the detector technology is less advanced in\nthis spectral region, so these wavelengths are generally used at longer ranges and lower\naccuracies. Airborne topographic mapping LIDARs generally use 1064 nm diodeepumped YAG\nlasers, while bathymetric systems generally use 532 nm frequency doubled diodeepumped YAG\nlasers because 532 nm penetrates water with much less attenuation than does 1064 nm. Variables\nin the individual systems include the ability to set the number of passes required through the gain\n(YAG, YLF, etc.) and Q-switch speed. Shorter pulses achieve better target resolution provided the\nLIDAR receiver detectors and electronics have sufficient bandwidth.\n\n2. Scanner and optics. How fast images can be developed is also affected by the speed at which\nthey can be scanned into the system. There are several different ways to scan the azimuth and\nelevation, including dual oscillating plane mirrors, a combination with a polygon mirror, a dual\naxes scanner. Optic choices affect the angular resolution and range that can be detected. A hole-\nmirror or beam splitter can be used to collect a laser return signal.\n\n3. Photodetector and receiver electronics. Two different photodetector technologies are used in\ntoday\u2019s LIDARs: solid-state photodetectors, such as silicon avalanche photodiodes, or\nphotomultipliers. The sensitivity of the receiver is another parameter that has to be balanced in a\nLIDAR design.\n\n4. Position and navigation systems. LIDAR sensors mounted on mobile platforms such as\nairplanes or satellites require instrumentation to determine the absolute position and orientation\n(pointing angle) of the sensor. GPS and inertial measurement unit systems are primary types of\nsystems used for this purpose.\n\n3.9 LIGHT DETECTION AND RANGING 117\n\n\n\n3.9.3 APPLICATIONS OF LIDAR SYSTEMS\nThere are many different applications of LIDAR systems, but we will concentrate on those primarily in\nmeteorology, which was one of the earliest applications of LIDAR remote sensing. The first LIDARs\nwere used for studies of atmospheric composition, structure, clouds, and aerosols. Initially based on\nrube lasers, LIDARs for meteorology were constructed shortly after the invention of the laser.\n\nSome modern LIDARs are as follows:\n\n1. Elastic backscatter LIDAR is the simplest form of LIDAR and is typically used for studies of\naerosols and clouds. The backscattered wavelength is identical to the transmitted wavelength, and\nthe magnitude of the received signal at a given range depends on the backscatter coefficient of\nscatterers at that range and the extinction coefficients of the scatterers along the path to that range.\nThe extinction coefficient is typically the quantity of interest.\n\n2. Differential absorption LIDAR (DIAL) is used for range-resolved measurements of a particular\ngas in the atmosphere, such as ozone, carbon dioxide, or water vapor. The LIDAR transmits two\nwavelengths: an \u201con-line\u201d wavelength that is absorbed by the gas of interest and an off-line\nwavelength that is not absorbed. The differential absorption between the two wavelengths is\na measure of the concentration of the gas as a function of range. DIAL LIDARs are essentially\ndual-wavelength elastic backscatter LIDARs.\n\n3. Raman LIDAR is also used for measuring the concentrations of atmospheric gases, but can also\nbe used to retrieve aerosol parameters as well. Raman LIDAR exploits inelastic scattering to\nsingle out the gas of interest from all other atmospheric constituents. A small portion of the\nenergy of the transmitted light is deposited in the gas during the scattering process, which shifts\nthe scattered light to a longer wavelength by an amount that is unique to the species of interest.\nThe higher the concentration of the gas, the stronger the magnitude of the backscattered signal.\n\n4. Doppler LIDAR is used to measure wind speed along the beam by measuring the frequency shift\nof the backscattered signal. Scanning LIDARs have been used to measure atmospheric wind\nvelocity in a large three-dimensional core. ESA\u2019s wind mission Atmospheric Dynamics Mission\nAeolus (ADM-Aeolus) will be equipped with a Doppler LIDAR system to provide global\nmeasurements of vertical wind profiles. Doppler LIDAR systems are now beginning to be\nsuccessfully applied in the renewable energy sector to acquire wind speed, turbulence, wind veer,\nand wind shear data. Both pulse and continuous wave systems are being used for these\napplications.\n\nThe number of spaceborne LIDARs has been very limited because of the reliability of lasers. So far,\nthe only LIDAR-based mission is the NASA/CNES cloud-aerosol LIDAR and infrared pathfinder\nsatellite observation (CALIPSO) mission, which belongs to the A-TRAIN constellation. CALIPSO\ncombines an active LIDAR instrument with passive IR and visible imagers to probe the vertical\nstructure and properties of thin clouds and aerosols over the globe. CALIPSO was launched on April\n28, 2006, with the cloud profiling radar system on the CloudSat satellite. Fig. 3.33 shows an artist\u2019s\nview of the CALIPSO mission in the A-TRAIN constellation, a picture and a drawing of it, and sample\nLIDAR returns from the sea surface up to 30 km height. The dark blue regions underneath the high-\nreflectivity regions (in pink) correspond to regions where the SNR is too low because of the increased\nattenuation of the signal in previous regions. The main engineering parameters of the CALIPSO\nLIDAR are listed in Table 3.4.\n\n118 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\n3.9.4 WIND LIDAR\nAs just mentioned a wind LIDAR is a Doppler LIDAR that uses the frequency shift of the back-\nscattered signal to determine the wind velocity. This concept is depicted here in Fig. 3.34 adapted from\nDobler et al., 2002.\n\nThis coherent Doppler wind LIDAR measures the frequency of the beat signal obtained by optically\nmixing the return signal with the local oscillator. As a consequence, both the local oscillator and the\nreturn signal must have narrow bandwidths to have sufficient coherent lengths. Thus, coherent LIDAR\ndetection relies of the aerosol scattering with very narrow Doppler broadening meaning the LIDARwind\nmeasurements apply only to those atmospheric regions with adequate aerosol loading. Since the Mie\nscattering due to aerosols is better suited to frequency analysis than is the molecular Rayleigh scattering\nthe choice of LIDAR wavelength depends on the expected return signal and the expected ratio of\n\nFIGURE 3.33\n\n(A) Artist\u2019s view of the NASA cloud-aerosol LIDAR and infrared pathfinder satellite observation (CALIPSO)\n\nmission in the A-TRAIN constellation. (B) Example of data collected by CALIPSO\u2019s LIDAR in June 2006: data\n\nextend from sea level to 30 km. (C) CALIPSO satellite picture and drawing indicating its main components.\n\nNote the large telescope to collect the laser returns. (http://images.slideplayer.com/17/5360190/slides/slide_\n\n3.jpg).\n\n3.9 LIGHT DETECTION AND RANGING 119\n\nhttp://images.slideplayer.com/17/5360190/slides/slide_3.jpg\nhttp://images.slideplayer.com/17/5360190/slides/slide_3.jpg\n\n\nTable 3.4 Main Parameters of the Cloud-Aerosol LIDAR and Infrared Pathfinder Satellite\nObservation LIDAR\n\nParameter Value/Description\n\nLaser Nd:YAG, diode-pumped, Q-switched, frequency-doubled\n\nWavelengths 532 nm, 1064 nm\n\nPulse energy 110 mJ/channel\n\nPulse repetition frequency 20.25 Hz\n\nReceiver telescope 1.0 m diameter\n\nFootprint/field of view 100 m/130 mrad\n\nVertical resolution 30e60 m\n\nHorizontal resolution 333 m\n\nLinear dynamic range 22 bits\n\nData rate 316 kbps\n\nFIGURE 3.34\n\nDoppler LIDAR wind measurement concept.\n\n120 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\naerosol-to-molecular backscatter. The molecular scattering cross-section is proportional to l?4, and the\naerosol signal is proportional to between l?2 and l\u00fe1, depending on the wavelength and particle size and\nshape. Even if the aerosol returns decrease with increasing wavelength, the molecular background de-\ncreases much faster, so that the aerosol-to-molecular backscatter ratio becomes more favorable to the\nmeasurement. Therefore, longer wavelengths are desirable to minimize the influence of molecular\n(Rayleigh) scattering. Coherent Doppler LIDARs use laser wavelengths between 1 and 11 mm.\n\n3.9.4.1 Vector Wind Velocity Determination\nVector wind measurements require radial velocity measurements from three independent \u201clines-of-\nsight\u201d meaning you must have three LIDARs. If it can be assumed that there is no vertical velocity\n(W \u00bc 0), then only two LIDARs are needed. If horizontal homogeneity of the wind field can be\nassumed, then a LIDAR beam scanning technique can be used to determine the wind velocity.\n\nThe two main techniques are the velocity azimuth display (VAD) which is a conical scan LIDAR\nbeam at a fixed elevation angle, and the Doppler beam swinging (DBS) which is a LIDAR pointing in\nthe vertical which is tilted east and tilted north. These two methods are graphically displayed in\nFig. 3.35.\n\nFIGURE 3.35\n\nSchematic of the scan technique of a Doppler LIDAR. DBS, Doppler beam swinging; VAD, velocity azimuth\n\ndisplay.\n\n3.9 LIGHT DETECTION AND RANGING 121\n\n\n\n3.9.4.1.1 Velocity Azimuth Display LIDAR Vector Wind Method\nThe VAD scheme is a conical scan LIDAR beam at a fixed elevation angle (Fig. 3.35). For a ground-\nbased LIDAR, positive u, v, w are defined as the wind blowing toward the East, North, and upward, and\nthe positive radial wind V\n\n!\nR as the wind blowing away from the LIDAR. V\n\n!\nR consists of the following\n\nu, v, and w components:\n\nV\n!\n\nR \u00bc u$sinq$cos4$bx \u00fe v$cosq$cos4$by \u00fe w$sin4$bz; (3.15)\nwhere q is the azimuth angle clockwise from the north, and 4 is the elevation angle.\n\nFor each VAD scan the elevation angle 4 is fixed and known, the azimuth angle q is varied, but is\nalso known. V\n\n!\nR is measured so the three unknowns u, v and w can be derived directly from fitting the\n\ndata with the above Eq. (3.15).\n\n3.9.4.1.2 Doppler Beam Swinging LIDAR Vector Wind Method\nThe DBS technique consists of pointing a LIDAR in the vertical up, and then tilting it east and north\n(Fig. 3.36).\n\nIf g is the off-zenith angle then:\n\nVRE \u00bc u$sing\u00fe w$cosg; (3.16a)\nVRN \u00bc v$sing\u00fe w$cosg; (3.16b)\nVRZ \u00bc w; (3.16c)\n\nFIGURE 3.36\n\nLIDAR orientation for the Doppler beam swinging wind vector.\n\n122 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nthen:\n\nu \u00bc VRE ? VRZ$cosg\nsing\n\n; (3.17a)\n\nv \u00bc VRN ? VRZ$cosg\nsing\n\n; (3.17b)\n\nw \u00bc VRZ ; (3.17c)\nwhere VRZ, VRE, VRN and are the vertical, tilted east, and tilted north radial velocities, respectively.\n\n3.9.4.2 Direct Detection Doppler Wind LIDAR\nDirect Detection Doppler (DDL) uses incoherent detection to measure the spectrum of returned sig-\nnals. DDL can use aerosol/molecular scattering and/or resonance fluorescence to measure the wind\nfrom the ground to the upper atmosphere. There are several different ways to do the spectral analysis\nfor the DDL method:\n\n\u2022 Resonance fluorescence Doppler LIDAR uses the atmospheric atomic or molecular absorption\nlines as the frequency analyzer/discriminator.\n\n\u2022 Direct detection Doppler LIDAR is based on molecular absorption edge filter, e.g., iodine (I2)\nvapor filter, Na or K magnetooptic filter.\n\n\u2022 Direct detection Doppler LIDAR is based on optical interferometer edge-filter, e.g., FabryePerot\netalon transmission edge.\n\n\u2022 Direct detection Doppler LIDAR is based on fringe patter imaging of an optical interferometer,\ne.g., FPI imaging.\n\n3.9.4.3 LIDAR Wind Summary\nDoppler wind techniques measure the wind velocity along the LIDAR beam requiring three independent\nradial velocity measurements from three independent lines of sight. Rather than point three different\nLIDARs in three different directions,we assumehorizontal homogeneity of thewindfield over thevolume\nwe are sensing and employ scanning LIDAR techniques to determine the vector wind. The two main\nscanning techniques are the VAD and the DBSmethods. There are different wavelength requirements for\ncoherent and incoherent detection LIDARs. Fig. 3.37 shows a commercial buoy carrying a VAD wind\nLIDAR (principles of operation explained below) to measure wind profiles up to 200 m height to\noptimize the selection of offshore aerogenerators.\n\nAn example of a spaceborne wind LIDAR is the upcoming ESA ADM-Aeolus that will be\nlaunched in 2017 and will provide for the first time global observation of wind profiles from space to\nfurther our knowledge of Earth\u2019s atmosphere and weather systems. Aeolus carries a single payload, the\natmospheric laser Doppler instrument (ALADIN), a direct detection Doppler wind LIDAR operating\nat near UV wavelengths (355 nm). It comprises two main assemblies: (1) Transmitter: diode lasere\npumped Nd:YAG laser, frequency tripled to 355 nm at 150 mJ pulse energy, 100 Hz pulse repetition\nand (2) Receiver: 1.5 m diameter SiC telescope, Mie channel (aerosol and water droplets) with Fizeau\nspectrometer, Rayleigh channel (molecular scattering). Fig. 3.38 shows an artist\u2019s view of the satellite\nADM-Aeolus and its different subsystems.\n\n3.9 LIGHT DETECTION AND RANGING 123\n\n\n\nFIGURE 3.37\n\nUniversitat Polite?cnica de Catalunya (UPC) designed EOLOS FLS200 buoy (manufactured by Eolos Floating\n\nSolutions) carrying a wind LIDAR to measure wind fields up to 200 m to optimize the location of offshore\n\naerogenerators.\n\nFIGURE 3.38\n\nAtmospheric Dynamics Mission Aeolus payload components (http://www.esa.int/Our_Activities/Operations/\n\nADM-Aeolus_operations). ALADIN, atmospheric laser doppler instrument.\n\nFrom ESA. http://www.esa.int/spaceinimages/Images/2007/01/ADM-Aeolus_payload_components\n\n124 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\nhttp://www.esa.int/Our_Activities/Operations/ADM-Aeolus_operations\nhttp://www.esa.int/Our_Activities/Operations/ADM-Aeolus_operations\nhttp://www.esa.int/spaceinimages/Images/2007/01/ADM-Aeolus_payload_components\n\n\n3.10 STUDY QUESTIONS\n\n1. Explain what the reflected radiance is in the visible part of the spectrum, its units, and how it can\nbe computed from the surface\u2019s parameters, and the Sun irradiance.\n\n2. At which wavelengths does the radiation of a blackbody at physical temperature equal to 300K\nand 6000K reach the maximum value?\n\n3. The Landsat Thematic Mapper sensor covers the visible and near-IR parts of the spectrum in the\nfollowing bands: TM-1 (0.45e0.52 mm), TM-2 (0.52e0.60 mm), TM-3 (0.63e0.69 mm), TM-4\n(0.76e0.90 mm), TM-5 (1.55e1.75 mm), TM-6 (10.40e12.50 mm) and TM-7 (2.08-2.35 mm).\nDiscuss which bands can be applied for the following applications and why:\na. Vegetation health\nb. Forest fires detection\nc. Water bodies and coastline definition\nd. Crop classification\n\n4. An optical instrument pointing at nadir from 500 km height has a CCD of 800 ? 600 pixels in\nthe focal plane of a convergent lens. Each photodetector has a size 10 mm ? 10 mm, and the\nsignal\u2019s bandwidth is 1 MHz. The lens diameter is 80 mm, and the focal distance 500 mm.\nDetermine the pixel size over the Earth, the NEP if the specific detectivity is D*(l) \u00bc\n2 ? 1010 cm\n\nffiffiffiffiffi\nHz\n\np\nW , and the image size in kilometers.\n\n5. A photodetector of 0.1 mm ? 0.1 mm is mounted in a telescope with a focal length of 80 cm and\nan aperture of 10 cm diameter. Compute the pixel size when it observes the Earth\u2019s surface from\na 780 km high satellite, and for an incidence angle of 45 degrees (major and minor axes)\nassuming a flat Earth and taking into account the Earth\u2019s curvature.\n\n6. Compute the optical power collected by the photodetector of the previous question when it\npoints to nadir, the surface is rough with a 30% reflectance, and the wavelength is l \u00bc 1.6 mm.\nNote: assume that the Solar exoatmospheric radiation at this wavelength is 100 W/m2 mm, the\none way atmospheric transmissivity is 90%, the spectral width of the photodetector is 0.3 mm,\nand the transmissivity of the telescope optics is 80%.\n\n7. Briefly explain the different types of LIDAR sensors to sense gas composition, and their\nprinciples of operation.\n\n8. An optical push-broom sensor has a linear array of photodetectors in the focal plane of a\nconvergent lens. If the photodetector\u2019s size is 0.75 mm ? 0.75 mm, the system\u2019s bandwidth is\n150 kHz, the diameter of the lens is 76.2 mm, and the focal length is 4 times the diameter of the\n\nlens, compute the NEP if the specific detectivity is D*(l) \u00bc 3.31 ? 1010 cm\nffiffiffiffiffi\nHz\n\np\nW .\n\n9. We want to design a multispectral airborne sensor (blue, green, red, and near-IR) for\ncartographic applications. The sensor will perform a push-broom scan and it has several parallel\nlinear CCDs in the focal plane of the camera, one per band, as sketched in the following figure.\nThe sensor has the following parameters:\nLinear CCD array with 12,000 pixels, photodetector size 6.5 mm ? 6.5 mm, and a 6.5 mm spacing\nbetween them.\nAccess time per line: 1 ms\nFocal length f \u00bc 107 mm and F# \u00bc f/D \u00bc 4, being D the aperture diameter of the optical system\nTransmissivity of the optics sopt \u00bc 0.68\nNominal flight altitude \u00bc 10 km\nNominal flight speed \u00bc 140 m/s\n\n3.10 STUDY QUESTIONS 125\n\n\n\nFor the CCD located in the center of the focal plane (green) compute:\na. The swath width in the cross-track direction (ground swath in the figure), assuming a flat\n\nsurface.\nb. The angular extent of each individual photodetector of the CCD (IFOV) and the pixel size\n\n(GIFOV) for a pixel in the center of the swath.\nc. To obtain images with an aspect ratio 1:1 in the swath center, obtain the frequency of\n\nacquisition of the lines of the CCD (in lines per second) at the nominal flight altitude and\nspeed.\n\nd. The optoelectrical conversion, access, and digitalization of the signals collected by the\nphotodetectors must be performed in the period of acquisition of each line. If all these\nprocesses are performed consecutively without dead times, compute the integration time for\nthe photodetectors.\n\ne. Determine the bandwidth B associated with the inverse of the integration time of each\nphotodetector.\n\nf. If the specific detectivity is D* \u00bc 9.5 ? 1011 cm (Hz)1/2/W, determine the NEP of each\nphotodetector.\n\ng. If the solar irradiance over the surface for the green band (l \u00bc 533e587 nm) is 1400 W/\nm2 mm under clear sky conditions, determine the minimum detectable reflectance change\n(NEDr) for a Lambertian surface. Note: the atmospheric transmissivity in the ascending path\ncan be assumed to be one.\n\nh. Taking into account that the maximum reflectance for rough surfaces is one (lossless\nLambertian reflector), determine the number of bits required in the analog-to-digital\nconversion for the whole dynamic range so that the quantization step be smaller or equal to\nthe NEDr of the sensor.\n\n126 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\n10. \u201cCubeSats\u201d are low-cost pico-satellites originally conceived by the California Polytechnic State\nUniversity for teaching and training. However, they are now being considered also for small\nscientific and technology demonstrator missions. The basic CubeSat structure consists of a\n10 cm side cube, with a maximum weight of 1.33 kg. All subsystems, including the onboard\ncomputer, electrical power supply, telecommunications, etc. have to fit inside, leaving only two\nboards for the payloads. We want to consider placing a CCD camera (photodiode\nlength \u00bc 20 mm, spacing \u00bc 0.2 mm; VGA resolution: 640 ? 480 pixels) in a CubeSat that will\norbit the Earth in a circular orbit at 650 km height. If the maximum focal length is then 10 cm,\nand the lens diameter 1 cm, please compute:\na. The pixel\u2019s size at nadir (in m).\nb. The image size (in km).\nc. The image acquisition time (in s) for a maximum blurring of 1/10th of the pixel size.\nd. With the acquisition time computed in (c) compute the maximum rotation speed for the same\n\npixel blurring.\ne. The bandwidth (Hz) if the readings have to be stabilized at 99.9% of their final value.\nf. The NEP (in W).\ng. The signal-to-noise ratio (in dB) when imaging the surface of the Earth (reflection\n\ncoefficient \u00bc 0.4, Lambertian surface).\nh. The number of bits required to sample each pixel of the image.\ni. The amount of information in one image (without compression) and the time to download it\n\nto the ground station with a 9.6 kbps downlink.\nj. If instead of a 1 unit CubeSat as in Fig. 3.39A, a three Unit one (3 times longer) is used so as\n\nto be able to increase the focal length by a factor of 3, how it will impact the pixel\u2019s size and\nthe swath?\n\nData:\nGravitational constant: k \u00bc 3.986 ? 1014 m3/s2\nSpectral range of the detectors: 0.4e0.7 mm\n\n(A)\n\nFIGURE 3.39A\n\nSample 1 Unit CubeSat.\n\n3.10 STUDY QUESTIONS 127\n\n\n\n11. To measure the temperature of the Earth at global scale in the thermal IR band (10 mm, where\nthere is an atmospheric transmission window), with a spatial resolution at nadir of 10 km, and a\nrevisit time of 15 min, a constellation of spin stabilized geostationary satellites is required,\ntaking advantage of the rotation to scan from East to West the images. The North to South scan is\nperformed every 15 min completing the image, as sketched in Fig. 3.40. Please compute:\na. The altitude of the satellite to be in geostationary orbit.\n\n(B)\n\n1E6\n\n1E7\n\n1E8\n\n1E9\n\n1E10\n\nCCD\n\nPMT\n\nSI\nDIODE\n\nInGaAS\nDIODE\n\nS1 PMT\n\nPDA\n\nTHERMOPILE\n\nPYROELECTRIC\n\nHgCdZnTe\n@ 243K\n\nHgCdZnTe\n@ 293K\n\nPbSe @  243K\nPbS  @ 243K\n\nIDEAL CASE FOR PHOTOVOLTAIC DETECTOR\nLIMITED BY 293K BACKGROUND1E11\n\n1E12\n\nD\n\u00b0 \n\n(c\nm\n\n H\nz\u00bd\n\n W\n-1\n\n)\n\n1E13\n\n1E14\n\n1E15\n\nWAVELENGTH [?m]\n2 4 6 8 10 12\n\nFIGURE 3.39B\n\nSpecific detectivity (cm\nffiffiffiffiffiffi\nHz\n\np \t\nW) versus wavelength (mm) for different types of detectors.\n\n(C)\n\nIrr\nad\n\nia\nnc\n\ne \n[W\n\n\u2022m\n-2\n\n\u2022?\nm\n\n-1\n]\n\n1E - 2\n\n1E - 1\n\n1E + 0\n\n1E + 1\n\n1E + 2\n\n1E + 3\n\n1E + 4\n\n0.2 1 10 25\n0\n\n0.5\n\n1\n\nAtmospheric\ntransmission\n\nExoatmospheric solar irradiance\n\nExitance (300K)\n\nTransm\nission\n\nWavelength [?m]\n\nFIGURE 3.39C\n\nSolar irradiance and atmospheric transmission versus wavelength (mm).\n\n128 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nb. The number of satellites to have global coverage. How much overlap (at the Equator) will\nexist between the FOVof two adjacent satellites? What is the range of latitudes that can be\nmeasured?\n\nc. The angular resolution of the system so that the spatial resolution at nadir is 10 km. What is\nthe spatial resolution of a pixel over the same Meridian, but at a latitude of 45 degrees?\n\nd. If the NortheSouth scan only covers the Earth\u2019s disk, i.e., all lines have at least one pixel\npointing towards the Earth, how many lines will the image have? If the image scan sweeps\nfour lines simultaneously without overlapping, what is the integration time per pixel, and the\nminimum bandwidth required?\n\ne. If the spectral radiance of a blackbody at 300K is L300 \u00bc 9924 W/(m2 sr mm), and assuming\nthat the average emissivity of the surfaces of interest at 300K is 90%, compute the optical\npower collected by the photodetector.\n\nf. If the minimum detectable temperature change is 1K, and the spectral radiance of a\nblackbody at 301K is L301 \u00bc 10,085 W/(m2 sr mm), compute the required NEP and the\nspecific detectivity of the photodetector in cm\n\nffiffiffiffiffiffi\nHz\n\np \t\nW.\n\ng. How many bits will be required to quantize each pixel?\nh. Compute the amount of information in kilobytes per second generated by each of the sensors\n\nin the different satellites.\n\nData:\n\u2022 spin rate of each geostationary satellite: three revolutions per second\n\u2022 spatial resolution at nadir: 10 km\n\u2022 revisit time: 15 min (maximum interval between consecutive images, the time of acquisition\n\nof an image can be smaller than that)\n\u2022 Longitude of the array of photodetectors: four\n\nNorth-South scan\nof the beams\n\nbeams\n\n#1\n#2\n#3...\n\nSatellite rotation\n\nNorth\n\nFIGURE 3.40\n\nGeostationary spinning satellite.\n\n3.10 STUDY QUESTIONS 129\n\n\n\n\u2022 Photodetector size: 0.2 ? 0.2 mm\n\u2022 Aperture diameter: 20 cm\n\u2022 Wavelength: 10 mm\n\u2022 Spectral width: 4 mm\n\u2022 Atmospheric transmissivity: 85%\n\u2022 Optical system transmissivity: 90%\n\u2022 Dynamic range: Tmin \u00bc 150K, Tmax \u00bc 320K, DT \u00bc 1K\n\n130 CHAPTER 3 OPTICAL IMAGING SYSTEMS\n\n\n\nMICROWAVE RADIOMETRY 4\nMicrowave radiometry is the science of the measurement of the noise emitted by bodies at a physical\ntemperature higher than zero Kelvin. In this chapter, the physical principles will be presented, and the\nmain technologies and techniques to perform these measurements.\n\n4.1 BASIC CONCEPTS ON MICROWAVE RADIOMETRY\n4.1.1 BLACKBODY RADIATION\nAs described in previous chapters, all bodies at a nonzero Kelvin temperature emit electromagnetic\nradiation. Gases radiate at discrete frequencies. According to quantum theory, each spectral line\ncorresponds to the transition of an electron from an atomic energy level E1 to another one E2. The\nradiation is produced at a frequency given by Bohr\u2019s equation:\n\nf1/2 \u00bc E1 ? E2\nh\n\n. (4.1)\n\nwhere h is the Planck\u2019s constant: h \u00bc 6.63 ? 10?34 J s. Alternatively, if a photon at a frequency f1/2 is\nabsorbed, an electron is excited from energy level E2 to energy level E1.\n\nWhen the interaction between gas atoms or molecules increases due to increased kinetic energy\n(higher temperature) or increased volumetric density, the energy levels split, and the emission is no\nlonger produced at a single frequency f1/2, but at a band around that frequency f1/2. As an example,\nFig. 4.1A and B show the water vapor and oxygen absorption bands around 22 GHz and from 55 to\n65 GHz, respectively, for different atmospheric heights. It can be appreciated that at higher altitudes\n(lower atmospheric pressure) the bands are narrower than at sea level (higher atmospheric pressure).\nTheir amplitude also decreases due to the shorter atmospheric path. In the case of O2, except at very\nhigh altitudes, the bands even overlap among them and appear as a single wide band. This information\nwill be used later to infer atmospheric temperature profiles.\n\nFor all materials at thermodynamic equilibrium, Kirchhoff\u2019s law (1860) states that all the absorbed\npower must then be reradiated, otherwise, if they radiate more power than they absorb, their physical\ntemperature would decrease indefinitely, while if they absorb more power than they emit, their\nphysical temperature would increase indefinitely.\n\nA \u201cblack body\u201d is an ideal body that acts as a perfect absorber, absorbing all the power impinging\non it, at all frequencies, from all directions, and at all polarizations. Blackbodies do not exist in real\nlife, but in the microwave part of the spectrum a close approximation to the blackbodies are the\nmicrowave absorbers used, for example, in the walls of anechoic chambers. In thermal equilibrium, the\n\nCHAPTER\n\nIntroduction to Satellite Remote Sensing. http://dx.doi.org/10.1016/B978-0-12-809254-5.00004-X\n\nCopyright \u00a9 2017 Elsevier Inc. All rights reserved.\n131\n\nhttp://dx.doi.org/10.1016/B978-0-12-809254-5.00004-X\n\n\npower absorbed by a blackbody is then reradiated isotropically, but with a frequency dependence\nwhich is given by Planck\u2019s law1 (Planck, 1901):\n\nBf \u00bc 2 $ h $ f\n3\n\nc2\n$\n\n1\n\ne\nh $ f\n\nkB $ Tph ? 1\n?\nW\n?\nm2 Hz strad\n\n?\n. (4.2)\n\nFIGURE 4.1\n\nAtmospheric absorption due to oxygen at different atmospheric heights as a function of the frequency in GHz\n\ncomputed for a US standard atmosphere, temperatures and pressures (Gary and Hereford, 2013).\n\n1Note that Eq. (4.2) is equivalent to Eq. (2.33), but expressed in terms of the frequency instead of the wavelength.\n\n132 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.1|tif\n\n\nIn Eq. (4.2), Bf is called the spectral brightness density, whose physical meaning is the amount of\npower being radiated per unit of surface, per unit of spectral width, and per unit of solid angle. The\nfrequency f is given in Hertz, kB is the Boltzmann\u2019s constant kB \u00bc 1.38 ? 10?23J/K, Tph is the absolute\ntemperature in Kelvin, and c is the speed of light. A set of plots of the spectral brightness density versus\nfrequency, for different temperatures is found here in Fig. 4.2.\n\nAs it can be seen, the higher the physical temperature, the larger the brightness is, and the higher\nthe frequency where the brightness reaches its maximum. This maximum is given by Wien\u2019s\ndisplacement law (Eq. 2.35).\n\nAs it can also be noted from Fig. 4.2, this maximum typically occurs for frequencies above the\nthermal infrared; therefore, in the microwave part of the spectrum, where the so-called Rayleighe\nJeans law can be applied. Actually, the RayleigheJeans law was obtained by Jeans based on classical\nmechanics, prior to Planck\u2019s quantum mechanics, but as for Eq. (2.36), it can be interpreted as a\nsimplification of Planck\u2019s law for low frequencies:\n\nBf \u00bc 2 $ h $ f\n3\n\nc2\n$\n\n1\n\ne\nh $ f\n\nkB $ Tph ? 1\nz\n\n2 $ h $ f 3\n\nc2\n$\nkB $ Tph\nh $ f\n\n\u00bc 2 $ kB $ f\n2 $ Tph\n\nc2\n\u00bc 2 $ kB $ Tph\n\nl2\n. (4.3)\n\nNote that there is a linear relationship between the spectral brightness density and the physical\ntemperature of the body, and it is inversely proportional to the square of the wavelength.\n\nIn Fig. 4.3, we compare the RayleigheJeans approximation and Planck\u2019s law. If l and T meet the\nrequirement that l ? Tph ? 0.77 m K or f/Tph ? 3.9 ? 108 Hz/K, the error committed by the\nRayleigheJeans approximation as compared to Planck\u2019s law is smaller than 1%. Thus, if the physical\ntemperature is 300K, the frequency must be smaller than 117 GHz, which covers a large part of the\nmicrowave spectrum.\n\nFIGURE 4.2\n\nPlanck\u2019s law for blackbodies at different physical temperatures.\n\n(Ulaby et al., 1981).\n\n4.1 BASIC CONCEPTS ON MICROWAVE RADIOMETRY 133\n\nmailto:Image of Figure 4.2|tif\n\n\n4.1.2 GRAY-BODY RADIATION: BRIGHTNESS TEMPERATURE AND EMISSIVITY\nA blackbody is an idealized body which is a perfect absorber and a perfect radiator. Real bodies,\nhowever, do not absorb all the incident power, a part is reflected, and part is transmitted into the body,\nwhich then is partially or totally absorbed. In thermodynamic equilibrium (temperature is constant),\nthe power that is absorbed is then radiated. Therefore, a real body radiates less power than a blackbody\nat the same physical temperature: these bodies are called gray bodies. A semi-infinite material at a\nuniform temperature T is depicted in Fig. 4.4.\n\nIf the emitted brightness depends on the direction B(q,f), a similar equation to that of the\nblackbody can be written:\n\nB\u00f0q;f\u00de \u00bc 2 $ kB\nl2\n\n$ TB\u00f0q;f\u00de; (4.4)\n\nby replacing the physical temperature Tph by the so-called \u201cbrightness temperature\u201d TB(q,f). Since the\nbrightness temperature of a gray body is smaller than that of a blackbody, the brightness temperature\nTB is smaller than the physical temperature Tph. The parameter relating both magnitudes is called the\nemissivity ef (q,f):\n\nef \u00f0q;f\u00de \u00bc\nBf \u00f0q;f\u00de\n\nBf ;black body\n\u00bc TB\u00f0f ; q;f\u00de\n\nTph\n. (4.5)\n\n10-8\n\n10-10\n\n10-12\n\n10-14\n\n10-16\n\n10-18\n\n10-20\n\n10-22\n108 109 1010 1011 1012 1013 1014 1015\n\nB\nrig\n\nht\nne\n\nss\n B\n\nf ,\nW\n\n m\n-2\n\n H\nz-\n\n1  \nsr\n\n-1\n\nWien Law\n\nPlanck Law\n\nRayleigh-Jeans Law\n\nFrequency, Hz ?\n\nFIGURE 4.3\n\nPlanck\u2019s radiation law approximations: RayleigheJeans law (low frequency limit, Eq. 4.3) and Wien\u2019s law\n\n(high frequency limit) (Ulaby et al., 1981).\n\nReproduced by permission from Ulaby, F., Moore, R.K., Fung, A.K., 1981. Microwave Remote Sensing. Active and Passive, Vol I:\n\nMicrowave Remote Sensing Fundamentals and Radiometry. Artech House, Inc., Norwood, MA. \u00a9 1981 by Artech House, Inc.\n\n134 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.3|eps\n\n\nsince Bf (q,f) ? Bf, black body, the emissivity is bounded by 0 ? ef (q,f) ? 1. The emissivity is zero for a\nperfect reflecting material, a lossless metal, and is one for a perfect absorber, the blackbody.\n\n4.1.3 GENERAL EXPRESSIONS FOR THE EMISSIVITY\nThe scattering of a rough surface is characterized by its cross-section per unit area s0p0;ps\u00f0q0;f0; qs;fs\u00de.\nThis parameter relates the scattered power in the (qs, fs) direction at ps polarization, for an incident\nplane wave from the (q0, f0) direction at p0 polarization. If ps \u00bc p0 \u00bc h, v, s0 is called the horizontal\n(h) or vertical (v) scattering coefficient. If (qs, fs) \u00bc (q0, f0), s0 is the backscattering coefficient, while\nif (qs, fs) \u00bc (p ? q0, f0) s0 is the forward scattering coefficient. If ps s p0, s0 is the cross-polar\nscattering coefficient. By applying Kirchhoff\u2019s law to the rough surface case, Peake developed in\n1959 the expressions for the horizontal and vertical emissivities eh,v(q0, f0) and the scattered down-\nwelling temperature TSC,h,v(q0, f0):\n\nep0\u00f0q0;f0\u00de \u00bc 1?\n1\n\n4p cos q0\n\nZZ n\ns0p0;p0\u00f0q0;f0; qs;fs\u00de \u00fe s0p0;ps\u00f0q0;f0; qs;fs\u00de\n\no\ndUs. (4.6)\n\nTSC;p0\u00f0q0;f0\u00de \u00bc\n1\n\n4p cos q0\n\nZZ n\ns0p0;p0\u00f0q0;f0; qs;fs\u00de \u00fe s0p0;ps\u00f0q0;f0; qs;fs\u00de\n\no\nTDN\u00f0qs;fs\u00dedUs (4.7)\n\nEqs. (4.6) and (4.7) can be simplified in two cases of special interest: a specular surface and a\ncompletely rough surface.\n\n4.1.3.1 Simple Emissivity Models: Emission From a Perfect Specular Surface\nThe scattering produced at a specular flat surface consists of the coherent reflection of the incident\nwave only. The cross-polar coefficients are zero, and the h and v scattering coefficients become delta\nfunctions:\n\ns0p0;ps\u00f0q0;f0; qs;fs\u00de \u00bc 0; (4.8)\n\nFIGURE 4.4\n\nBrightness temperature of a semi-infinite medium at a uniform temperature (Ulaby et al., 1981).\n\nReproduced by permission from Ulaby, F., Moore, R.K., Fung, A.K., 1981. Microwave Remote Sensing. Active and Passive, Vol I:\n\nMicrowave Remote Sensing Fundamentals and Radiometry. Artech House, Inc., Norwood, MA. \u00a9 1981 by Artech House, Inc.\n\n4.1 BASIC CONCEPTS ON MICROWAVE RADIOMETRY 135\n\nmailto:Image of Figure 4.4|tif\n\n\ns0p0;p0\u00f0q0;f0; qs;fs\u00de \u00bc 4pG\u00f0q0; p0\u00de\ncos q0\nsin qsp\n\nd\u00f0qs ? qsp\u00ded\n?\nfs ? fsp\n\n?\n; (4.9)\n\nwhere (qsp, fsp) is the specular reflection direction.\nReplacing Eqs. (4.8) and (4.9) in Eqs. (4.6) and (4.7) the following equations are readily obtained:\n\nep0\u00f0q0;f0\u00de \u00bc 1? G\u00f0q0; p0\u00de; (4.10)\nTSC;p0\u00f0q0;f0\u00de \u00bc G\u00f0q0; p0\u00de $ TDN\u00f0q0\u00de. (4.11)\n\nFig. 4.5 illustrates this behavior. The horizontal polarization (solid line) and vertical polarization\n(dashed line) emissivity (left axis) and reflectivity (right axis) for flat surfaces with different dielectric\nconstants are plotted versus the incidence angle. The following general trends can be observed:\n\n\u2022 At nadir (qi \u00bc 0?) the emissivity/reflectivity at horizontal and vertical polarizations are the same.\n\u2022 For the horizontal polarization, the emissivity/reflectivity always decreases/increases\n\nmonotonically down to zero/up to one at qi \u00bc 90?.\n\u2022 For the vertical polarization, the emissivity/reflectivity increases/decreases up to a given angle\n\nwhere it is a maximum/minimum, and then monotonically decreases/increases down to zero/up to\none at qi \u00bc 90?. The angle at which the emissivity is maximum/reflectivity is minimum (actually\nzero for a lossless medium) is called the Brewster angle. The Brewster angle increases for higher\n\n1.0\n\n0.9\n\n0.8\n\n0.7\n\n0.6\n\nHorizontally Polarized\nVertically Polarized\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0.0\n0 10 20 30 40\n\nAngle of Incidence ?, degrees\n50 60 70 80 90\n\n1.0\n\n0.9\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0.0\n\nE\nm\n\nis\nsi\n\nvi\nty\n\n, e\nv a\n\nnd\n e\n\nh\n\nR\nef\n\nle\nct\n\niv\nity\n\n, ?\nv a\n\nnd\n ?\n\nh\n\nSea Water, 20\u00b0 C\n36 \u2030 salinity\n\n? = 54.4 - j36.8\n\nLoamy Soil\n25% moisture content\n\n? = 17.9 - j7.2\n\nLoamy Soil\n5% moisture content\n\n? = 3.5 - j0.4\n\nFIGURE 4.5\n\nHorizontal (solid line) and vertical (dashed line) emissivity (left) and reflectivity (right) for flat surfaces with\n\ndifferent dielectric constants.\n\n(Ulaby et al., 1981).\n\n136 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.5|eps\n\n\ndielectric constant values, although if there are losses, the emissivity/reflectivity does not reach\nthe maximum/minimum value of one/zero.\n\nAs it will be seen later, the selection of the observation angle of the conical scanning micro-\nwave radiometers is very much linked to the Brewster angle over the ocean, to minimize the effect\nof the surface roughness (wind) on vertical polarization, and to be able to better perform atmo-\nspheric corrections, used in the horizontal polarization data resulting in more accurate surface\nwind speeds.\n\n4.1.3.2 Simple Emissivity Models: Emission From a Lambertian Surface\nThe scattering coefficient from a perfectly rough surface, also called a Lambertian surface, depends\nonly on the product of cosq0 $ cosqs:\n\ns0p0;p0\u00f0q0;f0; qs;fs\u00de \u00fe s0p0;ps\u00f0q0;f0; qs;fs\u00de \u00bc s00 $ cos q0 $ cos qs; (4.12)\nwhere s00 is a constant related to the dielectric properties of the scattering surface. The emissivity is\nthen readily obtained by replacing Eq. (4.12) in Eq. (4.6):\n\nep0\u00f0q0;f0\u00de \u00bc 1?\n1\n\n4p cos q0\n\nZZ\ns00 $ cos q0 $ cos qs $ dUs \u00bc 1?\n\ns00\n4\n; (4.13)\n\nwhich is independent of the polarization and incidence angles.\nNatural surfaces do not have either a perfect specular behavior, or a Lambertian behavior. They\n\nexhibit a mixed behavior, depending on the dielectric properties of the surface, and the surface\nroughness as compared to the wavelength.\n\n4.1.4 POWER COLLECTED BY AN ANTENNA SURROUNDED BY A BLACKBODY\nThe power collected by an antenna from a direction (q, f) can be computed as:\n\ndP\u00f0q;f\u00de \u00bc Aeff $Bf $ jFn\u00f0q;f\u00dej2; (4.14)\nwhere Aeff (m\n\n2) is the effective area of the antenna, and jFn(q, f)j2 is the normalized copolar antenna\nradiation pattern. Therefore, the total power collected by the antenna is computed as:\n\nP \u00bc 1\n2\n\nZ f0\u00feB2\nf0?B2\n\nZZ\n4 $p\n\nAeff $Bf $ jFn\u00f0q;f\u00dej2dU $ df ; (4.15)\n\nwhere the integration in Eq. (4.15) takes place over the whole space (4p stereo-radians, Fig. 4.6)\nand over the receiver\u2019s noise bandwidth defined as B \u00bc R\u00feN?N jHn\u00f0 f \u00dej2df , where Hn ( f ) is the\nnormalized receiver\u2019s (voltage) frequency response. The term\u00bd takes into account the fact that the\nantenna collects the power in one polarization only, while the thermal power emitted is randomly\npolarized.\n\n4.1 BASIC CONCEPTS ON MICROWAVE RADIOMETRY 137\n\n\n\nTaking into account that Aeff \u00bc l2/Ueq, where the antenna solid angle is defined as\nUeq \u00bc\n\nRR\n4 $pjFn\u00f0q;f\u00dej2dU, the total power collected by the antenna can be simply expressed as:\n\nP \u00bc 1\n2\n\nZ f0\u00feB2\nf0?B2\n\nZZ\n4 $p\n\nAeff $Bf $ jFn\u00f0q;f\u00dej2dU $ df\n\n\u00bc 1\n2\n\nZ f0\u00feB2\nf0?B2\n\nZZ\n4 $p\n\nl2\n\nUeq\n$\n2 $ kB $ Tph\n\nl2\n$ jFn\u00f0q;f\u00dej2dU $ df \u00bc kB $ Tph $B;\n\n(4.16)\n\nwhich is actually the same power as the one generated by a matched load at the same physical tem-\nperature, a result derived by Johnson and Nyquist in 1928. This means that for an ideal receiver of\nnoise bandwidth B, the antenna delivers to the load the same power as a resistance at the same physical\ntemperature. This is a very important result, and it will be emphasized when talking about the ar-\nchitecture of microwave radiometers and their internal calibration.\n\n4.1.5 POWER COLLECTED BY AN ANTENNA SURROUNDED BY A GRAY BODY:\nAPPARENT TEMPERATURE AND ANTENNA TEMPERATURE\n\nThe apparent temperature is an equivalent temperature related to the total brightness incident over the\nantenna, Bi(q, f):\n\nBi\u00f0q;f\u00de \u00bc 2 $ kB\nl2\n\n$ TAP\u00f0q;f\u00de. (4.17)\n\nMain lobe\nFn( ?,   )\n\nB( ?,    )\n\nd??\n\nSide-lobes\n\nx y\n\nz ?\n\n?\n\n?\n\nFIGURE 4.6\n\nGeometry of the radiation incident over the antenna (Ulaby et al., 1981).\n\nReproduced by permission from Ulaby, F., Moore, R.K., Fung, A.K., 1981. Microwave Remote Sensing. Active and Passive, Vol I:\n\nMicrowave Remote Sensing Fundamentals and Radiometry. Artech House, Inc., Norwood, MA. \u00a9 1981 by Artech House, Inc.\n\n138 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.6|eps\n\n\nThe apparent temperature depends on several terms related to the different sources irradiating the\nantenna. The relationship between them is shown in Fig. 4.7: the radiation emitted by the surface (land or\nsea) reaches the antenna attenuated by the atmosphere, the radiation emitted downwards by the at-\nmosphere and reflected off the Earth\u2019s surface in the antenna direction, and the upward radiation emitted\nby the atmosphere itself. The sum of all these contributions weighted by the antenna pattern leads to:\n\nP \u00bc 1\n2\n\nZ f0\u00feB2\nf0?B2\n\nZZ\n4 $p\n\nAeff $Bi $ jFn\u00f0q;f\u00dej2dU $ df\n\n\u00bc 1\n2\n\nZ f0\u00feB2\nf0?B2\n\nZZ\n4 $p\n\nl2\n\nUeq\n$\n2 $ kB $ TAP\u00f0q;f\u00de\n\nl2\n$ jFn\u00f0q;f\u00dej2dU $ df a kB $ TA $B;\n\n(4.18)\n\nwhich is similar to Eq. (4.16), but instead of the physical temperature Tph, a thermodynamic variable\ncalled the \u201cantenna temperature\u201d (TA, units of Kelvin) is defined.\n\nIn the frequency range from 1 to 10 GHz losses for a cloud-free atmosphere are very small and can\nbe neglected. Consequently, the apparent brightness temperature TAP can be approximated by the\nbrightness temperature TB.\n\nFIGURE 4.7\n\nRelationship between the antenna temperature, the apparent temperature and the brightness temperature\n\n(Ulaby et al., 1981).\n\nReproduced by permission from Ulaby, F., Moore, R.K., Fung, A.K., 1981. Microwave Remote Sensing. Active and Passive, Vol I:\n\nMicrowave Remote Sensing Fundamentals and Radiometry. Artech House, Inc., Norwood, MA. \u00a9 1981 by Artech House, Inc.\n\n4.1 BASIC CONCEPTS ON MICROWAVE RADIOMETRY 139\n\nmailto:Image of Figure 4.7|tif\n\n\n4.2 THE RADIATIVE TRANSFER EQUATION\nSo far, only the radiation at two polarizations has been considered, that in Earth observations are\nusually the vertical (v) and the horizontal (h) ones. As discussed in previous chapters, the polarization\nstate of an electromagnetic wave is completely described by four parameters, forming the\nso-called modified2 Stokes emission vector e\u00f0q;f\u00de \u00bc \u00bdeveheUeV ?T , which is related to the electric\nfields incident in the antenna at vertical and horizontal polarizations [Ev and Eh (V/m)] by (Tsang,\n1991, pp. 24e25):\n\nTB \u00bc\n\n266664\nTv\u00f0q;f\u00de\nTh\u00f0q;f\u00de\nT3\u00f0q;f\u00de\nT4\u00f0q;f\u00de\n\n377775 \u00bc Ts\n266664\nev\u00f0q;f\u00de\neh\u00f0q;f\u00de\ne3\u00f0q;f\u00de\ne4\u00f0q;f\u00de\n\n377775 \u00bc l\n2\n\nhkBB\n\n2666664\n?\nEvE\n\n?\nv\n\n??\nEhE\n\n?\nh\n\n?\n2Re\n\n?\nEvE\n\n?\nh\n\n?\n2Im\n\n?\nEvE\n\n?\nh\n\n?\n\n3777775; (4.19)\nwhere Tv and Th are, as above, the brightness temperatures at vertical and horizontal polarizations,\nrespectively; T3 and T4 are the so-called third and fourth modified Stokes elements, respectively; Ts is\nthe surface\u2019s soil temperature (assumed to be constant with depth), l is the electromagnetic\nwavelength, h is the wave impedance, kB is Boltzmann\u2019s constant, B is the radiometer\u2019s noise band-\nwidth, and < > stands for the expectation operator.\n\nIn Eq. (4.19) the third and fourth Stokes elements can also be computed not as complex cross-\ncorrelations, but as the difference between two absolute powers: T3 \u00bc T\u00fe45? ? T?45?, where T\t45?\nis the brightness temperatures at \t45?, and T4 \u00bc TLHCP ? TRHCP, where TLHCP and TRHCP are the\nbrightness temperatures at left and right hand circular polarizations.\n\nThe problem of computing the modified Stokes emission vector on top of a generic layer, that may\ninclude absorption and scattering, is a very complex one. In the following paragraphs the complete\nformulation will be provided, and later the most common simplifications used will be presented.\n\n4.2.1 THE COMPLETE POLARIMETRIC RADIATIVE TRANSFER EQUATION\nThe polarimetric emission can be computed by means of the radiative transfer equation (RTE)\n(Tsang, 1991) as:\n\ncos q $\ndTB\u00f0q;f; z\u00de\n\ndz\n\u00bc ?ke\u00f0q;f\u00deTB\u00f0q;f; z\u00de \u00fe F\u00f0q;f\u00de $ T\u00f0z\u00de\n\n\u00fe\nZ 2p\n0\n\nZ p\n0\n\nP\n?\nq;f; q\n\n0\n;f\n\n0?\nTB\n\n?\nq\n0\n;f\n\n0\n; z\n?\ndU0;\n\n(4.20)\n\nwhere T(z) is the temperature distribution, and the Stokes vector TB is related to the electric fields\nincident in the antenna at vertical and horizontal polarizations [Ev and Eh (V/m)], Eq. (4.20).\n\n2The word \u201cmodified\u201d is used because usually in optics the first Stokes parameter is the sum I \u00bc Tv \u00fe Th, while the second\none is the difference Q \u00bc Tv ? Th.\n\n140 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nThe extinction matrix ke is given by (Tsang, 1991):\n\nke \u00bc 2pn0\nk\n\n266664\n2Jmh fvvi 0 Jmh fvhi ?<eh fvhi\n\n0 2Jmh fhhi Jmh fhvi <eh fhvi\n2Jmh fhvi 2Jmh fvhi Jmh fvv \u00fe fhhi ?<eh fvv ? fhhi\n2<eh fhvi ?2<eh fvhi <eh fhh ? fwi Jmh fvv \u00fe fhhi\n\n377775 (4.21)\nwhere n0 is the number of particles per unit of volume, k \u00bc 2p/l is the wave number, and fpq are the\nforward scattering amplitude functions that provide the amplitude, phase, and polarization information\n\nof the scattered field at q-polarization E\n!\n\nq \u00bc e_qfpq\n?\nq; q\n\n0\n;f;f\n\n0?\ne?jkr\n\n?\nr, when a plane wave at\n\np-polarization E\n!\n\ni \u00bc e_pe?j k\n!\n\ninc r\n!\n\nis incident on each scatterer. The forward scattering amplitudes are\n\ncomputed as the average of the forward scattering amplitudes of each individual scatterer (branches,\nleaves, etc. in a canopy, or water drops, ice crystals, etc. in the atmosphere, for example) over the\nensemble of sizes (a0) according to their distribution [N(a0)]:\n\n< fpq > \u00bc\nZ amax\n0\n\nfpq\u00f0a0\u00deN\u00f0a0\u00deda0. (4.22)\nFor example, in the case of water droplets N (a0) could be the Laws and Parsons (1943) distribution,\n\namong others, and a0 is the radius of the water drops.\nThe emission vector F\u00f0q;f\u00de in Eq. (4.20) is given by (Tsang, 1991, p. 282):\n\nF\u00f0q;f\u00de \u00bc \u00bdka1\u00f0p? q;p\u00fe f\u00de ka2\u00f0p? q;p\u00fe f\u00de ? ka3\u00f0p? q;p\u00fe f\u00de ? ka4\u00f0p? q;p\u00fe f\u00de?T ;\n\nka1\u00f0q;f\u00de \u00bc ke11\u00f0q;f\u00de ?\nZ h\n\nP11\n\n?\nq;f; q\n\n0\n;f\n\n0?\u00fe P21?q;f; q0 ;f0?idU0;\nka2\u00f0q;f\u00de \u00bc ke22\u00f0q;f\u00de ?\n\nZ h\nP12\n\n?\nq;f; q\n\n0\n;f\n\n0?\u00fe P22?q;f; q0 ;f0?idU0;\nka3\u00f0q;f\u00de \u00bc 2ke13\u00f0q;f\u00de \u00fe 2ke23\u00f0q;f\u00de ? 2\n\nZ h\nP13\n\n?\nq;f; q\n\n0\n;f\n\n0?\u00fe P23?q;f; q0 ;f0?idU0;\nka4\u00f0q;f\u00de \u00bc ?2ke14\u00f0q;f\u00de ? 2k24\u00f0q;f\u00de \u00fe 2\n\nZ h\nP14\n\n?\nq;f; q\n\n0\n;f\n\n0?\u00fe P24?q;f; q0 ;f0?idU0.\n(4.23)\n\nAnd the phase matrix P\n?\nq; q\n\n0\n;f;f\n\n0\n?\nin Eqs. (4.20) and (4.23) is given by (Tsang, 1991):\n\nP\n?\nq; q\n\n0\n;f;f\n\n0? \u00bc n0\n266666664\n\nD\nj fvvj2\n\nE D\nj fvhj2\n\nE\n<e?fvvf ?vh? ?Jm? fvvf ?vh?D\n\nj fhvj2\nE D\n\nj fhhj2\nE\n\n<e?fhvf ?hh? ?Jm? fhvf ?hh?\n2<e? fvvf ?hv? 2<e? fvh f ?hh? <e? fvvf ?hh \u00fe fvh f ?hv? ?Jm? fvvf ?hh \u00fe fvh f ?hv?\n2Jm\n\n?\nfvvf\n\n?\nhv\n\n?\n2Jm\n\n?\nfvh f\n\n?\nhh\n\n?\nJm\n?\nfvvf\n\n?\nhh \u00fe fvh f ?hv\n\n? <e? fvvf ?hh \u00fe fvh f ?hv?\n\n377777775:\n\n(4.24)\nIt should be noted that in the computation of the phase matrix (Eq. 4.24) the multiple scattering\n\nbetween the scatterers and between scatterers and the surface has to be accounted for. However,\n\n4.2 THE RADIATIVE TRANSFER EQUATION 141\n\n\n\nusually, only scattering terms up to first-order scattering are included. For example, in the case of a\nvegetation structure over the ground only the following terms are included: (1) the direct scattered\nfield, (2) the scattered field when the incident field is reflected off the soil surface, (3) the scattered field\nreflected off the soil surface when the incident field impinges directly on the element, and (4) the\ncombination of (2) and (3) (Fig. 4.8). This assumption together with the far-field simplification helps to\nmaintain the overall computation complexity at an affordable level.\n\nFinally, the solution of Eq. (4.20) entails the application of the following boundary conditions:\nTup;p\u00f0q;f; z \u00bc 0\u00de the upwelling surface\u2019s emission (height \u00bc 0), and Tdn;p\u00f0q;f; z \u00bc h\u00de the down-\nwelling emission at the top of the layer (height \u00bc h).\n\n4.2.2 USUAL APPROXIMATIONS TO THE RADIATIVE TRANSFER EQUATION\nThe solution of Eq. (4.20) is very complex, and usually a number of approximations are made. These\n\napproximations assume that either the medium is a nonscattering one (P \u00bc 0) or that only the forward\nscattering is dominant. In this case if, in addition, the physical temperature of the medium is constant,\nthe radiative transfer equation becomes\n\nTap;p \u00bc Tphjz\u00bc0 $ ep\u00f0q;f\u00de $ e?sp=cos q \u00fe \u00f01? up\u00de $ Tph $\n?\n1? e?sp=cos q\n\n?\n$\nn\n1\u00fe Gp\u00f0q;f\u00de $ e?sp=cos q\n\no\n;\n\n(4.25)\n\nwhere the single scattering albedo up is defined as:\n\nuv \u00bc\n\nR h\nP11\n\n?\nq;f; q\n\n0\n;f\n\n0\n?\n\u00fe P21\n\n?\nq;f; q\n\n0\n;f\n\n0\n?i\n\ndU0\n\nke11\u00f0q;f\u00de ; (4.26a)\n\nuh \u00bc\n\nR h\nP12\n\n?\nq;f; q\n\n0\n;f\n\n0\n?\n\u00fe P22\n\n?\nq;f; q\n\n0\n;f\n\n0\n?i\n\ndU0\n\nke22\u00f0q;f\u00de ; (4.26b)\n\nand the opacity is defined as:\n\nsv \u00bc\nZ hly\n0\n\nke11\u00f0q;f\u00deds; (4.27a)\n\nSt Sgt Stg Sgtg\n\nFIGURE 4.8\n\nFour contributions to the scattered fields considered in the model. From left to right: trunketrunk,\n\ntrunkeground, groundetrunk, and groundetrunk-ground.\n\n142 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.8|eps\n\n\nsh \u00bc\nZ hly\n0\n\nke22\u00f0q;f\u00deds; (4.27b)\n\nThe physical interpretation of Eq. (4.25) is the following: the first term represents the surface\u2019s\n\nemission\n?\nTB;p \u00bc Tphjz\u00bc0 $ ep\u00f0q;f\u00de\n\n?\n, which is then attenuated on the way up by a factor e?sp=cos q; the\n\nsecond term is called Tup,p and represents the emission introduced by the losses in the medium\n\nTph $\n?\n1? e?sp=cos q?, that gets scattered on the way up [(1 ? up) term], and finally the third term is\n\nequal to the second one, but is the downwelling radiation (Tdn,p \u00bc Tup,p), which includes other con-\ntributions that are reflected over the surface (TSC,p \u00bc Gp(q, f)$Tdn,p \u00bc TSC,p) and are attenuated on the\nway up\n\n?\ne?sp=cos q\n\n?\n. These other noise sources include the Sun and Moon radiation (if visible), the\n\ncosmic background, which is nearly homogeneous Tcos \u00bc 2.7K, and the galactic noise, very important\nbeloww1 GHz, and strongly dependent on the antenna boresight direction, toward the galactic plane,\nor the galactic pole, which prevents useful observations below 1 GHz,\n\nTdn \u00bc Tatmdn \u00fe \u00f0Tgal \u00fe Tcos \u00fe TSun \u00fe TMoon\u00dee?s\u00f00;N\u00desec q. (4.28)\nThe largest solar flare ever recorded is depicted in Fig. 4.9 while the TRMM microwave imager\n\n(TMI) satellite\u2019s viewing angle matched the specular reflection angle from the Sun at 10.7 GHz\n(Remote Sensing Systems website, 2013). Fig. 4.10 shows the map of the galactic noise at 1.4 GHz this\nnoise reflects over the Earth\u2019s surface and ends up reaching the sensor. Figures correspond to wind\nspeed ranges 0e3, 3e6, 6e8, and 8e12 m/s. Note that for increasing wind speeds, the peak amplitude\nof the scattered galactic noise decreases, and the width of the band increases, due to the increased sea\nsurface roughness.\n\nWe show the computed antenna temperature in Fig. 4.11 for a narrow beam antenna as a function of\nthe elevation angle and frequency. Note the rapid increase below 1 GHz associated with the galactic\nnoise contribution, and above w10 GHz due to the increased atmospheric attenuation, which is\nespecially relevant at around 22 and 60 GHz. Note also that plots for lower elevation angles indicate a\nlarger antenna temperature due to the increased atmospheric path length, and attenuation.\n\nFIGURE 4.9\n\nLargest solar flare event ever recorded erupted while the TRMM microwave imager (TMI) satellite\u2019s viewing\n\nangle matched the specular reflection angle (November 4, 2003, atw19:47 UTC) (Remote Sensing Systems\nwebsite, 2013).\n\n4.2 THE RADIATIVE TRANSFER EQUATION 143\n\nmailto:Image of Figure 4.9|tif\n\n\nSolid curves correspond to the antenna temperature as a function of the elevation angle, for the\nmean galactic temperature. Upper dashed curve corresponds to the antenna temperature for the\nmaximum galactic noise (antenna pointing to the galaxy center). Lower dashed curve corresponds to\nthe antenna temperature for minimum galactic noise (antenna pointing to the galactic pole). Maxima\naround 22 and 60 GHz are due to the water vapor and oxygen absorption resonances, respectively\n(Blake, 1962).\n\nEven though, strictly speaking, Eq. (4.25) is only valid in the low microwave frequency range, it is\nusually applied up to very high frequencies, provided the parameters involved are empirically adjusted.\nAt microwave frequencies, for typical atmospheric conditions, scattering is minimal, except by liquid\nwater drops varying in size from small drops in clouds and fog (1e10 mm in diameter) to the largest\nrain drops (up to w5e10 mm). In these cases, the full RTE has to be solved, although often other\nassumptions, such as a horizontally stratified atmosphere, are applied for the sake of simplicity.\n\nFIGURE 4.10\n\nSky noise at 1.4 GHz. The band corresponds to the galactic plane.\n\n144 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.10|tif\n\n\nIn the following sections the behavior of the atmosphere, the soil, either bare or covered by vegetation\nor snow, or the sea, including the effects of wind, frozen or covered by oil slicks is explained.\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES\n4.3.1 THE ATMOSPHERE\nThe atmosphere acts as an attenuator and as a scatter. Up to about 300 GHz, the most significant gases\naffecting propagation are water vapor and oxygen. Depending on the frequency and, eventually, the\npresence of hydrometeors, scattering can be important.\n\nTo analyze the behavior of the atmosphere, let us first study the noise introduced by a homogeneous\n\u201cslice\u201d of the atmosphere using the model of a lossy transmission line of characteristic impedance Z0 at\nconstant temperature Tph terminated by two matched loads at its ends (Fig. 4.12). Each matched load\nproduces a noise power equal to kB $ Tph $ B, which at the other end appears attenuated by a factor 1/L.\nIn thermodynamic equilibrium, the transmission line must introduce an amount of noise equal to the\ndifference between what the matched loads are giving (kB $ Tph $ B), and what they are receiving\n(kB $ Tph $ B/L): kB $ Tph $ B $ (1 ? 1/L).\n\n10,000\n\n1,000\n\n0\u00b0\n\n90\u00b0\n\n? = 90\u00b0? = 90\u00b0? = 90\u00b0\n? = 30\u00b0? = 30\u00b0? = 30\u00b0\n\n? = 10\u00b0? = 10\u00b0? = 10\u00b0\n? = 5\u00b0? = 5\u00b0? = 5\u00b0\n\n? = 2\u00b0? = 2\u00b0? = 2\u00b0\n? = 1\u00b0? = 1\u00b0? = 1\u00b0\n\n? = 0\u00b0? = 0\u00b0? = 0\u00b0\n\n100\n\n10\n\n1\n100 1,000 10,000 100,000\n\nFrequency (MHz)\n\nN\noi\n\nse\n T\n\nem\npe\n\nra\ntu\n\nre\n (K\n\n)\n\nFIGURE 4.11\n\nAntenna sky temperature for an ideal lossless antenna at the Earth\u2019s surface as a function of frequency and\n\nelevation angle.\n\n(Ulaby et al., 1981).\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 145\n\nmailto:Image of Figure 4.11|eps\n\n\nTherefore, an absorbing atmosphere not only attenuates the radiation passing through it, but it also\nintroduces an additional noise, which in the upwelling direction is called Tatmup , and in the downwelling\ndirection Tatmdn .\n\nIn a more general, although simplified, case the atmosphere can be treated as a stratified series of\nattenuators each one at a given physical temperature, as illustrated in Fig. 4.13. The total upwelling\ntemperature (Eq. 4.29) can be computed as the sum of the contributions from every single layer at\n\nheight z and thickness secq $ dz attenuated by all upper layers e?s(z,H)secq, where s\n?\nz\n0\n;H\n? \u00bc RHZ 0 ka\u00f0z\u00dedz\n\nis called the atmospheric opacity. The brightness of each layer is the product of its physical\ntemperature T(z) times its emissivity, which by Kirchhoff\u2019s law is equal to the absorption coefficient\ne(z) \u00bc ka(z). Similarly, the downwelling temperature (Eq. 4.30) can be computed as the sum of the\ncontributions from every single layer at height z and thickness secq $ dz attenuated by all lower layers\n\ne?s(0,z)secq, where s\u00f00; z\u00de \u00bc R z0 ka?z0?dz0 .\nTatmup \u00f0q;H\u00de \u00bc sec q\n\nZ H\n0\n\nka\n\n?\nz\n0?\nT\n?\nz\n0?\ne?s\u00f0z\n\n0\n;H\u00desec qdz0 ; (4.29)\n\nTatmdn \u00f0q;H\u00de \u00bc sec q\nZ N\n0\n\nka\n\n?\nz\n0?\nT\n?\nz\n0?\ne?s\u00f00;z\n\n0 \u00desec qdz0 . (4.30)\n\nkBTphB\n\nkBTphB\n\nkBTphB/L\n\nkBTphB/L\n\nkBTphB(1-1/L) kBTphB(1-1/L)Z0Z0 Z0\n\nFIGURE 4.12\n\nLossy transmission line model to compute the noise introduced by a homogeneous \u201cslice\u201d of the atmosphere\n\nat constant temperature.\n\nH\nz\n\nAtmosphere Atmosphere\n\nTerrain Terrain\n\nTUP(?; H)\n\nTDN(?)\n\n? ?\n\nFIGURE 4.13\n\nHorizontally stratified model of the atmosphere to compute Tatmup and T\natm\ndn (Ulaby et al., 1981).\n\nReproduced by permission from Ulaby, F., Moore, R.K., Fung, A.K., 1981. Microwave Remote Sensing. Active and Passive, Vol I:\n\nMicrowave Remote Sensing Fundamentals and Radiometry. Artech House, Inc., Norwood, MA. \u00a9 1981 by Artech House, Inc.\n\n146 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.12|eps\nmailto:Image of Figure 4.13|eps\n\n\nAtmospheric attenuation can be due to gases, rain, clouds, and fog and in general hydrometeors in\nliquid phase. Due to the much lower dielectric constant of ice, and negligible losses, snow and ice do\nnot introduce much attenuation, but they do introduce scattering and wave depolarization. In the\nfollowing sections, the attenuation induced by different hydrometeors is detailed.\n\n4.3.1.1 Attenuation by Atmospheric Gases\nUp to 1 THz, the specific attenuation due to dry air and water vapor can be most accurately evaluated at\nany pressure, temperature, and humidity by summation of the individual resonance lines from oxygen\nand water vapor, together with small additional factors for the nonresonant Debye spectrum of oxygen\nbelow 10 GHz, pressure-induced nitrogen attenuation above 100 GHz, and a wet continuum to account\nfor the excess water vapor absorption found experimentally.\n\nThe specific attenuation using the model is displayed in Fig. 4.14, calculated from 0 to 350 GHz,\nfor a pressure of 1013 hPa, temperature of 15?C for the cases of a water vapor density of 7.5 g/m3 (blue\ncurve), and a dry atmosphere (red curve).\n\nNear 60 GHz, many oxygen absorption lines merge together, at sea-level pressure, to form a single,\nbroad absorption band, as shown in Fig. 4.14. At higher altitudes, the atmospheric pressure is lower,\nand the individual lines of the oxygen attenuation become resolved. Some additional molecular species\n(e.g., oxygen isotopic species, oxygen vibrationally excited species, ozone, ozone isotopic species, and\nozone vibrationally excited species, and other minor species) are not included in the\nline-by-line prediction method. These additional lines are insignificant for typical atmospheres, but\nmay be important for a dry atmosphere.\n\n102\n\n10\u20131\n\n10\u20132\n\n102\n10\u20133\n\n1 10\nFrequency (GHz)\n\nPressure: 1 013 hPa\nTemperature: 15\u00b0 C\n\nWater vapour density: 7.5 g/m3\n\n10\n\n1\n\n2\n\n5\n\n2\n\n5\n\n2\n\n5\n\n2\n\n5\n\n2\n\n2 5 2 5 2 3.5\n\n5\n\nS\npe\n\nci\nfic\n\n a\ntte\n\nnu\nat\n\nio\nn \n\n(d\nB\n\n/k\nm\n\n)\n\nTotal\n\nTotal\n\nWater vapour\n\nDry air\n\nFIGURE 4.14\n\nSpecific attenuation due to atmospheric gases (Recommendation ITU-R P.676, 2012) for water vapor (blue\n\nline) and a dry atmosphere (red line).\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 147\n\nmailto:Image of Figure 4.14|eps\n\n\nThe specific gaseous attenuation is given by:\n\ng \u00bc go \u00fe gw \u00bc 0:1820 $ f $N\n00 \u00f0 f \u00de \u00f0dB=km\u00de; (4.31)\n\nwhere go and gw are the specific attenuations [in (dB/km)] due to dry air (oxygen, pressure-induced\nnitrogen, and nonresonant Debye attenuation) and water vapor, respectively, and where f is the\nfrequency (GHz) and N\n\n00\nf is the imaginary part of the frequency-dependent complex refractivity:\n\nN\n00 \u00f0 f \u00de \u00bc\n\nX\ni\n\nSiFi \u00fe N 00D\u00f0 f \u00de; (4.32)\n\nwhere Si is the strength of the i-th line, Fi is the line shape factor, and the sum extends over all the\nlines,3 and N\n\n00\nD\u00f0 f \u00de is the dry continuum due to pressure-induced nitrogen absorption and the Debye\n\nspectrum.\n\n4.3.1.2 Attenuation by Rain\nA detailed analysis of rain effects requires accounting for the scattering and attenuation introduced by\neach raindrop size, weighted by their relative distribution, as shown in Fig. 4.15 (Laws and Parsons,\n1943) and calculated in Eq. (4.22) (see, for example, Duffo et al., 2009).\n\nHowever, if we are interested in the simpler horizontally stratified nonscattering atmosphere model,\nthe specific attenuation gR in (dB/km) as a function of the rain rate R (mm/h) can be computed using\nthe power-law relationship:\n\ngR \u00bc kRa; (4.33)\nwhere the coefficients kh,v and ah,v for horizontal and vertical polarizations are shown in Figs. 4.16\nand 4.17.\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\n0 0 1 2 3\nDrop diameter (mm)\n\n4 5 6 7\n\n%\n t\n\no\nta\n\nl \nv\no\nlu\n\nm\ne\n\n0.25 mm/hr\n\n1.25 mm/hr\n\n2.5 mm/hr\n5 mm/hr\n\n12.5 mm/hr\n25 mm/hr\n\n50 mm/hr\n100 mm/hr\n\n150 mm/hr\n\n(B)(A)\n\nFIGURE 4.15\n\n(A) Shape of a raindrop for equivalent radii: 0.25, 0.50, ., 3.25 mm. (B) Laws and Parsons equivalent radii\ndistribution versus rain rate (0.25, ., 150 mm/h).\n\n3For frequencies above 118.750343 GHz oxygen line, only the oxygen lines above 60 GHz complex should be included in\nthe summation; the summation should begin at i \u00bc 38 rather than at i \u00bc 1.\n\n148 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.15|eps\n\n\n4.3.1.3 Attenuation by Clouds and Fog\nFor clouds or fog consisting entirely of small droplets, generally less than 0.01 cm, the Rayleigh\napproximation is valid for frequencies below 200 GHz and it is possible to express the attenuation in\nterms of the total water content per unit volume. Thus the specific attenuation gc within a cloud or fog\ncan be written as:\n\ngc \u00bc Kl $M \u00f0dB=km\u00de (4.34)\n\nFIGURE 4.16\n\nCoefficients for kh (left) and kv (right) (Recommendation ITU-R P.838-3).\n\nFIGURE 4.17\n\nCoefficients for ah (left) and av (right) (Recommendation ITU-R P.838-3).\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 149\n\nmailto:Image of Figure 4.16|eps\nmailto:Image of Figure 4.17|eps\n\n\nwhere Kl is the specific attenuation coefficient in (dB/km)/(g/m\n3); and M is the liquid water density in\n\nthe cloud or fog in (g/m3).\nAt frequencies of the order of 100 GHz and above, attenuation due to fog may be significant. The\n\nliquid water density in fog is typically about 0.05 g/m3 for medium fog (visibility on the order of\n300 m), and 0.5 g/m3 for thick fog (visibility on the order of 50 m).\n\nThe values of Kl at frequencies from 5 to 200 GHz and temperatures between ?8?C and 20?C are\nshown here in Fig. 4.18. For cloud attenuation, the curve corresponding to 0?C should be used.\n\nTo obtain the attenuation [in (dB)] due to clouds for a given probability, the statistics of the total\ncolumnar content of liquid water L (kg/m2) or, equivalently, millimeters of precipitable water:\n\nA \u00bc LKl\nsin q\n\n\u00f0dB\u00de for 5? ? q ? 90? (4.35)\n\nwhere q is the elevation angle and Kl is provided in Fig. 4.18.\n\n4.3.2 THE IONOSPHERE\nThe ionosphere is a region in the uppermost portion of the Earth\u2019s atmosphere that extends from\nw50 km altitude to more thanw600 km. It is composed by ionized particles and electrons formed by\n\nFrequency (GHz)\n\nSp\nec\n\nifi\nc \n\nat\nte\n\nnu\nat\n\nio\nn \n\nco\nef\n\nfic\nie\n\nnt\n, K\n\nl (\n(d\n\nB\n/k\n\nm\n) /\n\n (g\n/m\n\n3 ))\n   \n\n0.01\n\n0.02\n\n0.05\n\n0.1\n\n0.2\n\n0.5\n\n1\n\n2\n\n5\n\n10\n\n5 10 20 50 100 200\n\n0\u00b0 C\n\n20\u00b0 C\n10\u00b0 C\n\n   \u2013 8\u00b0 C\n\nFIGURE 4.18\n\nSpecific attenuation by water droplets at various temperatures as function of frequency (Recommendation\n\nITU-R P.840-5).\n\n150 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.18|eps\n\n\nthe interaction of the solar wind with the very thin air particles that have escaped the Earth\u2019s gravity.\nSince the Sun is the source of energy to ionize these particles, solar activity plays a key role in the\nconcentration of ions, which exhibit a diurnal and seasonal cycles, as well as a 11-year cycle linked to\nthe solar activity (Fig. 4.19). The solar activity is measured in solar flux units (SFU) which is directly\nlinked to the daily sunspot number (R):\n\nSFU \u00bc 63:7\u00fe 0:728 $R\u00fe 0:00089 $R2; (4.36)\nbeing 1 SFUb 10?22 W\n\n?\nm2\n?\nHz.\n\nThe concentration of ionized particles is also very dependent on the altitude: the higher the altitude,\nthe more energy the solar wind particles have, but the lower the atmospheric density, and the lower the\naltitude, the more attenuated the solar particles are, but the higher the atmospheric density. The\ncombination of these two factors leads to a continuous vertical profile of the electron density [in\n(e?/cm3)], with local maxima and minima (Fig. 4.20), which leads to the definition of the layered\nstructure sketched in Fig. 4.21, with its diurnal dependence.\n\nFIGURE 4.19\n\nWolf number since 1750.\n\n1000\n\n500\n\n300\n\n200\n\n100\n\nA\nlti\n\ntu\nde\n\n (k\nm\n\n)\n\n10 102 103 104 105 106 107\n\nElectron density (per cm3)\n\nD D\n\nE E\n\nF\n\nF1\n\nF2\n\nNight time Solar minimum\n\nNight time Solar maximum\n\nDay time Solar minimum\n\nDay time Solar maximum\n\nFIGURE 4.20\n\nDiurnal variation of the ionospheric electron density profile as a function of the altitude (http://sidstation.\n\nloudet.org/ionosphere-en.xhtml).\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 151\n\nmailto:Image of Figure 4.19|tif\nmailto:Image of Figure 4.20|eps\nhttp://sidstation.loudet.org/ionosphere-en.xhtml\nhttp://sidstation.loudet.org/ionosphere-en.xhtml\n\n\nThe ionosphere layers are summarized below:\n\n\u2022 The D-layer is the lowest part of the ionosphere, and it appears from an altitude of 50e95 km.\nDue to the higher density it develops shortly after sunrise, but it also disappears shortly after\nsunset, reaching a maximum ionization when the Sun is at zenith.\n\n\u2022 The E-layer extends from an altitude of 90e150 km. It also develops shortly after sunrise, but\ndisappears a few hours after sunset. The maximum ionization of this layer is reached around\nmidday. The ions in this layer are mainly O2\n\n\u00fe.\n\u2022 The sporadic E-layer (Es) appears at an altitude that may vary anywhere between 80 and\n\n120 km. It is still not known how this layer actually develops, but, it can appear at any time of the\nday, with a preference for the late morning and early evening, mostly during the summer months\nand briefly at midwinter, with the peak occurring in the early summer.\n\n\u2022 The F-layer is the highest part of the ionosphere, extending between 250 and 500 km in altitude.\nJust before sunrise, the Sun illuminates the upper part of the atmosphere containing the F-layer,\nand due to an unclear physical mechanism, the sunlight causes the F-layer to split into two distinct\nlayers called the F1-layer and F2-layer. The F1-layer is located between 150 and 200 km in\naltitude during daylight hours. The maximum ionization is reached at midday. The F2-layer is\nlocated between 250 and 450 km in altitude, extending occasionally beyond 600 km. At the\n\nThe\nSun\n\nF2 layer\nD layer\n\nD layer\ndisappears\nat night\n\nE layer\nbecomes\nvery much\nweaker at\nnight\n\nF layer\n\nThe Earth\n\nE layer\n\nF1 layer\n\nFIGURE 4.21\n\nSimplified view of the layers in the ionosphere over the period of a day (http://www.radio-electronics.com/info/\n\npropagation/ionospheric/ionosphere.php).\n\nModified from http://www.radio-electronics.com/info/propagation/ionospheric/ionosphere.php\n\n152 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.21|eps\nhttp://www.radio-electronics.com/info/propagation/ionospheric/ionosphere.php\nhttp://www.radio-electronics.com/info/propagation/ionospheric/ionosphere.php\nhttp://www.radio-electronics.com/info/propagation/ionospheric/ionosphere.php\n\n\nlatitudes higher north or south of the equator, this layer is located at lower altitudes. The\nmaximum ionization is usually reached in winter, starting 1 h after sunrise and remaining until\nshortly after sunset. However, it shows a great variability during the day, due to its high sensitivity\nto solar activity and major solar events. Ions in the lower part of the F-layer are mainly NO\u00fe and\nare predominantly O\u00fe in the upper part.\n\nThe ionosphere plays an important role in the propagation of radio waves (also for radar systems),\nespecially at frequencies from 0.1 to 12 GHz. The main effects that take place on an Earth space path\nwhen the signal is passing through the ionosphere are (Recommendation ITU-R P.531-11, 2012)\nrotation of the polarization plane, also known as \u201cFaraday rotation,\u201d due to the interaction of the\nelectromagnetic wave with the ionized medium in the Earth\u2019s magnetic field along the path; absorption\nand emission due to ionospheric losses; group delay and phase advance of the signal due to the total\nelectron content accumulated along the path; rapid variations of the amplitude and phase (scintilla-\ntions) of the signal due to small-scale irregular structures in the ionosphere; a change in the apparent\ndirection of arrival due to refraction; and Doppler effects due to nonlinear polarization rotations and\ntime delays.\n\nFrom all these effects, in microwave radiometry only the Faraday rotation, the absorption and the\nemission are of concern, mainly at low microwave frequencies. For active systems (radar, satellite\nnavigation system, and other remote sensing systems using signals of opportunity) scintillation effects\nand group delay are also important, and for large bandwidth systems, dispersion effects (variation of\nthe group delay with frequency) are also of concern. The effects that are important for microwave\nradiometry are analyzed below.\n\n4.3.2.1 Faraday Rotation\nThe Faraday rotation is a rotation of the polarization plane due to the interaction between the elec-\ntromagnetic wave, the ionized medium (\u201cplasma\u201d) and the magnetic field of the Earth.\n\nThe magnitude of the rotation is given by (Le Vine and Abraham, 2002):\n\njF \u00bc\np\n\ncf 2\n\nZ\nf 2p \u00f0s\u00defB\u00f0s\u00decos\u00f0QB\u00f0s\u00de\u00deds; (4.37)\n\nwhereQB is the angle between the direction of propagation and the Earth\u2019s magnetic field; ds \u00bc sec(q)\ndz, z is the normal to the surface, q is the polar angle between the line of sight and the nadir;\n\nfp \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\nN $ e2\n\n4 $p2 $ ?0 $m\n\nq\nis the plasma frequency; and fB \u00bc e $B2 $p $m is the electron gyro frequency, being the\n\nnumber of electrons per cubic meter, e and m the charge and mass of the electron, respectively, and B\nthe Earth\u2019s magnetic field.\n\nAt L-band (1.413 MHz), for an altitude of 400 km, Eq. (4.37) becomes\n\njF z 6950 $B\u00f0h \u00bc 400 km\u00de $ cos\u00f0QB\u00de $ sec\u00f0q\u00de $VTEC; (4.38)\nwhere B is in Tesla, jF in degrees, and VTEC is the vertical total electron content (units of 10\n\n16 e/m2)\ndefined as the integral of the electron density (Fig. 4.20) in a vertical path:\n\nVTEC \u00bc\nZ h\n0\n\nNe\u00f0z\u00de $ dz. (4.39)\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 153\n\n\n\nThe rotation of the electric field emitted by the surface of the Earth implies that the electric fields\nmeasured in the antenna reference frame (x and y) do not correspond to the horizontal (h) and vertical\n(v) electric fields emitted by the Earth:\n\n\nEx\n\nEy\n\n?\n\u00bc\n\n\n\nA B\n\n?B A\n\n?\n\nEh\n\nEv\n\n?\n; (4.40)\n\nwhere A \u00bc cos(jF) and B \u00bc sin(jF).\nThis translates in a modification of the measured Stokes vector in the antenna reference frame:26664\n\nTxx\n\nTxy\n\nTyx\n\nTyy\n\n37775 \u00bc\n26664\n\nA2 AB AB B2\n\n?AB A2 ?B2 AB\n?AB ?B2 A2 AB\nB2 ?AB ?AB A2\n\n37775\n26664\nTh\n\nThv\n\nTvh\n\nTv\n\n37775; (4.41)\nwhere Thv \u00bc C0 < EhE?v > and Tvh \u00bc C\n\n0\n< EvE\n\n?\nh > do not correspond to T3 and T4 as defined in Eq.\n\n(4.19). It should be noted that, while Eq. (4.41) can always be inverted, in general, if only the first two\nStokes elements are measured: \n\n\nTxx\n\nTyy\n\n?\n\u00bc\n\"\nA2 B2\n\nB2 A2\n\n#\n\nTh\n\nTv\n\n?\n; (4.42)\n\nEq. (4.42) cannot be inverted, since the matrix becomes singular for jF \u00bc 45?.\nA figure from Le Vine and Abraham (2002), Fig. 4.22, shows the global distribution of Faraday\n\nrotation for local time of 6 a.m. (left) and noon (right). The data are for high solar activity (June 1989),\n\nFIGURE 4.22\n\nGlobal distribution of Faraday rotation for local time of 6 a.m. (left) and noon (right). The data are for high solar\n\nactivity (June 1989), an altitude of 675 km, and looking perpendicular to the satellite heading to the right at\n\nincidence angles as indicated (20?, 30?, 40?, and 50?) (Le Vine and Abraham, 2002).\n\n154 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.22|tif\n\n\nan altitude of 675 km, and looking perpendicular to the satellite heading to the right at incidence angles\nas indicated (20?, 30?, 40?, and 50?). As can be clearly seen, the maximum Faraday rotation takes\nplace at midlatitude, and when the local time is around noon (or slightly after), while it is minimum at\n6 a.m. The effect is also more important for larger incidence angles.\n\nAnother figure (Fig. 4.23) from Le Vine and Abraham (2002) shows the impact of the Faraday\nrotation over the brightness temperature over the sea, for the same conditions as in Fig. 4.22. As it can\nbe appreciated, the effect is relatively small, from a fraction of a Kelvin to a few Kelvin, but it is\nextremely large in terms of the magnitude of the parameter to be measured using L-band microwave\nradiometry, the sea surface salinity (SSS), whose sensitivity ranges from DTB/DSSS\nw0.25e0.5 K/psu, and the required accuracy w0.1 to 0.2 psu.\n\n4.3.2.2 Ionospheric Losses: Absorption and Emission\nExcept for the amplitude scintillation, that may introduce rapid and large attenuations, especially at\nequatorial and polar regions (e.g., Fig. 4.24), in general, ionospheric absorption can be neglected for\nmost applications. One of the applications in which these effects may be more serious is, again, SSS\nretrievals from L-band radiometric measurements. Due to the stringent accuracy requirements\n(w0.1e0.2 psu), ionospheric losses may have to be taken into account, both for the attenuation of the\nbrightness temperature, and for the extra noise added (see Fig. 4.10). Table 4.1 from Le Vine and\nAbraham (2002) shows the ionospheric attenuation and emission at 6 a.m. and 12 p.m., and their\nimpact of the brightness temperature of the sea (SSS \u00bc 35 psu), sea surface temperature\n(SST \u00bc 20?C). As it can be easily recognized, the effect is always smaller than 12 mK, which\nassuming a worst case sensitivity of 0.25 K/psu, translates into a salinity error of <0.04 psu.\n\nFIGURE 4.23\n\nGlobal distribution of the error in brightness temperature at L-band as a function of incidence angle due to\n\nneglecting Faraday rotation at 6 a.m. (left) and noon (right). The data are for high solar activity (June 1989;\n\nRz \u00bc 158) and for a sensor at altitude of 675 km and looking perpendicular to the satellite heading to the\nright. The surface is ocean with S \u00bc 35 psu and T \u00bc 20?C (Le Vine and Abraham, 2002).\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 155\n\nmailto:Image of Figure 4.23|tif\n\n\n4.3.3 LAND EMISSION\nIn Monerris and Schmugge (2009) a summary of the land surface\u2019s emission is presented. The emissivity\nof land depends not only on the soil moisture, but also on the soil temperature (Choudhury et al., 1982;\nWigneron et al., 2001), and the soil surface roughness (Mo and Schmugge, 1987; Escorihuela et al.,\n2007). It also depends on the vegetation canopy (Jackson et al., 1982; Ferrazzoli et al., 2002), the snow\ncover (Schwank et al., 2004), the relief (Ma?tlzler and Standley, 2000; Talone et al., 2007; Monerris et al.,\n2008), etc. In the following sections each of these effects are studied in more detail.\n\n4.3.3.1 Soil Dielectric Constant Models\nThe dielectric constant determines the response of the soil to an incident electromagnetic wave. This\nresponse is composed of two parts, real and imaginary (?r \u00bc ?0 \u00fe j $ ?00), which determine the wave\nvelocity and the energy losses, respectively. In an inhomogeneous medium such as soils, the dielectric\nproperties have a strong impact on its microwave emission. However, the relationship between the soil\ndielectric constant and the soil physical properties is not straightforward. The dependence of the dielectric\nconstant for different soil types is clearly shown in Fig. 4.25. This figure clearly demonstrates that the\nlarger the volumetric soil moisture, the larger the dielectric constant (both in real and imaginary parts).\n\nA large number of studies have been performed during the last decades to discover this relationship\nsince it plays an important part in the soil moisture retrieval algorithms from remote sensing data\n(Hipp, 1974: Wang and Schmugge, 2000; Topp et al., 1989; Hallikainen et al., 1985; Dobson\net al., 1985; Roth et al., 1992; Mironov et al., 2004). Some of these models are simple empirical models\nin which data is fitted by a unique curve for all soils; others propose semiempirical approaches which\ntake into account some soil physical properties. The dielectric constant of dry soils is almost\n\nP.0531-06\n\nN\noo\n\nn 18 00\n\nSolar maximum\n\nM\nid\n\nni\ngh\n\nt\n\nN\noo\n\nn 18 00\n\nSolar minimum\n\nM\nid\n\nni\ngh\n\nt\n\n> 15 dB\n 10 dB\n 5 dB\n 2 dB\n1 dB\n\nFIGURE 4.24\n\nDepth of scintillation fading at 1.5 GHz during solar maximum and minimum years (Recommendation ITU-R\n\nP.531-11, 2012).\n\n156 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.24|eps\n\n\nTable 4.1 Ionospheric Attenuation and Emission: SSS[ 35 psu, SST[ 20?C. June 6 a.m.\n(Left), 12 p.m. (Right). T[ [ Tup; TY[ Tdn Scattered Over the Ocean\n\nLocation\n\nRz\nVTEC\n(TECU)\n\ns\n\n(10L5 Np)\nDT\n(mK)\n\nT[\n(mK)\n\nTY\n(mK)Latitude Longitude\n\nIonospheric Attenuation and Emission (6 a.m.)\n\n30 N 220 E 158.4 19.9 2.64 2.18 20.87 16.08\n\n8.5 6.4 1.45 1.20 4.75 3.51\n\n0 220 E 158.4 20.6 2.47 2.04 23.01 18.22\n\n8.5 8.6 1.19 0.98 5.31 5.06\n\n30 S 220 E 158.4 12.7 1.00 0.83 9.35 7.54\n\n8.5 3.6 0.30 0.25 1.23 0.98\n\n30 N 330 E 158.4 24.9 3.51 2.89 31.42 23.98\n\n8.5 7.1 1.57 1.30 5.55 4.05\n\n0 330 E 158.4 20.3 2.49 2.05 22.81 17.91\n\n8.5 8.0 1.11 0.91 4.79 4.39\n\n30 S 330 E 158.4 9.5 0.65 0.53 5.38 4.60\n\n8.5 3.2 0.27 0.22 1.01 0.83\n\n30 S 60 E 158.4 5.3 0.31 0.25 1.83 1.68\n\n8.5 2.2 0.21 0.17 0.65 0.48\n\n75 N 160 E 158.4 18.7 3.32 2.74 17.70 22.86\n\n8.5 6.3 2.19 1.80 6.08 4.40\n\nIonospheric Attenuation and Emission (Noon)\n\n30 N 220 E 158.4 39.8 11.43 9.42 77.34 57.46\n\n8.5 14.2 5.00 4.12 18.49 13.52\n\n0 220 E 158.4 45.0 13.42 11.06 99.21 78.06\n\n8.5 17.3 5.81 4.78 22.22 19.41\n\n30 S 220 E 158.4 37.9 10.22 8.42 80.89 59.12\n\n8.5 9.0 3.26 2.69 10.32 7.59\n\n30 N 330 E 158.4 43.5 12.37 10.20 89.77 67.04\n\n8.5 13.8 5.03 4.15 18.50 13.45\n\n0 330 E 158.4 48.3 14.47 11.92 113.48 87.74\n\n8.5 17.7 5.93 4.88 23.24 19.51\n\n30 S 330 E 158.4 35.7 9.98 8.22 75.06 54.73\n\n8.5 11.3 3.64 3.00 13.08 9.76\n\n30 S 60 E 158.4 39.8 10.68 8.80 85.87 63.13\n\n8.5 9.8 3.46 2.85 11.82 8.57\n\n75 N 160 E 158.4 20.1 6.11 5.034 24.57 28.29\n\n8.5 6.7 2.60 2.134 7.29 5.27\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 157\n\n\n\nindependent of temperature (Topp et al., 1980) and frequency. On the contrary, wet soils show a\ncomplex behavior depending on the interaction between soil, water, and air particles. Hallikainen et al.\n(1985) performed a series of dielectric constant measurements of five soils with different texture\ncomposition at frequencies between 1.4 and 18 GHz and found out that texture has a strong effect on\nthe dielectric behavior, which is especially pronounced at frequencies below 5 GHz.\n\nIn the dielectric mixing model by Roth et al. (1992), differences in soil texture, and bound water\nand free water are ignored altogether. Other models use a semiempirical approach that contains a\nmodel of the complex dielectric constant and the volume fraction of each of the soil components. This\n\n?'\n\n?\u201d\n\nYUMA SAND, Wt = 0.17\nVERNON CLAY, Wt = 0.28\nMILLER CLAY, Wt = 0.33\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\nD\nIE\n\nLE\nC\n\nTR\nIC\n\n C\nO\n\nN\nS\n\nTA\nN\n\nT \n?\n\nVOLUMETRIC WATER CONTENT mv (g cm\u20133)\n\n0 0.1 0.2 0.3 0.4 0.5 0.6\n\nFIGURE 4.25\n\n(A) Real and imaginary parts of the dielectric constant at 1.4 GHz of different soil types, as a function of the\n\nvolumetric soil moisture content (Ulaby et al., 1986).\n\n158 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.25|eps\n\n\nkind of approach is used by two of the most widely used models presented in Wang and Schmugge\n(2000) and Dobson et al. (1985). The starting point of both of them is the dielectric mixing model by\n(Birchak et al., 1974):\n\n?\na \u00bc Vs?a \u00fe Va?aa \u00fe Vfw?afw \u00fe Vbw?afw; (4.43)\n\nwhere Vs(?s), Va(?a), Vfw(?fw), and Vbw(?bw) are the volume fraction (dielectric constant) of the solid\nphase, air, free water, and bound water in the soil, respectively. Eq. (4.43) can be rewritten as a function\nof the bulk density rb, the particle density rs, and the volumetric moisture mv as:\n\n?\na \u00bc 1\u00fe rb\n\nrs\n\n?\n?\na\ns ? 1\n\n?\u00fe Vfw?afw \u00fe Vbw?afw ? mv; (4.44)\nThe Wang and Schmugge (2000) model was proposed for 1.4 and 5 GHz frequencies and starts\n\nfrom Eq. (4.44) with a \u00bc 1. This model provides separate dielectric constant equations for volumetric\nwater content lower than or greater than the transition moisture wt. The transition moisture is the\nmoisture content at which the free water phase begins to dominate the soil hydraulics, and it is strongly\ndependent on the texture. The soil dielectric constant is then estimated as:\n\n? \u00bc\n?\nmv?x \u00fe \u00f0P? mv\u00de?a \u00fe \u00f01? P\u00de?r; mv < wt;\nwt?x \u00fe \u00f0mv ? wt\u00de?fw \u00fe \u00f0P? mv\u00de?a \u00fe \u00f01? P\u00de?r; mv > wt;\n\n(4.45)\n\nwith\n\n?x \u00bc\n\n8><>:\n?i \u00fe \u00f0?fw ? ?i\u00demv\n\nwt\ng; mv < wt;\n\n?i \u00fe \u00f0?fw ? ?i\u00deg; mv > wt;\n(4.46)\n\nand g \u00bc ?0.57 $ wt \u00fe 0.481, ?i, ?a, ?fw, and ?r the dielectric constants of the ice, air, free water, and\nrock, respectively, ?x the dielectric constant of the initially adsorbed water, and P the soil porosity. The\nvariable ?fw is estimated using the Debye equation.\n\nOn the other hand, the Dobson et al. (1985) model starts from Eq. (4.43) and assumes that there is\nno distinction between bound and free water. Taking this into account, the new expression for the\ndielectric constant is\n\n? \u00bc\n\n1\u00fe rb\n\nrs\n\n?\n?\na\ns ? 1\n\n?\u00fe mbv?afw ? mv?1=a. (4.47)\nThe real and imaginary parts of the dielectric constant of soils are obtained separately using the per-\n\ncentage of sand S and clayC in the soil, and b\u00bc (127.48 e 0.519 $ S? 0.152 $ C)/100 for the real part, and\nb\u00bc (1.33979 e 0.603 $ S? 0.166 $ C)/100 for the imaginary part. For further information on dielectric\nconstant models, please refer to Behari (2004), Chukhlantsev (2006), and in particular the new model from\nMironov et al. (2004) seems to provide better soil moisture estimates from L-band radiometric data.\n\n4.3.3.2 Bare Soil Emission\nThe emissivity of bare soils es is given by Eq. (4.11), reproduced here for convenience:\n\nep\u00f0q\u00de \u00bc 1? Gs;p\u00f0q\u00de; (4.48)\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 159\n\n\n\nwhere Gs,p is the total reflectivity at p-polarization in a chosen observation direction, which can be\nexpressed in terms of the bistatic scattering coefficients spp and spq as follows (Fung, 1994):\n\nGs;p\u00f0qi;4i\u00de \u00bc\n1\n\n4p\n\nZ\n2p\n\u00bdspp\u00f0qi;4i; qr;4r\u00de \u00fe spq\u00f0qi;4i; qr;4r\u00de?dUr . (4.49)\n\nSubscripts \u201ci\u201d and \u201cr\u201d stand for the incident and scattered radiation, respectively, and q and 4 are\nthe incidence and azimuth angles, respectively. The coefficient spp takes into account the scattering in\nthe same polarization, while spq takes into account the scattering in the orthogonal polarization. The\nintegration over the entire upper half space (2 $ p strad in Eq. 4.49) and errors in the modeling of the\nbistatic scattering coefficients make the computation of Eq. (4.49) very prone to errors. For this reason,\nthe half space model with a smooth surface is commonly adopted, usually assuming that it is uniform,\nand eventually including a dielectric constant and temperature profile. This model is very simple and\nthus suitable for soil moisture retrieval algorithms from remotely sensed data. In this case, the total\nreflectivity in Eq. (4.49) equals the reflection coefficient given by the Fresnel formulation.\n\nSoil brightness temperature is related to soil emission through the soil effective temperature, Teff,\nTB,p \u00bc ep $ Teff. The theoretical effective temperature of a soil profile can be estimated as (Ulaby et al.,\n1986):\n\nTeff \u00bc\nZ N\n0\n\nT\u00f0z\u00de $a\u00f0z\u00de $ exp\n8<:?\n\nZ x\n0\n\na\n?\nz\n0?\ndz\n\n0\n\n9=;dz; (4.50)\nwhere T(z) and a(z) are the thermodynamic temperature and the attenuation coefficient at a depth z.\nThe attenuation is a function of the soil dielectric constant and of the microwave emission wavelength\nl. Several simple formulations have been developed to estimate the soil effective temperature from soil\nproperties, and soil moisture and temperature profiles. Choudhury et al. (1982) proposed a parame-\nterization of Teff based on the soil temperature at deep soil (TN) corresponding to a depth between\n50 cm and 1 m, and on a surface temperature (Tsurf) corresponding to a depth of 0e5 cm:\n\nTeff \u00bc TN \u00fe C $ \u00f0Tsurf ? TN\u00de; (4.51)\nThe coefficient C was considered constant for a given frequency, and equal to 0.246 at L-band. On\n\nthe other hand, Chanzy et al. (1997) presented a model for the soil effective temperature at L- and\nC-bands based on the air temperature, a deep soil temperature, and the brightness temperature\nmeasured at X-band and V-polarization. Wigneron et al. (1997) proposed a parameterization based on\nEq. (4.51), but with a coefficient C dependent on the volumetric water content (ws), and two\nsemiempirical parameters. Another formulation using the soil dielectric constant instead of the\nvolumetric water content was proposed by Holmes et al. (2006). The performance of some of these\napproaches is analyzed in Wigneron et al. (1997).\n\nThe effect of soil surface roughness on the brightness temperature has been an issue widely\naddressed in the literature. In Fung (1994) a theoretical physical model based on surface characteristics\nderived from the measured soil height profile is proposed. A simple empirical roughness model which\ntakes into account only the coherent term of the scattering was reported in Choudhury et al. (1979):\n\nGs;p \u00bc G?s;p exp\nh\n? \u00f02kss cos q\u00de2\n\ni\n; (4.52)\n\n160 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nwhere G?s;p is the Fresnel specular reflectivity of soil, k is the electromagnetic wave number, ss is the\nstandard deviation of the surface height, and q is the incidence angle. In Wang and Choudhury (1981)\nthis model was reviewed, and another formulation was proposed:\n\nGs;p \u00bc\nh\n\u00f01? Qs\u00deG?s;p \u00fe QsG?s;q\n\ni\nexp\u00f0 ? hs cos qn\u00de. (4.53)\n\nIn this case, two semiempirical parameters were included to model the effects of the polarization\nmixing Qs, and surface roughness (hs and n). The dependence of these parameters on surface\nproperties such as correlation length or standard deviation of height is not yet clear. In Wigneron\net al. (2001), Mo and Schmugge (1987), it was concluded that the n \u00bc 2 dependence in Eq. (4.53) is\ntoo strong at L-band. A value of n \u00bc 0 at both polarizations was found to be consistent with mea-\nsurements in Wingeron et al. (2001), while in Escorihuela et al. (2007), different values of n for each\npolarization are found (n \u00bc 1 at horizontal, and n \u00bc ?1 at vertical polarizations). Similarly, there are\ndiscrepancies on the value of the roughness parameter hs. Some authors obtain hs from experimental\ndata by best-fit (Wingeron et al., 2001), while others propose expressions for hs as a function\nof geophysical parameters. In Mo and Schmugge (1987), good results were obtained with two\n\nparameterizations of hs \u00bc A $wBs $ \u00f0ss=lc\u00deC , with A \u00bc 0.5761, B \u00bc ?0.3475, and C \u00bc 0.4230, or\nhs \u00bc A0 $ (ss/lc)c0, with A0 \u00bc 1.3972 and c0 \u00bc 0.5879. Finally, there is a general agreement on the\nvalue of the cross-polarization parameter Qs, which has been found to be very small (0e0.12) at\nL-band.\n\nApart from these considerations, the effects of frequency and incidence angle on the roughness\nparameters have not been studied thoroughly. It was pointed out (Mo and Schmugge, 1987; Shi et al.,\n2002) that the roughness effects depend on both the frequency and the incidence angle. A parame-\nterization of the surface reflectivity derived from data simulated for a wide range of soil water content\nand roughness properties using the integral equation model (Fung, 1994) has also been suggested. The\nsurface reflectivity model in Shi et al. (2002) was tested in Schneeberger et al. (2004) and found not to\nbe capable of explaining discrepancies between the ground truth and remotely sensed data. As a\nconsequence, a new model was developed for describing the influence of the topsoil structure on the L-\nband emission as an impedance matching between the dielectric constants of soil and air (Ma?tzler,\n2006). Fig. 4.26 shows the impact on the 1.4 GHz brightness temperature of different bare soils at nadir\nas a function of the volumetric soil moisture content, and the impact of the surface\u2019s roughness (Ulaby\net al., 1986). As is clear, the larger the volumetric soil moisture content, the lower the brightness\ntemperature. For the same volumetric soil moisture content, this effect is more noticeable for sandy\nsoils, than for clays, due to the larger fraction of free water molecules in the interstices between soil\ngrains. It can also be appreciated (Fig. 4.26B) that the surface\u2019s roughness masks the presence of the\nsurface soil moisture, due to the decrease of the reflection coefficient (Eqs. 4.52 and 4.53).\n\nFinally, it is worth noting that the emission being sensed is coming mostly from the soil\u2019s top layer\ndue to the high attenuation that the electromagnetic waves being emitted undergo due to the presence\n\nof water. The soil penetration depth is given by dpzl\nffiffiffi\n?\n0p\n\n2p?00\nfor materials with ?00/?0 < 0.1. The soil\n\npenetration depth as a function of the frequency and the volumetric soil moisture content is plotted in\nFig. 4.27. At L-band (lz 20 cm) the penetration depth is w10 cm for 30% volumetric soil moisture.\n\n4.3.3.3 Vegetated Soil Emission\nIf the remote sensor is placed above a canopy looking downward, the measured brightness temperature\nwill contain not only information on the soil, but also on vegetation, since vegetation radiates its own\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 161\n\n\n\nenergy and, moreover, attenuates and scatters the soil radiation. Chukhlantsev (2006) revised the\ntheory and conducted experimental research over vegetated areas. Although the modeling of the land\nemission involves analytical solutions of the radiative transfer equation (Ferrazzoli et al., 2002), this\napproach is not easy to use with experimental data. Hence, the common practice is to use approximate\nformulas or semiempirical models in which the different components of the brightness temperature\ncould be differentiated. The brightness temperature of a soil covered by vegetation is usually estimated\nas the contribution of three terms: the radiation from the soil that is attenuated by the overlying\nvegetation, the upward radiation from the vegetation, and the downward radiation from the vegetation,\nreflected by the soil, and attenuated by the canopy (Ulaby et al., 1986):\n\nTmodelB;p \u00bc\n\n1\u00fe 1? es;p\n\nLveg\n\n?\n1? 1\n\nLveg\n\n?\n\u00f01? u\u00deTveg \u00fe es;p\n\nLveg\nTs; (4.54)\n\nwhere Tveg and Ts are the physical temperatures of the vegetation and soil, respectively,\nLveg \u00bc exp(s $ secq) is the attenuation due to the vegetation cover, s \u00bc b $ VWC is the optical thickness,\nb is a factor (Van de Griend and Wigneron, 2004) that depends on the vegetation type and frequency,\nVWC is the vegetation water content, and u is the single scattering albedo, which is a function of the\npolarization and the incidence angle. Actually, Lveg only follows the above expression at low incidence\nangles due to the larger anisotropy of the vegetation structure as the incidence angle increases, and the\nincreased scattering effects. This formulation is known as the s-u model, and it is based on the single\n\nFIGURE 4.26\n\n1.4 GHz brightness temperature at nadir for different soil types as a function of the volumetric soil moisture\n\ncontent (Ulaby et al., 1986).\n\n162 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.26|tif\n\n\nscattering approach proposed in Kirdiashev et al. (1979). The optical depth is related to the vegetation\ndensity and the frequency, while the single scattering albedo describes the scattering of the emitted\nradiation by the vegetation and is a function of plant geometry. This formula is actually only valid at low\nfrequencies, and when scattering mechanisms are negligible or small, while at higher frequencies, the\nfull polarimetric radiative transfer equation should be solved (Martinez-Vazquez et al., 2009).\n\nFig. 4.28 shows some simulated brightness temperatures at L-band for volumetric soil moisture 0%\nand 40%, and bare soil, and densely vegetated soil. As can be seen, for bare soil, the soil moisture\nchange translates into a large brightness temperature change, while this is no longer the case when\nthere is a very dense vegetation cover that masks the soil radiation. As can also be inferred, the\npresence of dense vegetation gets the vertical and horizontal brightness temperatures closer, while for\nbare soils, they are very much separated.\n\nThis polarimetric and multiangular information can be used to infer not only surface\u2019s soil\nmoisture, but vegetation water content (vegetation optical depth) as well, as is routinely done now with\nthe European Space Agency (ESA) SMOS mission.\n\nFIGURE 4.27\n\nSoil penetration depth as a function of the frequency and the volumetric soil moisture content. (The source of\n\nthis material is the COMET? Website at http://meted.ucar.edu/ of the University Corporation for Atmospheric\n\nResearch (UCAR), sponsored in part through cooperative agreement(s) with the National Oceanic and\n\nAtmospheric Administration (NOAA), U.S. Department of Commerce (DOC). \u00a91997e2016 University\n\nCorporation for Atmospheric Research. All Rights Reserved.)\n\nAdapted from Njoku, 1999\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 163\n\nmailto:Image of Figure 4.27|tif\nhttp://meted.ucar.edu/\n\n\n4.3.3.4 Snow-Covered Soil Emission\nWater ice has a very different structure than liquid water, as do soils and rocks. For ordinary ice the real\npart ?0 of the dielectric constant is independent of frequency from 10 MHz to about 300 GHz, and only\nslightly dependent on temperature (Ma?tzler and Wegmu?ller, 1987):\n\n?\n\n0\ni \u00bc 3:1884\u00fe 9:1$10?4 T ? 273K\u00f0 \u00de; 243K ? T ? 273K; (4.55)\n\nbelow 240K the temperature sensitivity decreases, and a constant value of ?\n0\niz3:10 is found at\n\nT < 100K (Gough, 1972). The imaginary part ?\n00\ni is given by:\n\n?\n\n00\ni \u00bc\n\nA\n\nf\n\u00fe B $ f C; (4.56)\n\nFIGURE 4.28\n\nSimulated vertical (red) and horizontal (blue) brightness temperatures for (A, C) 0% and (B, D) 40%\n\nvolumetric soil moisture, and (A, B) bare soil and (C, D) vegetated soil.\n\n164 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.28|tif\n\n\nwhere f is the frequency in (GHz), and the empirical constants are A \u00bc 3.5 $ 10?4, B \u00bc 3.6 $ 10?5, and\nC \u00bc 1.2 at T \u00bc ?15?C; and A \u00bc 6 $ 10?4, B \u00bc 6.5 $ 10?5, and C \u00bc 1.07 at T \u00bc ?5?C.\n\nActually, ice water is one of the most transparent media at microwave frequencies with very low\ndielectric loss. In addition, new (and dry) snow has a large fraction of air (w90%), i.e., its density is\nquite low, which reduces the reflection coefficient in the airesnow interface, while old (and wet) snow\nis much more compact (w20% air), is much denser and has a higher reflection coefficient [Table 4.2\nfrom Gough (1972), Fig. 4.29].\n\nTable 4.2 Typical Snow and Ice Densities (kg/m3)\n\nNew snow (immediately\nafter falling in calm)\n\n50e70\n\nDamp new snow 100e200\n\nSettled snow 200e300\n\nDepth hoar 100e300\n\nWind packed snow 350e400\n\nFirn 400e830\n\nVery wet snow and firn 700e800\n\nGlacier ice 830e917\n\nFIGURE 4.29\n\nSnow density and typical grain size and shape (https://www.meted.ucar.edu/).\n\nFrom NOAA\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 165\n\nmailto:Image of Figure 4.29|tif\nhttps://www.meted.ucar.edu/\n\n\nThis means that the dominant mechanism in the radiative transfer equation is not the absorption,\nbut the scattering in the ice crystals (dry snow). If there is liquid water in between the ice crystals (wet\nsnow), absorption becomes more important.\n\nThe upwelling radiation emitted by the soil surface under the snow is altered significantly by the\nsnowpack and it changes with time as illustrated in Fig. 4.30: the larger the thickness and/or the density\nof the snow layer, the larger the attenuation and scattering will be; the moister or older snowpack is, the\nlarger the attenuation will be; and the amount of scattered radiation is affected by the grain size as\ncompared to the microwave radiation: shallower/newer snowpack have smaller ice crystals and scatter\nless radiation than deeper/older snowpacks.\n\nFor dry snow a simple model using the snow single scattering albedo usnow, can be used:\n\nT\np\nB;dry snow\u00f0q\u00dez \u00f01? usnow\u00de $ Tsoil; (4.57)\n\nsince Gpair?snow\u00f0q\u00dez0. However, wet snow has a much larger emissivity than dry snow since the\npresence of water increases the absorption (losses), and therefore the emission, and the size of the snow\ngrains is reduced, therefore, scattering is reduced accordingly. These two effects lead to an\nunderestimation of the snow depth, unless properly accounted for.\n\nAccurate snow state information can only be retrieved using multifrequency and polarimetric\ninformation, mainly the 19 and 37 GHz channels, and 85 GHz as well at high latitudes for thin\nsnow layers. The microwave emissivity spectra for snow cover at 50? incidence angle is presented\nhere as Fig. 4.31. As can be seen, wet snow has the highest emissivity due to the largest losses, and\nit is relatively constant with frequency, while in general, the emissivity decreases significantly\n\nShallow/newer\nsnowpack, smaller\n\ncrystals\n\nDeeper/older\nsnowpack, larger\n\nsnow grains\n\n1-2 cm\n\nFIGURE 4.30\n\nSnow emission and scattering of the soil radiation depends on the thickness, wetness, and ice crystal size\n\n(https://www.meted.ucar.edu/).\n\n166 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.30|eps\nhttps://www.meted.ucar.edu/\n\n\nwith increasing frequency since scattering effects become more significant as the wavelength\ndecreases.\n\nFinally, Fig. 4.32A and B show the surface\u2019s emissivity spectra at 53? vertical and horizontal\npolarizations, respectively, for different soil types:\n\n\u2022 dry bare soil: which exhibits a very weak dependence on frequency, since the dielectric constant\ndoes not depend significantly on it,\n\n\u2022 wet land: which exhibits a lower emissivity than bare soils, and a slightly higher dependence with\nfrequency, due to the variation of the dielectric constant of water,\n\n\u2022 desert: which at low frequencies behaves as dry bare soil, but the emissivity decreases with\nincreasing frequency due to the larger scattering by the sand grains,\n\n\u2022 canopy: which behaves as dry bare soil, but it decreases with increasing frequency due to the more\nimportant scattering in the vegetation structures (trunk, branches, and leaves) specially for\nvertical polarization.\n\n\u2022 snow: which has the most significant decrease in the emissivity as frequency increases, due to\nscattering by the ice crystals, and\n\n\u2022 ocean: whose emissivity actually increases with increasing frequency, mainly due to the decrease\nof the imaginary part of the dielectric constant (i.e., the water stops behaving as a bad conductor\nto start behaving more as a dielectric).\n\nFIGURE 4.31\n\nMicrowave emissivity spectra for snow cover at 50? incidence angle (https://www.meted.ucar.edu/).\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 167\n\nmailto:Image of Figure 4.31|tif\nhttps://www.meted.ucar.edu/\n\n\n4.3.3.5 Topography Effects\nTopography (including Earth\u2019s curvature) refers to the large-scale surface roughness, as opposed to the\nsmall-scale surface roughness discussed in Eqs. (4.52) and (4.53). The effects can be summarized as\nfollows:\n\n\u2022 Assuming that the surface can be decomposed in facets, the local incidence angle ql differs from\nthe global one q (the one assuming a flat or ellipsoidal Earth):\n\ncos ql \u00bc bn $ bk \u00bc cos q $ cos a\u00fe sin q $ sin a $ cos b; (4.58)\nwhere a and b are the tilt and azimuth angles of the facet. This affects the emission and reflection of the\nfacet towards the sensor.\n\nFIGURE 4.32\n\nSurface\u2019s emissivity spectra at 53? (A) vertical and (B) horizontal polarizations, respectively, for different\nsurfaces (https://www.meted.ucar.edu/).\n\n168 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.32|tif\nhttps://www.meted.ucar.edu/\n\n\n\u2022 In addition, the global reflectivities [Gp(q)] and emissivities [ep(q)] are also affected by a rotation\n4 of the polarization reference frame:\n\nsin 4 \u00bc sin b $ sin ql. (4.59)\n\nAs explained in Section 4.3.2, this effect translates into a polarization mixing effect described in\nEq. (4.55), which is reproduced here for convenience (A \u00bc cos4, B \u00bc sin4). Please recall that in\nEq. (4.41) subscripts h, v, hv, and vh refer to the local reference frame, while xx, yy, xy, and xy to the\nglobal one. 26664\n\nTxx\n\nTxy\n\nTyx\n\nTyy\n\n37775 \u00bc\n26664\n\nA2 AB AB B2\n\n?AB A2 ?B2 AB\n?AB ?B2 A2 AB\nB2 ?AB ?AB A2\n\n37775\n26664\nTh\n\nThv\n\nTvh\n\nTv\n\n37775. (4.60)\nIt is usually assumed that Thv z 0 and Tvh z 0, and therefore:\n\nTxx \u00bc cos2 4 $ Th \u00fe sin2 4 $ Tv;\nTyy \u00bc sin2 4 $ Th \u00fe cos2 4 $ Tv.\n\n(4.61)\n\nHowever, it is worth noting that a nonzero third Stokes parameter appears, since:\n\nTxy \u00bc Tyx \u00bc cos 4 $ sin 4\u00f0Tv ? Th\u00de. (4.62)\n\n\u2022 Projection effects: since the area of the facet that is projected towards the sensor depends on the\nlocal incidence angle as cosql.\n\n\u2022 Shadowing when a given facet is hidden from the direct sensor\u2019s view.\n\u2022 Multiple scattering when either the radiation emitted by the surface or the atmospheric\n\ndownwelling one undergo a number of \u201creflections\u201d (scattering processes) in other facets of the\nsurface before they propagate in the direction of the sensor.\n\n\u2022 Finally, the atmospheric downwelling and upwelling brightness temperatures and the length\nof the atmospheric path and its associated attenuation are also affected and must be included\naccordingly in the radiative transfer equation (Section 4.2).\n\n4.3.4 OCEAN EMISSION\nThe ocean surface emission depends on a number of factors. On one side, the sea water dielectric\nconstant depends on the physical temperature, the salinity, and the frequency. On the other hand, the\nsea surface roughness, the presence of foam or oil slicks in the surface alters the interaction of the\nelectromagnetic waves with the water surface. In this section, these different effects are revisited.\n\n4.3.4.1 Water Dielectric Constant Behavior\nFollowing Eq. (4.11), the emission of a calm ocean is given by the physical temperature times the\nemissivity:\n\ne\np\nflat\u00f0SSS; SST; f ; q\u00de \u00bc 1? Gpspec;H2O\u00f0?r\u00f0SSS; SST; f \u00de; q\u00de. (4.63)\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 169\n\n\n\nIt has been suggested that a bimodal relaxation time expression is the most appropriate description\nof the dielectric properties of water (Buchner et al., 1999):\n\n?r \u00bc ?N \u00fe ?S ? ?2\n1\u00fe jusD \u00fe\n\n?2 ? ?N\n1\u00fe jus2 ; (4.64)\n\nwhere ?r is the complex permittivity, ?S is the relative permittivity at low frequencies (static region), ?2\nis the intermediate relative permittivity, and ?N is the relative permittivity at high frequencies (optical\npermittivity). In addition, u is the angular frequency in radians/second, and sD and s2 are relaxation\ntimes. Here, sD is relatively long (w18 ps at 0?C), due mainly to the rotational relaxation within a\nhydrogen-bonded cluster, but reduces considerably with temperature as hydrogen bonds are weakened\nand broken. s2 is small (w0.2e1 ps) and less temperature dependent being determined mainly by the\ntranslational vibrations within the hydrogen-bonded cluster. In Fig. 4.33 we show plots of the\ndependence of these parameters on the physical temperature. Note that ?N, the dielectric permittivity\nat very high frequencies, does not change significantly with temperature.\n\nThe dielectric permittivity (real part of ?r) and the dielectric loss (imaginary part of ?r) of water\nbetween 0?C and 100?C, and from 300 MHz to 3 THz are shown in Fig. 4.34. As the temperature\nincreases, the strength and extent of the hydrogen bonding decreases, which lowers the ?S, allows the\nwater molecule to oscillate at higher frequencies and reduces the rotation drag, thus reducing the\nfriction and hence the dielectric loss. Most of the dielectric loss is within the microwave range of\nelectromagnetic radiation (w1 to w300 GHz), and the frequency for maximum dielectric loss is\nw2.45 GHz, the frequency of operation of most microwave ovens.\n\nThe dilution of salt in water decreases the natural structure of the water so reducing the ?S, in a similar\nmanner to increased temperature. At the lower frequencies ions are able to respond and move with the\nchanging potential so producing frictional heat and increasing the loss factor (imaginary part of ?r).\nThus, whereas water becomes a poorer microwave absorber with rising temperature, salty water be-\ncomes a better microwave absorber with rising temperature. The evolution of the dielectric permittivity\n(real part of ?r) and the dielectric loss (imaginary part of ?r) of salty water (10 psu) between 0\n\n?C and\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n?s\n\n?2\n\n?D\n\n?2\n\n-40 -20 20 40\nTemperature, \u00b0C\n\n60 80 1000\n\n??\n\nFIGURE 4.33\n\nDependence of the parameters of the water dielectric constant model with physical temperature.\n\n170 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.33|eps\n\n\n100?C, and from 300 MHz to 3 THz are presented here in Fig. 4.35. As compared to Fig. 4.34, in the low\nmicrowave frequency range, the imaginary part of the dielectric constant does not tend to zero, but\nincreases sharply. This property is actually used to sense SSS from radiometric measurements.\n\nThe curves in Fig. 4.36 show the evolution of the real and imaginary parts of the water dielectric\nconstant at 1.4 GHz, for salinities ranging from 0 to 40 psu in 10 psu steps, for temperatures\nfrom ?2?C to \u00fe40?C.\n\n4.3.4.2 Calm Ocean Emission\n4.3.4.2.1 Influence of the Salinity\nThe water dielectric constant computed in Section 4.3.4.1. can now be used to evaluate the emissivity\nand brightness temperature of a flat water surface as a function of the temperature, salinity, frequency,\nand incidence angle. The water emissivity and brightness temperatures, respectively, at 1.4 GHz\nfrom ?2?C to 40?C, and from 0 to 40 psu are shown in Figs. 4.37 and 4.38. As can be easily seen, the\nbehavior is highly nonlinear with the physical temperature. The water emissivity is approximately flat\nbetween 10 and 20 psu for physical temperatures up to about 25?C. However, the water nadir\nbrightness temperature becomes insensitive to the physical temperature around 15?C and 35 psu.\nIndeed, this is good news for the SSS retrievals using microwave radiometry, since these conditions are\nclose to the ones encountered in the open oceans, and the SST can be accurately estimated using\nthermal infrared sensors4 or microwave radiometers at higher frequencies, the sea state correction will\nremain as the most important one.\n\nFIGURE 4.34\n\nDielectric permittivity (real part of ?r) and the dielectric loss (imaginary part of ?r) of freshwater between 0\n?C\n\nand 100?C, and from 300 MHz to 3 THz (http://www.lsbu.ac.uk/water/microwave.html).\n\n4Although thermal infrared sensors measure the skin temperature, and the sea brightness temperature at L-band corresponds\napproximately to the emission from the top centimeter, the bulk and the skin temperatures are barely the same, unless when\nthe water is in very calm conditions.\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 171\n\nmailto:Image of Figure 4.34|tif\nhttp://www.lsbu.ac.uk/water/microwave.html\n\n\nFIGURE 4.35\n\nDielectric permittivity (real part of ?r) and the dielectric loss (imaginary part of ?r) of 10 psu salty water between\n\n0?C and 100?C, and from 300 MHz to 3 THz (http://www.lsbu.ac.uk/water/microwave.html).\n\nFIGURE 4.36\n\nDielectric permittivity (real part of ?r) and the dielectric loss (imaginary part of ?r) of salty water at 1.4 GHz\n\nfrom ?2?C to 40?C, and from 0 to 40 psu.\n\n172 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.35|tif\nhttp://www.lsbu.ac.uk/water/microwave.html\nmailto:Image of Figure 4.36|tif\n\n\nFIGURE 4.38\n\nWater brightness temperature at qi \u00bc 0? and 1.4 GHz from ?2?C to 40?C, and from 0 to 40 psu.\n\nFIGURE 4.37\n\nWater emissivity at 1.4 GHz from ?2?C to 40?C, and from 0 to 40 psu.\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 173\n\nmailto:Image of Figure 4.38|tif\nmailto:Image of Figure 4.37|tif\n\n\n4.3.4.2.2 Influence of Frequency\nWe use Fig. 4.39 to show the water brightness temperature at different frequencies from 1.4 to 89 GHz,\n35 psu SSS, and 15?C versus incidence angle. The general behavior follows the trends of Fig. 4.5 with\nhorizontal polarization monotonically decreasing with increasing incidence angle, and vertical po-\nlarization increasing with increasing incidence angle up to an angle where the brightness temperature\nreaches a maximum, and then decreases down to zero at 90?. Recall that this maximum is related to the\nBrewster angle, at which the reflectivity vanishes completely in the case of lossless materials, or is\nclose to zero in the case of materials with losses. Note also that, for low incidence angles, as the\nfrequency increases, the brightness temperature increases as well, due to the reduction of the dielectric\nconstant (Fig. 4.35). That is, the sea water behaves less and less as a conductor (although a bad\nconductor) and starts behaving more as a dielectric.5\n\n4.3.4.2.3 Influence of the Water Temperature\nHere Fig. 4.40 shows the water brightness temperature at different frequencies from 1.4 to 89 GHz, for\n35 psu SSS, and qi \u00bc 0? versus the SST. In this case, the behavior is more complex to understand\nintuitively than that in Fig. 4.39 because of the strong nonlinearity with temperature. Around 35 psu, at\nlow microwave frequencies (e.g., 1.4 GHz), the sensitivity of the brightness temperature versus the\nphysical temperature is zero. It becomes positive at 2.6, 6.8, and 10.7 GHz. At 18.7 GHz, the sensi-\ntivity is slightly positive or negative depending on the surface\u2019s temperature itself, and at 36.5 and\n89 GHz, it is negative, that is, the emissivity decrease is not compensated by the physical temperature\nincrease.\n\nFIGURE 4.39\n\nBrightness temperature evolution versus incidence angle at different frequencies from 1.4 to 89 GHz, 35 psu\n\nSSS, and 15?C.\n\n5Radio-waves attenuate much faster in the sea water than light waves.\n\n174 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.39|tif\n\n\n4.3.4.3 Influence of the Sea State\nOver a perfectly calm sea, the wind has practically no friction but, as it slides over the water surface film, it\nmakes it move. Above 0.23 m/s eddies and small ripples (\u201cshort\u201d capillary waves using surface tension for a\nrestoring force) are formed that make the water\u2019s surface rough, thus increasing the friction. The surface still\nlooks glassy overall, but as thewind speed increases, gravity waves form and thewaves become high enough\nto interact with the air flow and the surface starts to look rough. The wind then becomes turbulent just above\nthe surface and starts transferring more energy to the waves. Due to the dispersive nature of the waves, as\nthey propagate, energy is transferred from the shorter waves to the longer ones that keep propagating over\nlong distances even when the wind has stopped blowing. This phenomenon is known as swell.\n\nWhen the sea surface becomes rough (there are waves) the scattering of the electromagnetic waves\nover the surface becomes more diffuse and less specular, and therefore the emissivity increases.\nHigh-frequency microwave instruments (both active and passive) respond quickly to the \u201cshort\u201d\nwaves, showing a good correlation with the wind speed. However, at the lower end of the microwave\nspectrum (i.e., at L-band), due to the longer electromagnetic wavelengths involved, the interaction\nbetween the electromagnetic waves and the sea surface is also affected by the \u201clong\u201d sea waves.\nTherefore the radiometer response does not correlate so well with the wind speed, which ultimately\nlimits the accuracy of the SSS retrievals from spaceborne microwave radiometers.6\n\nIn addition, when the sea waves\u2019 slope exceedsw15?e20?, waves break creating foam, which is a\nmixture of air and sea water, and therefore acts as a matching layer between the air and the sea water\nbeneath, reducing the scattering coefficient and increasing the emissivity. This effect is particularly\nnoticeable above 7 m/s when whitecaps start appearing in the sea surface. However, the whitecap\n\nFIGURE 4.40\n\nBrightness temperature evolution versus physical temperature at nadir for different frequencies from 1.4 to\n\n89 GHz, 35 psu SSS, and 15?C physical temperature.\n\n6Sea state can be compensated, at least partially, using synergetic radar (Chapter 5) or GNSS-R (Chapter 6) measurements.\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 175\n\nmailto:Image of Figure 4.40|tif\n\n\ncoverage not only depends on the wind speed, but also on atmospheric stability DT b\u00bc Twater ? Tatm (by\n\t9% for DT \u00bc \t1?C), water temperature Twater (water viscosity changes with Twater), wind duration,\nfetch, and water salinity (51% larger whitecap coverage on the sea than on freshwater).\n\nThe modeled brightness temperature of the sea surface at 37 GHz, for different wind speeds from 3 to\n15 m/s as a function of the incidence angle, is compared to Meissner and Wentz (2004) geophysical\nmodel function at qi \u00bc 53? (Fig. 4.41). Close to nadir, from 7 to 11 m/s there is a sharp increase in the\nbrightness temperature, which is due to the appearance of foam at the sea surface. In the range of\nincidence angle modeled, the behavior of the brightness temperatures is monotonic: increasing at vertical\npolarization and decreasing at horizontal polarization. The effect of wind speed is more noticeable for\nhorizontal polarization, and therefore it will be used for wind speed retrievals. On the other hand, the lack\nof sensitivity at vertical polarization around 53?, which is related to the Brewster angle, is used as a\nreference to compensate for the atmospheric effects that affect in a similar way both polarizations.\n\n4.3.4.3.1 Influence of the Look Angle\nWhen the emitting surface is not completely random, but it has prreferred directions, as in the case of\nthe sea surface driven by the wind, the solution of the RTE (Section 4.2) leads to a solution in which the\nStokes elements do exhibit an angular dependence not only on the incidence angle, but on the azimuth\nangle as well defined as the angle between the look angle and the wind direction:\n\nTh\u00f0q;f\u00de \u00bc Th0\u00f0q\u00de \u00fe Th1\u00f0q\u00decos f\u00fe Th2\u00f0q\u00decos\u00f02f\u00de;\nTv\u00f0q;f\u00de \u00bc Tv0\u00f0q\u00de \u00fe Tv1\u00f0q\u00decos f\u00fe Tv2\u00f0q\u00decos\u00f02f\u00de;\nT3\u00f0q;f\u00de \u00bc T3;1\u00f0q\u00desin f\u00fe T3;2\u00f0q\u00desin\u00f02f\u00de.\n\n(4.65)\n\nIntuitively, the cosf and sinf terms in Eq. (4.65) are induced by the different upwind\n(s2u \u00bc 0:00316w) and crosswind (s2c \u00bc 0:003\u00fe 0:00192w) rms slopes, while the cos(2f) and sin(2f)\nterms are induced by the skewness (c21 \u00bc 0.01 e 0.0086w, c03 \u00bc 0.04 e 0.033w) and peakedness\n\n0 10 20 30 40 50 60 70\n130\n\n140\n\n150\n\n160\n\n170\n\n180\n\n190\n\n200\n\n210\n\n220\n\n230\n\nObservation angle ? [degrees], ? = 0\u00ba \n\n0 10 20 30 40 50 60 70\n60\n\n70\n\n80\n\n90\n\n100\n\n110\n\n120\n\n130\n\n140\n\n150\n\nObservation angle ? [degrees], ? = 0\u00ba \n\nT H\n [K\n\nel\nvi\n\nn]\n\nT V\n [K\n\nel\nvi\n\nn]\n\n(A) (B)\n\nFIGURE 4.41\n\nModeled (A) vertical and (B) horizontal brightness temperatures at 37 GHz versus observation angle, for wind\n\nspeeds of 3 m/s (solid line), 7 m/s (dotted line), 11 m/s (dashed line), and 15 m/s (dash-dot line). Wentz\u2019s\n\n(1992) geophysical model marked with crosses for comparison, with SST \u00bc 12?C and SSS \u00bc 33 psu.\n\n176 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.41|eps\n\n\n(c40 \u00bc 0.40, c22 \u00bc 0.12 and c04 \u00bc 0.23) terms in the GrameCharlier probability density function of\nthe sea surface slopes (Cox and Munk, 1954):\n\nP \u00bc 1ffiffiffiffiffiffiffiffiffiffiffiffiffi\n2psus\n\np\nc\n\nexp\n\n\"\n? 1\n2q2z\n\n \nq2x\ns2u\n\n\u00fe q\n2\ny\n\ns2c\n\n!#\n(\n1? 1\n\n2\nc21\n\n \nqy\nsc\n\n?2\n? 1\n!\n\nqx\nsu\n\n? 1\n6\nc03\n\n \nqx\nsu\n\n?3\n? 3 qx\n\nsu\n\n!\n\u00fe 1\n24\n\nc40\n\n \nqy\nsc\n\n?4\n? 6\n\nqy\nsc\n\n?2\n\u00fe 3\n!\n\n\u00fe 1\n4\nc22\n\n \nqy\nsc\n\n?2\n? 1\n! \n\nqx\nsu\n\n?2\n? 1\n!\n\n\u00fe 1\n24\n\nc04\n\n \nqx\nsu\n\n?4\n? 6\n\nqx\nsu\n\n?2\n\u00fe 3\n!)\n\n;\n\n(4.66)\n\nwhere w is the 10 m height wind speed, qx/qz and qy/qz are the slopes in the x and y-axes, respectively.\nAn example from Coriolis/WindSat (Anguelova and Gaiser, 2013, Fig. 4.42) shows the third Stokes\n\nparameter (T3) plotted as a function of the relative azimuth angle for different wind speeds (color coded).\nAlthough having units of temperature (power), as we can infer, T3 can be either positive or negative,\ndepending on the relative azimuth angle, since it is not an absolute power measurement, but a\n\nFIGURE 4.42\n\nHurricane Isabel on September 14, 2003, as seen by WindSat 18.7 GHz third Stokes parameter. Notice how\n\nthe signal changes around the circulation pattern of the storm (Anguelova and Gaiser, 2013). The source of\n\nthis material is the COMET? Website at http://meted.ucar.edu/ of the University Corporation for Atmospheric\n\nResearch (UCAR), sponsored in part through cooperative agreement(s) with the National Oceanic and At-\n\nmospheric Administration (NOAA), U.S. Department of Commerce (DOC). \u00a91997e2016 University Corpo-\n\nration for Atmospheric Research. All Rights Reserved.\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 177\n\nmailto:Image of Figure 4.42|tif\nhttp://meted.ucar.edu/\n\n\ncross-correlation between the electric fields at horizontal and vertical polarizations. Since T3 is less\naffected by atmospheric effects than Tv and Th, it is more robust to infer the wind direction than Tv and Th.\n\n4.3.4.4 Emissivity of the Sea Surface Covered With Oil\nOil spills are of particular concern in environmental monitoring and microwave radiometry can help to\nmonitor their extension and thickness. Once again, the change in the emissivity (or brightness tem-\nperature) provides the clue to measure it:\n\nDTpB;sea\u00f0q\u00de \u00bc\nh\nepoil\u00f0q\u00de ? epH2O\u00f0q\u00de\n\ni\n$ Tsea \u00bc\n\nh\nGpH2O\u00f0q\u00de ? G\n\np\noil\u00f0q\u00de\n\ni\n$ Tsea; (4.67)\n\nThis change is mainly due to two factors:\n\n\u2022 the reduced water surface roughness as compared to that of the clean water, for the same wind\nspeed (Cox and Munk, 1954). Since oil damps the short capillary waves, the surface becomes\nmore specular, the reflectivity is increased, and the emissivity decreases;\n\n\u2022 the reduced reflection coefficient due to the fact that the oil layer acts as an interface layer\nbetween the air and the water. The amount of matching depends on the oil characteristics and,\nmost important, on the oil layer thickness. Partial reflection at the oilewater atmosphere interface\nleads to interference fringes that lead to minimum reflection coefficient values (maximum\nemissivity) for normal incidence when the oil thickness is equal to an odd number of a quarter of\nthe electromagnetic wavelength of the oil: (2 $ n \u00fe 1) $ l/4, and maximum reflection coefficient\nvalues (minimum emissivity) when it is equal to an even number of a quarter of the\nelectromagnetic wavelength: (2 $ n) $ l/4. This periodic increase is shown in Fig. 4.43 versus the\noil film thickness in millimeters, for three different frequencies (5, 17, and 34 GHz) and it can be\nused to remove the oil film thickness ambiguity when trying to infer it from multifrequency\nmicrowave radiometry data. In Fig. 4.43, the incidence angle of the radiometer field of view\n(FOV) on the oil surface is 41? (5 GHz), 54? (17 GHz), and 50? (34 GHz).\n\nFIGURE 4.43\n\nOil spills cause a TB increase periodic in frequency and oil spill thickness (http://www.seos-project.eu/\n\nmodules/marinepollution/marinepollution-c02-ws02-p03-s.html).\n\nReproduced from SEOS tutorial. http://www.seos-project.eu/modules/marinepollution/marinepollution-c08-p02.html\n\n178 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.43|tif\nhttp://www.seos-project.eu/modules/marinepollution/marinepollution-c02-ws02-p03-s.html\nhttp://www.seos-project.eu/modules/marinepollution/marinepollution-c02-ws02-p03-s.html\nhttp://www.seos-project.eu/modules/marinepollution/marinepollution-c08-p02.html\n\n\nA fuel oil spill as seen from a 32 GHz microwave radiometer is depicted in Fig. 4.44. Hot spots are\nclearly seen, indicating the presence of oil spills.\n\n4.3.4.5 Emissivity of the Sea Ice Surface\nWhen the sea water gets frozen the emissivity changes dramatically. While most materials have a\ndielectric constant between 1 and 4 (ice is 3.2), that of water is 80 approximately, which makes passive\nmicrowave sensing extremely sensitive to the presence of ice. Also, the detection of the melt onset can\nbe easily detected, although there are problems afterwards when water and ice coexist.\n\nThe ice emissivity depends on a number of factors, including the frequency, the seasonal variation,\nthat is whether the ice layer is of 1-year-old, several years old (Fig. 4.45A), or if it has melted and then\nrefrozen (Fig. 4.45B). Additionally, the presence of snow layers complicates even more the\nmeasurement of the ice properties, since the snow scatters the ice\u2019s emitted radiance. While first-year\nice emissivity is quite constant with frequency, multiyear ice\u2019s emissivity drops significantly with\nincreasing frequency due to the increased scattering effects.\n\nDespite the abovementioned effects, the iceewater contrast is so high, that the detection of the\nfraction of ice cover in the ocean is quite straightforward. It is based on the measurement of the\ndistance between the brightness temperatures, or observables derived from them such as the polari-\nzation ratio (PR) and the gradient ratio (GR):\n\nPR \u00bc T19;v ? T19;h\nT19;v \u00fe T19;h ; (4.68)\n\nGR \u00bc T37;v ? T19;v\nT37;v \u00fe T19;v . (4.69)\n\nFig. 4.46 shows the clustering of the different types of ice (first year and multiyear) and the ice-free\nsurface, and how this scatter plot can be used to discriminate the type of surface, and also to infer the\nice cover fraction for borderline pixels.\n\nIn Fig. 4.47 we show sample results of the application of this technique to infer ice cover maps in\nthe Arctic and Antarctic oceans, while in Fig. 4.48 we show the ice cover map in the Antarctic Ocean\nduring 1991.\n\nFIGURE 4.44\n\nHeavy fuel oil slick with a total volume of 17 m3, measured with a 32 GHz MWR Scanner. The angle of\n\nincidence of the radiometer field of view on the sea surface is 40?. The maximum brightness temperature\nvariation is 17K.\n\nReproduced from SEOS tutorial. http://www.seos-project.eu/modules/marinepollution/marinepollution-c08-p02.html\n\n4.3 EMISSION BEHAVIOR OF NATURAL SURFACES 179\n\nmailto:Image of Figure 4.44|tif\nhttp://www.seos-project.eu/modules/marinepollution/marinepollution-c08-p02.html\n\n\nThe new radiometers operating at the lowest frequency bands (e.g., SMOS at L-band) are capable\nof \u201cseeing through\u201d the ice layer, provided it is not too thick (<50 cm), and therefore are sensitivity to\nthe sea surface emission below the ice layer as shown in Fig. 4.49. This allows us to determine the ice\nthickness, despite the cloud cover, which is quite persistent in the highest latitudes (Fig. 4.50).\n\nFIGURE 4.45\n\n(A) Ice emissivity changes with frequency and type of ice layer (Svendsen et al., 1983), (B) the sea ice\n\nmicrowave signature also has a seasonal dependence (Comiso, 1986).\n\n180 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.45|tif\n\n\nFIGURE 4.46\n\nSample plot of the gradient ratio (GR) versus polarization ratio (PR) with typical clustering of grid cell values\n\n(small dots) around the 0% ice (open water) point (blue star) and the 100% ice line (circled in red). Points\n\nwith a mixture of ice and water (circled in green) fall between these two extremes.\n\nAdapted from Fig. 10.2 of Steffen, K., Key, J., Cavalieri, D.J., Comiso, J., Gloersen, P., St. Germain, K., Rubinstein, I., 1992. The\n\nestimation of geophysical parameters using passive microwave algorithms. In: Carsey, F.D. (Ed.), \u201cMicrowave Remote Sensing of\n\nSea Ice.\u201d American Geophysical Union Monograph 68, Washington, DC, pp. 201e231.\n\nFIGURE 4.47\n\nSample seasonal variation of the ice cover in polar regions: (A) Arctic Ocean, (B) Antarctica detected by\n\nspecial sensor microwave imager. Note: the black circle in the Arctic corresponds to the area not measured by\n\nthe sensor, despite being in a polar orbit.\n\n4.4 UNDERSTANDING MICROWAVE RADIOMETRY IMAGERY\nTo understand how to interpret microwave radiometry imagery, in this section a few special sensor\nmicrowave imager (SSM/I) and advanced microwave sounding unit (MSU/AMSU) brightness tem-\nperature images are presented at different frequency bands. They have been selected to illustrate some\nof the effects described in Section 4.3 on the emission by natural surfaces and the atmosphere.\n\nTo begin with, Fig. 4.51 shows a Meteosat near-infrared image corresponding to September 29,\n1997 at 18:00 h. This image has been selected, because it is the closest in time to the SSM/I afternoon\n\n4.4 UNDERSTANDING MICROWAVE RADIOMETRY IMAGERY 181\n\nmailto:Image of Figure 4.46|tif\nmailto:Image of Figure 4.47|tif\n\n\noverpass. In this image, clouds appear as white, since they are reflecting the solar radiation. Recall that\noptical and infrared sensors do not penetrate through clouds. Recall also, that while in the thermal\ninfrared, the natural emission of bodies at a physical temperature different from zero is measured, and\ntherefore sensors can operate during day and night, in the ultraviolet, visible, and near-infrared, they\nrequire the Sun as a source of illumination, and therefore they will only be sensing during the daytime.\n\nThe reader is requested to pay attention to the elongated cloud structure in the south east of Spain,\nmarked in red, and to relate it with the microwave brightness temperatures, and to the geophysical\nparameters retrieved, notably rain. Please recall that microwaves, especially in the lower part of the\nspectrum, pass through the atmosphere and are able to sense the surface of the Earth.\n\nThe SSM/I is family of multifrequency (19, 22, 37, and 89 GHz) dual-polarization (horizontal and\nvertical, except at 22 GHz) radiometers that perform a conical scan to achieve a constant incidence\n\n1/91 2/91 3/91 4/91\n\n5/91 6/91 7/91 8/91\n\n9/91 10/91 11/91 12/91\n\nFIGURE 4.48\n\nSeasonal evolution of the ice cover in the Antarctic Ocean during 1991.\n\n182 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.48|eps\n\n\nangle over land of about 53?. Fig. 4.52 presents the different brightness temperatures as measured by\nthe SSM/I (platform F14) at 19 GHz (horizontal and vertical polarizations), and 22, 37, and 89 GHz\n(vertical polarization only).\n\nIn Fig. 4.52, the first thing that becomes very apparent is the high contrast between land and water at\nall frequencies, being the water much \u201ccooler\u201d (in terms of the brightness temperature) than the land. As\nthe frequency increases, this contrast reduces, which is mainly due to the increased atmospheric opacity,\nthat masks both land and water bodies, except at very high latitudesdeven for the highest frequency\nchannelsdwhere the water vapor density is very low, and so the atmospheric attenuation associated to it.\n\nOver the ocean, strips of increased brightness temperature are quite visible around the equator and\nless towards midlatitudes. These strips are due to increased atmospheric opacity due to the water vapor,\nwhich is more important close to the equator, and in cloudy regions. This happens at all frequencies,\nbut it is more evident at 22 GHz, where there is a water vapor absorption peak in the passive mi-\ncrowave spectrum. Sea ice is also clearly visible at higher latitudes north and south. Due to the sharp\ndecrease of the sea water dielectric constant when water gets frozen, a large increase in the brightness\ntemperature is observed.\n\nOver land, bare soil regions such as the Sahara Desert clearly exhibit a much higher brightness\ntemperature at vertical polarization than at horizontal polarization. Actually, warm deserts are\nidentified when T19v ? T19h > 20K at the SSM/I 53? incidence angle. Over densely vegetated areas\n\nFIGURE 4.49\n\n(A) Time series of advanced microwave scanning radiometer ice concentration and NCEP surface air tem-\n\nperature, and (B) Soil Moisture and Ocean Salinity (SMOS) observed and modeled brightness temperature\n\nwith the corresponding ice thickness at 77.5?N, 137.5?E (indicated in Fig. 4.50). The particular ice growth\nperiod discussed in the text is indicated in gray. The modeled brightness temperature is based on an\n\nexponential model and the ice thickness from Lebedev\u2019s growth parameterization (Kaleschke et al., 2012).\n\n4.4 UNDERSTANDING MICROWAVE RADIOMETRY IMAGERY 183\n\nmailto:Image of Figure 4.49|tif\n\n\nsuch as the tropical rainforests over Africa and America, the high attenuation of the vegetation layer,\nand the polarization mixing introduced by the leaves and branches, increases the brightness\ntemperatures, while at the same time makes both polarizations more similar. Snow is identified by the\nbrightness temperature depression produced by the scattering in the snow layer of the radiation emitted\nby the land (e.g., the Andes). The so-called spectral polarization difference or\nSPD \u00bc (T19v ? T37v) \u00fe (T19v ? T19h) uses the 37 GHz channel at vertical polarization and both\nchannels at 19 GHz to estimate the presence of snow. Since scattering increases with increasing\nfrequency, when snow is present T19v > T37v, and also the difference T19v ? T19h increases. Actually, it\nhas been empirically demonstrated that the snow depth can be directly related to the SPD by\nSD[cm] \u00bc 0.68 $ SPD ? 0.67, for all data, and by SD[cm] \u00bc 0.72 $ SPD ? 1.24, when TMAX air < 0.\n\nFinally, rain exhibits a particular behavior. For light to moderate rains, and low frequencies,\nabsorption mechanisms dominate over scattering, and the brightness temperature increases. Scattering\n\nFIGURE 4.50\n\nSea ice thickness in the Russian Arctic on (top) November 1 and (bottom) November 15, 2010. The white star\n\nindicates the grid cell position for the time series analysis (Fig. 4.49) (Kaleschke et al., 2012).\n\n184 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.50|tif\n\n\neffects start to dominate when the frequency increases and/or the rain intensity increases (raindrop size\nincreases as compared to the wavelength). This effect starts being observed first over land (e.g.,\nFig. 4.52C in the northern part of the Gulf of Guinea), than over the sea, since the radiation emitted by\nland is larger than that emitted by the ocean. In Fig. 4.52D and E additional \u201cblue\u201d spots can be\nappreciated also in South America, in equatorial region of the Atlantic Ocean, and in the south of the\nIberian Peninsula, where a cold front event was taking place.\n\nSample brightness temperature images measured by the MSU/AMSU are presented here in\nFig. 4.53. This sensor operates mainly in the frequency bands from 51.3 to 57.95 GHz, and 183 GHz,\nwith additional channels at 23.8, 31.4, 89, and 159 GHz. The first band covers the atmospheric oxygen\nabsorption band. Since the oxygen concentration is quite homogeneous all over the world, the\nattenuation due to the oxygen is rather constant, and the brightness temperatures measured at different\nchannels are sensitive to the physical temperatures at different heights in the atmosphere.\n\nFig. 4.54 from http://www.ssmi.com/msu/msu_data_monthly.html?channel\u00bc2&type\u00bcabsolute\nshows the so-called \u201cweighting functions,\u201d which represent the relative contribution of each atmo-\nspheric layer to the antenna temperature measured from the satellite. As in the SSM/I, the 23.8 GHz\nchannel is sensitive to water vapor, while the 31.4, the 89, and the 159 GHz channels are in trans-\nmission bands for calibration purposes.\n\nThe MSUs make measurements of microwave radiance in four different frequencies (or channels)\nranging from 51.3 to 57.95 GHz. Of these four channels, MSU channels 2, 3, and 4 were used to\nconstruct the following data sets:\n\n\u2022 The temperature of the lower stratosphere (TLS) is constructed from MSU channel 4, and it\ncorresponds to a layer of the atmosphere from about 12 km to about 25 km above Earth\u2019s surface.\n\n\u2022 The temperature of the troposphere stratosphere (TTS) is constructed from MSU channel 3 and\ncorresponds to a layer of the atmosphere from about 3 km to about 20 km above the surface, with\nmost of the weight coming from about 10 km.\n\nFIGURE 4.51\n\nMETEOSAT near-infrared image of Europe and North Africa corresponding to September 29, 1997 at 18:00 h.\n\nNote the cyclonic structure over the Iberian Peninsula.\n\n4.4 UNDERSTANDING MICROWAVE RADIOMETRY IMAGERY 185\n\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nmailto:Image of Figure 4.51|eps\n\n\n\u2022 The temperature of the middle troposphere (TMT) is constructed using data fromMSU channel 2\nand corresponds to a layer of the atmosphere from the surface to about 15 km, with the peak\nweight at about 4 km.\n\n\u2022 The temperature of the lower troposphere (TLT) is constructed from MSU channel 2 by\nsubtracting measurements made at different angles from each other.\n\nFIGURE 4.52\n\nSpecial sensor microwave imager brightness temperatures at 19 GHz (h- and v-polarizations), and 22, 37,\n\nand 89 GHz (v-polarization only).\n\n186 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.52|tif\n\n\nBeginning in 1998, a series of follow-on instruments to the MSUs, the advanced AMSUs, began\noperation. The AMSU instruments are similar to the MSUs, but they make measurements using a\nlarger number of channels, thus sampling the atmosphere in a larger number of layers, including a\nnumber of layers higher in the stratosphere. By using the AMSU channels that most closely match the\nchannels in the MSU instruments, the data set can be extended beyond 2005. For example, TLS is\nextended using AMSU channel 9, TTS is extended using AMSU channel 7, and TMT and TLS are\nextended using AMSU channel 5. With the AMSU series of instruments, temperatures can be\nmonitored higher in the stratosphere using data channels 10 through 14.\n\n4.5 APPLICATIONS OF MICROWAVE RADIOMETRY\nIn the previous sections the basic concepts of microwave radiometry have been reviewed, including\nthe RTE, and the emission behavior of the atmosphere, and natural surfaces (land and ocean), and the\nperturbing effects of the ionosphere. The emission behavior has been linked to a number of phenomena\nthat can be sensed by means of microwave radiometry. We summarize the dependence of the emis-\nsivity on different surfaces and that of rain in Fig. 4.55 (https://www.meted.ucar.edu/).\n\nThe separation of these bands is made on the basis of maximizing the sensitivity to the different\nparameters to be sensed. The relative sensitivity of the brightness temperatures to different geophysical\nparameters can be found in Fig. 4.56.\n\nFIGURE 4.52 Cont\u2019d\n\n4.5 APPLICATIONS OF MICROWAVE RADIOMETRY 187\n\nhttps://www.meted.ucar.edu/\nmailto:Image of Figure 4.52|tif\n\n\nThe following figures show some sample geophysical products that are routinely derived from\npassive microwave observations. These examples are provided as samples of the different land, ocean,\nand atmosphere applications that will be described in more depth in the corresponding chapters of this\nbook, using the different types of remote sensors. The first set of examples (Figs. 4.57e4.61)\n\nFIGURE 4.53\n\nBrightness temperatures for different advanced microwave sounding unit (MSU/AMSU) channels (http://\n\nwww.ssmi.com/msu/msu_data_monthly.html?channel\u00bc2&type\u00bcabsolute).\n\n188 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.53|tif\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\n\n\ncorrespond to the SSM/I brightness temperatures shown in Fig. 4.52 (September 29, 1997). To un-\nderstand these data, it is important to recall that the retrieved values correspond to average values over\nthe antenna footprint, which does not mean that the value is constant over the whole footprint, and\npoint measurements can be very different from the average values.\n\nThe second set of examples (Figs. 4.62e4.67) corresponds to WindSat brightness temperatures from\nOctober 29, 2012, when Hurricane Sandy hit New York City. Most of the geophysical parameter retrieval\n\nFIGURE 4.53 Cont\u2019d\n\n4.5 APPLICATIONS OF MICROWAVE RADIOMETRY 189\n\nmailto:Image of Figure 4.53|tif\n\n\nalgorithms have a strong heritage from previous missions, but since there are new channels and WindSat\nis the first full-polarimetric instrument, new information can be extracted. Among this new information,\nthere are mainly the SST, thanks to the new 6.8 GHz channel, and the wind direction (in addition to wind\nspeed) over the ocean thanks to the polarimetric capabilities of the WindSat radiometer.\n\nFIGURE 4.54\n\nWeighting functions of the AMSU-A1 channels (http://www.ssmi.com/msu/msu_data_monthly.html?\n\nchannel\u00bc2&type\u00bcabsolute, http://amsu.ssec.wisc.edu/explanation.html).\n\nFIGURE 4.55\n\nSummary of thedependenceof theemissivity ofdifferent surfacesand that of rain (https://www.meted.ucar.edu/).\n\n190 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.54|tif\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://www.ssmi.com/msu/msu_data_monthly.html?channel=2&amp;type=absolute\nhttp://amsu.ssec.wisc.edu/explanation.html\nmailto:Image of Figure 4.55|tif\nhttps://www.meted.ucar.edu/\n\n\n0\n\n+\n\n\u2013\n\n(ARB UNITS)\n\n?TB\n?Pi\n\nWIND SPEED\n\nLIQUID\nCLOUDS\n\nFREQUENCY\n\nSEA SURFACE\nTEMPERATURE\n\nWATER\nVAPOR\n\nGHz\n\n10 20 30 40\n\nFIGURE 4.56\n\nNormalized sensitivity of the brightness temperatures to different geophysical parameters.\n\nFIGURE 4.57\n\nSnow coverage (100% of footprint) as derived from satellite F-14 corresponding to September 29, 1997.\n\nRecall that the presence of snow is mainly determined by the scattering signature present in the 19 and\n\n37 GHz channels.\n\nCourtesy of National Oceanic and Atmospheric Administration.\n\n4.5 APPLICATIONS OF MICROWAVE RADIOMETRY 191\n\nmailto:Image of Figure 4.56|eps\nmailto:Image of Figure 4.57|tif\n\n\nFIGURE 4.58\n\nRain intensity as derived from satellite F-13 corresponding to September 29, 1997. The rain intensity is mainly\n\ndetermined by the increased absorption at the lower frequency bands with increased rain rate, while at higher\n\nfrequencies and/or rain rates scattering produces a depletion of the measured brightness temperatures.\n\nCourtesy of Remote Sensing Systems.\n\nFIGURE 4.59\n\nCloud liquid water as derived from satellite F-13 corresponding to September 29, 1997. The cloud liquid water\n\nis mainly determined using the 22 and 37 GHz bands.\n\nCourtesy of Remote Sensing Systems.\n\nmailto:Image of Figure 4.58|tif\nmailto:Image of Figure 4.59|tif\n\n\nFIGURE 4.60\n\nAtmospheric water vapor as derived from satellite F-13 corresponding to September 29, 1997. The atmo-\n\nspheric water vapor is mainly determined using the brightness temperature increase at the 22 GHz band.\n\nCourtesy of Remote Sensing Systems.\n\nFIGURE 4.61\n\nSurface wind speed as derived from satellite F-13 corresponding to September 29, 1997. The surface wind\n\nspeed is mainly determined based on the brightness temperature increase at horizontal polarization at\n\n37 GHz band with corrections for ocean surface temperature and atmospheric effects using the brightness\n\ntemperatures at the 19, 22, and 37 GHz bands and vertical polarization, which are almost insensitive to\n\nsurface roughness effects.\n\nCourtesy of Remote Sensing Systems.\n\nmailto:Image of Figure 4.60|tif\nmailto:Image of Figure 4.61|tif\n\n\nFIGURE 4.62\n\nSea Surface Temperature (SST) as derived from WindSat corresponding to October 29, 2012. The SST is\n\nmainly determined from the brightness temperature at vertical polarization at 6.8 GHz band. Note the\n\nabsence of parameter returns in those regions where the presence of rain has been detected (Fig. 4.65).\n\nCourtesy of Remote Sensing Systems.\n\nFIGURE 4.63\n\nAtmospheric water vapor as derived from WindSat corresponding to October 29, 2012. Note the higher\n\nconcentration of atmospheric water vapor in the equatorial regions, where evaporation is more intense, and in\n\nregions where either cloud liquid water (Fig. 4.64) or rain (Fig. 4.65) are detected later, and in particular in the\n\nNorth Atlantic Coast of the United States.\n\nCourtesy of Remote Sensing Systems.\n\nmailto:Image of Figure 4.62|tif\nmailto:Image of Figure 4.63|tif\n\n\nFIGURE 4.64\n\nCloud liquid water as derived from WindSat corresponding to October 29, 2012. Note the higher concen-\n\ntration of atmospheric water vapor in the equatorial regions, where atmospheric water vapor (Fig. 4.64) is\n\npresent.\n\nCourtesy of Remote Sensing Systems.\n\nFIGURE 4.65\n\nRain rate as derived from WindSat corresponding to October 29, 2012. Note the higher concentration of\n\natmospheric water vapor in the equatorial regions, where atmospheric water vapor (Fig. 4.64) is present.\n\nCourtesy of Remote Sensing Systems.\n\nmailto:Image of Figure 4.64|tif\nmailto:Image of Figure 4.65|tif\n\n\nFIGURE 4.66\n\nZoom of Fig. 4.67 corresponding to the North Atlantic region. Hurricane Sandy can be clearly seen as well as\n\nthe decreased wind speed (w10 m/s) in the hurricane\u2019s eye.\n\nFIGURE 4.67\n\nWind vector maps derived from WindSat corresponding to October 29, 2012. Color indicates the wind in-\n\ntensity, and arrows indicate the wind direction. Wind direction is inferred thanks to the third Stokes parameter\n\nand thanks to two-look observations of the same pixel. Note the extreme high winds in the North East coast of\n\nthe United States, overpassing 45 m/s.\n\nCourtesy of Remote Sensing Systems.\n\nmailto:Image of Figure 4.66|tif\nmailto:Image of Figure 4.67|tif\n\n\n4.6 SENSORS\n4.6.1 HISTORICAL REVIEW OF MICROWAVE RADIOMETERS AND FREQUENCY\n\nBANDS USED\nTable 4.3 is a nonexhaustive table (from Recommendation ITU-R RS.515-5) summarizing the main\nfrequency bands and applications up to about 1 THz. The bands listed are not necessarily reserved and/\nor protected for passive observations, either in part or completely. For example, the bandwidth from\n1.400 to 1.427 GHz is nominally reserved exclusively for passive observations, but it does not neces-\nsarily mean that it is free of radio frequency interference (RFI). The band from 1.370 to 1.400 GHz is\nshared with other services, so it is likely to encounter other signals. Similarly, the band from 10.68 to\n10.70 GHz is nominally protected for passive observations, but not the one from 10.60 to 10.68 GHz.\nThe use of bandwidths larger than the strictly protected one is a trade-off between improved radiometric\nresolution and the probability to suffer from RFI. For ocean sensors, where RFI is usually less frequent,\nand better radiometric resolution is often required, it is not uncommon to use bandwidths larger than the\nones reserved exclusively. The topic of RFI detection and mitigation is becoming a very important one\ndue to wider use of wireless communications over larger bandwidths, and at higher frequencies. This\ntopic will be discussed at the end of this chapter, since it is likely that most future microwave radi-\nometers will include some sort of digital back end to detect, and eventually mitigate, RFI.\n\nTable 4.4 presents a nonexhaustive list of microwave radiometers and missions, together with a\nshort description of their applications and main performance parameters. This table is provided to\nillustrate the use of the different frequency bands and bandwidths for different applications, to be\ncompared with Table 4.3. Later in this section, this table will be revisited again to look in more detail at\nthe imaging and scanning configurations for the different applications and their relative occurrence.\n\nTable 4.5 presents a noncomprehensive summary historical overview of spaceborne microwave\nradiometers. As can be noticed, there is a general trend towards the use of an increasing number of\nchannels (and polarizations) and higher frequency bands, so as to achieve a better spatial resolution.\nHowever, this trend has been recently reversed with three missions ESA\u2019s SMOS Soil Moisture and\nOcean Salinity mission (launch November 2009), NASA/CONAE Aquarius/SAC-D Ocean Salinity\nmission (launch June 2010), and NASA\u2019s SMAP (Soil Moisture Active/Passive) mission (launch\nJanuary 2015), all three using a single polarimetric radiometer at L-band, and in the case of the\nAquarius/SAC-D and SMAP missions an L-band radar.\n\n4.6.2 MICROWAVE RADIOMETERS: BASIC PERFORMANCE\nIn Section 4.2 the four Stokes elements were derived from the electric fields measured in a single\nposition. In this section, before the different types of microwave radiometers are discussed (total power\nor correlation radiometers, real or synthetic aperture), a general framework is presented to give a unified\nunderstanding of them. The definition of the Stokes elements given in Eq. (4.19) can be extended to the\ncase where the electric fields are measured at different positions (i.e., by different antennas). For the\nsake of simplicity, it will be assumed that the surface under measurement is an extended source of\nrandom electromagnetic emission (thermal noise) spatially uncorrelated, that the system is narrowband,\nand the source is in the far-field of the pair of antennas collecting the electric fields.\n\nIn the general case, a correlation radiometer is formed by two antennas located at (xm,ym,zm) and\n(xn,yn,zn), and measures the cross-correlation between the signals received by each antenna. This\n\n4.6 SENSORS 197\n\n\n\nTable 4.3 Main Frequency Bands and Applications Up to 1 THz for Passive Observations\n\nFrequency\nBand(s) (GHz)\n\nTotal Bandwidth\nRequired (MHz)\n\nSpectral Line(s) or\nCenter Frequency (GHz)\n\nMeasurement (Meteorology-\nClimatology, Chemistry)\n\nTypical\nScan\nMode N,\nC, La\n\n1.37e1.427 57 1.4 Soil moisture, ocean salinity, sea surface\ntemperature, vegetation index\n\nN, C\n\n2.64e2.7 60 2.67 Ocean salinity, soil moisture, vegetation\nindex\n\nN\n\n4.2e4.4 200 4.3 Sea surface temperature N, C\n\n6.425e7.25 350d 6.85 Sea surface temperature N, C\n\n10.6e10.7 100 10.65 Rain rate, snow water content, ice\nmorphology, sea state, ocean wind speed\n\nN, C\n\n15.2e15.4 200 15.3 Water vapor, rain rate N, C\n\n18.6e18.8 200 18.7 Rain rates, sea state, sea ice, water vapor,\nocean wind speed, soil emissivity and\nhumidity\n\nN, C\n\n21.2e21.4 200 21.3 Water vapor, liquid water N\n\n22.21e22.5 290 22.235 Water vapor, liquid water N\n\n23.6e24 400 23.8 Water vapor, liquid water, associated\nchannel for atmospheric sounding\n\nN, C\n\n31.3e31.8 500 31.4 Sea ice, water vapor, oil spills, clouds,\nliquid water, surface temperature,\nreference window for 50e60 GHz range\n\nN, C\n\n36e37 1,000 36.5 Rain rates, snow, sea ice, clouds N, C\n\n50.2e50.4 200 50.3 Reference window for atmospheric\ntemperature profiling (surface\ntemperature)\n\nN, C\n\n52.6e59.3 6,700b Several between 52.6 and 59.3 Atmospheric temperature profiling (O2\nabsorption lines)\n\nN, C\n\n86e92 6,000 89 Clouds, oil spills, ice, snow, rain,\nreference window for temperature\nsoundings near 118 GHz\n\nN, C\n\n100e102 2,000 100.49 N2O, NO L\n\n109.5e111.8 2,300 110.8 O3 L\n\n114.25e116 1,750 115.27 CO L\n\n115.25e122.25 7,000b 118.75 Atmospheric temperature profiling (O2\nabsorption line)\n\nN, L\n\n148.5e151.5 3,000 150.74 N2O, Earth surface temperature, cloud\nparameters, reference window for\ntemperature soundings\n\nN, L\n\n155.5e158.5c 3,000 157 Earth and cloud parameters N, C\n\n1\n9\n8\n\nC\nH\nA\nP\nT\nE\nR\n4\n\nM\nIC\nR\nO\nW\nA\nV\nE\nR\nA\nD\nIO\nM\nE\nT\nR\nY\n\n\n\n164e167 3,000b 164.38, 167.2 N2O, cloud water and ice, rain, CO, ClO N, C, L\n\n174.8e191.8 17,000b 175.86, 177.26, 183.31, 184.75 N2O, water vapor profiling, O3 N, C, L\n\n200e209 9,000b 200.98, 203.4, 204.35, 206.13, 208.64 N2O, ClO, water vapor, O3 L\n\n226e231.5 5,500 226.09, 230.54, 231.28 Clouds, humidity, N2O (226.09 GHz), CO\n(230.54 GHz), O3 (231.28 GHz),\nreference window\n\nN, L\n\n235e238 3,000 235.71, 237.15 O3 L\n\n250e252 2,000 251.21 N2O L\n\n275e285.4 10,400 276.33 (N2O), 278.6 (ClO) N2O, ClO L\n\n296e306 10,000 Window for 325.1, 298.5, (HNO3), 300.22\n(HOCl), 301.44 (N2O), 303.57 (O3), 304.5\n(O17O), 305.2 (HNO3)\n\nWing channel for temperature sounding\nOxygen, HNO3, HOCl, N2O, O3, O\n\n17O\nN, L\n\n313.5e355.6 42,100 313.8 (HDO), {315.8, 346.9, 344.5, 352.9}\n(ClO), {318.8, 345.8, 344.5} (HNO3), {321.15,\n325.15} (H2O), {321, 345.5, 352.3, 352.6, 352.8}\n(O3), {322.8, 343.4} (HOCl), {345.0, 345.4}\n(CH3Cl), 345.0 (O\n\n18O), 345.8 (CO), 346 (BrO),\n349.4 (CH3CN), 351.67 (N2O), 354.5 (HCN)\n\nWater vapor profiling, cloud, wing\nchannel for temperature sounding\nHDO, ClO, HNO3, H2O, O3, HOCl,\nCH3Cl, O\n\n18O, CO, BrO, CH3CN, N2O,\nHCN\n\nN, C, L\n\n361.2e365 3,800 364.32 (O3) Wing channel for\nwater vapor profiling\nO3\n\nN, L\n\n369.2e391.2 22,000 380.2 (H2O) Water vapor profiling\nH2O\n\nN, L\n\n397.2e399.2 2,000 Water vapor profiling N, L\n\n409e411 2,000 Temperature sounding L\n\n416e433.46 17,460 424.7 (O2) Oxygen, temperature profiling\nO2\n\nN, L\n\n439.1e466.3 27,200 442 (HNO3), {443.1, 448} (H2O), 443.2 (O3),\n452.09 (N2O), 461.04 (CO)\n\nWater vapor profiling, cloud\nHNO3, H2O, O3, N2O, CO\n\nN, L, C\n\n477.75e496.75 19,000 487.25 (O2) Oxygen, temperature profiling\nO2\n\nL\n\n497e502 5,000 {497.6, 497.9} (BrO), 497.9 (N2\n18O), 498.6 (O3) Wing channel for water vapor profiling\n\nBrO, N2\n18O, O3\n\nL, N\n\n523e527 4,000 Window for 556.9 Wing channel for water vapor profiling N\n\n538e581 43,000 {541.26, 542.35, 550.90, 556.98} (HNO3),\n{544.99, 566.29, 571.0} (O3), 556.93 (H2O),\n575.4 (ClO)\n\nWater vapor profiling\nHNO3, O3, H2O, ClO\n\nN, L\n\n611.7e629.7 18,000 620.7 (H2O), 624.27 (ClO2), {624.34, 624.89,\n625.84, 626.17} (SO2), {624.48, 624.78}\n(HNO3), 624.77 (\n\n81BrO), 624.8 (CH3CN), 624.98\n(H37Cl), 625.04 (H2O2), {625.07, 628.46}\n(HOCl), 625.37 (O3), 625.66 (HO2), 625.92\n(H35Cl), 627.18 (CH3Cl), 627.77 (O\n\n18O)\n\nWater vapor profiling, oxygen\nOxygen, H2O, ClO2, SO2, HNO3, BrO,\nCH3CN, (H\n\n37Cl), H2O2, HOCl, O3, HO2,\nH35Cl, CH3Cl, O\n\n18O\n\nL\n\nContinued\n\n4\n.6\n\nS\nE\nN\nS\nO\nR\nS\n\n1\n9\n9\n\n\n\nTable 4.3 Main Frequency Bands and Applications Up to 1 THz for Passive Observationsdcont\u2019d\n\nFrequency\nBand(s) (GHz)\n\nTotal Bandwidth\nRequired (MHz)\n\nSpectral Line(s) or\nCenter Frequency (GHz)\n\nMeasurement (Meteorology-\nClimatology, Chemistry)\n\nTypical\nScan\nMode N,\nC, La\n\n634e654 20,000 635.87 (HOCl), 647.1 (H2\n18O), 649.24 (SO2),\n\n649.45 (ClO), 649.7 (HO2), 650.18 (\n81BrO),\n\n650.28 (HNO3), 650.73 (O3), 651.77 (NO),\n652.83 (N2O)\n\nWing channel for water vapor profiling\nHOCl, H2\n\n18O, SO2, ClO, HO2, BrO,\nHNO3, O3, NO, N2O\n\nL, N\n\n656.9e692 35,100 658 (H2O), 660.49 (HO2), 687.7 (ClO), 688.5\n(CH3Cl), 691.47 (CO)\n\nWater vapor profiling, cloud\nH2O, HO2, ClO, CH3Cl, CO\n\nL, N, C\n\n713.4e717.4 4,000 715.4 (O2) Oxygen\nO2\n\nL\n\n729e733 4,000 731 (HNO3), 731.18 (O\n18O) Oxygen\n\nHNO3, O\n18O\n\nL\n\n750e754 4,000 752 (H2O) Water\nH2O\n\nL\n\n771.8e775.8 4,000 773.8 (O2) Oxygen\nO2\n\nL\n\n823.15e845.15 22,000 834.15 (O2) Oxygen\nO2\n\nN, C, L\n\n850e854 4,000 852 (NO) NO L\n\n857.9e861.9 4,000 859.9 (H2O) Water\nH2O\n\nL\n\n866e882 16,000 Cloud, window N, C\n\n905.17e927.17 22,000 916.17 (H2O) Water\nH2O\n\nN, L\n\n951e956 5,000 952 (NO), 955 (O18O) Oxygen\nNO, O18O\n\nL\n\n968.31e972.31 4,000 970.3 (H2O) Water\nH2O\n\nL\n\n985.9e989.9 4,000 987.9 (H2O) Water\nH2O\n\nL\n\naN, nadir; nadir scan modes concentrate on sounding or viewing the Earth\u2019s surface at angles of nearly perpendicular incidence. The scan terminates at the surface or at various\nlevels in the atmosphere according to the weighting functions. L, limb; limb scan modes view the atmosphere \u201con edge\u201d and terminate in space rather than at the surface, and\naccordingly are weighted zero at the surface and maximum at the tangent point height. C, conical; conical scan modes view the Earth\u2019s surface by rotating the antenna at an offset\nangle from the nadir direction.\nbThis bandwidth is occupied by multiple channels.\ncThis band is needed until 2018 to accommodate existing and planned sensors.\ndThis bandwidth is the required sensor bandwidth within the frequency range given in Column 1.\nExtracted from Recommendation ITU-R RS.515-5.\n\n2\n0\n0\n\nC\nH\nA\nP\nT\nE\nR\n4\n\nM\nIC\nR\nO\nW\nA\nV\nE\nR\nA\nD\nIO\nM\nE\nT\nR\nY\n\n\n\nTable 4.4 Nonexhaustive List of Microwave Radiometers and Missions, With Short Description of Their Applications and Main Performance\n\nInstrument Mission(s) Launch Date/EOL Date Applications Observation Requirements and Techniques Products Description\n\nATSR-MWS (along-\n\ntrack scanning radiometer-\n\nmicrowave sounder)\n\nERS-1 17/07/1991e10/03/2000 \u00b7 Atmosphere\n(primary)\n\n\u00b7 Land\n\u00b7 Ocean\n\u00b7 Snow\n\u00b7 Ocean\n\nGeometry: near-nadir looking (\u00fe35 km, ?25 km\nfrom nadir)\n\nSpatial resolution: 22.4 km (fore), 21.2 km (aft)\n\nSwath size: w20 km (1 pixel only)\n\nBand: 23.8 and 36.5 GHz\n\nAntenna type: offset parabola, two feeds\n\nBandwidth: 200 MHz\n\nAcquisition modes: continuous\n\n\u00b7 WVC (water vapor column)\n\u00b7 CLW (cloud liquid water), as correction terms for\n\nthe radar altimeter signal.\n\n\u00b7 MWR data also useful for surface\u2019s emissivity and\nsoil moisture, sea ice, and snow.\n\nERS-2 21/04/1995e05/09/2011\n\nENVISAT 01/03/2002e08/04/2012\n\nSENTINEL-3 16/02/2016epresent\n\nMIRAS (microwave\n\nimaging radiometer by\n\naperture synthesis)\n\nSMOS (Soil\n\nMoisture and\n\nOcean salinity)\n\nmission\n\n2/11/2009epresent \u00b7 Land\n\u00b7 Ocean\n\u00b7 Cryosphere\n\nGeometry: snap-shot imaging >1000 ? 1000\nkm2 image\n\nSpatial resolution:w40 km (varies with position\n\nin field of view)\n\nSwath size: w1000 km\n\nBand: L (1.4 GHz)\n\nAntenna type: dual-polarization microstrip\n\npatches (69 antenna array)\n\nBandwidth: 27 MHz\n\nAcquisition modes: Dual-polarization and full-\n\npolarimetric (after commissioning phase full\n\npolarimetric mode only)\n\n\u00b7 Soil moisture\n\u00b7 Ocean surface salinity maps\nBy-products:\n\n\u00b7 RFI maps\n\u00b7 High winds mapping (hurricane mapping)\n\u00b7 Ice thickness maps (thin ice)\n\nSSM/I (special sensor\n\nmicrowave imager)\n\nDMSP-F8 20/06/1987e01/10/2006 \u00b7 Atmosphere\n\u00b7 Land\n\u00b7 Ocean\n\u00b7 Snow\n\nGeometry: conical scan, 53.1? incidence angle\nSpatial resolution: 13e50 km swath size:\n\nw1400 km\n\nBand: 19.35, 22.235, 37.0 and 85.5 GHz (4\n\nfrequencies, 7-channels MW radiometer)\n\nAntenna type: offset parabola\n\nBandwidth: varies with channel\n\nAcquisition modes: continuous global mapping\n\n\u00b7 Ocean surface wind speed\n\u00b7 Ice cover/edge/age\n\u00b7 Precipitation over land and water,\n\u00b7 CLW & integrated WVC\n\u00b7 Soil moisture\n\u00b7 Land/sea surface temperature,\n\u00b7 SWE (snow water equivalent)\n\nDMSP-F10 17/12/1990e04/11/1997\n\nDMSP-F11 28/11/1991e16/05/2000\n\nDMSP-F12 29/08/1994e10/08/2007\n\nDMSP-F13 24/03/1995e18/11/2009\n\nDMSP-F14 04/04/1997e23/08/2008\n\nDMSP-F15 12/12/1999epresent\n\nSSM/T (Or SSM/T-1)\n\n(special sensor microwave\n\ntemperature sounder)\n\nDMSP-F5 06/06/1979e14/07/1980 \u00b7 Atmosphere Geometry: Cross-track scan \t36? from nadir\n(7 spots)\n\nSwath: 1500 km\n\nSpatial resolution: 174 km at nadir, up to\n\n213 x 304 km\n\nBands: 50.5, 53.2, 54.35, 54.9, 58.4, 58.825, and\n\n\u00b7 Atmospheric (0e30 km) vertical temperature\nprofilesDMSP-F7 18/11/1983e16/05/1988\n\nDMSP-F10 01/12/1990e04/11/1997\n\nDMSP-F11 28/11/1991e16/05/2000\n\nDMSP-F12 29/08/1994e10/08/2007\n\nContinued\n\n\n\nTable 4.4 Nonexhaustive List of Microwave Radiometers and Missions, With Short Description of Their Applications and Main\nPerformancedcont\u2019d\n\nInstrument Mission(s) Launch Date/EOL Date Applications Observation Requirements and Techniques Products Description\n\n59.4 GHz\n\nBandwidth: 400, 400, 400, 400, 350, 300, 250\n\nMHz\n\nAntenna type: reflector\n\nAcquisition modes: continuous global mapping\n\nPolarization: horizontal\n\nDMSP-F13 24/03/1995e18/11/2009\n\nDMSP-F14 04/04/1997e23/08/2008\n\nDMSP-F15 12/12/1999epresent\n\nSSM/T-2 (special sensor\n\nmicrowave water vapor\n\nprofiler)\n\nDMSP-F12 29/08/1994e10/08/2007 \u00b7 Atmosphere Geometry: cross-track scan \t40.5? from nadir\n(28 spots)\n\nSwath: 1500 km\n\nSpatial resolution: 48 km\n\nBands: 91.655 \t 1.250, 150.0 \t 1.250,\n183.3 \t 7, 183.31 \t 3.0, 183.31 \t 1.0 GHz\nBandwidth: 3000, 1500, 500, 1000, 1500 MHz\n\nAntenna type: offset reflector\n\nAcquisition modes: continuous global mapping\n\n\u00b7 Concentration of water vapor in the atmosphere\nDMSP-F13 24/03/1995e03/02/2015\n\nDMSP-F14 04/04/1997e23/08/2008\n\nDMSP-F15 12/12/1999epresent\n\nSSMI/S (special sensor\n\nmicrowave imager/\n\nsounder)\n\nDMSP-F16 18/10/2003epresent \u00b7 Atmosphere\n\u00b7 Land\n\u00b7 Ocean\n\u00b7 Snow\n\nGeometry: conical scan, 53.1? incidence angle\nSpatial resolution: (see below)\n\nSwath size: w1700 km\n\nBands/bandwidths/spatial resolution/\n\npolarization:\n\n1. 50.3 GHz/400 MHz/38 ? 38 km/V;\n2. 52.8 GHz/400 MHz/38 ? 38 km/V;\n3. 53.596 GHz/400 MHz/38 ? 38 km/V;\n4. 54.4 GHz/400 MHz/38 ? 38 km/V;\n5. 55.5 GHz/400 MHz/38 ? 38 km/V\n6. 57.29/350 MHz/38 ? 38 km/RHCP;\n7. 59.4 GHz/250 MHz/38 ? 38 km/RHCP;\n8. 150 GHz/1500 MHz/14 ? 13 km/H;\n9. 183.31 \t 6.6 GHz/1500 MHz/14 ? 13\n\nkm/H;\n\n10. 183.31 \t 3 GHz/1500 MHz/14 ?\n13 km/H;\n\n11. 183.31 \t 1 GHz/1500 MHz/14 ?\n13 km/H;\n\n12. 19.35 GHz/400 MHz/73 ? 47 km/H;\n13. 19.35 GHz/400 MHz/73 ? 47 km/V;\n14. 22.235 GHz/400 MHz/73 ? 47 km/V\n15. 37 GHz/1500 MHz/41 ? 31 km/H;\n\nReplacing and merging SSM/I, SSM/T and SSM/T-2\n\nflown on DMSP up to F15\n\nMultipurpose MW conical-scan imager with\n\ntemperature/humidity sounding channels for improved\n\nprecipitation\n\nDMSP-F17 04/11/2006epresent\n\nDMSP-F18 18/10/2009epresent\n\nDMSP-F19 03/04/2014e11/02/2016\n\nDMSP-F20 Canceled\n\n\n\n16. 37 GHz/1500 MHz/41 ? 31 km/V;\n17. 91.655 GHz/3000 MHz/75 ? 75 km/\n\nRHCP;\n\n18. 91.655 GHz/3000 MHz/75 ? 75 km/\nRHCP;\n\n19. 63.283248 \t 0.285271 GHz/3 GHz/75 ?\n75 km/RHCP;\n\n20. 60.792668 \t 0.357892 GHz/3 GHz/75 ?\n75 km/RHCP;\n\n21. 60.792668 \t 0.357892 \t 0.002 GHz/6\nMHz/75 ? 75 km/RHCP;\n\n22. 60.792668 \t 0.357892 \t 0.006 GHz/12\nMHz/75 ? 75 km/RHCP;\n\n23. 60.792668 \t 0.357892 \t 0.016 GHz/32\nMHz/75 ? 75 km/RHCP;\n\n24. 60.792668 \t 0.357892 \t 0.050 GHz/120\nMHz/75 ? 75 km/RHCP\n\nAntenna type: offset parabola\nAcquisition modes: V, H, and/or RHCP\npolarizations\nSame as SSMI/S in DMSP-16, but 1st 5\nchannels are H- instead of V-polarization\n\nTMI (TRMM microwave\n\nimager)\n\nTRMM 27/11/1997epresent \u00b7 Atmosphere Geometry: conical scan (49?)\nSpatial resolution: 4.6 ? 7.2 km to 36.8 ?\n63.2 km\n\nSwath size: 760 km\n\nBands/Bandwidths/Polarization/Footprint\n\n1. 10.65 GHz/100 MHz/V/35.7 ?\n59.0 km\n\n2. 10.65 GHz/100 MHz/H/36.4 ? 60.1 km\n3. 19.35 GHz/500 MHz/V/18.4 ? 30.5 km\n4. 19.35 GHz/500 MHz/H/18.2 ? 30.1 km\n5. 21.3 GHz/200 MHz/V/16.5 ? 27.2 km\n6. 37.0 GHz/2000 MHz/V/9.7 ? 16.0 km\n7. 37.0 GHz/2000 MHz/H/9.7 ? 16.0 km\n8. 85.5 GHz/3000 MHz/V/4.1 ? 6.7 km\n9. 85.5 GHz/3000 MHz/H/4.2 ? 6.9 km\nAntenna type: offset reflector\nAcquisition modes: continuous\n\n\u00b7 Rain:\n\u00b7 Very heavy/oceans (10 GHz)\n\u00b7 Heavy/ocean (19.35 GHz)\n\u00b7 Light rain (37 GHz)\n\u00b7 Very light rain (85.5 GHz)\n\n\u00b7 Water vapor content (21.3 GHz).\n\nWindSat CORIOLIS 06/01/2003epresent \u00b7 Atmosphere\n\u00b7 Ocean\n\nGeometry: conical scan (w50?e53? incidence\nangle, see below)\n\nSpatial resolution: (see below)\n\n\u00b7 Sea surface temperature\n\u00b7 atmospheric water Vapor\n\u00b7 Surface wind speed vector\n\nContinued\n\n\n\nTable 4.4 Nonexhaustive List of Microwave Radiometers and Missions, With Short Description of Their Applications and Main\nPerformancedcont\u2019d\n\nInstrument Mission(s) Launch Date/EOL Date Applications Observation Requirements and Techniques Products Description\n\nSwath size: 1025 km\n\nBands/bandwidths/polarizations/incidence\n\nangle/footprint:\n\n1. 6.8 GHz/125 MHz/V, H/53.5?/40 ? 60 km\n2. 10.7 GHz/300 MHz/V, H, \t45?, LHCP,\n\nRHCP/49.9?/25 ? 38 km\n3. 18.7 GHz/750 MHz/V, H, \t45?, LHCP,\n\nRHCP/55.3?/16 ? 27 km\n4. 23.8 GHz/500 MHz/V, H/53.0?/12 ?\n\n20 km\n\n5. 37 GHz/2000 MHz/V, H, \t45?, LHCP,\nRHCP/53?/8 ? 13 km\n\nAntenna type: offset reflector\nAcquisition modes: continuous\n\n\u00b7 Cloud liquid water\n\u00b7 Rain rate\n\nAMSU-A NOAA-15 13/05/1998epresent\n\n(AMSU-A not nominal)\n\nGeometry: cross-track scan, \t48.3? from nadir\n(30 IFOVs per line)\n\nSpatial resolution: 48 km (nadir)\n\nSwath size: 2250 km\n\nBands/Bandwidths/Polarization:\n\n1. 23800 MHz/270 MHz/V;\n2. 31400 MHz/180 MHz/V;\n3. 50300 MHz/180 MHz/V;\n4. 52800 MHz/400 MHz/V;\n5. 53596 \t 115 MHz/170 MHz/H;\n6. 54400 MHz/400 MHz/H;\n7. 54940 MHz/400 MHz/V;\n8. 55500 MHz/330 MHz/H;\n9. 57290.344 MHz/330 MHz/H;\n\n10. 57290.344 \t 217 MHz/78 MHz/H;\n11. 57290.344 \t 322.2 \t 48 MHz/\n\n36 MHz/H;\n\n12. 57290.344 \t 322.2 \t 22 MHz/\n16 MHz/H;\n\n13. 57290.344 \t 322.2 \t 10 MHz/\n8 MHz/H;\n\n\u00b7 Temperature (0e45 km)\n\u00b7 Water vapor profiles\n\u00b7 Snow and ice\n\u00b7 Cloud liquid water\n\u00b7 Rain rate\n\nNOAA-16 21/09/2000e09/06/2014\n\nNOAA-17 24/06/2002e10/04/2013\n\nNOAA-18 20/05/2005epresent\n\nNOAA-19 06/02/2009epresent\n\nAQUA 04/05/2002epresent\n\n\n\n14. 57290.344 \t 322.2 \t 4.5 MHz/3 MHz/\nH;\n\n15. 89000 MHz/6000 MHz/V\n\nAcquisition modes: V and/or H\npolarizations\n\nAMSU-B NOAA-15 13/05/1998epresent\n\n(AMSU-B off sine 3/2011)\n\u00b7 Atmosphere Geometry: cross-track scan, \t48.95? from nadir\n\n(90 IFOVs per line)\n\nSpatial resolution: 16 km (nadir)\n\nSwath size: 2250 km\n\nBands/bandwidths/polarization:\n\n16. 89.0 GHz/1000 MHz/V;\n17. 150.0 GHz/1000 MHz/V;\n18. 183.31 \t 7.00 GHz/2000 MHz/V;\n19. 183.31 \t 3.00 GHz/1000 MHz/V;\n20. 183.31 \t 1.00 GHz/500 MHz/V;\nAntenna type: offset parabola\n\n\u00b7 Atmospheric moisture sounding\n\nNOAA-16 21/09/2000e09/06/2014\n\nNOAA-17 24/06/2002e10/04/2013\n\nNOAA-18 20/05/2005epresent\n\nMHS NOAA-18 20/05/2005epresent \u00b7 Atmosphere Geometry: cross-track scan, \t49.44? from nadir\n(90 IFOVs per line)\n\nSpatial resolution: 17 km (nadir)\n\nSwath size: 1500 km\n\nBands/bandwidths/polarization:\n\n1. 89.0 GHz/2800 MHz/V;\n2. 157.0 GHz/2800 MHz/V;\n3. 183.311 \t 1.00 GHz/1000 MHz/H;\n4. 183.311 \t 3.00 GHz/2000 MHz/H;\n5. 190.311 GHz/2200 MHz/V\n\nAntenna type: offset parabola\n\n\u00b7 Atmospheric moisture sounding\nNOAA-19 06/02/2009epresent\n\nMetOp-A\n\nMetop-B\n\n19/10/2006epresent\n\n17/09/2012\n\nAMR (advanced\n\nmicrowave radiometer)\n\nJASON-2 20/06/2008epresent \u00b7 Atmosphere Geometry: nadir pointing only\nSpatial resolution: 25 km\n\nSwath size: 25 km\n\nBand: 18.7, 23.8, and 34.0 GHz\n\nAntenna type: parabolic reflector\n\nAcquisition modes: continuous\n\nInternal calibration only: 3 noise diodes\n\n\u00b7 Water vapor content\n\u00b7 Cloud liquid water\n\nAltika SARAL 25/02/2013epresent \u00b7 Atmosphere Geometry: nadir pointing only\nSpatial resolution: 8 km\n\nSwath size: 8 km\n\nBands: 23.8 and 37 GHz\n\n\u00b7 Water vapor content\n\u00b7 Cloud liquid water\n\nContinued\n\n\n\nTable 4.4 Nonexhaustive List of Microwave Radiometers and Missions, With Short Description of Their Applications and Main\nPerformancedcont\u2019d\n\nInstrument Mission(s) Launch Date/EOL Date Applications Observation Requirements and Techniques Products Description\n\nBandwidths: 400 MHz and 1 GHz\n\nAntenna type: parabolic reflector\n\nAcquisition modes: continuous\n\nMADRAS MEGHA-\n\nTROPIQUES\n\n12/10/2011epresent \u00b7 Atmosphere Geometry: conical scan 56?\nSpatial resolution: (see below)\n\nSwath size: 1700 km\n\nBands/bandwidths/polarization/footprint:\n\n1. 18.7 GHz/100 MHz/V, H/40 km;\n2. 23.8 GHz/200 MHz/V/40 km;\n3. 36.5 GHz/500 MHz/V, H/40 km;\n4. 89 GHz/1350 MHz/V, H/10 km;\n5. 157 GHz/1350 MHz/V, H/6 km\n\nAntenna type: offset parabola\nAcquisition modes: continuous\n\n\u00b7 Rain over oceans\n\u00b7 Integrated water vapor\n\u00b7 Liquid water in clouds,\n\u00b7 Convective rain over land and sea\n\u00b7 Cloud top ice\n\nSaphir MEGHA-\n\nTROPIQUES\n\n12/10/2011epresent \u00b7 Atmosphere Geometry: cross-track scan, up to 50? incidence\nangle\n\nSpatial resolution: 10 km (nadir)\n\nSwath size: 1700 km\n\nBands: 183.31 \t 0.2, 183.31 \t 1.1, 183.31 \t\n2.7, 183.31 \t 4.2, 183.31 \t 6.6, 183.31 \t\n11 GHz\n\nAntenna type: offset parabola\n\nBandwidth: 200, 350, 500, 700, 1200, 2000 MHz\n\nPolarization: horizontal\n\nAcquisition modes: continuous\n\n\u00b7 Atmospheric humidity sounder\n\nSMR (submillimeter\n\nradiometer)\n\nOdin 20/02/2001epresent \u00b7 Atmosphere Geometry: limb sounder\nSpatial resolution: 1.5e3 km (vertical from 5 to\n\n100 km) ? 300 km (horizontal)\nBand: 118.25e119.25, 486.1e503.9, and\n\n541.0e580.4 GHz\n\nAntenna type: gregorian reflector\n\nBandwidth: e\n\nAcquisition modes: continuous\n\n\u00b7 Atmospheric studies: Clorine monoxide, nitrous\noxide, nitrogen dioxide, hydrogen peroxide,\n\nnitrous oxide, nitric acid, etc.\n\nSMAP-radiometer SMAP 31/01/2015epresent \u00b7 Land \u00b7 Soil moisture\n\n\n\nGeometry: conical scan 40?\n\nSpatial resolution: 40 km\n\nSwath size: w1000 km\n\nBands: 1.4 GHz\n\nBandwidths: 22 MHz\n\nPolarization: Th, Tv, T3, and T4 (full\n\npolarimetric)\n\nAntenna type: offset parabola\n\nAcquisition modes: continuous\n\nMLS EOS-AURA 15/07/2004epresent \u00b7 Atmosphere Geometry: limb sounder\nSpatial resolution: 1.5 km (vertical from 5 to 120\n\nkm) ? 300 km (horizontal)\nBands: 5 bands/36 subbands: 118 GHz\n\n(9 subbands), 190 GHz (6 subbands), 240 GHz\n\n(7 subband), 640 GHz (9 subbands) and 2.5 THz\n\n(5 subbands).\n\nBandwidths: e\n\nPolarization: e\n\nAntenna type: scanning offset antenna (?640\nGHz) and telescope and scan mirror (2.25 THz)\n\nAcquisition modes: continuous\n\nTemperature and pressure profiles (118 GHz)\n\n\u00b7 Water vapor and nitric profiles (190 GHz)\n\u00b7 Ozone and CO concentrations (240 GHz)\n\u00b7 Nitrous acid, HCl, CIO, BrO, and sulfur dioxide\n\n(640 GHz)\n\n\u00b7 OH concentration (2.25 THz)\n\nInformation compiled from https://www.wmo-sat.info/oscar/satellites, August 2016.\n\nhttps://www.wmo-sat.info/oscar/satellites\n\n\nTable 4.5 Historical Evolution of Microwave Radiometers\n\nYear Platform/Instrument\n1.4\nGHz\n\n6\nGHz\n\n10\nGHz\n\n18\nGHz\n\n21\nGHz\n\n37\nGHz\n\n50e60\nGHz\n\n90\nGHz\n\n160\nGHz\n\n183\nGHz\n\nSpatial\nResolution\n(km)\n\n1962 Mariner X X 1.300\n\n1968 Cosmos 243 X X 37\n\n1970 Cosmos 384 X X 13\n\n1972 Nimbus-5 ESMR X 25\n\nNEMS X X X(3) 180\n\n1973 Skylab S-193 X 16\n\nS-194 X 115\n\n1974 Meteor X\n\n1975 Nimbus-6 ESMR X 20 ? 43\nSCAMS X X X(3) 150\n\n1978 DMSP SSM/T X(7) 175\n\n1978 Tiros-N MSU X(4) 110\n\n1978 Nimbus-7 SMMR X X X X X 18 ? 27\nSeasat SMMR X X X X X 22 ? 35\n\n1982 DMSP SSM/I X X X X 16 ? 14\n1986 NOAA AMSU-\n\nA\nX X X(12) X 50\n\nAMSU-\nB\n\nX X X(3) 15\n\n1992 DMSP SSM/T-2 X X X 50\n\n2002 Aqua\n\nAMSR-E X X X X X X\n\nAMSU-A X X X(24) X\n\nHSB X(1) X(3)\n\n2002 Envisat MWR X X\n\n2003 Coriolis X X X X X\n\n2009 SMOS X 30e100\n\n2010 Aquarius X w70\n\n2014 SMAP X 10\n\nSMMR, scanning multichannel microwave radiometer.\n\n\n\nmeasurement is a sample of the visibility function (V) measured at a spatial frequency\n(umn,vmn,wmn) \u00bc (xn ? xm,yn ? ym,zn ? zm)/l0 (Fig. 4.68A), being l0 \u00bc c/f0 the wavelength at the\ncentral frequency of operation ( f0) and can be derived from the Van CitterteZernike theorem\n(Goodman, 1968, 1985):\n\nVpqmnaV\npq umn; vmn;wmn\u00f0 \u00deb 1\n\nkB\nffiffiffiffiffiffiffiffiffiffiffi\nBmBn\n\np ffiffiffiffiffiffiffiffiffiffiffiffi\nGmGn\n\np $1\n2\n\n?\nbpm t\u00f0 \u00debq?n t\u00f0 \u00de\n\n?\n\u00bc 1ffiffiffiffiffiffiffiffiffiffiffiffi\n\nUmUn\np\n\nZZ\nx2\u00feh2?1\n\nTpq x; h\u00f0 \u00de ? Tph$dmnffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\np Fm x; h\u00f0 \u00deF?n x; h\u00f0 \u00de\n\n$rmn ?\numnx\u00fe vmnh\u00fe wmn\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\nq\nf0\n\n0@ 1A\n$exp ?j2p umnx\u00fe vmnh\u00fe wmn\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\nq\n ?\n ?\ndxdh;\n\n(4.70)\n\nwhere bp;qm;n\u00f0t\u00de are the analytic signals collected by the antennas m and n, at p- and q-polarizations,\nrespectively, (x,h) \u00bc (sinqcosf,sinqsinf) are the director cosines with respect to the X- and Y-axes\nrespectively, Bm,n and Gm,n are the noise bandwidth and the power gain of the receiving chains\n(Fig. 4.68B), Um,n and Fm,n(x,h) are the equivalent solid angle and the normalized radiation voltage\npatterns of antennas m and n, and T pq(x,h) (Kelvin) are defined in Eq. (4.19) and are proportional to\n\nTpq\u00f0x; h\u00def\nD\nEant;pm \u00f0x; h\u00deEant;q?n \u00f0x; h\u00de\n\nE\n, where Eant p;qm;n are the electric fields collected by antennasm and\n\nn at p- and q-polarizations, that are related to the electric fields at a given pixel (x,h) by geometrical\nrelationships and the co- and cross-polar antenna patterns as defined by Ludwig\u2019s third definition\n(Ludwig, 1973; Claassen and Fung, 1974; Martin-Neira, 2001). The term Tph $ dmn accounts for the\nthermal noise emitted by one receiver as coupled to the other ones (Corbella et al., 2004). This term\nappears in Eq. (4.70) if ms n.\n\nz\n\nbn\n\nX\n\n(A) (B)\n\nComplex\nCorrelator\n\nTA\n\nTA\n\nFm Gm\nbmHnm (f)\n\n(?, ?)\n\n\u00bd<bm b*n>\n\nGnFn\n\nHnn (f)\n\n(?, ?)\nObservation\n\npointsx\n\nY\ny\n\nz\n\nx\n\nm\nn\n\nrn\n\nrm\n\nr\n?\n\n\u00f8\n\nSource plane\n\ndS\n\nFIGURE 4.68\n\n(A) Two antennas of a correlation radiometer. (B) Diagram of a correlation radiometer: two receiving chains\n\nand a complex correlator (Camps and Swift, 2002).\n\n4.6 SENSORS 209\n\nmailto:Image of Figure 4.68|eps\n\n\nThe function ermn\u00f0t\u00de is the so-called fringe-washing function that accounts for spatial decorrelation\neffects\n\n?\nt \u00bc ?\n\n?\numnx\u00fe vmnh\u00fe wmn\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\np ?.\nf0\n\n?\nand depends on the normalized frequency\n\nresponse Hnm;n\u00f0f \u00de of each channel (Thompson et al., 1986; Camps, 1996; Camps et al., 1999), and may\ninclude several amplifiers, filters, and frequency conversions:\n\nermn\u00f0t\u00de \u00bc e?j2pf0tffiffiffiffiffiffiffiffiffiffiffi\nBmBn\n\np\nZ N\n0\n\nHnm\u00f0 f \u00deH?nn\u00f0 f \u00deej2pftdf ; Bm;n \u00bc\nZ N\n0\n\n??Hnm;n\u00f0 f \u00de??2df . (4.71)\nIn an ideal system ermn\u00f0s\u00de \u00bc 1, Hnm\u00f0 f \u00de \u00bc Hnn\u00f0 f \u00de and Fm(x,h) \u00bc Fn(x,h), Eq. (4.70) reduces\n\nto a continuous Fourier transform between the so-called modified brightness temperature\n\n\u00f0Tpq\u00f0x; h\u00de? Tph $ dmn\u00de $ jF\u00f0x; h\u00dej2\n.?\n\nU $\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\np ?\nand Vpq(u,v).\n\nAt this stage, the following particular cases can be considered:\n\n\u2022 Total power radiometer (TPR): If both antennas have the same polarization (p) and are located\nin the same physical position (umn,vmn,wmn) \u00bc (0,0,0) (single-polarization antenna), then the\nvisibility sample Vpp(0,0,0) is equal to the antenna temperature at p-polarization.\n\n\u2022 Polarimetric radiometer: If both antennas have two orthogonal linear polarizations p- and q-\nand are located in the same physical position (umn,vmn,wmn) \u00bc (0,0,0) (dual-polarization antenna),\nthen the visibility sample Vpq(0,0,0) \u00bc 1/2(T3 \u00fe j $ T4) provides a measurement of the third and\nfourth Stokes parameters.\n\n\u2022 Synthetic aperture radiometer7: If both antennas have the same polarization, but are located at\ndifferent positions then the visibility sample Vpp(umn,vmn,wmn) is equal to a sample of a Fourier\ntransform8 of the radiation intensity of the source at a spatial frequency (umn,vmn,wmn), which is\nthe result known as the Van CitterteZernike theorem (Goodman, 1985). The first Stokes\nparameter I \u00bc Tv \u00fe Th can be recovered everywhere in the FOV.\n\n\u2022 Polarimetric synthetic aperture radiometer: If both antennas have orthogonal linear\npolarizations, but are located at different positions, and the visibility sample Vmn(umn,vmn,wmn) is\nmeasured in any polarization combination, the full Stokes vector can be recovered for any pixel in\nthe FOV.\n\n4.6.2.1 Spatial Resolution\n4.6.2.1.1 Real Aperture Radiometers\nImaging with real aperture radiometers (polarimetric or not) is achieved by scanning the antenna beam\nalong the different \u201cpixels\u201d of the image. The radiometer\u2019s output provides the measurement at the\nparticular pixel being pointed by the antenna beam. Along the scan direction, the radiometer\u2019s output\nmust be sampled at least at the Nyquist rate that is twice per pixel size (antenna footprint), which will\nultimately limit the maximum integration time and the achievable radiometric precision.\n\n7This name has been subject to some polemics among some authors because it may be misleading in the sense that the syn-\nthetic aperture may be formed as in a synthetic aperture radar. However, since the term is widely used in the radio-astronomy\nand in the microwave radiometry communities, it is kept in this book.\n8Usually the antennas are either aligned along the X-axis or on the XY plane, and therefore (umn,vmn,wmn) \u00bc (umn,0,0) (e.g.,\nLe Vine et al. (1992) or (umn,vmn,wmn) \u00bc (umn,vmn,0) by design (e.g., Kerr et al., 2010; Font et al., 2010). Therefore, the rela-\ntionship becomes either a one- or two-dimensional Fourier transform.\n\n210 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nThe scanning techniques most widely used in microwave radiometry are (Fig. 4.69) as follows:\n\n1. nadir-looking: the antenna beam is fixed and points to the nadir direction. This configuration is\ntypically used in the radiometers that sense the atmospheric water vapor for radar altimeters.\n\n2. limb sounders: the antenna beam is fixed and points to the Earth\u2019s limb. This configuration is used\nin atmospheric limb sounders for gas concentration tracing.\n\n3. cross-track scan: a zig-zag movement with varying incidence angle and pixel size, typically used\nin atmospheric sounders.\n\n4. conical scan of the antenna beam with a constant incidence angledtypically between 50? and\n55?, where the vertical polarization emissivity exhibits a minimum dependence with surface\u2019s\nroughnessdand constant pixel size. This configuration is typically used in Earth imagers since it\neliminates the angular dependence of the emissivity.\n\n5. push-broom antenna: the antenna has several contiguous fixed, or fast switching, beams and the\nimage is formed as the beams \u201csweep\u201d the scene by the movement of the platform.\n\nFrom all of them, the most widely used in imagers is the radiometer with a conical scan, a\nconfiguration successfully used in the SSM/I series and the cross-track in atmospheric sounders.\n\nThe antenna footprint determines the spatial resolution (pixel size), which is given by the antenna\nhalf-power beam width (Dq?3 dB), the distance from the radiometer to the target (r), and the incidence\nangle (qi), defined in Fig. 4.69:\n\nDx \u00bc r $Dq?3 dB; (4.72a)\n\nDy \u00bc r $Dq?3 dB\ncos qi\n\n. (4.72b)\n\nThe antenna half-power beam width is usually approximated by Dq?3 dB z l0/\u00d8, where l0bc\n?\nf0\n\nis the electromagnetic wavelength, and \u00d8 is the maximum antenna size. We illustrate the antenna\nfootprint from a low Earth orbit (LEO) and from a geostationary Earth orbit satellites at 400 and\n35.760 km height in Fig. 4.70. This figure explains why microwave radiometers have a quite poor\nspatial resolution as compared to other sensors, even at very high frequencies.\n\nThe ideal antenna pattern of a microwave radiometer should have a conical shape with constant gain\nover the antenna beamwidth, and zero elsewhere. However, actual antenna patterns exhibit a main beam,\nwhose width is usually defined at half-power with respect to the peak directivity, and side lobes that\ncollect radiation from directions outside the main beam. The amplitude of the side lobes can be reduced\nby design of the distribution of the amplitude of the electric field over the antenna aperture (\u201caperture\nillumination\u201d), so it is tapered so that it gradually decreases towards the edge of the aperture. The price to\npay is a larger main beam, with the corresponding loss of spatial resolution (Eq. 4.72).\n\nInstead of the relative amplitude of the side lobes, in microwave radiometry the figure of merit used\nis the so-called \u201cmain beam efficiency\u201d (hML), defined as the fraction of the total power collected by\nthe main beam (defined up to a given angle from the antenna boresight) with respect to the total power\ncollected from all directions:\n\nhML \u00bc\n1\n\nUA\n$\n\nZZ\nMain beam\n\nt\u00f0q;4\u00dedU; (4.73)\n\n4.6 SENSORS 211\n\n\n\nFIGURE 4.69\n\nTypical microwave radiometer scanning configurations: (A) nadir looking, (B) limb sounders, (C) cross-track\n\nscanner, (D) conical scanner, and (E) push-broom.\n\n212 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.69|tif\n\n\nwhere UA is the so-called antenna solid angle:\n\nUA \u00bc\nZZ\n4p\n\nt\u00f0q;4\u00dedU; (4.74)\n\nand t(q,4) is the antenna radiation power pattern.\nThe evolution of the antenna main beam efficiency is a function of the off-boresight angle for\n\ndifferent antenna aperture illuminations (Fig. 4.71). As it can be appreciated, the uniform illuminations\nachieve the highest main beam efficiencies if the beam is defined close to the boresight, since the\nuniform illumination lead to the narrowest beams. However, since it exhibits the highest side lobes\n(side lobe level: SLL \u00bc ?13.2 dB), the main beam efficiency stops increasing quickly. On the other\nhand, highly tapered illuminations (smooth transition from the amplitude of the electric field in the\ncenter of the aperture toward the edge) provide very low side lobes, and ultimately achieve the highest\nmain beam efficiencies. Typical well-behaved microwave radiometer antennas exhibit a main beam\nefficiency on the order of hML z 0.96 or even higher.\n\nThe resulting antenna temperature image can then be deconvolved to remove errors from radiation\npicked through the secondary lobes and by antenna finite cross-polarization or to improve the spatial\nresolution.\n\n4.6.2.1.2 Synthetic Aperture Radiometers\nIn synthetic aperture radiometers, the brightness temperature images are obtained from the visibility\nfunction (Eq. 4.70) using Fourier synthesis techniques, and in the ideal case, when antenna patterns are\n\nFIGURE 4.70\n\nAntenna footprint at nadir from a low Earth orbit (LEO) and from a geostationary Earth orbit (GEO) satellites as\n\na function of frequency for three different antenna sizes.\n\n4.6 SENSORS 213\n\nmailto:Image of Figure 4.70|tif\n\n\nidentical, and spatial decorrelation is negligible, the relationship between the modified brightness\n\ntemperature\n\n\nT\n^pq\u00f0x; h\u00de\n\n?\nand the visibility samples is a Fourier transform:\n\nVpq \u00bc F\n?\nT\n^pq\u00f0x; h\u00de\n\n?\n\u00bc F\n\n8<:\u00f0Tpq\u00f0x;h\u00de ? Tph\u00de $ jF\u00f0x; h\u00dej2U ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi1? x2 ? h2p\n9=;: (4.75)\n\n10\n\n20\n\n30\n\n40\n\n50\n\nB\nE\n\nA\nM\n\n E\nFF\n\nIC\nIE\n\nN\nC\n\nY,\n P\n\nE\nR\n\nC\nE\n\nN\nT\n\n60\n\n70\n\n80\n\n90\n\n100\n\nCIRCULAR APERTURE\n\n95%\n\n90%\n\nRECTANGULAR APERTURE\n\nUNIFORM R. A. \u201313.2\n\nUNIFORM C. A. \u201317.6\n\n[1 \u2013 (P/a)2] C. A. \u201324.6\n\n[1 \u2013 (P/a)2]2 C. A. \u201330.6\n\ncos2  ? x/a R. A. \u201331.5\n\n1 ST SIDELOBE\nLEVEL, dB\n\n0 1 2 3 4 5 6 7 8 9\nU (U = Ka sin   )?\n\nFIGURE 4.71\n\nMain beam efficiency as a function of the antenna aperture illumination and the off-boresight angle\n\nparametrized in terms of U \u00bc K0 $ sinq. R.A. stands for rectangular aperture, and C.A. stands for circular\naperture.\n\nAdapted from Johnson, R.C., Jasik, H., 1993. Antenna Engineering Handbook. McGraw-Hill Professional.\n\n214 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.71|eps\n\n\nFIGURE 4.72\n\nMicrowave imaging radiometer by aperture synthesis (A) Y-shaped array topology and (B) associated (u,v)\n\ncoverage.\n\nHowever, the visibility function can only be sampled at some spatial frequencies (umn,vmn) determined\nby the antenna positions (assumed from now on that lie on the XY plane). That is, the reconstructed\nbrightness temperature image will suffer from the artifacts associated with discrete Fourier transforms\n(aliasing and ringingdor Gibbs phenomenondat brightness temperature steps). Therefore, applying a\nwindow W(umn,vmn) to the visibility samples V(umn,vmn) prior to the image reconstruction will reduce\nthe side lobes and will improve the main beam efficiency, at the expense of a widening of the synthetic\nbeam, in a very similar way as the tapering of the antenna aperture impacts the antenna beam in a real\naperture radiometer.\n\nActually, the behavior of a synthetic aperture radiometer can be interpreted as a phased array with\nan antenna element located at each (u,v) point, although the final response is not squared, since\nthe brightness temperature is already a measure of the received power. Consequently, the impulse\nresponse of a synthetic aperture is named the \u201cequivalent array factor,\u201d which can be computed\nanalytically as:\n\nAFeq\u00f0x; x0; h; h0\u00de \u00bc DS\nX\nm;n\n\nW\u00f0umn; vmn\u00de $ er\n? umn $ x\u00fe vmn $ h\nf0\n\n?\n$ e j2p\u00bdumn $ \u00f0x? x0\u00de \u00fe vmn $ \u00f0h? h0\u00de?;\n\n(4.76)\n\nwhere DS is the area of the (umn,vmn) cells (Fig. 4.72B) that tessellate the (u,v) plane. As previously\ndiscussed, depending on the array configuration, synthetic aperture radiometers can be either one- or\ntwo-dimensional imagers:\n\n\u2022 The Electronically Steered Thinned Array Radiometer (ESTAR) was initially proposed by Le\nVine et al. in the early 1980s (LeVine and Good, 1983) and validated by an airborne system\ndeveloped by the University of Massachusetts at Amherst (LeVine et al., 1992). It achieves\nspatial resolution in the along-track direction by the narrow beam of the stick antennas, and in\nthe cross-track direction by aperture synthesis. Aliasing is avoided by setting the antenna\n\n4.6 SENSORS 215\n\nmailto:Image of Figure 4.72|tif\n\n\nspacing to half the electromagnetic wavelength (l0/2). The maximum achievable angular\nresolution in the case that a rectangular window is used is:\n\nDq?3 dBz\nl0\n\n2L\n; (4.77)\n\nbeing L the maximum array length. It is worth noting thatdas compared to real aperture radiometersd\nsince Vpqmn \u00bc Vpq?nm , the maximum spatial frequency coverage is twice the maximum array length, then the\nangular resolution is halved.\n\u2022 The microwave imaging radiometer by aperture synthesis (MIRAS) aboard the ESA SMOS\n\nEarth Explorer Opportunity Mission achieves two-dimensional spatial resolution by sampling\nthe visibility function in two dimensions with a Y-shaped array (Fig. 4.72A). To avoid aliasing the\nantenna elements spacing must be d \u00bc 1? ffiffiffi3p wavelengths (Camps, 1996). However, since in\nSMOS d \u00bc 0:875? 1? ffiffiffi3p wavelengths, the Nyquist criterion is not satisfied and there is aliasing,\nwhich is the limiting factor of the instrument\u2019s FOV, in a similar way the diffraction lobes (grating\nlobes) limit the maximum angular scan of a real aperture antenna array. The angular resolution of\nthe instrument is determined by the maximum spacing of the (u,v) spatial frequency points\n(Fig. 4.72B):\n\nDumax \u00bc 2$\nffiffiffi\n3\n\np\n$NEL $ d; (4.78)\n\nbeing NEL the number of antenna elements in each arm of the Y-array, spaced d wavelengths. For large\narrays, since x \u00bc sinq z q for small q, if the visibility samples are not tapered (i.e., rectangular\nwindow is used), the angular resolution is given by:\n\nDq?3 dBzDx?3 dBz\np\n\n2 $Dumax\n. (4.79)\n\nFIGURE 4.73\n\nMicrowave imaging radiometer by aperture synthesis normalized equivalent array factor or \u201cimpulse\n\nresponse\u201d to a point target at nadir for (A) rectangular and (B) Blackman windowing.\n\n216 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.73|tif\n\n\nOut of boresight (x0,h0), due to the spatial decorrelation of the received electric field being cross-\ncorrelated (Bara? et al., 1998), the angular resolution is slightly degraded in the radial direction by a\nfactor 1 \u00fe Dr, where Dr is defined as:\n\nDr \u00bc B\nf0\n\n$\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nx20 \u00fe h20\n\nq\n. (4.80)\n\nSimilarly to a real aperture radiometer, if, for example, a Blackman window with rotational\nsymmetry and a null at the furthermost visibility samples is used to taper the visibility samples, the\namplitude of the side lobes is decreased, the main beam efficiency is increased from 0.43 to 0.90, and\nthe main beam is widened by a factor w1.48, as shown in the equivalent array factors of Fig. 4.73.\n\nTo illustrate the imaging principle of a Y-shaped two-dimensional synthetic aperture radiometer as\nMIRAS in SMOS, we use Fig. 4.74. Each pixel is seen up to 78 times since it enters in the alias-free\nFOV (determined by the array topology and the antenna spacing) until it leaves it, under a wide range\nof incidence angles. This multi-look capability can be used to infer simultaneously several geophysical\nparameters even with a single frequency instrument (see Fig. 4.27).\n\n4.6.2.2 Radiometric Resolution\nIn this section the radiometric resolution is assessed for ideal total power, and aperture synthesis\nradiometers, i.e., gain fluctuations are negligible. The radiometric precision is defined as the standard\ndeviation of the random error due to the thermal noise. Assuming identical receivers with a rectangular\n\nFIGURE 4.74\n\nScanning configuration of a Y-shaped two-dimensional synthetic aperture radiometer such as microwave\n\nimaging radiometer by aperture synthesis.\n\n4.6 SENSORS 217\n\nmailto:Image of Figure 4.74|tif\n\n\nfrequency response, the standard deviation of the output of a correlation radiometer (Eq. 4.81) is given\nby (Thompson et al., 1986; Camps, 1996; Ruf et al., 1988; Camps et al., 1998a,b):\n\ns2Vr;i \u00bc\n1\n\n2 $B $ seff\n\n?\nT2sys $\n\n\n\n1\u00feL\n\n\n2Df\n\nB\n\n??\n\u00fe V2r;i $\n\n\n\n1\u00feL\n\n\n2Df\n\nB\n\n??\n? V2i;r $\n\n\n\n1?L\n\n\n2Df\n\nB\n\n???\n;\n\n(4.81)\n\nwhere Tsys \u00bc TA \u00fe TR is the system\u2019s temperature, TA is the antenna temperature, TR is the receiver\u2019s\nnoise temperature. The effective integration time seff \u00bc s/Q depends on the integration time s and the\ncorrelator type: Q \u00bc 1 for analog or multibit correlators, Q \u00bc 1.29 for two-bit by two-bit correlators,\nQ \u00bc 2.46 for 1 bit/2 level digital correlators, etc. when samples taken at Nyquist rate (Hagen and\nFarley, 1973. Other parameters are Df \u00bc f0 ? fLO, where f0 is the center frequency and fLO is the local\noscillator frequency, f0 and L(x) \u00bc 1 ? jxj for jxj ? 1 and zero elsewhere.\n\n4.6.2.2.1 Real Aperture Radiometers\nIn the case of a single side-band receiverDf ? B/2, the standard deviation in each correlation reduces to:\n\nsV \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\ns2Vr \u00fe s2Vi\n\nq\n\u00bc Tsysffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\nB $ seff\np ; (4.82)\n\nwhich is the equation of the radiometric precision of an ideal TPR (Ulaby et al., 1981). The radio-\nmetric precision of other types of real aperture radiometers will be studied in more detail in the\nfollowing sections.\n\nSince the third and fourth Stokes parameters can be computed as T3 \u00bc 2 $<\n?\nVpqmn\n\n?\nand\n\nT4 \u00bc 2 $J\n?\nVpqmn\n\n?\n(Eq. 4.19) and Tsys[\n\n??Vpqmn??, the radiometric precision of a real aperture\npolarimetric radiometer is\n\nffiffiffi\n2\n\np\n$ sVr;i:\n\nsT3;4 \u00bc\nffiffiffi\n2\n\np\n$ Tsysffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\nB $ seff\np . (4.83)\n\nActually, this is the same value as if the third and fourth Stokes parameters were computed as\nT3 \u00bc T\u00fe45? ? T?45?, and T4 \u00bc TLHCP ? TRHCP, being T\t45? and TLHCP, RHCP are the brightness tem-\nperatures at \t45?, and left/right hand circular polarizations.\n\n4.6.2.2.2 Synthetic Aperture Radiometers\nFor an aperture synthesis interferometric radiometer, the radiometric precision is degraded because\nthe aperture being synthesized is much larger than the actual collecting area. Alternatively, it can be\nunderstood as the consequence of the combination of the errors in all visibility samples when\ncombined through the same Fourier synthesis process to form an image pixel. The radiometric\nprecision of the modified brightness temperature (Eq. 4.75) can be expressed as (Camps et al., 1998a):\n\nDT\n^ \u00bc UA $\n\nffiffiffi\n3\n\np\n$ d2\n\n2\n$\n\nTsysffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nB $ seff\n\np $ ffiffiffiffiffiffiNVp $aW $aLO\naF\n\n; (4.84)\n\nwhere NV is the total number of different (u,v) points, aW is a parameter that depends on the window\nused to taper the visibility samples and ranges between 0.45 and 1 (nonredundant case), aLO is a\n\nparameter that depends on the type of demodulation used aDSBLO \u00bc\nffiffiffi\n2\n\np \u00f0Df \u00bc 0\u00de, aSSBLO \u00bc 1\u00f0Df ? B=2\u00de,\n\n218 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nand 1 ? aF ?\nffiffiffi\n24\n\np\nis a parameter that depends on filters\u2019 shape (from rectangular to Gaussian), and the\n\ncorrelation between errors (Bara et al., 2000) has been neglected. The radiometric precision of the\nbrightness temperature degrades off-boresight with the obliquity factor and the inverse of the antenna\n\nradiation power pattern:\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\np .\njF\u00f0x; h\u00dej2.\n\n4.6.2.3 Trade-off Between Spatial Resolution and Radiometric Precision\nA last comment regarding the basic performance of microwave radiometers is the relationship between\nthe achievable spatial resolution and the radiometric precision, which cannot be improved arbitrarily.\nFor the sake of simplicity, in this text the derivation will be performed for a cross-track scanner with\nzero return time (e.g., an electronically steered array) and an ideal TPR, but similar developments can\nbe applied for any other imaging configurations.\n\nLet us assume that the platform\u2019s height is h, the ground speed is v, that the angular extent of the\nwhole swath as seen from the sensor is the FOV, and the sensor\u2019s angular resolution is Dq. In this case,\nthe total number of pixels in the swath is:\n\nn \u00bc FOV\nDq\n\n. (4.85)\n\nSince the minimum spatial resolution is Dx \u00bc h $ Dq, the maximum time in which the whole swath\nmust be scanned is:\n\nTswath \u00bc Dx\nv\n; (4.86)\n\nand the maximum integration time per pixel is:\n\ns \u00bc Tswath\nn\n\n\u00bc h\nv\n$\nDq2\n\nFOV\n; (4.87)\n\nwhich ultimately limits the radiometric precision:\n\nDT \u00bc Tsysffiffiffiffiffiffiffiffiffi\nB $ s\n\np \u00bc Tsysffiffiffi\nB\n\np $\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nv $ FOV\n\nh\n\nr\n$\n1\n\nDq\n. (4.88)\n\nThat is, the better the angular resolution (Dq), the worse the radiometric precision (DT),\nand the product Dx $ DT turns out to be a constant that depends only on platform and instrument\nparameters:\n\nDx $DT \u00bc Tsysffiffiffi\nB\n\np $\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nh $ v $ FOV\n\np\n. (4.89)\n\nEq. (4.89) is known as the uncertainty principle of a microwave radiometer and determines the best\nachievable performance. Since Tsys ? TA (the equality holds for an ideal noise-free receiver), and B is\nlimited by the allocations of the radio-electric spectrum (see Section 4.6.1), and for a spaceborne\ninstrument v(h), to improve Dx and DT simultaneously, the only design parameter that remains free is\nthe FOV, which determines the swath width. However, it should be noted that reducing the swath width\ntranslates into an increase of the revisit time, which could only be kept constant if more platforms and\nsensors are deployed, that is, a constellation of microwave radiometers is formed.\n\n4.6 SENSORS 219\n\n\n\nFor a conical scanner, a similar development can be performed, since halving the angular resolution,\ntranslates into twice as many pixels in one antenna rotation, which has to rotate twice as fast to avoid\ngaps on the ground between consecutive rotations. The integration time being reduced by a factor of four,\ntranslates into an increase of the radiometric precision by a factor of two.\n\nSimilar developments can be derived for synthetic aperture radiometers as well, although in this\ncase, the angular resolution can be modified during the processing by just adapting the window used to\nweight the visibility samples (Camps, 1996; Camps et al., 1998a,b):\n\nDx?3 dB $DT zUA $\nTsysffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nB $ seff\n\np $aLO\naF\n\n$ d. (4.90)\n\nSo far, a unified perspective of the operation and basic instrument performance of all radiometer\ntypes has been provided. In the following sections, a more detailed explanation of the particulars of\neach radiometer type will be provided.\n\n4.6.3 REAL APERTURE RADIOMETERS\nIn this section more advanced concepts of the sensor technology and calibration strategies are dis-\ncussed, and it can be skipped by those readers not interested in the technological aspects.\n\n4.6.3.1 Instrument Considerations\n4.6.3.1.1 Antenna Considerations\nIn Section 4.6.2.2.1, antenna considerations related to the spatial resolution and scanning configuration\nwere addressed. In this section, other aspects influencing the specification/design of the antenna (or the\nimpact of a given antenna in the measurements) are described.\n\n\u2022 Antenna losses (LA) either generated by the finite conductivity of the metals forming them or by\nthe connectors or transitions used to connect its output attenuate the noise power collected from\nthe surroundings and introduce additional noise. This effect was studied in detail in Section 4.3.1\nwhen analyzing the effect of atmospheric losses.\n\nT\n0\nA \u00bc hU $ TA \u00fe \u00f01? hU\u00de $ Tph; A; (4.91)\n\nwhere hU \u00bc 1/LA is the so-called antenna ohmic efficiency and equals one when the antenna is lossless\n(LA \u00bc 1) and equals zero when losses are infinite.\n\nFor example, if LA \u00bc 0.5 dB, then hU \u00bc 0.90, that is, 90% of the received radiation is passed to the\nreceiver and 10% is added by the antenna. This is a very important effect since a 1?C variation of the\nphysical temperature of the antenna will translate into a 0.1K drift of the radiometer\u2019s output. The only\nway to keep these variations under control is by proper thermal stabilization of the antenna itself, if\nfeasible, or the parts of the antenna in which losses are generated, that is, in regions where the\namplitude of the electric field is higher, in the connectors or cables connecting the antenna output and\nthe receiver front-end. Fig. 4.75 shows the impact of the antenna losses in the radiometer\u2019s output as a\nfunction of the difference between the antenna temperature and the physical temperature of the an-\ntenna. As a consequence, errors are larger when this difference is larger, which usually happens when\nthe radiometer is performing a cold sky calibration.\n\n220 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\n\u2022 Polarization mixing occurs when the XYantenna reference frame is not properly aligned with the\nHV Earth\u2019s reference frame. This effect was also studied in Section 4.3.2.1 when analyzing the\nimpact of the Faraday rotation. The solution consists of the inversion of Eq. (4.42), which is\nalways feasible provided the rotation angle is different 45?. Otherwise, the matrix becomes\nsingular in which case only Eq. (4.41) can be used.\n\n\u2022 Finite antenna cross-polarization refers to the capability of the antenna to separate to incoming\northogonal polarizations. This effect will be analyzed in more detail in the next bullets.\n\n\u2022 Finite antenna pattern beam width effects refer to the mix of the Stokes elements as measured by\nthe sensor due to the spatial averaging over the antenna beam of the different contributions to the\nStokes elements each with a different rotation angle (polarization mixing) and cross-polarization\nvalue. The measured Stokes vector [Tv, Th, T3, T4]\n\nmeas is then a linear combination of the nominal\none [Tv, Th, T3, T4]\n\nnominal averaged over the antenna beam. The electric fields measured by the\nantenna in the XY antenna reference frame can be related to the h and v electric fields by:\" bExbEy\n\n#\n\u00bc\n\n\n\nRx cos a? Cx sin a Rx sin a\u00fe Cx cos a\n?Cy cos a? Ry sin a ?Cy sin a\u00fe Ry cos a\n\n?\n\nEh\n\nEv\n\n?\n; (4.92)\n\nwhere Rx,y and Cx,y are the co- and cross-polar antenna patterns at X- and Y-polarizations.\n\nAnd the Stokes elements can then be computed as:\n\nbTxx \u00bc 1\nUA\n\nZZ\n4p\n\nn\njRxj2Txx \u00fe 2Re\n\n?\nRxC\n\n?\nx\n\n?\nTyx \u00fe jCxj2Tyy\n\no\ndU; (4.93a)\n\nbTyx \u00bc 1\nUA\n\nZZ\n4p\n\n?? CyR?xTxx \u00fe ?RyR?x ? CyC?x?Tyx \u00fe RyC?xTyy?dU; (4.93b)\n\nFIGURE 4.75\n\nImpact of antenna losses in the radiometer\u2019s output as a function of the difference between the antenna\n\ntemperature and the physical temperature.\n\n4.6 SENSORS 221\n\nmailto:Image of Figure 4.75|tif\n\n\nbT yy \u00bc 1\nUA\n\nZZ\n4p\n\nn\njCyj2Txx \u00fe 2Re\n\nn\nRyC\n\n?\ny\n\no\nTyx \u00fe jRyj2Tyy\n\no\ndU; (4.93c)\n\nThis effect for an antenna array of 4?4, 6?6, and 8?8 microstrip patches with triangular illu-\nmination, and a 20?, 15?, and 10? beam width, assuming the ocean surface at 1.4 GHz is illustrated in\nFig. 4.76. At nadir, the bias between the brightness temperature at boresight and the antenna tem-\nperature computed from Eq. (4.93) is the same at both polarizations, but, as expected, decreases with\ndecreasing antenna beam. As the incidence angle increases, the bias remains quite constant at hori-\nzontal polarization, but quickly increases at vertical polarization, being approximately zero for all\nbeam widths around 50?. However, despite this bias, the sensitivities of the vertical and horizontal\nantenna temperatures versus salinity, SSS, temperature, and wind speed remained nearly constant.\n\nAs an example, the above considerations led to the final antenna design of the L-band AUtomatic\nRAdiometer (LAURA) developed by UPC in 2000, a 4?4 patch dual-polarization array to be used in a\nnumber of field experiments over the ocean and over land in preparation for the ESA SMOS mission.\nThe antenna array consisted of an array of 4?4 microstrip patches with dielectric air to minimize\nlosses (LA \u00bc 0.4 dB, hU \u00bc 0.91) and was all thermally stabilized to have constant added thermal noise.\nExtreme care was taken during the design and manufacturing to optimize the antenna cross-polar\npattern. The measured co-polar and cross-polar antenna patterns and the main antenna parameters\nare displayed in Fig. 4.77A and B.\n\n4.6.3.1.2 Receiver Considerations\nThe basic topology of a microwave radiometer is that of a superheterodyne receiver, such as those used\nin communications. Since the input signal is very weak (the thermal noise):\n\nN \u00bc kB $ Tsys $B; (4.94)\n\n0 10 20 30 40 50 60\n-2\n\n-1.5\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nIncidence Angle [deg]\n\n[K\nel\n\nvi\nn\n\n]\n\nFIGURE 4.76\n\nImpact of antenna array beam width: 20? (circles), 15? (diamonds), and 10? (squares) at horizontal (blue)\nand vertical (red) polarizations, for a radiometer observing the sea surface at 1.4 GHz, with SST \u00bc 15?C,\nSSS \u00bc 36 psu, U10 \u00bc 0 m/s.\n\n222 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.76|eps\n\n\nand the signal power at the detector\u2019s input (Pdet, in) is typically between ?20 and ?30 dBm, the\namount of gain must be very large. Values from 60 to 80 dB, or even larger, are not uncommon.\n\nIf the signal is sampled for digital processing, the power at the analog-to-digital converter (ADC)\ninput must be even higher (and so the gain), typically around 0 dBm, which corresponds to\ns \u00bc 0.224Veff over 50 U. The signal power, the number of bits of the ADC, the ADC window, and the\nsampling frequency must be carefully selected to minimize the error.\n\nDepending on the frequency, different technologies can be used: coaxial components are widely\navailable below w50 GHz, allowing an easy reconfigurability of the hardware, and \u201clow cost\u201d;\nmicrostrip circuits allow for small circuit layouts at low cost and are used at most atw100 GHz due to\nthe increased radiation losses; waveguide circuits exhibit very low losses, at a moderate cost, but\ncircuits are difficult to reconfigure, and the selection of components is limited to w300 GHz; and\nfinally quasi-optical techniques become necessary at higher frequencies (>200 GHz) due to the lower\nlosses at millimeter and submillimeter wavelengths, but circuits are designed for unique applications,\nand the cost is higher.\n\nAs in any receiver, there are passive and active components that perform different functions.\nPassive components include directional couplers to inject calibration and test signals, power splitters to\nsplit or combine signals, attenuators to set the signal power levels, matched loads used as terminations\nor temperature reference (N \u00bc kB $ Tph $ B), isolators to improve the matching, isolate or switch\nsignals, filters to set the radiometer\u2019s bandwidth and filter out unwanted signals, mixers to downconvert\nsignals for processing at a lower frequencies, and detectors to convert the input signal power into a DC\nvoltage. Active components include radio frequency (RF) amplifiers, handle the low-incoming signal\nlevels, have a low noise figure and operate typically from 100 MHz to 200 GHz; intermediate-\nfrequency (IF) amplifiers handle low to high power signals that have been previously down-\nconverted from RF to an IF frequency typically in the range 1 MHz to 1e2 GHz; video amplifiers\n\nFIGURE 4.77\n\nLAURA\u2019s measured (A) copolar and (B) cross-polar antenna pattern. Main parameters: Dq?3 dB \u00bc 20? in\nboth planes, side lobes: 26 and ?19 dB (E- and H-planes), cross-polar <?40 dB in main beam, <?35 dB\npeak value, hML \u00bc 0.965, and losses \u00bc 0.4 dB.\n\nCourtesy of Prof. Sebastia?n Blanch, UPC.\n\n4.6 SENSORS 223\n\nmailto:Image of Figure 4.77|tif\n\n\nhandle the detected signals, have low noise and are highly stable, and operate typically from DC to\n10 MHz; oscillators to generate sinusoidal signals, typically up to 200 GHz, either directly or as an\nharmonic of a lower frequency, that is mixed (multiplied) with the incoming signal to downconvert it\ninto an IF (depending on the frequency and stability requirements, oscillators can be crystal oscillators,\ndielectric resonator oscillators, Gunn oscillators, klystron, or frequency synthesizers); noise diodes are\nused for calibration purposes generating high equivalent noise temperatures up to frequencies larger\nthan 100 GHz; ADCs to convert the analog signal, either the detected one or the predetected one, into a\ndigital word for storage or later digital signal processing9; sample-and-hold (S&H) circuits may be\nused to multiplex different outputs before they are digitized, voltage-to-frequency converters convert\nthe detected analog signal into a frequency modulated signal to avoid transmission problems with\ndifferent grounds, interferences, etc. and are used for integration times larger than 10 ms; and finally\n(diode) detectors convert the input analog signal into a DC signal that is proportional to the input\npower.\n\nDetectors need to operate in the square law region, which requires operating at low power levels,\ntypically from ?20 to ?30 dBm, and be stable in temperature. They also need to have a low linearity\nerror, that is the function V0(Pi) must be a line with deviations less than 0.1%e0.5%. Tunnel diodes are\nthe best choice, with detector\u2019s constants10 on the order of Cd w1 mV/mW, but Schottky diodes are\nusually used as well because of the larger sensitivity, although they have a poorer temperature stability.\nIn this case, differential configurations are used to improve temperature stability. Fig. 4.78 shows the\ntypical transfer characteristic of a Schottky diode, showing the square and linear law regions.\n\nThe nonideal properties of the microwave components introduce errors in the observables that will\nrequire proper mitigation by design and calibration: losses attenuate the signal and add extra noise,\nsince noise is correlated at multiport outputs, it may also induce correlation offsets in correlation\nradiometers; impedance mismatches cause signal reflections that add unwanted noise and add some\nextra losses; and finite directivity of directional couplers also injects unwanted signals. These effects\nintroduce calibration errors, since the estimated slope and bias of the calibration line will be (slightly)\ndifferent from the true ones during the measurements. This is an important topic, but requires advanced\nconcepts of microwave engineering. The interested reader is referred to for a comprehensive analysis\nusing the noise waves (Camps, 2010).\n\n4.6.3.1.3 Sampling Considerations\nDigitization effects can be separated into quantization and sampling effects. Mainly, the effects related\nwith the quantization of the input signal (thermal noise) imply the loss of its statistical properties due to\nthe nonlinear quantization process. Consequently, it is not possible to apply the well-known Gaussian\nstatistical relationships to the quantified signal. This effect has a large impact when limited quanti-\nzation levels are considered, and it can be mitigated by increasing the number of quantization levels.\nNonlinear effect studies on Gaussian signals started with the early analysis of the spectrum of clipped\nnoise by Van Vleck and Middleton (1966). In the late 1950s, Price (1958) published a work focusing\non the relationship between the ideal correlation between two random signals with Gaussian\n\n9If the detected signal is sampled, the number of bits must be high, typically between 12 and 16 bits per sample, so that the\nquantization noise is negligible in front of the radiometric resolution. If the predetected signal is sampled, often a much lower\nnumber of bits can be used, although the final processed value must be stored with much longer digital words. In the limit, in\ncorrelation radiometers, samples at just 1 bit are required to compute the complex cross-correlations.\n10The detector constant plays a similar role as the responsibility (A/W) in photodetectors.\n\n224 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nprobability density function (PDF) and the correlation measured after a nonlinear manipulation of\nthese random signals. This relationship can be used to study the effects of arbitrary quantization\nschemes on the correlation of two signals. Recall that a power measurement is just the cross-\ncorrelation at the origin, so the following considerations may be of general interest for all types of\n(digital) radiometers.\n\nThe discontinuities of the ADC transfer function impact the correlation spectrum by enlarging and\ndistorting the spectrum of the input signals. At the same time, sampling also has an impact on the\ncorrelation of the two input signals by creating replicas of the previously distorted spectra. Therefore,\nadditional noise can be added to the mean correlation value due to spectra replication, but the exact\namount depends on the ratio between the sampling frequency and the signal\u2019s bandwidth.\n\ns2Rxy \u00bc\ns2p\n\nNq\n\u00fe 2\nN2q\n\nXNq\nn\u00bc1\n\n\u00f0Nq ? n\u00deRxx\u00f0nTs\u00deRyy\u00f0nTs\u00de; (4.95a)\n\nwhere, s2p \u00bc s2g1\u00f0x\u00des2g2\u00f0y\u00de is the variance for each sample of the correlation (Nq \u00bc 1), and Rxx/yy are the\nautocorrelation functions of the two signals being correlated. To mitigate this effect, the sampling\nfrequency must be increased above the Nyquist by, at least, the factor given in Hagen and Farley\n(1973).\n\nMoreover, the sampling period and its inaccuracies (skew and jitter in the sampling periods) of the\nADC can affect and distort the sampled signal and so the cross-correlation value. For VADC \u00bc 5sx,y and\nat least 15 quantization levels (4 bits) the quantization scheme neither spreads nor distorts the spectrum\n(<1% rejected band increase).\n\nFIGURE 4.78\n\nTypical transfer characteristic of a Schottky diode.\n\n4.6 SENSORS 225\n\nmailto:Image of Figure 4.78|tif\n\n\nTo compare different sampling and quantization schemes an equivalent integration time is defined\nas that required to obtain the same resolution as in the ideal (analog) correlation. Hagen and Farley\n(1973) conducted important work on this topic, where the effective time was defined and some easy-to-\ncalculate digitization configurations were analyzed in depth. In the case of quantifying with two levels\n(Price, 1958):\n\nRxy\n?\nrxy\u00f0s\u00de\n\n? \u00bc 2\np\narcsin\n\n?\nrxy\u00f0s\u00de\n\n?\n. (4.95b)\n\nWhen the quantization scheme is more complex, it can only be analyzed numerically; Fig. 4.79\nshows some results when using 15 levels (log215 \u00bc 3.9 bits), VADC \u00bc 5sx,y, and different quantization\nschemes.\n\nThe root mean square error (RMSE) coefficient between Rxy(s) and rxy(s) for different quantization\nlevels and ratios of the ADC conversion window (VADC) to the standard deviation of the input signal\n(sx,y) is shown in Fig. 4.80. The minimum of each curve corresponds to the optimum configuration of\nVADC with respect to sx,y. As the number of quantization levels increases, the minimum gets closer to 0,\nand the VADC/sx,y range where the curves remain close to 0 increases as well, since the function q[$] is\nlinear over a wider range of input powers. For VADC < 2sx,y, clipping of the input signal(s) has a\ndominant impact on the non-linear correlation, and it is more important for 1 bit. When VADC/\nsx,y /N, the RMSE asymptotically increases again up 14.2% (as for 1 bit/2 levels sampling) for all\nthe quantization schemes. This effect is explained as a decrease of the effective number of bits, as\nfewer bits are being used as the VADC/sx,y ratio increases. In the limit, only two levels are effectively\nused for quantization.\n\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\nq[\u00b7] function for 15 levels correlation for VADC=5?\n\nideal correlation\n\nno\nn-\n\nlin\nea\n\nr c\nor\n\nre\nla\n\ntio\nn\n\nequally spaced\n1bit/2 level \nideal\ngain compression\nrandomly spaced\n\nFIGURE 4.79\n\nRelationship between the nonlinear and the ideal correlation for different digitization schemes (Bosch-Lluis\n\net al., 2011).\n\n226 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.79|eps\n\n\n4.6.3.2 Types of Real Aperture Radiometers\nThe simplest concept of a microwave radiometer is sketched in Fig. 4.81, and it is called the total\npower radiometer (TPR). An antenna collects the radiation (thermal noise) in a given band, which is\namplified and filtered, and then detected and averaged (low-pass filtered). The detected output\n\nV0 \u00bc kB $\n?\nT\n\n0\nA \u00fe TR\n\n?\n$B $G $Cd \u00fe Z; (4.96)\n\nis proportional to the input system temperature, times the receiver\u2019s noise bandwidth (predetection\n\nbandwidth) B b\u00bc \" RN0 G\u00f0 f \u00dedf\n#2,\"RN\n\n0 G\n2\u00f0 f \u00dedf\n\n#\n, times the chain\u2019s power gain, times the detector\u2019s\n\nconstant Cd, plus an offset term Z originated by impedance mismatches or by the detector itself.\n\n0 2 4 6 8 10 12 14 16 18 20\n0\n\n0.02\n\n0.04\n\n0.06\n\n0.08\n\n0.1\n\n0.12\n\n0.14\n\n0.16\nRMSE for different equally spaced quantization levels\n\nVADC/?x,y\n\nR\nM\n\nS\nE\n\n2 Levels\n\n3 Levels\n\n7 Levels\n\n31 Levels\n\n15 Levels\n\nFIGURE 4.80\n\nRoot mean square error (RMSE) and analog-to-digital converter span window relationship for different equally\n\nspaced quantification levels (Bosch-Lluis et al., 2011).\n\nFIGURE 4.81\n\nBasic block diagram of a total power radiometer. Note: due to practical implementation issues, this topology is\n\nseldom used, since it becomes unfeasible to have enough gain in front of the detector, without amplifier\n\ninstability problems.\n\n4.6 SENSORS 227\n\nmailto:Image of Figure 4.80|eps\nmailto:Image of Figure 4.81|tif\n\n\nTo understand its operation, it is worth spending some time discussing Fig. 4.82, which shows a\nnumerical simulation of the signals in Fig. 4.81 for a radiometer with center frequency 1.413.50 MHz,\nRF bandwidth 20 MHz, and a low-pass filter of 0.5 MHz. The RF signal (first row, number 1 in\nFig. 4.82) is a 20 MHz band-pass signal with Gaussian in-phase and quadrature components of unity\nvariance (third column). The RF spectrum (second column) is nearly flat from 1405 to 1425 MHz\n(oscillations are due to the finite averaging of the different realizations performed). The detected signal\n(second row, number 2 in Fig. 4.82) is the instantaneous power of the RF signal, obtained by squaring it\nsample by sample. Its spectrum consists of a delta function (average power) and an approximately\ntriangular function of width w40 MHz, which, due to the squaring process, is the result of the\nconvolution of the quasirectangular RF frequency response with itself. Finally, the output of the\nintegrator (third row, number 3 in Fig. 4.82), in this case a low-pass bandwidth of 0.5 MHz (low-pass\nfilters of real instruments have much smaller bandwidths), is a smoothed version of the rapid fluc-\ntuations of the instantaneous power (second row), or equivalently most of the AC components have\nbeen removed due to the lower bandwidth. Therefore, the ratio of the standard deviations is equal to the\nratio of the bandwidths\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n20 MHz=0:5 MHz\n\np \u00bc 1:41.0:22 \u00bc 6:4.\nTherefore, the radiometric precision is given by:\n\nsT\n\nT\n\u00bc\n\nffiffiffi\n2\n\np\n$\n\nffiffiffiffiffiffiffiffiffiffi\nBLPF\nBRF\n\nr\n\u00bc 1ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\nBRF $ sLPF\np ; (4.97)\n\nFIGURE 4.82\n\nEvolution of the signals in a basic total power radiometer in first row: radio frequency input, second row:\n\ninstantaneous detected power, third row: low-pass filtered detected power. Signal representation in first\n\ncolumn: time domain, second column: frequency domain, third column: histogram.\n\n228 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.82|tif\n\n\nor\n\nsT \u00bc Tffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nBRF $ sLPF\n\np \u00bc T\n0\nA \u00fe TRffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\nBRF $ sLPF\np . (4.98)\n\nHowever, this expression is ideal, in the sense that it does not account for any receiver imper-\nfections except for the thermal noise. The main limitations of the TPRs come from the gain fluctua-\ntions of the receiving chain (Tiuri, 1964), which can be long-term ones, such as thermal drifts, aging,\netc. and can be corrected for by periodic calibration, and short-term ones (wHz), which are the ones\nthat ultimately limit the radiometric precision, since the gain variation is attributed to a variation of the\nantenna temperature: V0 \u00bc kB $\n\n?\nT\n\n0\nA \u00fe TR\n\n?\n$B $ \u00f0G\u00fe DG\u00de $Cd \u00fe Z.\n\nSince the random gain fluctuations produce a variation of the measured system\u2019s temperature, that\nis uncorrelated with the random fluctuation of the magnitude being measured, the global radiometric\nprecision of TPRs includes these two terms:\n\ns2T \u00bc\n?\nT\n\n0\nA \u00fe TR\n\n?2\nB $ s\n\n\u00fe\n?\nT\n\n0\nA \u00fe TR\n\n?2\n$\n\n\nDG\n\nG\n\n?2\n; (4.99)\n\nbut it is usually governed by gain fluctuations \u00f0DG=G\u00de2 b\u00bc R\u00feN0 SG\u00f0f \u00de $ df , where SG(f) is the spectrum\nof the gain fluctuations of G(f), the radiometer\u2019s power transfer function.\n\nFig. 4.83 shows a typical spectrum of the gain fluctuations, which can be fitted by\n\nSG\u00f0 f \u00de \u00bc ag \u00fe bg\nf\n; (4.100)\n\nwhere ag is set by the white noise term, which depends on B $ s and, bg is fit to system measurements.\nGain fluctuations can be minimized by controlling the stability of the output voltage of the power\n\nsupply and the physical temperature of the radiometer\u2019s environment. However, at high frequencies, it\nis difficult to build highly stable receivers with small gain fluctuations. A possibility is to eliminate the\nRF amplifier and minimize gain fluctuations using a mixer as a first stage (e.g., Fig. 8 in Hersman and\nPoe, 1981), but in this case the receiver\u2019s noise temperature becomes very large.\n\nThe Dicke radiometer (DR) implements a simple way to minimize the gain fluctuations (Dicke,\n1946). The input is modulated using an input switch (the \u201cDicke switch\u201d) to commute between the\n\n-5\n\n-4\n\n-3\n\n-2\n\n-1\n\nLO\nG\n\n P\nO\n\nW\nE\n\nR\nS\n\nP\nE\n\nC\nTR\n\nU\nM\n\n10-1-2-3\n\nMEASURED\n\nLOG FREQUENCY (Hz)\n\n\u201cWHITE\u201d\n\n\u201c1/f\u201d\n\nFIGURE 4.83\n\nTypical gain fluctuations spectrum. Fluctuation power <1e10 Hz, requires calibration every <0.1e1 s.\n\n4.6 SENSORS 229\n\nmailto:Image of Figure 4.83|eps\n\n\nantenna and a matched load at a known and stable physical temperature (TREF) (Fig. 4.84). At the same\ntime, the detected output is DC blocked and demodulated by multiplying it synchronously by \t1\nbefore the low-pass filter, that acts as an integrator. With this synchronous demodulation technique, the\noutput is no longer proportional to the Tsys, but to the difference between the antenna temperature\n(including ohmic losses) and the reference temperature as illustrated in Fig. 4.85:\n\nV0 \u00bc 1\n2\n$ kB $\n\n?\nT\n\n0\nA ? TREF\n\n?\n$B $G $Cd; (4.101)\n\nand provided the switching rate ( fs) is much higher than the bandwidth of the gain fluctuations\u2019\nspectrum, so that DG/Gjf \u00bc m $ fs << DG/Gjf \u00bc 0, the impact of gain fluctuations in the radiometric\nprecision is minimized (Thomsen, 1984):\n\nsT \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2 $\n?\nT\n\n0\nA \u00fe TR\n\n?2\nB $ s\n\n\u00fe 2 $ \u00f0TREF \u00fe TR\u00de\n2\n\nB $ s\n\u00fe ?T 0A ? TREF?2 $\nDGG\n\n?2s\n; (4.102)\n\nsince they are no longer proportional to\n?\nT\n\n0\nA \u00fe TR\n\n?\n, but to\n\n?\nT\n\n0\nA ? TREF\n\n?\n, which is much smaller. In Eq.\n\n(4.102), the \u201c2\u201d factors come from the fact that the antenna and the reference load are being measured\nduring only half the integration time s.\n\nG, TR\n1   \n\n2\n\u00b11\n\nTREF\n\nfs, ? = 1/2 \n\nAT\n\nLPFB2\n1\n\n?\n=?\n\n'\n\nFIGURE 4.84\n\nBasic block diagram of a Dicke radiometer.\n\nFIGURE 4.85\n\nSynchronous demodulation minimizes gain fluctuation effects: signal at detector\u2019s output (upper panel), after\n\nthe DC block (central panel) most gain fluctuations have been removed, and, after the synchronous\n\ndemodulation an output proportional to 1/2 of the difference between the antenna temperature and the\n\nreference temperature is obtained.\n\n230 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.84|eps\nmailto:Image of Figure 4.85|tif\n\n\nEventually, the impact of gain fluctuations can be completely mitigated if T\n0\nA \u00bc TREF . When this\n\ncondition is met, the radiometer is said to be \u201cbalanced.\u201d In this case, the radiometric precision is twice\nthat of an ideal TPR (Eq. 4.98 or Eq. 4.102 with DG/G \u00bc 0) due to the shorter integration time.\n\nFor the DR to perform well there are a number of conditions that have to be met: the switching\nfrequency and the cut-off frequency of the DC block must be much higher than the maximum fre-\nquency of the gain fluctuations spectrum (\u201cknee\u201d in Fig. 4.83), and the video amplifier\u2019s bandwidth\nmust be large enough so that the rise time (ssw) is much smaller that the switching period (e.g.,\nssw < 0.5 $ 10\n\n?2/fs. In addition, usually TREF is set to be higher than the highest TA to be measured, so\nthat the sign of the voltage after the synchronous demodulator does not change. This is achieved by\nthermal stabilization of the whole instrument at a physical temperature typically around 40e45?C.\n\nIf TA s TREF, the gain fluctuations are not totally compensated, and other \u201cbalancing\u201d techniques\nmust be devised, such as the duty-cycle modulation (Orhaug and Waltman, 1962), automatic-gain\ncontrol (AGC) methods and gain-modulation methods (Thomsen, 1984), two-reference tempera-\nture radiometer (Hach, 1968), or noise injection techniques can be devised so that the balancing\ncondition (T\n\n0\nA \u00fe TI \u00bc TREF) is always met such as in the noise-injection radiometer (Goggins, 1967),\n\nusing the reference-channel radiometer (Machin et al., 1952), or using other more sophisticated\ntechniques taking advantage of digital processing techniques such as in the \u201cultra-stable radiometer\u201d\n(Wilson et al., 2003, 2005). Pseudo-correlation radiometers such as the Planck LFI instrument\n(Mennella et al., 2003) or in the PAU hybrid radiometer/GNSS-reflectometer (Camps et al., 2007) also\nachieve some of the balancing benefits, but the noise is injected in a subtler way. Table 4.6 from Camps\nand Tarongi (2010) summarizes the main properties of the main types of radiometers.\n\nHere Fig. 4.86 is taken from Camps and Tarongi (2010) and illustrates the relative performance of\nthe different types of radiometers for DG/G \u00bc 0.01, TR \u00bc 400K, TREF \u00bc 318K, TON \u00bc 913K,\nTOFF \u00bc 30K, B \u00bc 20 MHz, s \u00bc 1 s, and sAGC \u00bc 1 s. As it can be seen, for DG/G \u00bc 0.01 the TPR\nperforms the worst, and the DR with the reference channel the best. The performance of other types of\nradiometers is quite similar and quite constant over a wide range of TA\u2019s. However, these relative\nperformances are strongly dependent on hardware parameters (DG/G, TR, etc.) and the thermal sta-\nbilization of the whole instrument including, as much as possible, the antenna where a significant part\nof the ohmic losses originate.\n\nRadiometric stability refers to the mid- or long-term variations of the radiometer\u2019s output for a\nconstant input, not to the radiometric precision discussed before. In general, for well-designed in-\nstruments, DRs are more stable than total power ones, and noise injection radiometers (NIRs) are more\nstable than DRs. A fair intercomparison between a Ku-band (18.6e18.8 GHz) radiometer designed to\noperate either as total power (TPR), DR, or NIR is given here in Fig. 4.87A. It is said that the com-\nparison is fair because the data presented is acquired exactly under the same conditions, same hard-\nware, and same temperature (and temperature drifts), after the same initial calibration was performed\n(Camps and Tarongi, 2010). The first thing that becomes apparent is the much larger drifts of the TPR,\nas compared to the other two. The second thing is that the drifts for the DR and NIR, follow the same\ntrend, with a larger temperature sensitivity for the DR than for the noise injection one. The measured\ntemperature sensitivity is DTNIR/DTph w 4K/?C, which demonstrates the exquisite care that must be\npaid to the thermal control. The figure of merit of the radiometer\u2019s stability is the so-called Allan\u2019s\nvariance (Allan, 1987), originally conceived to assess the stability of clocks. It is defined as the\nvariance of the difference of two consecutive averages yi \u00fe 1 and yi obtained over a time s \u00bc M $ Ts:\n\ns2y\u00f0s\u00de \u00bc\n1\n\n2\u00f0N ? 1\u00de\nXN?1\ni\u00bc1\n\n\u00f0yi\u00fe1 ? yi\u00de2; (4.103)\n\n4.6 SENSORS 231\n\n\n\nTable 4.6 Main Types of Microwave Radiometers and Basic Performance (Camps and Tarongi, 2010)\n\n1. Total power radiometer\n\nV0 \u00bc kB$\n?\nT\n\n0\nA \u00fe TR\n\n?\n$B$G$Cd \u00fe Z\n\nsT \u00bc\n?\nT\n\n0\nA \u00fe TR\n\n?\n$\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1\nB$s \u00fe\n\n\nDG\nG\n\n?2s\n\n2. Dicke radiometer (unbalanced) (Dicke, 1946)\n\nV0 \u00bc 12$kB$\n?\nT\n\n0\nA ? TREF\n\n?\n$B$G$Cd\n\nsT \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2$\u00f0T 0A\u00feTR\u00de2\n\nB$s \u00fe 2$\u00f0TREF\u00feTR\u00de\n2\n\nB$s \u00fe\n?\nT\n\n0\nA ? TREF\n\n?2\n$\n\n\nDG\nG\n\n?2s\n3. Balanced Dicke radiometer by duty-cycle modulation\n\n(Orhaug and Waltman, 1962)\n\nV0 \u00bc 0\n\nh \u00bc \u00f0TREF \u00fe TR\u00de\n??\n\nT\n0\nA \u00fe TREF \u00fe 2$TR\n\n?\nsT \u00bc\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\u00f0T 0A\u00feTR\u00de2\nB$s$h \u00fe \u00f0TREF\u00feTR\u00de\n\n2\n\nB$s$\u00f01?h\u00de\n\nr\n\n4. Balanced Dicke radiometer by gain modulation (Thomsen,\n1984)\n\nV0 \u00bc 0\na \u00bc ?T 0A \u00fe TR??\u00f0TREF \u00fe TR\u00de\nsT \u00bc\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2$\u00f0T 0A\u00feTR\u00de2\n\nB$s \u00fe 2$\u00f0TREF\u00feTR\u00de\n2\n\nB$s\n\nr\n\n5. Balanced Dicke radiometer by reference channel\n(Machin et al., 1952)\n\nV0 \u00bc 0\n\nT\n0\nA \u00bc T\n\n0\nREF sT \u00bc\u00bc\n\n2$\n?\nT\n0\nA\u00feTR\n\n?ffiffiffiffiffiffi\nB$s\n\np\n\n6. Noise injection radiometerdvariable noise (Goggins, 1967)\n\nV0 \u00bc 0\nT\n\n0\nA \u00fe TON \u00bc TREF sT \u00bc 2$\u00f0TREF\u00feTR\u00deffiffiffiffiffiffiB$sp\n\n7. Noise injection radiometerdvariable duty cycle (Hardy,\n1973)\n\nV0 \u00bc 0\n\nh$TON \u00fe \u00f01? h\u00de$TOFF \u00fe TA \u00bc TREF\n\nsT \u00bc 2$\u00f0TREF\u00feTR\u00deffiffiffiffiffiffiB$sp\n\n8. Hach radiometer (Hach, 1968)\n\nV0 \u00bc VR$2$T\n0\nA ? T1 ? T2\nT2 ? T1\n\nVAGC \u00bc VR\n\u00f0g \u00bc gAGC\u00de\n\nsT \u00bc 1ffiffiffiffiffiffiB$sp\n241\u00fe 1\n\n1\u00fe\nsAGC\ns\n\n \nT2\u00feT1?2$T 0A\n\nT2?T1\n\n!23512\n\n$\n\n\n\n\u00f0T2 \u00fe TR\u00de2 \u00fe \u00f0T1 \u00fe TR\u00de2 \u00fe 2\n\n?\nT\n\n0\nA \u00fe TR\n\n?2?12\n\n\n\nTable 4.6 Main Types of Microwave Radiometers and Basic Performance (Camps and Tarongi,\n2010)dcont\u2019d\n\n9. Ultra-stable radiometer (Wilson et al., 2003, 2005)a\n\nVA \u00bc kB $\n?\nT\n\n0\nA \u00fe TOFF \u00fe TR\n\n?\n$B$G$Cd \u00fe Z\n\nVA\u00feN \u00bc kB$\n?\nT\n\n0\nA \u00fe TON \u00fe TR\n\n?\n$B$G$Cd \u00fe Z\n\nVREF \u00bc kB$\u00f0TREF \u00fe TR\u00de$B$G$Cd \u00fe Z\n\nRNIR b\u00bc VREF ? VA\nVA\u00feN ? VA \u00bc\n\nTREF ? T 0A ? TOFF\nTON ? TOFF\n\nsT \u00bc\nffiffiffiffiffiffi\n3\nB$s\n\nq\n$\n\n(\n\u00f0TREF ? TOFF \u00fe TR\u00de2 \u00fe\n\n?\nT\n\n0\nA \u00fe TR\n\n?2\n$\n\n\"\n1?\n\n?\nTREF?TOFF?T 0A\n\n?\nTON?TOFF\n\n#2\n\n\u00fe\n?\nT\n\n0\nA \u00fe TR \u00fe TON ? TOFF\n\n?2\n$\n\n\"\nTREF ? TOFF ? T 0A\n\nTON ? TOFF\n\n#2)1\n2\n\n10. Advanced pseudo-correlation radiometers (Planck LFI\ninstrument) (Mennella et al., 2003).\n\nV0 \u00bc V01 ? V02\n\u00bc kB$\n\nh?\nT\n\n0\nA \u00fe TR\n\n?\n? r $ \u00f0TREF \u00fe TR\u00de\n\ni\n$B$G$Cd \u00bc 0\n\nGain modulation factor : r \u00bc T\n0\nA \u00fe TR\n\nTREF \u00fe TR\n\nsT \u00bc\nffiffiffi\n2\n\np\n$ TA\u00feTREFffiffiffiffiffiffi\n\nB$s\np\n\n11. Pseudo-correlation radiometer using Wilkinson power\nsplitter (Camps et al., 2007)\n\nV0 \u00bc kB$\n?\nT\n\n0\nA ? TREF\n\n?\n$\nffiffiffiffiffiffiffiffiffiffiffiffiffi\nB1$B2\n\np\n$\nffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nG1$G2\n\np\n\nsT \u00bc TA \u00fe TR \u00fe 2$Tphffiffiffiffiffiffiffiffi\nB$s\n\np\n\naThe above result can be optimized by adjusting the integration times as described (Camps and Tarongi, 2010).\n\n4.6 SENSORS 233\n\n\n\n0 50 100 150 200 250 300\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\nTA' [Kelvin]\n\nTA' [Kelvin]\n\n? \nT \n\n[K\nel\n\nvi\nn]\n\n? \nT \n\n[K\nel\n\nvi\nn]\n\nParameters: ? G/G = 0.01, T  = 400 K, T  = 318 K, T  = 318 K, T  = 393 K, T  = 913 K, T  = 30 K, B = 20 MHz, ? = 1 s, ?  = 1 s\n\nTotal Power Radiometer\nDicke\nDicke with variable duty cycle\nDicke with variable gain\nDicke with reference channel\nNoise Injection Radiometer - noise adding\nHach\nUltra-stable radiometer\nUltra-stable radiometer with optimum ? , ?  and ?\n\n0 50 100 150 200 250 300\n0.15\n\n0.2\n\n0.25\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\n0.5\n\n0.55\nParameters: ? G/G = 0.01, T  = 400 K, T  = 318 K, T  = 318 K, T  = 393 K, T  = 913 K, T  = 30 K, B = 20 MHz, ? = 1 s, ?  = 1 s\n\nTotal Power Radiometer\nDicke\nDicke with variable duty cycle\nDicke with variable gain\nDicke with reference channel\nNoise Injection Radiometer - noise adding\nHach\nUltra-stable radiometer\nUltra-stable radiometer with optimum ? , ?  and ?\n\n(A)\n\n(B)\n\nFIGURE 4.86\n\n(A) Radiometric precision of different radiometers as a function of the antenna temperature (including\n\nantenna ohmic losses), and (B) zoom of Fig. 4.86A. For DG/G \u00bc 0.01 the total power radiometer perform the\nworst, and the DR with the reference channel the best. The performance of other types of radiometers is quite\n\nsimilar and quite constant over a wide range of T\n0\nAs.\n\n234 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.86|eps\n\n\nFIGURE 4.87\n\n(A) Temporal evolution of radiometers\u2019 output reveals larger drifts for the total power radiometer (green), than\n\nfor the Dicke radiometer (DR) (red), and greater DR drift than for the noise injection radiometer (black)\n\n(Camps and Tarongi, 2010). (B) Allan\u2019s variance computed for the time series in Fig. 4.87A.\n\nwhere:\n\nyi \u00bc 1\nM\n\nXM\nj\u00bc1\n\nx\u00f0\u00f0j\u00fe i $M\u00de $ Ts\u00de. (4.104)\n\nFor the example in Fig. 4.87A, the computed Allan\u2019s variance is shown in Fig. 4.87B. The min-\nimum Allan\u2019s variances for the three cases occur at 1, 11, and 42 s for the TPR, the DR, and the NIR,\nrespectively. If the radiometric precision at 1 s integration time are compared, the following results are\nobtained: sT, TPR \u00bc 0.96K, sT, DR \u00bc 1.58K, and sT, NIR \u00bc 2.30K, that is sT, DR \u00bc 1.58 $ sT, TPR and sT,\nNIR \u00bc 2.30 $ sT, TPR, that compare well, although they are slightly worse, to the expected ratios for the\nideal cases: sT;DR \u00bc\n\nffiffiffi\n2\n\np\n$ sT;TPR and sT, NIR \u00bc 2 $ sT, TPR.\n\nThe selection of the radiometer topology depends on one side on the radiometric resolution required\nfor a particular application (e.g., ideally a TPR has a better resolution than a NIR) and on the stability,\nwhich determines the intercalibration period. Most scanning radiometers, either conical or cross-track\nscanners, are TPRs, because a two-point calibration (hot and cold external targets) can be performed in\nevery scan. Other radiometers that cannot perform such a frequent calibration, e.g., the NASA/CONAE\nAquarius 3 beam push-broom radiometer, the radar-altimetry companion radiometers for the \u201cwet\ndelay\u201d correction, or the ESA SMOS radiometers to measure the \u201czero baseline,\u201d are NIRs, even though\nfrom time to time a satellite maneuver is performed to assess the instrument\u2019s stability.\n\n4.6.3.3 Radiometer Calibration\nRadiometer calibration refers to the process of finding the relationship between the radiometer\u2019s output\n(Vd) and the input antenna temperature (TA), by means of well-known internal or external targets\n(Fig. 4.88A).\n\nVd \u00bc 1\na\n\u00f0TA ? b\u00de; (4.105a)\n\nTA \u00bc a $Vd \u00fe b; (4.105b)\n\n4.6 SENSORS 235\n\nmailto:Image of Figure 4.87|tif\n\n\nThis definition does include the correction for the antenna ohmic losses, but formally does not\ninclude the process of compensating for antenna pattern errors that will require some sort of decon-\nvolution of the antenna beam. However, in the case of external calibration, some antenna pattern\ncorrections must be required to ensure that the radiation is the one coming from the main beam:\n\nTA \u00bc hML $ TML \u00fe \u00f01? hML\u00de $ TSL; (4.106)\nwhere hML is the main beam efficiency defined in Eq. (4.73), and TML and TSL are the average\nbrightness temperatures in the main and side lobes, respectively.\n\nAssuming that the radiometer\u2019s response is linear, the calibration procedure reduces to the determi-\nnation of two points of a straight line (Fig. 4.88). One of the points is at a \u201chigh\u201d input noise temperature\nsuch as a microwave absorber at ambient temperature (Fig. 4.89), and the other one at a \u201clow\u201d noise\ntemperature, such as the sky or a microwave absorber embedded in liquid nitrogen, as described in Section\n4.6.3.3.1. These points are called the \u201chot\u201d and \u201ccold\u201d loads, respectively. From these two measurements:\n\nThot \u00bc a $Vd;hot \u00fe b; (4.107a)\nTcold \u00bc a $Vd;cold \u00fe b; (4.107b)\n\nthe slope and the ordinate at the origin are determined:\n\na \u00bc Thot ? Tcold\nVd;hot ? Vd;cold ; (4.108a)\n\nb \u00bc Thot ? a$Vd;hot; or b \u00bc Tcold ? a$Vd;cold . (4.108b)\nIf the radiometer\u2019s response is not linear, then additional input temperatures are required so as to\n\ndetermine the nonlinear transfer function.\nInternal calibration targets, such as thermal loads (either ambient, hot, or cold loads), or noise\n\nsources, have the advantage of allowing for much faster and frequent calibrations, independent of the\nweather conditions, and potential external RFI. On the other hand external calibration targets, such as\ncold space (2.7K, except at some particular frequency bands, and in the direction of the galaxy plane,\nthe Sun, or other \u201chot spots\u201d in the sky, see Section 4.2.2), Earth targets used for vicarious calibration,\nsuch as some regions of the ocean, the Amazon rain forest, Dome C in Antarctica, or the atmosphere\n\nFIGURE 4.88\n\nThe radiometer calibration procedure consists of measuring the instrument\u2019s response to two known input\n\ntargets: the \u201chot load\u201d and \u201ccold load\u201d measurements.\n\n236 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.88|tif\n\n\nitself using \u201ctip curves,\u201d allow for a true end-to-end calibration from the antenna to the ADC output,\nincluding changes in losses, physical temperature, etc. and can be used to periodically vicariously\ncalibrate the internal calibration targets themselves. When it is not possible to perform an external\ncalibration, or the atmosphere is so opaque that tip curves are not an option either, radiometers must\nrely solely in internal calibration targets.\n\nFinally, a note again on the radiometer\u2019s thermal stability that must be controlled to a fraction of the\nexpected calibration accuracy requirement, usually a small fraction of a 1?C.\n\n4.6.3.3.1 External Calibration\n4.6.3.3.1.1 Using Hot and Cold Targets. External calibration targets are designed to have an\nemissivity very close to one and a uniform distribution of the physical temperature, stabilized using\nheating and thermoelectric cooling, or accurately measured at ambient temperature. At microwave and\nmillimeter-wave frequencies, the materials that exhibit a very high emissivity (reflectivity very close to\nzero) are the microwave absorbers either at ambient temperature (as \u201chot\u201d loads) or cooled down (as\n\u201ccold\u201d loads) (Figs. 4.90e4.94).\n\nFIGURE 4.89\n\nA microwave absorber at ambient temperature can be used as the \u201chot load\u201d calibration target (Skou, 1989).\n\nReproduced by permission from Skou, N., 1989. Microwave Radiometer Systems: Design and Analysis, First Edition, Artech\n\nHouse, Inc., Norwood, MA. \u00a9 1989 by Artech House, Inc.\n\nFIGURE 4.90\n\n(Left) Sample microwave absorbers used in an anechoic chamber for antenna pattern characterization of\n\nthe SMOSillo or miniature microwave imaging radiometer by aperture synthesis instrument to test the\n\nperformance of the Soil Moisture and Ocean Salinity mission or for microwave radiometer calibration (right).\n\nLeft: courtesy of UPC Antenna Lab; right: courtesy of the Science and Technology Facilities Council UKdRAL Space.\n\n4.6 SENSORS 237\n\nmailto:Image of Figure 4.89|tif\nmailto:Image of Figure 4.90|tif\n\n\nAmicrowave absorber at a physical temperature T0 emits a brightness temperature TB very close to\nits physical temperature, and therefore, if the whole antenna pattern is surrounded by a microwave\nabsorber at a physical temperature T0, the antenna temperature will be TA \u00bc T0 as well. If T0 is the\nambient temperature, this provides the \u201chot load\u201d calibration target.\n\n(A)\n\n(B) (C)\n\n32 mm\n7 mm\n\nBREWSTER 12.5\u00b0\nANGLE\n\nINTERNAL VIEWSIDE\nVIEW\n\nCR 117 (EMERSON\nAND CUMING)\nABSORBER TILES\n\nCOOLING COILS (LN2 CRYOGEN)\n(COVERED BY STYROFOAM)\n\nFIGURE 4.91\n\n(A) Schematics of the microwave calibration target inverted pyramid used in scanning multichannel\n\nmicrowave radiometer (SMMR) (Skou, 1989). (B) SMMR target without cooling tubes. (C) Cooling tubes on\n\nthe SMMR target.\n\n(A) Reproduced by permission, from N. Skou, Microwave Radiometer Systems: Design and Analysis, First Edition, Norwood, MA:\n\nArtech House, Inc., 1989. \u00a9 1989 by Artech House, Inc.\n\n238 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.91|eps\n\n\nThe reflectivity of the microwave absorbers in the normal direction is usually quite small: values\nof ?30, ?40 dB are common. This is achieved by several means. First, the shape of the absorber is\npyramidal, providing a gradual transition between the medium air and the medium \u201cabsorbing\nmaterial.\u201d Second, the material is usually a foamy material that provides a gradual transition of the\n\nRADIOMETER\n\nANTENNA HORN\n\nFOAM INSULATION\n\nLIQUID NITROGEN\n\nMICROWAVE ABSORBER\n\nAL FOIL\n\nFIGURE 4.92\n\nA cooled microwave absorber can be used as the \u201ccold load\u201d calibration target (Skou, 1989).\n\nReproduced by permission, from N. Skou, Microwave Radiometer Systems: Design and Analysis, First Edition, Norwood, MA:\n\nArtech House, Inc., 1989. \u00a9 1989 by Artech House, Inc.\n\nCopper Wire\n\nAluminum\nCore\n\nDielectric\nAbsorber\n\nEmbedded\nTemperature\nSensor\n\nThermal\nIsolation\n\nHorn Antenna\n\nAbsorber\n\nFoam Insulation\n\nLHe Tank\n\nGas Cooling low\n\nFIGURE 4.93\n\nMitigating \u201ccold load\u201d commonly induced errors (Kogut et al., 2006): array of conical microwave absorbers,\n\nconsisting of a metal core covered by microwave absorber to improve thermal homogeneity weakly coupled to\n\na superfluid liquid helium reservoir. A single absorbing cone consists of a metal core covered by microwave\n\nabsorber. Thermometers embedded within the absorber monitor the temperature of the calibrator.\n\n4.6 SENSORS 239\n\nmailto:Image of Figure 4.92|eps\nmailto:Image of Figure 4.93|eps\n\n\ndielectric constant. And third, the material is a lossy one (using graphite, ferrites, etc.) that attenuating\nthe wave as it travels through it to the base of the pyramid. However, especially at low frequencies,\nhaving a low reflectivity requires very large pyramids, which are infeasible, or at least impractical in\nmany systems. Away to reduce the absorbers\u2019 reflectivity is by using incidence at the Brewster angle,\nat which for vertical polarization, the reflection coefficient exhibits a minimum and eventually van-\nishes. An example of this technique is the variable temperature calibration target that was manufac-\ntured by JPL in the 1970s for the calibration of the scanning multichannel microwave radiometer\n(SMMR) (Fig. 4.91). The tiles of epoxy absorbing material inside the pyramid are at the Brewster\nangle, which is nearly frequency independent. The metallic enclosure provides good thermal con-\nductivity to ensure a homogeneous temperature distribution, and the outside serpentine is a pipe in\nwhich liquid nitrogen circulates to cool down the absorbers so as to achieve the \u201ccold target,\u201d or heated\nnitrogen gas up to 400K for the \u201chot target.\u201d\n\nThe \u201ccold load\u201d used as a second target of the calibration is usually a microwave absorber embedded\nin liquid nitrogen (LN2), which has a boiling temperature of 77K and an emissivity very close to one,\nand therefore does not affect the absorber\u2019s reflectivity. The concept is illustrated in Fig. 4.92.\n\nHowever, there are a few known problems with this method: the surface of the boiling LN2 presents\na complicated nonspecular surface to the radiometer antenna; microwave emission from the antenna,\nand the radiometer enclosure reflected over the LN2 surface back to the antenna increases the apparent\nantenna temperature; if absorber tips are exposed to the air, water condensing on the absorber increases\nthe antenna temperature; and nitrogen vapor may cool down the antenna, and therefore the term\n\nFIGURE 4.94\n\nGround-based scanning radiometer (GSR) fromNational Oceanic and Atmospheric Administration Environmental\n\nTechnology Lab, Microwave Systems Development Division http://cet.colorado.edu/instruments/gsr/.\n\n240 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.94|tif\nhttp://cet.colorado.edu/instruments/gsr/\n\n\nassociated to the noise generated by the antenna ohmic losses (Tph $ (1 ? hU)) decreases. The solution\nto some of these problems consists of tilting the antenna so that the antenna boresight is not\nperpendicular to the absorber\u2019s surface, and inserting a radiometer to divert the cold air and nitrogen\nvapor from reaching the antenna, or by cooling the absorber, with the antenna looking up, as illustrated\nin Fig. 4.93.\n\nFinally, Fig. 4.94 shows the calibration system of the ground-based scanning radiometer (GSR)\nfrom NOAA, in which \u201chot\u201d and \u201ccold\u201d targets are enclosed in thermal boxes for calibration purposes.\nThe radiometer scan head points to them during the calibration, and then exits the box to perform the\nsky measurements at different elevation angles.\n\nFIGURE 4.95\n\n(A) Fully polarimetric calibration target developed at the National Oceanic and Atmospheric Administration\n\n(NOAA) Environmental Technology Lab (ETL), (B) NOAA fully polarimetric calibration setup: (a) polarimetric\n\nscanning radiometer (PSR) housing, (b) PSR scan head, (c) microwave retardation plate, and (d) linearly\n\npolarized standard, (C) Retardation plate of the NOAA/ETL fully polarimetric calibration standard. Plate is\n\nmounted in a wooden disk (Lahtinen et al., 2003).\n\n4.6 SENSORS 241\n\nmailto:Image of Figure 4.95|tif\n\n\n4.6.3.3.1.2 Fully Polarimetric Radiometer Calibration Using External Targets. The output of a fully\npolarimetric radiometer can be expressed as the vector r shown in Eq. (4.109):\n\nr \u00bc\n\n26664\nrv\n\nrh\n\nr3\n\nr4\n\n37775 \u00bc\n26664\ngvv gvh gv3 gv4\n\nghv ghh gh3 gh4\n\ng3v g3h g33 g34\n\ng4v g4h g43 g44\n\n37775 $\n26664\nTv\n\nTh\n\nT3\n\nT4\n\n37775\u00fe\n26664\nov\n\noh\n\no3\n\no4\n\n37775\u00fe n \u00bc G $ TB \u00fe o\u00fe n; (4.109)\n\nThe first term in the sum represents the weighting and cross-talk among the true four Stokes pa-\nrameters. The sources of cross-talk are the antenna limited polarization isolation, cross-talk in the\nradiometer receiver, cross-talk in the correlator, or an unbalance in the signals before detection used to\nmeasure the third and fourth Stokes parameters in the polarization-combining method. The o and n\nterms represent the calibration offsets and instrument noise referred to the outputs.\n\nA possible implementation of the calibrator using external targets is shown in Fig. 4.95 from\nLahtinen et al. (2003). When the polarizing grid is along the X-direction (perpendicular to the plane of\nthe figure, as shown q \u00bc 0?), it reflects toward the radiometer the hot blackbody target at\nX-polarization, while the cold blackbody target at X-polarization is reflected back to the blackbody,\nand the radiation at Y-polarization passes through. When the polarizing grid is along the Y-direction\n(parallel to the plane of the figure, perpendicular to the plot as drawn q \u00bc 90?), it reflects toward the\n\n0\n\n1st Stokes\n2nd Stokes\n3rd Stokes\n4th Stokes\n\n\u2013300\n\n\u2013200\n\n\u2013100\n\n100\n\n200\n\n300\n\nB\nrig\n\nht\nne\n\nss\n T\n\nem\npe\n\nra\ntu\n\nre\n (K\n\n)\n\n\u201390 \u201345 45\nRotation Angle ? (deg)\n\n900 135 180 225\n\nFIGURE 4.96\n\nSample fully polarimetric calibration as a function of the rotation angle (Lahtinen et al., 2003).\n\n242 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.96|eps\n\n\nradiometer the hot blackbody target at Y-polarization, while the cold blackbody target at Y-\npolarization is reflected back to the blackbody, and the radiation at X-polarization passes through.\nWhen the polarization grid is rotated an intermediate angle q, a fraction of each polarization passes and\nthe first three Stokes elements vary as:\n\n\u00f0Tvh\u00deTxx \u00bc Thot $ cos2 q\u00fe Tcold $ sin2 q (4.110a)\n\u00f0Thh\u00deTyy \u00bc Thot $ sin2 q\u00fe Tcold $ cos2 q (4.110b)\n\nT3 \u00bc \u00f0Thot ? Tcold\u00de $ sin 2 q (4.110c)\nThe fourth Stokes parameter is only nonzero when a phase shift d is induced among the two\n\northogonal polarizations:\n\nT4 \u00bc ?\u00f0Thot ? Tcold\u00de $ sin 2 q $ sin d (4.110d)\n\nExperimental results for the polarimetric scanning radiometer are shown in Fig. 4.96.\n4.6.3.3.1.3 Tip Curves. Tip curves are believed to be the most reliable technique for external cali-\nbration (Han and Westwater, 2000). They use the cosmic background temperature as an ultrastable,\nknown cold source, which is Tcos \u00bc 2.7K nearly constant above 2 GHz. The principle of the technique\nlies on the assumption of an effective \u201catmospheric height\u201d h, so that when the radiometer is pointed to\nthe zenith the downwelling brightness temperature is:\n\nTdn \u00bc Tcos \u00fe Tatm \u00f0depth \u00bc h\u00de; (4.111a)\nand when it is pointed to a zenith angle q, the downwelling brightness temperature is:\n\nTdn \u00bc Tcos \u00fe Tatm=cos q \u00f0depth \u00bc h=cos q\u00de: (4.111b)\nThe concept is sketched in Fig. 4.97.\nIf the atmosphere is measured at a number of zenith angles and the antenna temperature is plotted\n\nwith respect to the \u201cnumber of atmospheres,\u201d i.e., sec(q), a straight line will result. The extrapolated\nvalue at zero atmospheres corresponds to the cosmic background.\n\nTip curves rely on assumption of a \u201cvertically stratified atmosphere,\u201d i.e., horizontally homoge-\nneous. This assumption can be checked using a two-sided tipping curve, scanning on both sides of\nzenith, preferably from east to west, because it is the direction in which weather systems typically\nmove. In addition, care must be taken with the lower zenith angles to avoid radiation being picked up\nfrom the ground by antenna side lobes. In some very high absorption peaks (e.g., O2 around 55 GHz)\nthe atmosphere is so opaque that it is not feasible to perform \u201ctip curves.\u201d These radiometers must be\ncalibrated by internal calibration targets only.\n\nFIGURE 4.97\n\nCalibration concept using a \u201ctip curve.\u201d Number of \u201ceffective\u201d atmospheres as a function zenith angle.\n\n4.6 SENSORS 243\n\nmailto:Image of Figure 4.97|tif\n\n\n4.6.3.3.1.4 Earth Targets: Vicarious Calibration. Earth targets such as the Amazon rain forest, some\nparts of the ocean, or Dome C in Antarctica have been used for calibration of microwave radiometers\nbecause they appear as very stable targets over time. Among the class of methods that use Earth\ntargets, the so-called \u201cvicarious calibration\u201d method was devised in 2000 (Ruf, 2000) to calibrate\nsatellite microwave radiometers. It was used to identify long-term drifts in the TOPEX/POSEIDON\nradiometers used to correct altimeter measurements for the effects of water vapor, and it relies on the\nfact that Earth brightness temperatures measured from space have a well-known, repeatable, and\npredictable lower bound due to the specular emissivity of the sea surface in low humidity conditions.\nThis minimum occurs at different SSTs, depending on the radiometer\u2019s frequency. Histogram analysis\nis used to find the coldest point in a set of satellite radiometer data, and this value is then compared to\nthe theoretical model and then adjusted accordingly.\n\nAword of caution with regard to the method is the constraint on the accuracy of a dielectric model\nfor the sea surface, since recent models disagree by up to 2K in the 18e37 GHz range. This implies\nthat the method does not provide an absolute calibration, but it allows us to track small changes and to\nperform precise intersatellite cross-calibration. The brightness temperature models at 37 GHz for\nhorizontal and vertical polarizations, and 53.1? incidence angles for a flat sea, without clouds, and low-\nintegrated water vapor are presented in Fig. 4.98A and B. As it can be easily seen, a minimum occurs,\nand this minimum is at a different SST. Fig. 4.98C shows the histograms of the offset between\nmeasured brightness temperature and the modeled one at 18, 21, and 37 GHz.\n\nThe evolution of the position of the minimum brightness temperature indicates the offset drift with\nrespect to the model that can be tracked over long time series. This is exemplified in Fig. 4.99 by the\nevolution of the minimum brightness temperatures for the three channels of TOPEX/POSEIDON. The\ndrift (almost linear) of the 18 GHz channel is clearly evident and traceable, which allows for an off-line\ncompensation.\n\n4.6.3.3.2 Internal Calibration\nInternal calibration targets, such as thermal loads (either ambient, hot, or cold loads) or noise sources,\nhave the advantage of allowing for much faster and frequent calibrations. In this section a brief\noverview is provided, using examples of commercial devices whenever possible, with their basic\nperformance.\n\n\u2022 Matched loads at ambient temperature (Fig. 4.100A). In this case the noise temperature TN is\nequal to the physical temperature T0. As for an external calibration target (microwave absorber)\nthe key parameter is the reflection coefficient, which must be as low as possible, or the voltage\nstanding wave ratio as close to one as possible.\n\n\u2022 Solid-state hot noise sources consist of avalanche diodes (Fig. 4.100B) that produce an equivalent\nnoise temperature TN much higher than the ambient temperature:\n\nTN \u00bc N\nkB $B\n\n[T0; (4.112)\n\nThe amount of noise generated is usually expressed in decibels in terms of the excess noise ratio\n(ENR), defined as:\n\nENR \u00bc 10 $ log\n\nTN\nT0\n\n?\n; (4.113)\n\n244 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\ntypical values of ENR are on the order of 12e15 dB. This amount of noise is generated by reverse\npolarizing an avalanche diode, with a typical voltage of 28 V. Since the typical ENR variations with\ntemperature and voltage are 0.01 dB/?C and 0.1 dB/V, respectively, both the temperature of the noise\nsource and the voltage of the power supply must be very stable. For example, a 0.1?C temperature\nvariation or a 1 mV power supply voltage variation translate into a 0.001 dB ENR variation which, for\nENR \u00bc 15 dB noise source corresponds to a TN variation of 2.1K, which is unacceptable for most\napplications.\n\n\u2022 Precision hot loads are ovenized matched loads (Fig. 4.100C) that provide a very accurate and\nstable noise temperature as determined by the physical temperature at which they are heated.\nCalibration tests performed at JPL with a precision hot load as these ones showed a repeatability\nwithin 0.1K rms over 2 months.\n\n\u2022 Cryogenic loads (Fig. 4.100D) are precision matched loads cooled with liquid nitrogen at an\noperating temperature of 77.36K that provide a very accurate and stable noise temperature. As for\n\nSea Surface Temperature (C)\n\n37 GHz Horizontal Pol\u2019z TB Model\nSSS=34ppt; vary Integrated Water Vapor\n\n37 GHz Vertical Pol\u2019z TB Model\nSSS=34ppt; vary Integrated Water Vapor\n\n(A)\n\n(C)\n\n(B)\n\n%\n o\n\ncc\nur\n\nre\nnc\n\nes\n in\n\n 0\n.1\n\n K\n b\n\nin\ns\n\nSea Surface Temperature (C)\n\n124\n\n125\n\n126\n\n127\n\n128\n\n129\n\n130\n\n131\n\n132\n\n133\n\n204\n\n205\n\n206\n\n207\n\n208\n\n209\n\n210\n\n211\n\n0\n\n0.05\n\n0.1\n\n0.15\n\n0.25\n\n0.35\n\n0.2\n\n0.3\n\n0.4\n\n-10 -8 -6 -4 -2 0\nTB offset from first guess coldest (K)\n\n2 4 6 8 10\n\n37 GHz\n\n18 GHz\n\n21 GHz\n\nTB\n @\n\n 5\n3.\n\n1 \nde\n\ng \nin\n\nci\nde\n\nnc\ne \n\nan\ngl\n\ne \n(K\n\n)\n\nIWV=0.50cm\n\nIWV=0.25cm\n\nIWV=0.50cm\n\nIWV=0.25cm\n\nIWV=0.00cmIWV=0.00cm\n\nTB\n @\n\n 5\n3.\n\n1 \nde\n\ng \nin\n\nci\nde\n\nnc\ne \n\nan\ngl\n\ne \n(K\n\n)\n\n0 5 10 15 20 25 30 35 0 5 10 15 20 25 30 35\n\nFIGURE 4.98\n\n(A and B) Brightness temperature models at 37 GHz for horizontal and vertical polarizations, and 53.1?\n\nincidence angles for a flat sea, without clouds, and low-integrated water vapor. (C) Histograms of coldest\n\nbrightness temperatures measured by the radiometer allow us to track small bias drifts (Ruf, 2000).\n\n4.6 SENSORS 245\n\nmailto:Image of Figure 4.98|eps\n\n\nthe precision hot loads their matching is much better than for the avalanche diodes, although the\noutput noise temperature is fixed and cannot be controlled. The system performs well until the\nliquid nitrogen has evaporated, which will require to be refilled.\n\n\u2022 Noise calibration systems (Fig. 4.100E) are the combination of a precision hot load warmed with\nan accuracy of\t0.2K and a cryogenic load cooled with liquid nitrogen, together with a precision\nswitch into a single unit. Although the performance is much better than the avalanche diodes, but\nit is worse than the cryogenic loads or precision loads that have been isolated, because of the\nuncertainties introduced by the switch between them (Fig. 4.101).\n\n\u2022 Solid-state cold noise sources or active cold loads (ACLs) were first described in 1981 (Frater and\nWilliams, 1981). ACLs are active devices that generate an equivalent noise temperature lower\nthan the physical temperature. The physical mechanism for this apparently counterintuitive\nbehavior lies in the fact that active devices, when operated normally amplify the signal (and the\nnoise) present at their input, while introducing additional noise themselves. However, in the\n\n92 93 94 95 96 97 98 99\n\n1%\n\n3%\n\n5%\n\n1%\n\n3%\n\n5%\n\n1%\n\n3%\n\n5%\n\n123\n\n123.5\n\n124.5\n\nTB\n18\n\n, m\non\n\nth\nly\n\n a\nve\n\nra\nge\n\n o\nf c\n\nol\nde\n\nst\n n\n\n%\n (K\n\n)\n\n125.5\n\n126.5\n\n124\n\n125\n\n126\n\n(A)\n\ntime (yr after 1900) time (yr after 1900)\nTMR - 37 GHz channel\nprocessed 10 Sep 98\n\nTMR - 18 GHz channel\nprocessed 10 Sep 98\n\nTMR - 21 GHz channel\nprocessed 10 Sep 98\n\n153\n\n154\n\nTB\n37\n\n, m\non\n\nth\nly\n\n a\nve\n\nra\nge\n\n o\nf c\n\nol\nde\n\nst\n n\n\n%\n (K\n\n)\n\n155\n\n156\n\n153.5\n\n154.5\n\n155.5\n\n92 93 94 95\ntime (yr after 1900)\n\n96 97 98 99\n\n92\n130.5\n\n131\n\n132\n\n133\n\n134\n\n131.5\n\n132.5\n\n133.5\n\n93 94 95 96 97 98 99\n\n(C)\n\n(B)\n\nTB\n21\n\n, m\non\n\nth\nly\n\n a\nve\n\nra\nge\n\n o\nf c\n\nol\nde\n\nst\n n\n\n%\n (K\n\n)\n\nFIGURE 4.99\n\nEvolution of the minimum brightness temperatures for the 18, 21, and 37 GHz channels (Ruf, 2000).\n\n246 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.99|eps\n\n\nreverse direction, the signal (and noise) are usually strongly attenuated, and for most of them, the\nextra noise added is fairly small, so that the total noise emitted at their input (Tout,1) is lower than\nthe physical temperature.\n\nAn amplifier is characterized by its two-port S-parameters (Sij), and its four noise parameters: Rn\nthe noise resistance, Gopt the optimum input complex reflection coefficient, and Fmin the minimum\nnoise figure (Fukui, 1966). The output of the amplifier is terminated with a matched load (G2 \u00bc 0) at a\ntemperature T2. The available output noise temperature seen at the input of the amplifier (port 1) can be\nwritten as:\n\nTout; 1 \u00bc Trev \u00fe A12 $ T2; (4.114a)\nwhere the first term in Eq. (4.114a), Trev, is the ideal lowest temperature when the load temperature T2\nis zero. Trev can be expressed only in terms of the conventional noise parameters as (Weatherspoon and\nDunleavy, 2006):\n\nTrev \u00bc\nTk ? Te;min $\n\n?\n1?\n\n???G0opt???2?\n1?\n\n???G0opt???2 ; (4.114b)\n\nFIGURE 4.100\n\n(A) Matched load at ambient temperature in waveguide, (B) solid-state hot noise sources, (C) ovenized hot\n\nload, (D) cryogenic cold load, and (E) noise calibration system.\n\nFrom https://www.maurymw.com/Precision/Noise_Calibration_Systems_Accessories.php.\n\n4.6 SENSORS 247\n\nmailto:Image of Figure 4.100|tif\nhttps://www.maurymw.com/Precision/Noise_Calibration_Systems_Accessories.php\n\n\nwith:\n\nTe;min \u00bc T0 $\n?\n10Fmin=10 ? 1\n\n?\n; (4.114c)\n\nG\n0\nopt \u00bc\n\nS?11 ? Gopt\nGoptS11 ? 1; (4.114d)\n\nTk \u00bc 4T0RnGopt; (4.114e)\n\nGopt \u00bc 1\nZ0\n\n<\n?\n1? Gopt\n1\u00fe Gopt\n\n?\n; (4.114f)\n\nand the reverse available gain of the amplifier:\n\nA12 \u00bc jS12j\n2\n\n1? jS22j2\n$\n1? ??G02??2\n1? jG1ij2\n\n; (4.114g)\n\nG\n0\n2 \u00bc\n\nG2 ? S?22\n1? S22G2 . (4.114h)\n\nSince the input reflection coefficient of the ACL may be too high for radiometer calibration, an\nisolator may be used, at the expense of the extra thermal noise generated by the internal matched load\nin the isolator that is reflected at the ACL input and sent back to the input.\n\nACLs and programmable arbitrary wave generators have been used in prototypes of programmable\npartially correlated noise sources for the calibration of polarimetric radiometers (Ruf and Li, 2003).\n\n4.6.3.3.3 Radiometer Linearity\nSo far, the radiometer\u2019s transfer function V0(TA) has been assumed to be a linear function. However,\nsystems may have a gain expansion behavior, and gain compression at the higher levels, and the best\nlinearization results have to be found with an nth order polynomial. Usually a second-order polynomial\nsuffices, but still software corrections are required to compensate for these \u201cnonlinearities.\u201d\n\nTo measure the radiometer\u2019s linearity a variable and known antenna temperature must be present at\nthe main antenna input that will be compared to the calibrated antenna temperature (radiometer\u2019s\noutput). The nonconstant term of the difference between the known input and the calibrated output is\nthe nonlinearity error. The constant term is just the average radiometric accuracy (systematic error).\nTwo sample ways to achieve a variable noise temperature at the input are discussed below:\n\n\u2022 Starting from a cold load (e.g.,w98K, cold reference load in a cryostat), extra noise generated by\na noise source with a large ENR followed by an adjustable attenuator L, is added through a\ndirectional coupler (C ):\n\nTIN z TCOLD \u00fe\n?\nTHOT $\n\n1\n\nL\n\u00fe Tph $\n\n\n1? 1\n\nL\n\n??\n1\n\nC\n. (4.115)\n\nThe block diagram is shown in Fig. 4.101A. For example, assuming that ENR \u00bc 25 dB, that\nTcold \u00bc 98K (typical value from Maury cryogenic loads) and the step attenuator ranges from 15\n\n248 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nto 30 dB in steps of 3 dB, the values of the noise temperature at the input of the radiometer are: 423.9,\n276.2, 202.2, 165.1, 146.5, and 137.2K, that correspond to noise temperature steps of 147.7, 74.0,\n37.1, 18.6, and 9.3K. That is, each step is very approximately half the previous one, from which the\nlinearity of the instrument can be inferred with great accuracy. The accuracy is driven by the\nrepeatability of the step attenuator divided by the coupling factor.\n\n\u2022 Another method to perform the linearity correction is given in Colliander et al. (2007). It\nconsists of inserting a variable, but extremely repetitive attenuator in series with the cold load in\nsuch a way that the output noise be TIN \u00bc Tcold/L \u00fe Tph (1 ? 1/L). When L \u00bc 1 (0 dB):\nTIN \u00bc Tcold, while when L tends to infinite TN tends to Tph (L \u00bc 20 dB, Tph \u00bc 298K,\nTIN \u00bc 296K), being TIN the noise temperature of the ensemble cryogenic load \u00fe variable\nattenuator. The attenuation L is adjusted in known steps and its physical temperature must be\naccurately measured. It determines the \u201cantenna temperature\u201d where the nonlinearity will be\nmeasured. On top of this noise, an additional noise level is added. This amount of noise is\nconstant for all TN values, and therefore this is an extremely stable method to assess the linearity\nof the system through the whole dynamic range of the radiometer. A schematic diagram of the\nmeasurement setup used in this technique is shown in Fig. 4.101B. The idea is to add a constant\namount of noise on top of a noise level that can be varied. The benefit is the fact that the only\ncritical parameter for the accuracy of the measurement is the stability of the added noise, which\nis relatively easily to achieve.\n\nFIGURE 4.101\n\nSample block diagram for radiometer linearity tests (A) #1, and (B) #2.\n\n4.6 SENSORS 249\n\nmailto:Image of Figure 4.101|tif\n\n\n4.6.3.4 Radio Frequency Interference Detection and Mitigation\nRFI includes spurious signals and harmonics from lower frequency bands, spread-spectrum signals\noverlapping the \u201cprotected\u201d band of operation, or out-of-band emissions not properly rejected by the\npredetection filters due to its finite rejection. The presence of RFI increases the detected power and the\nestimated antenna temperature, leading to a degradation in the accuracy of the retrieved geophysical\nparameters, if they can be retrieved at all. RFI is specially a serious problem in populated land areas\n(Njoku et al., 2005; Ellingson and Johnson, 2006; Younis et al., 2007), although due to different\nspectrum regulations not all bands are affected the same way in all regions.\n\nCurrent RFI detection and, eventually, mitigation methods in microwave radiometry include the\nfollowing ones:\n\n\u2022 Time-domain techniques blank (\u201celiminate\u201d) signal samples with power peaks larger than a\npredefined factor of the expected variance (Gu?ner et al., 2007). However, the detected power is an\naverage of the instantaneous power, therefore RFI peaks shorter than the integration time may\npass undetected.\n\n\u2022 Frequency-domain techniques blank subbands with power larger than a predefined factor of the\nexpected variance (Gu?ner et al., 2007). Similar to the time-domain techniques, the detected power\nis an average over a given bandwidth, therefore RFI power peaks narrower than the resolution\nbandwidth is \u201cblurred\u201d and may pass undetected.\n\n\u2022 Spectrogram techniques (simultaneous time- and frequency-domain signal decomposition, e.g.,\nTarongi and Camps, 2011) use very long sequences of data to achieve fine resolution\nsimultaneously in time and frequency. Image processing techniques such as edge detection of\nclusters of high power timeefrequency bins are then used to detect anomalously high power\ntimeefrequency bins, which are then eliminated.\n\nIn these three cases, the signal power is estimated from the remaining signal samples, subbands, or\ntimeefrequency bins, properly scaled.\n\n\u2022 Statistical techniques are based on the fact that the RFI-free radiometric signal should be a zero-\nmean random Gaussian variable. Therefore, the PDF and the statistical parameters are perfectly\nknown. If the normality test is not passed, the whole sequence is eliminated. In the remote sensing\nliterature, the Kurtosis method (ratio of the fourth moment and the square of the second moment,\nMisra et al., 2009) is the most widely test used, and there are time- and frequency-domain\nversions of it. To prevent a blind spot of the Kurtosis method, other methods have been studied\nsuch as the sixth-order moment (De Roo and Misra, 2008), the ShapiroeWilk (SW) test (Gu?ner\net al., 2008), or in Tarongi and Camps (2010) several other normality tests were also carefully\nreviewed.\n\n\u2022 Polarimetric techniques look for anomalous signatures in the third and fourth Stokes parameters,\nand, if found, the corresponding first and second Stokes parameters are discarded. These\ntechniques have been applied to both real (Ellingson and Johnson, 2006) and synthetic aperture\nradiometers (Camps et al., 2011a; Kristensen et al., 2012).\n\nIn these two cases, all data are lost when RFI is detected.\n\n\u2022 Finally, wavelet techniques can also be used to estimate the RFI signal without any priori\nknowledge of it and then cancel it (Camps and Tarongi, 2009). In this case, there is no signal loss,\n\n250 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nalthough a residual RFI may be present. Its performance depends mainly on the ratio of sampling\nfrequency to signal bandwidth, the interference-to-noise ratio (INR), and the wavelet family and\ndecomposition level.\n\nActually, it has to be acknowledged that many of these methods were first used in radio-astronomy,\nwhere the RFI problems where first experienced.\n\nThe performance of the different methods is characterized by two parameters:\n\n\u2022 The probability of a false alarm (Pfa), or the \u201cdetection\u201d of RFI in the absence of RFI (Type I\nerror or rejection of a true hypothesis), which leads to the blanking of correct data, and\n\n\u2022 The probability of a missed detection (Pmiss), or the \u201cno detection\u201d of an RFI when there is RFI\npresent (Type II error or acceptance of a false hypothesis), which leads to an erroneous\nmeasurement. In our context the term probability of detection (Pdet) is usually used and it is\ndefined as Pdet \u00bc 1 e Pmiss.\nThe objective is to obtain a low Pfa and a high Pdet, but since both are strongly correlated, setting\n\nthe value of one determines the value of the other one. To achieve a low Pfa, the threshold used to\ntake the decision of \u201cpresence of RFI\u201d in methods 1 to 5 must be high enough, but then many RFI are\nnot detected and Pmiss increases. The combined performance of a technique in terms of Pdet and Pfa\ndepends on the PDF of the signal values, and it is given by the receiver operating characteristic\n(or ROC) curves Pdet (Pfa(threshold)). The ROC curves have been previously derived for many of the\nmethods discussed in this book and will not be repeated here. The interested reader is referred, for\nexample, to Misra et al. (2009) or Tarongi and Camps (2010).\n\nThe performance of the statistical tests is summarized in the following plots. In Fig. 4.102 we present\nthe INR value required to obtain an ROC curve with a Pfa \u00bc 0.1 for Pdet \u00bc 0.9 for different normality\ntests. This value is given for a pulsed sinusoidal signal with variable duty cycle. In general, the Kurtosis\n(K) test outperforms, i.e., it requires a lower INR for a given Pfa and Pdet, except around the 0.5 duty\ncycle, where it has a blind spot. The JB (Jarque-Bera) and the K2 (D\u2019Agostino K-square) do have a blind\nspot as well, since they are based on the K test. JB and K2 test results cannot be used with 1024 samples.\n\nAround a duty cycle of 0.5, it is the SW test the one that has the best performance, followed by the\nAndersoneDarling (AD) test for 1024 samples, while AD tests present the best performance for\n16,384 samples, since SW test performance is degraded due to averaging.\n\nHowever, the presence of a blind spot is not restricted to pulsed sinusoidal RFI signals only. It does\naffect other pulsed signals that have a Kurtosis larger than three for a duty cycle of 100%. Results are\nshown in Fig. 4.103 for other signals, including pseudorandom-noise and telegraphic signals.\n\nFinally, the determination of the presence or not of RFI, based on a finite number of signal samples,\nis prone to uncertainties that decrease as the number of samples increases. For example, for a confi-\ndence level of 0.05, the Kurtosis thresholds are w3 \t 0.2, which requires w2000 samples, but for\nthresholds w3 \t 0.1, the number of samples required is w6000.\n\nIn summary, the Kurtosis seems to be the best RFI detection algorithm for almost all kinds of\ninterfering signals, although it has a blind spot for sinusoidal (chirp) signals of 0.5 of a duty cycle. The\nAD test is a complementary normality test that covers this blind spot, and has a very good performance\nfor all the studied sample sizes. The combination of the Kurtosis and the AD tests seems capable to\ndetect most types of RFI. The performance of the detection tests improves with the sample size and\ndepends on the duty cycle of the pulsed RFI.\n\n4.6 SENSORS 251\n\n\n\nSpectrogram-based algorithms treat the radiometric signal\u2019s spectrogram (timeefrequency rep-\nresentation of the signal) as an image and apply image processing techniques to detect the presence of\nanomalous features. The spectrogram is a powerful tool that has also been previously used in RFI\ndetection in radio-astronomy (Offringa et al., 2010; Winkel et al., 2007). The presence of RFI can be\ndetected by identifying power peaks, usually clustered in the timeefrequency domain, larger than a\ngiven threshold above the variance (power) measured for the thermal noise in regions free of RFI,\nsimilarly as it is done for time- or frequency-domain blanking (Gu?ner et al., 2007; Misra et al., 2009;\nTarongi and Camps, 2011). An advantage of spectrogram methodsdeventually in combination with\nnormality tests either globally or at timeefrequency bin leveldis that pulsed RFI, which is wide in\nfrequency, but narrow in time, or CW-like RFI, which is long in time, but narrow in frequency (see RFI\npresent in Fig. 4.104) can be detected and eliminated, leaving a lot more of \u201cclean\u201d bandwidth to be\nprocessed. Spectrogram methods have also demonstrated their power in detecting RFI, that otherwise\nwould have passed over inadvertently (Forte et al., 2013; Tarongi, 2013). More recently, improved\nperformance has been achieved using the multiresolution Fourier transform (Querol et al., 2015, 2016).\n\nFIGURE 4.102\n\nNormality test performance in the detection of a pulsed sinusoidal interference of 1024 samples (dotted line)\n\nand 16,384 samples (solid line) as a function of signal\u2019s duty cycle. Graphs represent the interference-to-\n\nnoise ratio value required to obtain a receiver operating characteristic curve with a Pfa \u00bc 0.1 for Pdet \u00bc 0.9.\nResults obtained from a Monte-Carlo set of 215 simulations (Tarongi and Camps, 2010).\n\n252 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.102|tif\n\n\nFIGURE 4.103\n\nOther signals used in communications have a Kurtosis value of three for a determined duty cycle. PRN,\n\npseudorandom noise; OFDM, orthogonal frequency division multiplexing (Forte et al., 2013).\n\nFIGURE 4.104\n\n(A) Uncalibrated power spectrogram measured in Barcelona city during the months of May and June 2012.\n\n(B) Zoom of Fig. 4.104A starting on May 15, 2012, at t0 \u00bc 16:56:55 h spanning from 1410 to 1415 MHz and\nfrom t1 \u00bc t0 \u00fe 11 s to t2 \u00bc t0 \u00fe 20 s. Detected radio frequency interference in the spectrogram using the\nMERITXELL instrument (Tarongi, 2013) are marked in black. Note: the power in each timeefrequency bin is\n\nuncalibrated and it is expressed in relative units (dB).\n\n4.6 SENSORS 253\n\nmailto:Image of Figure 4.103|tif\nmailto:Image of Figure 4.104|tif\n\n\nIn summary, there is not a single method that performs satisfactorily for all sorts of RFI signals, but\ncombinations of them can do a decent job. The best candidates are the Kurtosis test, for its simplicity\nand good performance in most cases, in combination with the AD test to mitigate the blind spot. These\nmethods can also be applied at the timeefrequency bin level in the spectrogram before RFI mitigation\nalgorithms are applied. The NASA SMAP mission radiometer, for example, implemented a combi-\nnation of time and frequency diversity and Kurtosis to mitigate RFI (Entekhabi et al., 2010).\n\n4.6.3.5 Example: Special Sensor Microwave Imager Radiometric and Geometric\nCorrections\n\nFrom all the sensors listed in Table 4.4, the SSM/I has been the one that resulted in the greatest change\nin the way radiometers are used today. This sensor flew since 1987 continuously aboard the platforms\nDMSP F8 to F15 of the Department of Defense of the United States, and since then, merged with the\nSSM/T and SSM/T-2 and named as the SSMI/S, up to the DMSP F19. These platforms orbit the Earth\nin a Sun-synchronous polar orbit at h \u00bc 890 km, with an inclination of 98.8?, and a period of 102 min.\nThe radiometer is a seven channel instrument, with dual-polarization capabilities, except at 22 GHz,\nwhere only the vertical polarization is implemented. Table 4.7 summarizes the main instrument pa-\nrameters: frequency bands, polarizations, antenna footprint, and integration time (Hollinger et al.,\n1987). Note that the antenna footprint size is inversely proportional to the instrument band. As\ncompared to its predecessor the SMMR, the SSM/I does not have the 6.6 and 10.7 GHz channels, but it\ndoes include the 85.5 GHz one (see Table 4.4).\n\nThe imaging process is performed using a conical scan of the 79 cm diameter reflector. The rotation\nevery 1.9 s and the 42? off-nadir angle lead to a swath width of 1400 km, and a constant incidence\nangle over the Earth of approximately 53.1?, for which the emissivity at vertical polarization exhibits a\nminimum sensitivity with respect to surface roughness, which allows a simpler classification and\ngeophysical parameter retrieval. Fig. 4.105A shows an artist\u2019s view of the SSM/I instrument, and\nFig. 4.105B the geometry of observation, the antenna footprints and the sampling in scans A and B,\nwhile Fig. 4.106 presents the sampling strategy for the A and B scans. The sampling is produced every\n12.5 km for scans A and B for the 85 GHz channel only (128 pixels per swath), while at 25 km for\nscans A only, for the rest of the channels (64 pixels per swath).\n\nDuring the conical scan, in the farthermost points from the ground-track direction, the calibration is\nperformed. At one swath edge the so-called \u201csky mirror\u201d diverts the radiation from the sky into the\nantenna feed, providing the \u201ccold load\u201d calibration. At the other swath edge, a microwave absorber\nblocks the antenna feeders for the \u201chot load\u201d calibration. The data acquired in between calibrations are\n\nTable 4.7 Main Parameters of the Special Sensor Microwave Imager Instruments\n\nFrequency 19.35 GHz 22.235 GHz 37.0 GHz 85.5 GHz\n\nPolarization h/v v h/v h/v\n\nIntegration time 7.95 ms 7.95 ms 7.95 ms 3.89 ms\n\nFootprint (along-track) 69 km 50 km 37 km 15 km\n\nFootprint (cross-track) 43 km 40 km 28 km 13 km\n\n254 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\ncorrected using the prior/later calibration data. However, if the calibration is wrong, then the entire line\nis discarded (see black arcs in Fig. 4.52).\n\nDue to antenna/platform effects, the Earth incidence angle (EIA) can also vary along the swath\nposition (Fig. 4.107A), which will require a proper compensation. Near the swath edges the feed\ncollects partial power from the sky mirror, and the antenna temperature drops, which requires proper\ncorrection (w1K, see Fig. 4.107B).\n\nThen, the brightness temperatures (TB) are computed from the antenna temperatures (TA) as the\nweighted sum of the central pixel and the adjacent pixels (including adjacent scans) at the same\nfrequency and polarization. The information of the central pixel at the orthogonal polarization (h/v) is\nincluded as well in the algorithm to model the polarization mixing due to antenna misalignment and\ncross-polarization errors.\n\nFIGURE 4.105\n\n(A) Artist\u2019s view of special sensor microwave imager instrument (http://podaac.jpl.nasa.gov/SSMI), and\n\n(B) geometry of observation: antenna footprints and scans A and B (Hollinger et al., 1987).\n\n4.6 SENSORS 255\n\nmailto:Image of Figure 4.105|tif\nhttp://podaac.jpl.nasa.gov/SSMI\n\n\nThe brightness temperatures recovered are stored in 2 byte integers, multiplied by 10, leading to a\n0.1K resolution. All brightness temperatures must be between 50 and 350K. If the temperatures are\noutside this range or are erroneous, they are set to zero and not processed. If the time tag is wrong, it\ntranslates into a position error. If the calibration is wrong, the whole scan calibration is wrong.\n\nFIGURE 4.106\n\nSampling strategy for the A and B scans. See text for description (Hollinger et al., 1987).\n\n-50 50 100 150 200 2500\n\n6.8 GHz\n10.7 GHz\n18.7 GHz\n23.8 GHz\n37 GHz\n\nAscending\nDescending\n\n144\n\n145\n\n146\n\n147\n\n148\n\nTb\n (K\n\n)\n\n149\n\n150\n\n151\n\n152(B)\n\nScan Downcount\n0 60 100 150 200 250 300 350-100\n\n50\n\n51\n\n52\n\n53\n\nE\nIA\n\n (d\neg\n\n.)\n\n54\n\n55\n\n56\n\n(A)\n\nScan Angle (deg.)\n\nFIGURE 4.107\n\n(A) Variation of the Earth\u2019s incidence angle (EIA) along the swath position. (B) Variation of the antenna\n\ntemperature near the swath edges due to the collection of sky radiation scattered in the sky mirror (http://\n\nwww.jcsda.noaa.gov/documents/meetings/WARSO2007/BettenhausenWindSat08061300.pdf).\n\n256 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.106|tif\nmailto:Image of Figure 4.107|eps\nhttp://www.jcsda.noaa.gov/documents/meetings/WARSO2007/BettenhausenWindSat08061300.pdf\nhttp://www.jcsda.noaa.gov/documents/meetings/WARSO2007/BettenhausenWindSat08061300.pdf\n\n\nBoth the electronically scanning microwave radiometer (EMSR) and the SMMR used the \u201cdrop-in-\nthe-bucket\u201d technique to assign a radiometer value to a given pixel. This technique consisted of\nassigning to the central pixel the average value, which was averaged later with all the values in a single\nday. After analyzing more sophisticated techniques, that took into account the distance to the central\npixel and performed interpolations with adjacent pixels, it was found that the improvement was not\nsignificant, while the computational load increased significantly. Finally, the \u201cdrop-in-the-bucket\u201d\ntechnique was also used in the SSM/I. Geolocation errors can be important, even higher than 20 or\n30 km (about half pixel, though!). Sources of errors are data processing software errors, inaccurate\nsatellite ephemeris due to satellite tracking errors and, orbit prediction (specially under intense solar\nactivity periods), and alignment error between SSM/I\u2019s boresight and instrument\u2019s boresight. The\ncorrection is performed by computing the average and filters the satellite ephemeris in a 7-day period\ncentered in the orbit to be processed. The final accuracy achieved is w5 km.\n\n4.6.4 SYNTHETIC APERTURE RADIOMETERS\nThis section deals with the novel imaging radiometers in which the image is formed by the cross-\ncorrelation of the signals collected by a number of antennas, as opposed to the pseudo-correlation\nradiometers in which the signals being correlated were collected by the same antenna.\n\nIn synthetic aperture radiometers the antennas can have either a wide beam or a narrow one, either\nin one or in two directions, and in some cases, antenna movement is required to achieve angular\nresolution by some sort of matched filtering. At present, there is only one satellite mission carrying a\nsynthetic aperture radiometer, it is the ESA\u2019s SMOS mission and the MIRAS payload. This new\ntechnique is now being pursued in several other missions such as the NASA/JPL PATH and the\nChinese Academy of Sciences GIMS.\n\nAs a reminder, Eq. (4.70) provides the expression of the cross-correlation (Vpqmn) of the signals\nbp;qm;n\u00f0t\u00de collected by a pair of antennas m and n at positions (xm,n,ym,n,zm,n), at p- and q-polarizations,\nrespectively, and pointing towards the \u00fez direction:\n\nVpqmnyV\npq umn; vmn;wmn\u00f0 \u00dey 1\n\nkB\nffiffiffiffiffiffiffiffiffiffiffi\nBmBn\n\np ffiffiffiffiffiffiffiffiffiffiffiffi\nGmGn\n\np $1\n2\n\n?\nbpm t\u00f0 \u00debqm ? t\u00f0 \u00de\n\n?\n\u00bc 1ffiffiffiffiffiffiffiffiffiffiffiffi\n\nUmUn\np\n\nZZ\nx2\u00feh2?1\n\nTpq x; h\u00f0 \u00de ? Tphdmnffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\np Fm x; h\u00f0 \u00deF?n x; h\u00f0 \u00de\n\n$ermn ?umnx\u00fe vmnh\u00fe wmn\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\nq\nf0\n\n0@ 1A\n$exp ?j2p umnx\u00fe vmnh\u00fe wmn\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\nq\n ?\n ?\ndxdh: (4.70)\n\nThe terms in Eq. (4.70) have already been previously defined and are not be repeated here.\nEq. (4.70) provides the basic observable of the different types of synthetic aperture radiometers that are\npresented in the next Sections.\n\n4.6 SENSORS 257\n\n\n\n4.6.4.1 Types of Synthetic Aperture Radiometers\n4.6.4.1.1 Mills Cross\nThe Mills Cross is one of the simplest and oldest sparse-aperture microwave radiometers (Christiansen\nand Hogbom, 1985). It consists of two antennas forming a cross, as sketched in Fig. 4.108. Each\nantenna is very large in one dimension, thus generating a very narrow beam11 (Dq1Y z l/L1Y and\nDq2X z l/L2X), while they are narrow in the other dimension, thus generating a very wide beam\n((Dq1X z l/L1X and Dq2Y z l/L2Y). These beams that are very wide in one direction and narrow in the\nother one are called \u201cfan beams.\u201d The \u201cpencil beam\u201d (narrow in both dimensions: Dq1Y z l/L1Y and\nDq2X z l/L2X) is formed from the cross-correlation of the signals collected by both antennas. Since the\nthermal noise signal is spatially uncorrelated, the only net contribution to the cross-correlation is coming\nfrom the thermal noise being collected by both antennas simultaneously, that is from the noise coming\nfrom the intersection of the two fan beams. Contributions coming from other directions do contribute to\nthe detected output noise, but not to the cross-correlation. This is equivalent to a reduction of the\nmeasured antenna temperature (absolute value of the cross-correlation) by a factor:\n\nUMills?crossffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nU1 $U2\n\np \u00bc\nl2\n\nL1Y $ L2Xffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nl2\n\nL1X $ L1Y\n$\n\nl2\n\nL2X $ L2Y\n\ns \u00bc ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiL1Y\nL1X\n\n$\nL2X\nL2Y\n\nr\n; (4.116)\n\nand an increase in the radiometric precision sV \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\ns2Vr \u00fe s2Vi\n\nq\n(Eq. 4.82) by the inverse of that factor.\n\nThis is again, the radiometer\u2019s uncertainty principle. The amount gained in angular resolution is\nexactly the same factor the radiometric precision is degraded.\n\nFIGURE 4.108\n\nPrinciple of operation of the Mills cross radiometer.\n\n11Recall from Section 4.6.2.1 that the angular resolution is proportional to the electromagnetic wavelength and inversely\nproportional to the antenna size.\n\n258 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.108|tif\n\n\n4.6.4.1.2 Synthetic Aperture Radiometers using Matched Filtering\nIn the early 1970s the concept of spaceetime matched filtering was conceived in the former USSR\n(Melnik, 1972a,b), but it was not until the first half of the 1990s that the so-called supersynthesis\nradiometer (Komiyama et al., 1994, 1997; Komiyama and Kato, 1995, 1996; Komiyama, 1998) and the\nRadSAR (Edelson, 1994; Edelson et al., 1998) concepts were developed in Japan and in the United\nStates. Both concepts are quite similar, in the sense that both require the movement of the antenna to\nform a brightness temperature image after matched filtering of the measured visibility function (as a\nfunction of time) with the impulse response of a point source in each single position of FOV to achieve\nspatial resolution.\n\nIf the antenna array is moving, this is equivalent to having a brightness temperature image\nTpq(x,h,t) moving in the opposite direction. For simplicity, it will be assumed that the array is a linear\narray at a height zm,n \u00bc h, moving along the X-axis at constant speed v, and that Tpq(x,h) is a point\nsource at (x0,0,0), as illustrated in Fig. 4.109. It will be assumed as well that antenna patterns are\nidentical, and that fringe-washing effects are negligible, which means that the maximum antenna\nspacing is much smaller than the coherence distance c/B.\n\nFIGURE 4.109\n\nConcept of a supersynthesis radiometer or RadSAR. Long stick antennas are used to spatially filter a dwell\n\nline. Swath can be increased with a multibeam antenna as in a push-broom configuration.\n\n4.6 SENSORS 259\n\nmailto:Image of Figure 4.109|tif\n\n\nUnder these conditions, Eq. (4.70) can be rewritten in Cartesian coordinates as:\n\nVpg umn; vmn; t\u00f0 \u00de \u00bc 1ffiffiffiffiffiffiffiffiffiffiffiffi\nUmUn\n\np\nZZ\n\nx2\u00feh2?1\n\nTpq x;h; t\u00f0 \u00de ? Tphdmnffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\np Fm x; h\u00f0 \u00deF?n x; h\u00f0 \u00de\n\n$ermn ?umnx\u00fe vmn;h\u00fe wmn\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\nq\nf0\n\n0@ 1A\n$exp ?j2p umnx\u00fe vmnh\u00fe wmn\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\nq\n ?\n ?\ndxdh\n\n\u00bc 1ffiffiffiffiffiffiffiffiffiffiffiffi\nUmUn\n\np\nZ \u00feN\n?N\n\nZ \u00feN\n?N\n\nTpq x; y; t\u00f0 \u00de ? Tphdmn\n? ?\n\n$Fm x; y\u00f0 \u00deF?n x; y\u00f0 \u00deexp ?j\n2p\n\nl\nr2 t\u00f0 \u00de\u00f0 \u00de ? r1 t\u00f0 \u00de\u00f0 \u00de\n\n\n ?\ndxdy\n\n\u00bc 1ffiffiffiffiffiffiffiffiffiffiffiffi\nUmUn\n\np Tpq x0; y0\u00f0 \u00dejF x0; y0\u00f0 \u00dej2 exp ?j 2p\nl\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nx2 \u00fe vt ? x0\u00f0 \u00de2 \u00fe h2\n\nq\n\n\n?\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nx1 \u00fe vt ? x0\u00f0 \u00de2 \u00fe h2\n\nq\n\u00de\u00dedxdy (4.117)\n\nwhere r1,2(t) are the distances from the pixel being focused on the antennas. In Eq. (4.117) the phase of\nthe \u201cinstantaneous visibility function\u201d is:\n\n4\u00f0t\u00de \u00bc ?2p\nl\n\n\n ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\u00f0x2 \u00fe v $ t ? x0\u00de2 \u00fe h2\n\nq\n?\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\u00f0x1 \u00fe v $ t ? x0\u00de2 \u00fe h2\n\nq ?\n; (4.118)\n\nfrom which the instantaneous frequency can be defined as:\n\nfinst\u00f0t\u00de \u00bc ? 1\n2p\n\n$\nv4\u00f0t\u00de\nvt\n\n; (4.119)\n\nalthough it should be estimated in practice from discrete differences from consecutive measurements\ntn \u00bc n $ s:\n\nfinst\u00f0tn\u00de \u00bc ? 1\n2p\n\n$\n4V\u00f0tn\u00de ? 4V\u00f0tn?1\u00de\n\ns\n. (4.120)\n\nAs in a synthetic aperture radar, the image focusing consists of applying a matched filter so as to\ncompensate the phase modulation history of each target in the scene, while the phase of other targets is\nnot, and their contribution vanishes during the integration. We present an example of the phase history\nof two targets at 0 and 25 km in Fig. 4.110, as would be observed by a supersynthesis radiometer at\n800 km height, at 7.5 km/s speed, with a baseline of 4 m at a frequency of 1.413 GHz.\n\n260 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nAs in a synthetic aperture radar, the wider the elementary antenna beam, the longer the integration\ntime, and the better the achievable angular resolution, which is given by Komiyama et al. (1994, 1997),\nKomiyama and Kato (1995, 1996), Komiyama (1998):\n\n4s \u00bc 0:886\n1\n\nd$4A\n; (4.121)\n\nwhere d is the baseline (antenna spacing), and fA is the antenna beam width in the along-track\ndirection (the direction in which the synthetic aperture is formed). The factor 0.886 is due to the\nuniform weighting (windowing) of the visibility samples during the focusing, but may be larger if they\nare tapered to reduce the amplitude of the side lobes of the synthetic pattern.\n\nOne consideration that has to be taken into account is that the maximum baseline (d \u00bc x1 ? x2) is\nsmaller than the coherence distance (c/B) so that the correlation is not lost. One way to increase the\nmaximum baseline is to reduce the bandwidth, but this reduces the radiometric precision. Alterna-\ntively, the integration (focusing) can be performed over a shorter period of time so that the coherence is\npreserved: ????t???? ? h $ sin qi;maxv ; (4.122)\n\nFIGURE 4.110\n\nUnwrapped phase history of the cross-correlation corresponding to two targets at positions x0 \u00bc 0 km (red)\nand x0 \u00bc \u00fe25 km (blue), which allows us to focus it and isolate it from the rest.\n\n4.6 SENSORS 261\n\nmailto:Image of Figure 4.110|tif\n\n\nwhere:\n\nsin qi;max \u00bc c\nd $B\n\n; (4.123)\n\nalthough this translates into a poorer angular resolution. Another possibility consists of applying\nsubbanding, i.e., dividing the original band into smaller ones so that the above condition is met.\n\nAlthough computationally far more complex, an alternative solution consists of the use a variable true-\ntime delay for each pixel to be focused so that the maximum baseline is no longer limited by the coherence\ndistance. This concept is the \u201cDoppler-delay radiometer\u201d (Camps and Swift, 2001) which uses just three\nantennas, which was later extended to a larger number of antennas motion induced synthetic aperture\nradiometer (MISAR) to recover part of the radiometric resolution lost (Park and Kim, 2009a,b).\n\n4.6.4.1.3 Synthetic Aperture Radiometers using Fourier Synthesis\nAs real aperture microwave radiometers, synthetic aperture microwave radiometers were first devised\nin radio-astronomy as a means to achieve high angular resolution, with \u201cmoderate size\u201d antennas\n(Thompson et al., 1986). The very large array (VLA), a turning point in radio-astronomy using syn-\nthetic aperture microwave radiometers is depicted in Fig. 4.111.\n\n(A)\n\n(B)\n\nFIGURE 4.111\n\n(A) Aerial view of the very large array\n\n(VLA), New Mexico, Socorro (United\n\nStates), and (B) view of the\n\n\u201celementary\u201d antennas forming the\n\nVLA array.\n\nCourtesy of NRAO.\n\n262 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.111|eps\n\n\nIts application to Earth observation was first proposed by LeVine and Good in 1983. This led to the\nconcept of the ESTAR instrument (illustrated in Fig. 4.112) that performed aperture synthesis in the\ncross-track dimension and achieved angular resolution in the along-track dimension by means of long\nantennas. The concept was demonstrated in the late 1980s with the ESTAR instrument prototype\ndesigned and built at the University of MassachusettsdAmherst (Tanner, 1990; Tanner and Swift,\n1993; Ruf et al., 1988).\n\nDespite the fact that the main concept is similar, the differences between radio-astronomy and\nEarth observation are important:\n\n\u2022 In radio-astronomy the antenna spacing is very large and the antennas are very directive, this\ndecreases the antenna coupling, which allows the use of simpler image reconstruction\napproaches. Antenna coupling distorts the antenna voltage radiation pattern, which will have to be\nvery well characterized and corrected for during the image reconstruction process. Differences in\nthe antenna patterns have proven to be one of the main limitations in the accuracy error budget of\nsynthetic aperture radiometers.\n\n\u2022 In radio-astronomy, the FOV is very narrow, as opposed to Earth observation, in which the FOV\nmay easily be 60? from a LEO.\n\n\u2022 Due to the narrow FOV (q z 0?), in radio-astronomy the obliquity factor\n(1=cos q \u00bc 1\n\n. ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? x2 ? h2\n\np\n) can be approximated by 1.\n\nFIGURE 4.112\n\n1D aperture synthesis radiometer scanning configuration is similar to a push-broom.\n\n4.6 SENSORS 263\n\nmailto:Image of Figure 4.112|tif\n\n\n\u2022 In addition, due to the narrow FOV, antenna patterns are approximately constant (amplitude and\nphase) over the FOV.\n\n\u2022 In radio-astronomy the brightness temperature scenes are typically quasipoint sources imaged\nover a cold background, this allows us to use super-resolution image reconstruction algorithms, as\nopposed to Earth observation, in which the brightness temperatures have very low contrast,\noccupy the whole FOV, or even more, and may not even exhibit the Earthesky contrast due to\naliasing during the imaging process.\n\nAfter the success of ESTAR, ESA pushed for and evolved a concept that performed 2D aperture\nsynthesis. It was the MIRAS instrument that ended up being the single payload of ESA\u2019s SMOS Earth\nExplorer Opportunity Mission (Font et al., 2010; Kerr et al., 2010). We illustrate this concept in\nFig. 4.113.\n\nThe principles of operation of 1D and 2D synthetic aperture radiometers are quite similar, although\nthere are some differences. The fundamentals were already presented in Section 4.6.2.2.2, but are\nbriefly revised here, since they have implications in the selection of the array topology.\n\nThe basic observable is the so-called visibility function Vpqmn, measured as the cross-correlation of\neach pair of signals bp;qm;n\u00f0t\u00de collected by the array antennas m and n, at p- and q-polarizations, located\nover the z plane (i.e., z\u00bc0). Since the antennas occupy specific locations in the array, the visibility\nfunction is not measured continuously, but sampled at particular wave numbers (umn,vmn) determined\nby the antenna positions, normalized to the wavelength.\n\nFIGURE 4.113\n\n2D aperture synthesis radiometer imaging configuration as in microwave imaging radiometer by aperture\n\nsynthesis in Soil Moisture and Ocean Salinity.\n\n264 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.113|tif\n\n\nVpqmn b\u00bc Vpq\u00f0umn; vmn\u00de \u00bc 1kB ffiffiffiffiffiffiffiffiffiffiffiBmBnp ffiffiffiffiffiffiffiffiffiffiffiffiGmGnp 12 ?bpm\u00f0t\u00debq?n \u00f0t\u00de?; (4.124)\nwith:\n\n\u00f0umn; vmn\u00de \u00bc \u00f0xn ? xm; yn ? ym\u00de=l0 \u00bc \u00f0Dxmn;Dymn\u00de=l0. (4.125)\nThe brightness temperature\n\nTpq\u00f0x; h\u00de \u00bc Fn1\u00f0x; h\u00deF\n?\nn2\n\u00f0x; h\u00deffiffiffiffiffiffiffiffiffiffiffi\n\nU1U2\np TB\u00f0x; h\u00de ? Tph recffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\n1? x2 ? h2\np ; (4.126)\n\nwith the director cosines defined as:\n\n\u00f0x; h\u00de \u00bc \u00f0sin q cos f; sin q sin f\u00de; (4.127)\ncan be then reconstructed in the ideal case (identical antenna patterns, negligible spatial decorrelation\neffects, and no antenna positioning errors), as a 1D or 2D Fourier process:\n\nTpq\u00f0x; h\u00de \u00bc F?1\u00bdVpq\u00f0umn; vmn\u00de?. (4.128)\nDue to the crucial impact of this in the array topology, antenna spacing selection, number of\n\ncomplex correlators, etc., this will be analyzed in more detail in the following sections for the 1D and\n2D cases.\n4.6.4.1.3.1 1D Synthetic Aperture Radiometers: Array Thinning. In a full linear array of N antennas\nequally spaced d wavelengths, V(u) \u00bc V(u, v \u00bc 0) can be measured N times at u \u00bc 0, N ? 1 times at\nu \u00bc 1d, N ? 2 times at u \u00bc 2d; etc. and only once at umax \u00bc (N ? 1)d. This is obviously an inefficient\nuse of the available antennas, since most of the measurements are redundant. In 1955, Arsac found that\ngreater efficiency can be achieved by spacing the N antennas out in such a way that the greatest\nmultiple of d, umax \u00bc Nmax $ d, is greater than (N ? 1)d and all multiples up to umax are also present.\n\nThe so-called \u201crestricted\u201d minimum-redundancy problem is to find, for a given N, a spacing pattern\nof this kind that has maximum efficiency (minimum redundancy). The \u201cgeneral\u201d problem allows Nmax\nto be greater than the numberM for which all multiples of d up toM$d are present. The redundancy R is\nquantitatively defined as the number of pairs of antennas divided by Nmax (Moffet, 1968):\n\nR \u00bc 1\n2\n$\nN $ \u00f0N ? 1\u00de\n\nNmax\n; (4.129)\n\nFor N ? 4 Arsac (1955) found arrays with R \u00bc 1 (\u201czero-redundancy\u201d linear arrays or ZRLAs), and\nBracewell (1966) proved that these are the only ZRLAs. In 1956, Leech provided some optimum\nsolutions for N ? 11 and demonstrated that 1.217 ? R ? 1.332 for N /N. Although the solutions\nprovided for N ? 11 were not zero-redundant, the redundancy was the lowest possible (R \u00bc Ropt > 1:\nminimum-redundancy linear arrays, MRLA). For larger values of N > 11, the optimum solutions have\nnot been found, but some semiempirical and numerical array patterns that approach Leech\u2019s bounds\n(low-redundancy linear arrays, LRLA) have been found (Leech, 1956; Ishiguro, 1980; Ruf, 1993;\nTrucco et al., 1997; Rossouw et al., 1997).\n\nTable 4.8 from Camps et al. (2002) summarizes the ZRLA, MRLA, and LRLA with some new\nLRLA found in Camps et al. (2002). The nomenclature used to denote an array of N antennas is a\nbracketed list of N ? 1 numbers {x; y; .; z} indicating the spacing between adjacent antennas. For\n\n4.6 SENSORS 265\n\n\n\nTable 4.8 Comparison of Existing Zero-Redundancy Linear Array (ZRLA), Minimum-Redundancy Linear\nArray (MRLA), and Low-Redundancy Linear Array (LRLA)With New LRLAObtained by a RecursiveMethod\nProposed in Camps et al. (2002)\n\nNumber of\nAntennas\n(N)\n\nMaximum\nArray\nSpacing\n(Nmax) Pattern\n\nRedundancy\n(R)\n\nComments\n(Array\nFamily)\n\n1 0 {0} 1.00 ZRLA [1]\n\n2 1 {1} 1.00 ZRLA [1]\n\n3 3 {1,2} 1.00 ZRLA [1] (A)\n\n4 6 {1,3,2} 1.00 ZRLA [1] (A)\n\n5 9 {1,3,3,2} 1.11 MRLA [1,3] (A)\n\n{1,1,4,3} (B)\n\n6 13 {1,1,4,4,3} 1.15 MRLA [l,3] (B)\n\n{1,5,3,2,2} (C1)\n\n{1,3,1,6,2}\n\n7 17 {1,1,4,4,4,3} 1.24 MRLA [1,3] (B)\n\n{1,7,3,2,2,2} (C1)\n\n{1,3,6,2,3,2} (D)\n\n{1,1,6,4,2,3}\n\n{1,1,6,4,3,2}\n\n{1,1,1,5,5,4}\n\n8 23 {1,1,9,4,3,3,2} 1.22 MRLA [1.3] (C2)\n\n{1,3,6,6,2,3,2} (D)\n\n9 29 {1,2,3,7,7,4,4,1} 1.24 MRLA [1,3] (E)\n\n{1,1,12,4,3,3,3,2} (C2)\n\n{1,3,6,6,6,2,3,2} (D)\n\n10 36 {1,2,3,7,7,7,4,4,1} 1.25 MRLA [1,3] (E)\n\n11 43 {1,2,3,7,7,7,7,4,4,1} 1.28 MRLA [1,3] (E)\n\n12 50 {1,2,3,7,7,7,7,7,4,4,1} 1.32 LRLA [6]\n\n{1,1,1,20,5,4,4,4,4,3,3} New LRLA\n\n13 58 {1,2,3,11,3,7,8,10,4,4,4,1} 1.34 LRLA [6]\n\n{1,1,1,24,5,4,4,4,4,4,3,3} New LRLA\n\n{1,4,3,4,9,9,9,9,5,1,2,2} New LRLA\n\n{1,3,7,3,9,9,9,9,2,4,1,1} New LRLA\n\n{1,1,6,7,1,10,10,10,3,4,2,3} New LRLA\n\n14 68 {1,1,6,6,6,11,11,11,5,5,3,1,1} 1.34 LRLA [6]\n\n{1,1,6,7,1,10,10,10,10,3,4,2,3} New LRLA\n\n15 79 {1,1,6,6,6,11,11,11,11,5,5,3,1,1} 1.33 LRLA [6]\n\n16 90 {1,1,6,6,6,11,11,11,11,11,5,5,3,1,1} 1.33 LRLA [6]\n\n17 101 {1,1,6,6,6,11,11,11,11,11,11,5,5,3,1,1} 1.35 LRLA [6]\n\n18 112 {1,1,6,6,6,11,11,11,11,11,11,11,5,53,1,1} 1.37 LRLA [6]\n\n266 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nTable 4.8 Comparison of Existing Zero-Redundancy Linear Array (ZRLA), Minimum-Redundancy Linear\nArray (MRLA), and Low-Redundancy Linear Array (LRLA) With New LRLAObtained by a Recursive Method\nProposed in Camps et al. (2002)dcont\u2019d\n\nNumber of\nAntennas\n(N)\n\nMaximum\nArray\nSpacing\n(Nmax) Pattern\n\nRedundancy\n(R)\n\nComments\n(Array\nFamily)\n\n19 121 {1,1,1,1,1,45,8,7,6,6,6,6,6,6,6,5,5,4} 1.41 LRLA [6]\n\n123 {1,1,6,6,6,11,11,11,11,11,11,11,11,5,5,!,1,1} 1.39 New LRLAb\n\n20 133 {1,1,2,5,7,7,1,13,13,13,13,13,13,13,6,6,4,1,1} 1.43 LRLA [6]\n\n134 {1,1,6,6,6,11,11,11,11,11,11,11,11,11,5,5,3,1,1} 1.42 New LRLAb\n\n21 145 {1,1,1,1,1,1,53,9,6,5,8,7,7,7,7,7,7,4,6,6} 1.45 LRLA [6]\n\n{1,2,1,1,1,5,5,5,14,14,14,14,14,14,14,9,4,9,3,1} New LRLA\n\n22 160 {1,2,6,6,8,1,13,13,8,5,13,13,13,13,\n13,13,5,2,5,4,3}\n\n1.44 LRLA [6]a\n\n159 {1,2,1,1,1,5,5,5,14,14,14,14,14,14,\n14,14,9,4,9,3,1}\n\n1.45 New LRLAb\n\n{1,1,1,1,1,1,60,9,6,5,8,7,7,7,7,7,7,7,4,6,6} New LRLAb\n\n23 173 {1,2,1,1,1,5,5,5,14,14,14,14,14,14,14,\n14,14,9,4,9,3,1}\n\n1.46 LRLA [6]\n\n24 188 {1,2,3,1,1,5,2,5,7,16,16,16,16,16,16,16,\n16,9,9,4,7,2,2}\n\n1.47 LRLA [6]\n\n191 {1,1,1,1,8,1,9,9,9,17,17,17,17,17,17,17,\n8,8,8,5,1,1,1}\n\n1.45 New LRLAb\n\n25 208 {1,1,1,1,8,1,9,9,9,17,17,17,17,17,17,17,17,\n8,8,8,5,1,1,1}\n\n1.44 LRLA [6]\n\n26 225 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,17,17,9,\n9,1,9,9,1,1,1}\n\n1.44 LRLA [6]\n\n27 236 {1,1,2,6,3,6,6,16,16,16,16,16,16,16,16,16,16,\n16,10,3,4,3,7,3,4,1}\n\n1.49 LRLA [6]\n\n242 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,17,17,\n17,9,9,1,9,9,1,1,1}\n\n1.45 New LRLAb\n\n28 257 {1,1,1,5,8,7,1,7,17,17,17,17,17,17,17,\n17,17,17,17,9,9,9,6,3,1,1,1}\n\n1.47 LRLA [6]\n\n259 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,\n17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.46 New LRLAb\n\n29 270 {1,1,3,2,2,20,2,1,19,19,19,19,19,19,\n19,19,19,19,16,1,4,3,9,1,3,8,2,1}\n\n1.50 LRLA [6]\n\n276 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,17,\n17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.47 New LRLAb\n\n30 287 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,19,\n19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.52 LRLA [6]\n\n293 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,17,\n17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.48 New LRLAb\n\n31 306 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,\n19,19,19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.52 New LRLA\n\nContinued\n\n4.6 SENSORS 267\n\n\n\nexample, the ZRLA {1,3,2} is a four-antenna array that looks like xxooxox (Fig. 4.114A) where\ncrosses indicate positions occupied by an antenna, and circles are empty positions. The MRLA\n{1,3,3,2} is a five-antenna array that looks like xxooxooxox (Fig. 4.114B). As we can clearly see, just\nadding one more antenna the maximum antenna spacing passes from 6d up to 9d, adding just one\nredundant baseline (3d), indicated with a dashed arrow. Adding another antenna will increase the\nmaximum antenna spacing up to 13d, which illustrates the advantages of the array thinning in terms of\nhardware savings.\n\nTable 4.8 Comparison of Existing Zero-Redundancy Linear Array (ZRLA), Minimum-Redundancy Linear\nArray (MRLA), and Low-Redundancy Linear Array (LRLA) With New LRLAObtained by a Recursive Method\nProposed in Camps et al. (2002)dcont\u2019d\n\nNumber of\nAntennas\n(N)\n\nMaximum\nArray\nSpacing\n(Nmax) Pattern\n\nRedundancy\n(R)\n\nComments\n(Array\nFamily)\n\n310 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,\n17,17,17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.50 New LRLAb\n\n32 325 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,19,19,\n19,19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.53 New LRLA\n\n327 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,17,17,17,\n17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.52 New LRLAb\n\n33 344 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,19,19,\n19,19,19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.53 New LRLAb\n\n344 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,\n17,17,17,17,17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.53 New LRLAb\n\n34 363 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,19,19,19,\n19,19,19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.55 New LRLAb\n\n361 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,\n17,17,17,17,17,17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.55 New LRLA\n\n35 382 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,19,19,\n19,19,19,19,19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.56 New LRLAb\n\n378 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,17,17,17,\n17,17,17,17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.57 New LRLA\n\n36 401 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,19,19,19,19,\n19,19,19,19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.57 New LRLAb\n\n395 {1,1,1,2,2,3,8,8,8,17,17,17,17,17,17,17,17,17,\n17,17,17,17,17,17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.59 New LRLA\n\n37 420 {1,1,12,2,6,6,8,6,19,19,19,19,19,19,19,19,19,19,\n19,19,19,19,19,19,19,19,11,2,5,6,3,2,2,3,1,1}\n\n1.59 New LRLAb\n\n412 {1,1,1,2,3,8,8,8,17,17,17,17,17,17,17,17,17,17,\n17,17,17,17,17,17,17,17,17,17,9,9,1,9,9,1,1,1}\n\n1.62 New LRLA\n\naThere is a typographical error in (Ruf, 1993), since there are 12 antenna spacing missing in the pattern given for N \u00bc 22, Nmax \u00bc 160.\nbNew and largest LRLAs with the least redundancies reported up to date.\n\n268 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nFIGURE 4.114\n\n(A) Zero-redundancy linear array (ZRLA) {1,3,2} with 4 antennas and a maximum baseline \u00bc 6d, and (B)\nminimum-redundancy linear array (MRLA) {1,3,3,2} with 5 antennas, maximum baseline 9d and only one\n\nredundant baseline (3d). Dark gray circles indicate the antenna positions. Light gray circles indicate the\n\npositions where there is no longer an antenna. In a full array ZRLA {1,3,2} will have 7 antennas, while MRLA\n\n{1,3,3,2} will have 10 antennas.\n\nIt is worth noting that the effective length of a synthetic array is twice the maximum antenna separation\nsince\n\n?\nbm\u00f0t\u00de $ b?n\u00f0t\u00de\n\n? \u00bc ?bn\u00f0t\u00de $ b?m\u00f0t\u00de??. Therefore the angular resolution is roughlywl/(2 $ Nmax $ d)\ninstead of wl/(Nmax $ d), at the expense of higher side lobes (twice higher in dBs).\n4.6.4.1.3.2 2D Synthetic Aperture Radiometers: Array Topologies. In 2D synthetic aperture radi-\nometers, there is not much interest in thinning the array due to the inherent low level of redundancy.\nFor example, a Y-shaped array, such as the one in Fig. 4.115A, with N elements in each arm, and one in\nthe center (3N \u00fe 1 in total), will have NNRV non-Hermitian (u,v) points:\n\nNNRV \u00bc 3N2 \u00fe 3N \u00fe 1; (4.130)\nwhile the total number of independent cross-correlations is:\n\nNRV \u00bc 1\n2\n$ \u00f03N \u00fe 1\u00de $ 3N. (4.131)\n\nAs in the definition of the 1D case, it should be noted that in Eqs. (4.130) and (4.131) Hermitian\nvisibilities (V(?u,?v) \u00bc V?(u,v)) have not been accounted for since?\nbm\u00f0t\u00de $ b?n\u00f0t\u00de\n\n? \u00bc ?bn\u00f0t\u00de $ b?m\u00f0t\u00de??.\nThe level of redundancy is:\n\nR \u00bc\n1\n\n2\n$ \u00f03N \u00fe 1\u00de $ 3N\n3N2 \u00fe 3N \u00fe 1 ; (4.132)\n\nwhich tends to 3/2 as N / N, as shown in Fig. 4.115B.\nThe shape of the array determines the sampling of the spatial frequency plane, and how the aliases\n\nwill be repeated. The \u201caliases\u201d are periodic repetitions of the main image that are formed during the\n\n4.6 SENSORS 269\n\nmailto:Image of Figure 4.114|tif\n\n\nFIGURE 4.115\n\n(A) Y-array with 10 elements, 3 elements per arm (red circles), leading to 73 (u,v) points, from which 36\n\ncorrespond to non-Hermitian visibilities plus the zero baseline (Eq. 4.130). (B) Redundancy level (Eq. 4.132)\n\nas a function of N the number of elements per arm.\n\nFourier synthesis process. Arrays whose arms are oriented forming 90? (e.g., T- or U-shaped arrays)\nwill lead to (u,v) points distributed over a rectangular grid, and alias images also centered over a\nrectangular grid (Fig. 4.116A). Arrays whose arms are oriented 120? apart (e.g., a Y-, or a D-, or a\nhexagonal-array) will lead to (u,v) points distributed over a hexagonal grid, and alias images also\ncentered over a hexagonal grid (Fig. 4.116B).\n\nAntenna spacing dictates the separation of the alias images in the (x,h) domain. Since the\nwhole semispace in front of the antenna array is mapped into the unit circle, that is\n0? ? q ? 90?,0? ? 4 < 360? map into x2 \u00fe h2 ? 1, for rectangular sampling the minimum antenna\nspacing to avoid aliasing is d \u00bc l/2 (Fig. 4.116A), while for hexagonal sampling it is\n\n270 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.115|tif\n\n\nFIGURE 4.116\n\nUnit circle (blue) where the whole brightness temperature in front of the array is mapped, and alias images of\n\nthe unit circle (red), for (A) rectangular sampling (d \u00bc l/2) and (B) hexagonal sampling (d \u00bc l\n. ffiffiffi\n\n3\np\n\n).\n\nd \u00bc l? ffiffiffi3p \u00bc 0:577l (Fig. 4.116B). This translates into a 15.5% savings in terms of antennas and\nreceivers (0.577l as compared to 0.5l), and a 33.3% (\u00bc1.1552) in correlators as compared to the\nrectangular sampling case. This can be intuitively understood as the savings in the space between the\ncircles that do not correspond to any physical direction. Actually, since the physical space maps into\nthe unit circle, it can be demonstrated that hexagonal sampling is the optimum one, and from all array\ntopologies, the Y-shaped array is the one providing the largest (u,v) coverage, and therefore the best\nangular resolution (Camps et al., 1997).\n\nIn practice, the antenna spacing can be larger than the minimum required not to have aliasing, since\nthe FOV does not have to cope with the whole unit circle, for example, in SMOS (Font et al., 2010;\nKerr et al., 2010), the ground incidence angle can be smaller than 90? (d \u00bc 0.875l, Fig. 4.117), or in\n\n4.6 SENSORS 271\n\nmailto:Image of Figure 4.116|tif\n\n\nPATH (https://directory.eoportal.org/web/eoportal/satellite-missions/g/geostar) or in GAS (Christensen\net al., 2007) the Earth will be seen from a geostationary orbit and therefore the Earth disk occupies only a\ndisk of radius 0.3 (0? ? q ? 17?,0? ? 4 < 360?, that is x2 \u00fe h2 ? 0.32).\n\nOther array configurations exist, including nonuniform antenna spacing (Camps et al., 2008),\ncircular array such as in GIMS (Zhang et al., 2013), random arrays, etc., but they have to be analyzed\nnumerically.\n4.6.4.1.3.3 Other Synthetic Aperture Radiometer Concepts. Other synthetic aperture microwave\nradiometer concepts involve, for example, 1D or 2D synthetic aperture radiometers such as ESTAR or\nMIRAS, with a certain tilt angle and with a conical scan so as to enlarge the swath width, while,\npotentially, reducing the range of incidence angles. These concepts have been studied by Martin-Neira\nand Font-Rosello (1997) and are sketched in Fig. 4.118.\n\nOther concepts involve 1D synthetic aperture radiometry and frequency scanned antennas, as\nillustrated in Fig. 4.119.\n\n4.6.4.2 Radiometer Calibration\nThe calibration of a synthetic aperture radiometer is a very complex process, but conceptually, it is\nsimilar to that of real aperture radiometers, involving two steps:\n\n\u2022 An internal calibration first, prior to the image reconstruction, to correct for the relative errors of\neach visibility sample (cross-correlation) to prevent image aberration, and\n\n\u2022 An external calibration to set the absolute value and the gain (equivalent to the \u201cbrightness\u201d and\n\u201ccontrast\u201d of an image), and involves the measurement of external known targets.\n\nThese procedures are explained in the next sections.\n\n(B)\n\n200\n\n400\n\nal\non\n\ng-\ntra\n\nck\n c\n\noo\nrd\n\nin\nat\n\ne \n[k\n\nm\n]\n\n600\n\n800\n\n1000\n\n0\ncross-track coordinate [km]\n\n200 400 600 800 1000-200-400-600-800-1000\n\n-2\n\n-1\n\n0\n\n1\n\n-0.5\n\n0.5\n\n1.5\n\n?\n\nhsat=755, tilt=32.00\u00ba, d=0.88\nUnit circle\n\nPrincipal domain\nof (?,?) points\n\nAlias-free Field Of View\n\n-2 -1 0 1 2\n?\n\nEqui-incidence\nangle contours\n\nEarth \u201caliases\u201d\n\nEarth contour\n\n0\n9\n\n8\n\n20\n\n20 30\n30\n\n40\n8 6\n\n5 40\n\n50\n\n60\n\n6\n7\n\n8\n\n9\n\n7\n10\n\nnadir\n\nboresight\n\n(A)\n\nFIGURE 4.117\n\nAliasing in the microwave imaging radiometer by aperture synthesis instrument aboard European Space\n\nAgency\u2019s Soil Moisture and Ocean Salinity mission. (A) Antenna spacing is d \u00bc 0.875l, which induces some\nlevel of aliasing, but despite it, (B) the swath width is w1000 km and the range of incidence angles extends\n0?ew60?.\n\n272 CHAPTER 4 MICROWAVE RADIOMETRY\n\nhttps://directory.eoportal.org/web/eoportal/satellite-missions/g/geostar\nmailto:Image of Figure 4.117|eps\n\n\nFIGURE 4.118\n\n(A) 1D and (B) 2D synthetic aperture radiometers with a tilt angle b and a conical scan.\n\n4.6 SENSORS 273\n\nmailto:Image of Figure 4.118|tif\n\n\n4.6.4.2.1 Internal Calibration\nIf in a real aperture radiometer (nonpolarimetric) the basic calibration equations are:\n\nVd \u00bc 1\na\n\u00f0TA ? b\u00de; (4.133a)\n\nTA \u00bc a$Vd \u00fe b; (4.133b)\nthe internal calibration of a synthetic aperture radiometer is a quite complex procedure and requires a\ndetailed instrument error model. The interested reader is referred to Corbella et al. (2005) for a detailed\ndescription. For the sake of clarity, a conceptually simpler case is explained first, in which there are no\nquadrature errors,12 and instrumental errors are said to be separable, that is, they can be assigned to\neach particular receiver forming the baseline.\n\nThe basic calibration equation (simplified case) of the baseline (complex cross-correlation) formed\nbetween the signals collected by antennas m and n of a synthetic aperture radiometer is:\n\nVmn \u00bc Amn $Rmn \u00fe Bmn; (4.134)\n\nFIGURE 4.119\n\n1D synthetic aperture radiometer: array is thinned in the cross-track direction and scanning in the along-track\n\ndirection is performed by frequency scanned elementary antennas.\n\n12Quadrature errors refer to the error in the I/Q demodulators by which the in-phase and the quadrature components are not\northogonal. This error can be (is) frequency-dependent within the instrument\u2019s bandwidth.\n\n274 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.119|tif\n\n\nwhere Vmn is the calibrated visibility sample, Rmn is the measured cross-correlation (after inversion of\nthe correlator transfer function), and Amn and Bmn are complex amplitude and offset terms. Since the\nobservables are complex cross-correlations, the amplitude and offset can be determined when\ncorrelated and uncorrelated signals are present at receivers\u2019 inputs, respectively. Since in microwave\nradiometry the correlators often use just a few bits (or even just one as in MIRAS/SMOS) the measured\ncross-correlation is a distorted version of the cross-correlation that would be measured by an analog or\na multibit correlator (e.g., Eq. 4.95 for the 1 bit/2 level case). Therefore, since the particular form of the\ncorrelation function depends on the signal statistics, it is crucial that the input signals used for cali-\nbration purposes exhibit the same statistics. This can be achieved using either true noise signals, or\npseudorandom signals with a flat spectrum over the receiver\u2019s bandwidth (Ramos-Perez et al., 2009).\n\nThe offset term can be corrected for by connecting matched loads to receivers\u2019 inputs, since each\nmatched load will be generating an uncorrelated noise signal with a power equal to kB $ Tph $ B.\n\nThe amplitude term can be corrected for (after proper offset correction) by injecting a common\ncorrelated noise to all receivers simultaneously. However, since the noise distribution networks or\nNDNs (power splitters) used to distribute the common correlated noise signal introduce correlated\nnoise themselves as well, the common correlated noise must be of much higher level than the one\ngenerated by the NDNs themselves. This common correlated noise can be generated by a common\nnoise source such as the solid-state hot noise sources discussed before. Since the correlated noise\ngenerated by the NDNs is additive, it can be canceled out by subtracting two measurements with\ndifferent levels of the common correlated noise.\n\nThis procedure is sketched in Fig. 4.120, and summarized in the following equations assuming an\nideal 1:N NDN, so that the input correlated noise signals are in-phase and have a power equal to TN/N:\n\n\u2022 for the uncorrelated noise injection:\n\n0 \u00bc Amn $R\u00f03\u00demn \u00fe Bmn; (4.135)\n\nFIGURE 4.120\n\nBasic calibration concept of a baseline of a synthetic aperture radiometer. Input switch position: (1) antenna\n\nmeasurement, (2) correlated noise injection either at TN1 or TN2 levels, and (3) uncorrelated noise injection.\n\n4.6 SENSORS 275\n\nmailto:Image of Figure 4.120|tif\n\n\n\u2022 for the correlated noise injection:\n\nTNhot\nN\n\n\u00fe Toffset;NDN \u00bc Amn $R\u00f03;hot\u00demn \u00fe Bmn; (4.136a)\nTNcold\nN\n\n\u00fe Toffset;NDN \u00bc Amn $R\u00f03;cold\u00demn \u00fe Bmn; (4.136b)\n\nSubtracting Eqs. (4.136a) and (4.136b), the complex amplitude term can be derived:\n\nAmn \u00bc \u00f0TNhot ? TNcold\u00de=N\nR\n\u00f03;hot\u00de\nmn ? R\u00f03;cold\u00demn\n\n; (4.137a)\n\nand replacing Eq. (4.137a) into Eq. (4.135), the complex offset term can be derived:\n\nBmn \u00bc 0? Amn $R\u00f03\u00demn . (4.137b)\nThe parallelism between the internal calibration of a baseline of a synthetic aperture radiometer\n\nand a real aperture radiometer becomes evident when comparing Eqns. (4.136a,b) and (4.137a,b) with\nEqns. (4.107a,b) and (4.108a,b).\n\nIn this simplified case, the complex amplitude terms Amn can be factored as the product of two\nterms, associated to each of the receiving channels involved:\n\nAmn \u00bc Am $A?n \u00bc\n???Am??? $ ???An??? $ ej\u00f0fm?fn\u00de. (4.138)\n\nThis assumption is not completely true in the general case, and more sophisticated methods have to\nbe used. However, it holds in many cases in radio-astronomy and allows to some particular external\ncalibration methods that will be described afterwards.\n\n4.6.4.2.2 External Calibration\n\n\u2022 The external calibration of the instrument is used for the absolute calibration of the NIR by viewing\nknown cold scenes, similar to many other real aperture radiometers (e.g., SSM/I in Section 4.6.3.5).\nThe cold sky is obtained by inertial pointing the MIRAS instrument towards the galactic poles, so as to\nminimize the impact of the Galactic plane (see Section 4.2.2, Fig. 4.10), and an internal matched load\nplaced in each NIR, and at a well-monitored physical temperature. The calibration of the NIR (actually\nthree redundant NIRs in the case of MIRAS/SMOS) provides the absolute value of the scene:\n\nTpqA bV\npq\u00f00; 0\u00de; (4.139)\n\nand serves as reference for the calibration of the on-board noise diodes, and the power measurement\nsystem (PMS) of each receiver (acting as a TPR), used to denormalize the visibility samples.\n\u2022 The measurement of the flat-target response (FTR) (Martin-Neira et al., 2008), which is the\n\ninstrument response to a scene as homogeneous as possible, allows us to compensate for the\ntermeTph $ dpq in Eq. (4.70) and improves the instrument performance since it reduces the impact\nof the antenna pattern errors which are of a multiplicative nature. The measurement of the FTR\nmust be as clean as possible from any perturbation, including the Sun, the Galaxy plane, the Earth\nthrough the antenna back lobes, attitude pointing errors from zenith, etc.\n\n276 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\n\u2022 The ocean target transformation (OTT) proposed by Tenerelli and Reul (2010) compensates\nfor the residual instrument calibration errors and, mainly, the antenna imperfect characterization\nthat, after the image reconstruction algorithm, induces ripples in the brightness temperature\nimages. The OTT is an additive mask that is applied to each pixel over the ocean and has proven to\nbe very effective in the accurate retrieval of the SSS.\nHowever, the actual nature of these errors is not additive, but multiplicative (Camps et al., 2008),\nso when the OTT is applied to land or ice targets errors become larger.\n\n\u2022 To overcome this, amultiplicative mask derived by Wu et al. (2011) to correct at a pixel level for\nthe residual aberrations induced during the image reconstruction process due to phase/amplitude\nresidual errors, as well as antenna pattern errors.\n\nOther calibration methods that do not rely on internal calibration signals can be used in principle.\nThey have been used in radio-astronomy with success (Thompson et al., 1986), although their\napplicability to Earth observation is more limited (Camps, 1996), since the brightness temperatures\nbeing imaged do not consist of point sources, but are quite homogeneous instead, which translates into\nvisibility functions more concentrated in the lower frequencies, than in radio-astronomy. These other\nmethods are as follows:\n\n1. the redundant space calibration, based on the fact that redundant baselines must measure the\nsame visibility value, and if not, this difference can be attributed to separable amplitude and phase\nerrors associated with each receiving chain (Thompson et al., 1986; Camps et al., 2003).\nTherefore, this technique cannot be applied to arbitrary arrays or moving arrays, since the number\nof redundant baselines may be very limited (if any) and\n\n2. the phase/amplitude closures, based on the following two properties: the sum of the uncalibrated\n(\u201craw\u201d) phases of three visibilities forming a triangle is equal to the sum of the calibrated phases:\n\nfrawp;q \u00fe frawq;r \u00fe frawr;p \u00bc fp;q \u00fe fq;r \u00fe fr;p; (4.140)\nand the ratio of the product of the uncalibrated (\u201craw\u201d) amplitudes of the visibilities forming opposite\nsides of a quadrilateral is equal to that of the calibrated amplitudes:???Vrawm;n ??????Vrawp;q ??????Vrawm;p ??????Vrawn;q ??? \u00bc\n\n??Vm;n????Vp;q????Vm;p????Vn;q?? . (4.141)\nThe main limitation of amplitude and phase closures in the MIRAS/SMOS case is the residual\n\nerror amplification along the arms.\n\n4.6.4.3 Image Reconstruction\nThe first image reconstruction algorithm for synthetic aperture radiometers was the G-matrix (Ruf\net al., 1988; Tanner, 1990; Tanner and Swift, 1993), devised for the ESTAR instrument, the first\nairborne 1D synthetic aperture interferometric radiometer. The G-matrix relates in a matricial form the\nmeasured visibility samples to a point source located in different directions. Each measurement\nbecomes thus a column of G:\n\nV \u00bc G $ T . (4.142)\n\n4.6 SENSORS 277\n\n\n\nAs originally devised, this method cannot be directly applied to large 2D synthetic aperture\nmicrowave radiometers, because either the matrix is too large or because it is ill-conditioned and errors\nget amplified, but still the basic idea is the same as in Eq. (4.142). The main differences are twofold: (1)\nthe way the G matrix is computed, stored in memory, and inverted (Camps et al., 1998a,b; Anterrieu,\n2004; Corbella et al., 2009) and (2) the preprocessing of the visibility samples to minimize the ringing\nin the regions with high brightness temperature contrasts, such as in the Earth\u2019s limb or in the coast\nlines, the way to minimize the effect of the Sun, etc. (Camps et al., 2008), and the way the mitigate RFI\nsources in the imagery (Camps et al., 2011a).\n\nThe interested readers are invited to consult Camps et al. (2016) for a detailed description of the\ninstrument error model and their classification, the calibration and image reconstruction algorithms,\nincluding the random arrays.\n\n4.6.4.4 ESA\u2019s SMOS Mission and the MIRAS Instrument\nSo far ESA\u2019s SMOS mission has been the only spaceborne mission using synthetic aperture radiometry.\nTherefore, despite the fact that there are a few other missions planned using this technique, the example\nmust be focused on the MIRAS instrument, the single payload of the SMOS mission (Fig. 4.121). The\nMIRAS instrument achieves a \u201cgood\u201d13 spatial resolution (w50 km) with an array of small antennas\n(w20 cm). In principle, this solution is the lowest cost possible, while it is more easily scalable.\n\nFIGURE 4.121\n\nArtist\u2019s view of European Space Agency\u2019s Soil Moisture and Ocean Salinity mission carrying the microwave\n\nimaging radiometer by aperture synthesis instrument, whose three long arms forming 120? are clearly seen.\nFrom ESA. http://www.esa.int/spaceinimages/Images/2004/06/SMOS\n\n13In terms of other microwave radiometers at the same frequency band.\n\n278 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.121|tif\nhttp://www.esa.int/spaceinimages/Images/2004/06/SMOS\n\n\nThe SMOS mission was launched on November 2, 2009, and it has been a challenge itself for a\nnumber of reasons:\n\n\u2022 First, it uses a brand new type of instrument, never before tried in space. It required revising the\nfundamental equation, making a new and detailed error model and correction (calibration)\nalgorithms, and image reconstruction algorithms, as well.\n\n\u2022 Second, it provides new types of observations at L-band, including multilook and multiangle\nobservations, in which pixels are seen with different size and orientation, different noise level and\nprecision, etc. and polarization mixing due to geometric and Faraday rotation effects that mix the\nStokes elements.\n\n\u2022 Third, it required the development of new L-band and multiangular ocean and soil emission\nmodels, over a wide range of incidence angles (0?e60?), to use them in the geophysical\nparameters retrievals.\n\n\u2022 And fourth, new geophysical parameter retrieval algorithms had to be developed, taking into\naccount the three issues above.\n\nSMOS scientific measurements led to a Sun-synchronous (mean orbital plane inclination \u00bc 98.416?),\ndawn/dusk (local time ascending node \u00bc 6 a.m.), and quasicircular orbit (mean altitude \u00bc 755.5 km\nand eccentricity \u00bc 0.001165). The antenna spacing in the MIRAS array was selected to be d \u00bc 0.875l,\nwhich is larger than d \u00bc l/O3, required to avoid aliasing. This configuration reduces the number\nof antennas for a given angular resolution, while maintaining the swath width. The MIRAS array\nwas steered 30?14 so as to enlarge the swath width and homogenize the number of observations\nin the central part of the swath, and tilted 32.5? so as to enlarge the range of incidence angles\nobserved.\n\nThe MIRAS instrument itself is described below. The most visible part of the MIRAS instrument is\nits large antenna array, of more than 4 m along each arm. Since the arms have to be fold so as to fit in\nthe upper part of the launcher (Fig. 4.122A), and then deploy (Fig. 4.122B) the arms are made of three\nsections each with six antenna elements, as illustrated in Fig. 4.123.\n\nThe individual receiving elements are \u201csimple\u201d superheterodyne receivers with one down-\nconversion. As characteristics, each receiver has a 4:1 input switch to select between the antenna\npolarization (either horizontal or X-pol, or vertical or Y-pol), the correlated noise or the uncorrelated\nnoise (internal matched load) sources, an input isolator to improve matching and minimize the noise\nradiated toward the antenna,15 a slope corrector to improve the flatness of the spectrum, the 1 bit/2\nlevel samplers, and the PMS, which is a diode detector that allows each receiver to behave as a TPR. It\nis needed to denormalize the \u201cnormalized\u201d correlations (obtained using 1 bit/2 level correlators).\n\nThe NIRs have triple redundancy, since they provide the reference for any other calibration\n(reference noise source of calibration subsystem or CAS) and provide the average value of the antenna\ntemperature of the scene (Vpq(0,0) \u00bc TApq). They are located in the hub and are fully polarimetric, that\nis, they do measure the four Stokes elements. The block diagram of the NIRs is shown in Fig. 4.125.\nThey are composed of two LICEF receivers connected each to one antenna polarization. Correlated\nnoise inputs from the NDN allow phase/amplitude calibration of receivers as LICEFs and the third and\nfourth Stokes parameters measurements (Fig. 4.124A).\n\n14One of the arms was pointing toward the Sun.\n15Actually the radiated term will be the one generated by the internal matched load mainly.\n\n4.6 SENSORS 279\n\n\n\nThe digitized signals from each LICEF are transmitted using an optical link (MOHA: microwave\noptical harness) to the DICOS (Digital COrrelator System) in the CCU to compute the complex cross-\ncorrelations of all signal pairs (Fig. 4.126). With 1 bit/2 level sampling, the cross-correlator reduces to\nan NOT-XOR gate to perform the multiplication (output equals one when the two inputs are the same,\nand it is zero when the two inputs are different), and an upcounter.\n\nA final subsystem required to the correct operation of the instrument is the CAlibration System or\nCAS that includes all the noise sources (with double redundancy), switches and power splitters to drive\nthe correlated noise signal to the receivers. One of the requirements of the CAS is the exquisite\nmatching both in amplitude in phase, and stability, of the power splitters. Fig. 4.127A and B shows the\nCAS can be in the hub (Fig. 4.127A) or in one arm (Fig. 4.127B).\n\nFinally, Fig. 4.128A and B show two pictures of the whole MIRAS instrument, during a deploy-\nment test at EADS-CASA premises (Madrid, Spain), MIRAS prime contractor, and prepared for\nfunctional tests at ESA/ESTEC (Noordwijk, The Netherlands).\n\nMIRAS has two modes of operation:\n\n\u2022 the dual-polarization one, in which all LICEFs at X-polarization or at Y-polarization at a time,\nand both polarizations are measured sequentially, and\n\n\u2022 the full polarimetric one, in which LICEFs are at orthogonal polarizations. However, to measure\nthe whole set of (u,v) points, a particular switching sequence has to be commanded. This sequence\nrequires one arm to be at p-polarization, while the other two arms are at q-polarization. In the next\ntwo integration times the arm at p-polarization is changed. A fourth step with all arms at\np-polarization is required to have the complete Stokes vector. In addition, to homogenize the\nintegration times and have the same radiometric precision at both polarizations, the role of the\np- and q-polarizations is swapped in the next four steps.\n\nMIRAS data are geolocated using the ISEA family of grids, instead of the EASE-Grid, more\npopular among many of the US Earth observation missions, namely AQUA (NASA/NASDA) and\n\nFIGURE 4.122\n\n(A) Soil Moisture and Ocean Salinity (SMOS) in the upper stage while fairing opens, and (B) SMOS in orbit and\n\nmicrowave imaging radiometer with aperture synthesis antennas deploying.\n\nCredits ESA multimedia.\n\n280 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.122|tif\n\n\nCMN\n\nCMN\n\nHUB\n\nCMN\n\nCMN\n\nARME\n\nARMA\n\nARMC\n\nLICEF/NIR\n\nNS (CENTRALISED)\n\nNS (DISTRIBUTED)\n\nLICEF/NIR\n\nLICEF\n\nLICEF/NIR\n\nLICEF\n\nPD\n\nPD\n\n1\nST SEGMENT OF ARMB\n\nPD\n\n1\nST\n\n SEGMENT OF ARMC\n\n1\nST SEGMENT OF ARMA\n\nOptical Splitter\n\nOptical Splitter\n\nOptical \nSplitter\n\nOptical Splitter\n\nLCF_A_21\n\nLCF_A_16\nLCF_A_15\n\nLCF_A_10\nLCF_A_09\n\nLCF_A_03\nLCF_A_02\nLCF_A_01\n\nHUB\n\nLCF_A_04\n\nLCF_AB_01\n\nNIR_AB_02\n\n(A)\n\n(B) (C)\n\nFIGURE 4.123\n\n(A) Microwave imaging radiometer with aperture synthesis instrument array topology: 69 antenna elements\n\n(LICEF, Fig. 4.124B) are equally distributed over the three arms and the hub, with three sections of six el-\n\nements each. Each section has a control monitoring node (CMN) to control the instrument state, and a\n\n(distributed) noise source. The acquired signals are transmitted optically (blue cables) to a central correlator\n\nunit (CCU), which computes the complex cross-correlations of all signal pairs. (B) Image of a segment with\n\nthe different elements, and (C) CCU with a bunch of fiber optic cables bringing all digitized signals.\n\n(Courtesy of Astrium EADS-CASA Espacio, Madrid, Spain; now Airbus Defence and Military).\n\n4.6 SENSORS 281\n\nmailto:Image of Figure 4.123|eps\n\n\nAquarius (NASA), which are particularly interesting for comparison with the SMOS products. Spatial\npartitioning of ISEA can be triangular, hexagonal, or diamond-based. In its hexagonal form, ISEA\nhas a higher degree of compactness, quantizes the plane with the smallest average error, and provides\nthe greatest angular resolution. It also possesses uniform adjacency with its neighbors, unlike\nthe square EASE-Grid. ISEA hexagonal at aperture 4 and resolution 9 (ISEA 4-9) is made up of\n2,621,442 points over the Earth spaced w15 km, while the EASE-Grid at w12 km has 3,244,518\npoints.\n\nFIGURE 4.124\n\n(A) Block diagram of a LICEF (light and cost-effective front-end) of microwave imaging radiometer by aperture\n\nsynthesis, and (B) front and back pictures of a LICEF. On the left (top center) the isolator is clearly seen, while\n\non the right (top right corner) the very selective cavity filter is located.\n\nCourtesy of Mier Comunicaciones SA, Barcelona, Spain (now Tryo Aerospace).\n\n282 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.124|tif\n\n\nC_V\n\nHPF ALC\nTRF_V\n\nLO_V\n\nTQ_V\n\nREFCLK_V\n\nDI/Q_V\n\nT I_V\n\nPMS_V\n\n1B2L\n\n1B2L\n\nMux\n\nPMS\nVertical Polarisation LICEF\n\nNIR ELECTRONICS\n\nV\n\nH TDH\n\nTDV\nNoise\n\nSource\n\nNoise\nSource\n\nRegulator\n\n+12v\n\nRegulator\n\nN\nIR\n\n A\nN\n\nTEN\nN\n\nA\n\nE/O\n\nE/O\n\nS\nP\n\n4\nT\n\nC_H\n\nHorizontal Polarisation LICEF\n\nHPF ALC\n\nTRF_H\nLO_H\n\nTQ_H\n\nREFCLK_H\n\nDI/Q_H\n\nT I_H\n\nPMS_H\n\n1B2L\n\n1B2L\n\nMux\n\nPMS\n\nA/D\n\nE/O\n\nE/O\n\nS\nP\n\n4\nT\n\nS\nP\n\n4\nT\n\nS\nP\n\n4\nT\n\nS\nP\n\n4\nT\n\nS\nP\n\n4\nT\n\nA/D\n\nFPGA\n\nTC/TM\n\nV_NsOn\n\nH_NsOn\n\nDicke CLK out\n\nRfSw_V+12v\n15v\n\n15v\n\nFIGURE 4.125\n\nBlock diagram of MIRAS NIRs made of two individual LICEFs and the noise injection electronics block.\n\n1-BIT DIGITAL CORRELATORPREDETECTION\nUNIT\n\nPREDETECTION\nUNIT\n\nAntenna i\n\nAntenna j\n\nPMS\n\nPMS 1 bit ADC (comparator)\nin each LICEF\n\nCorrelator =\n= NOT-XOR + up-counter\n\nPower\n\nCorrelation\n\nPi\n\nPower\nPj\n\n( . )2\n\n( . )2\n\ni j(u, v)\n\nCounter\n\nFIGURE 4.126\n\nBlock diagram of a digital correlator system.\n\n4.6 SENSORS 283\n\nmailto:Image of Figure 4.125|eps\nmailto:Image of Figure 4.126|eps\n\n\nFinally, multiangular emissivity models are fit to the data aggregated for each pixel at different\nincidence angles to obtain the different geophysical parameters. Since ESA is only in charge of the\nprocessing up to level 2, there are two centers for processing levels 3 and 4, one in France (the CATDS:\nhttps://www.catds.fr/) and another one in Spain (the SMOS CP34: http://cp34-bec.cmima.csic.es/).\nA composite SSS and soil moisture map generated at the CP34 is presented here in Fig. 4.129.\nFig. 4.130 shows the residual first Stokes parameters, which is associated to the excess surface\nroughness induced by the high winds of hurricane Danielle crossing the Atlantic and hitting the East\ncoast of the United States.\n\nNoise Source\nUnits\n\nPower Divider\nUnits\n\n(A)\n\nTo LICEF\nand NIR\n\nTo LICEF\nand NIR\n\nTo LICEF\nand NIR\n\nFrom\nArm A\n\nFrom\nArm B\n\nFrom\nArm C\n\nNoise Source\nUnit\n\n(B)\n\nTo \nLICEF\n\nTo \nLICEF\n\nTo \nLICEF\n\nPower Divider\nUnits\n\nTo Hub\n\nMatched\nLoad\n\nFIGURE 4.127\n\n(A) CAlibration System (CAS) in the hub: a noise source drives correlated noise to the first six elements in each\n\narm, from which three are in the first part of the arm and two correspond to the redundant elements, one of\n\nthem being an NIR (with two LICEFs). (B) CAS in the arms: noise sources distribute noise to groups of the\n\nsections (6 \u00fe 6 receivers). All noise sources have double redundancy.\nCourtesy of Astrium EADS-CASA Espacio, Madrid, Spain (now Airbus Defence and Military).\n\nFIGURE 4.128\n\n(A) Microwave imaging radiometer by aperture synthesis (MIRAS) instrument at Astrium EADS-CASA\n\npremises (Madrid, Spain) for deployment tests (credits Astrium EADS-CASA), (B) MIRAS at ESA/ESTEC\n\n(Noordwijk, The Netherlands) for functional tests.\n\nCourtesy of Astrium EADS-CASA Espacio, Madrid, Spain (now Airbus Defence and Military).\n\n284 CHAPTER 4 MICROWAVE RADIOMETRY\n\nhttps://www.catds.fr/\nhttp://cp34-bec.cmima.csic.es/\nmailto:Image of Figure 4.127|eps\nmailto:Image of Figure 4.128|tif\n\n\nAs previously discussed, the spatial resolution that can be achieved with passive microwave sensors\nis quite poor, even at the highest frequency bands, because it is limited by the antenna size. This prevents\none from using microwave radiometry data for regional or local applications. One might think that\ntechnology would remedy this situation in the coming years, by allowing us to manufacture and deploy\nin orbit larger and larger antennas, however \u201cthe radiometer uncertainty principle\u201d cannot be exceeded.\nIt states that the product of the spatial resolution and the radiometric precision is a constant for a given\ntype of radiometer. For example, using the same receivers, if one could manufacture a 10 times larger\nMIRAS instrument, the spatial resolution would improve from w30 to w3 km, but the radiometric\nprecision would have degraded by a similar factor (w?10 times larger), and instead of 2e3K, this new\ninstrument would have 20e30K rms radiometric resolution, which is useless for many applications.\n\nTo overcome this limitation, achieving a better spatial resolution, while keeping good radiometric\nprecision additional high quality and high resolution multispectral data can be merged with the\nradiometry data (Piles et al., 2011). Since June 2012, the SMOS Barcelona Expert Center (SMOS-BEC\nhttp://cp34-bec.cmima.csic.es/) is routinely producing near real time (morning and afternoon passes, if\navailable) soil moisture maps of the Iberian peninsula16 at 1 km, from SMOS and MODIS/AQUA and\nTERRA data (Fig. 4.131), that are used by the regional authorities as a proxy for forest fires prevention\n(Chaparro et al., 2016), or to estimate forest decline (Chaparro et al., 2017).\n\nFIGURE 4.129\n\nSample global soil moisture and ocean salinity maps for November 2011.\n\nCourtesy of Dr. Jordi Font, ICM/CSIC; http://cp34-bec.cmima.csic.es/.\n\n16SMOS Barcelona Expert Centre on Radiometric Calibration and Ocean Salinity (SMOS-BEC) website: http://www.smos-bec.\nicm.csic.es/smos_bec.\n\n4.6 SENSORS 285\n\nhttp://cp34-bec.cmima.csic.es/\nmailto:Image of Figure 4.129|tif\nhttp://cp34-bec.cmima.csic.es/\nhttp://www.smos-bec.icm.csic.es/smos_bec\nhttp://www.smos-bec.icm.csic.es/smos_bec\n\n\n4.6.5 FUTURE TRENDS IN MICROWAVE RADIOMETERS\nToday\u2019s evolution of microwave radiometers includes (1) a much wider use of digital technology,\nincluding sampling at IF, digital I/Q demodulation, digital filtering, etc., and many techniques/tech-\nnologies inherited from software-defined radio, (2) a much wider use of RFI detection and mitigation\ntechniques, both real and synthetic aperture radiometers, to face the increasingly worrying problem\nof interferences, (3) highly integrated microwave and millimeter-wave circuits, that will allow low-\npower miniature radiometers, to be boarded in nano-satellites, and (4) a spread of synthetic aperture\ntechniques after the success of ESA\u2019s SMOS mission. At present, three new millimeter-wave\n\nFIGURE 4.130\n\nWind maps over hurricanes as imaged by Soil Moisture and Ocean Salinity: (top) Hurricane Danielle, August\n\n25 (75 kt at 982 mb) and August 27 (115 kt at 942 mb) 2010, (bottom) Hurricane Earl September 2 (100 kt\n\nat 947 mb) and September 3 (90 kt at 955 mb) 2010.\n\nCourtesy of Dr. Nicolas Reul, IFREMER and Joseph Tenerelli, ODL.\n\n286 CHAPTER 4 MICROWAVE RADIOMETRY\n\nmailto:Image of Figure 4.130|tif\n\n\nFIGURE 4.131\n\n(A) Soil moisture map of the Iberian Peninsula at 1 km spatial resolution generated from the combination of\n\nSoil Moisture and Ocean Salinity and MODIS/AQUA and TERRA data. (B) Zoom over the Ebro river valley. (C)\n\nZoom over the Pyrenees. In (B) the cultivated regions near the river and its tributaries are clearly wetter than\n\nthe rest. In (C) the north side of the mountains is clearly wetter than the south side which is drier.\n\n4.6 SENSORS 287\n\nmailto:Image of Figure 4.131|tif\n\n\natmospheric sounders from a geostationary orbit are under study: the NASA/JPL PATH mission, the\nESA GAS mission, and the China GIMS mission.\n\n4.7 STUDY QUESTIONS\n\n1. When the electromagnetic radiation passes through the atmosphere it may suffer two types of\neffects. Which ones? What is their frequency dependence?\n\n2. What happens in the atmosphere around 22 and 60 GHz? And around 36 and 89 GHz?\n3. The emissivity of a surface increases or decreases with increasing values of the dielectric\n\nconstant? Why?\n4. The emissivity of a surface increases or decreases with increasing surface roughness? Why?\n5. From a satellite, the brightness temperature of the rain over the sea increases or decreases with\n\nincreasing frequency. And, at the same frequency, increases or decreases with the rain rate?\nWhy?\n\n6. From a satellite, the brightness temperature of the rain over land increases or decreases with\nincreasing frequency. And, at the same frequency, increases or decreases with the rain rate?\nWhy?\nAt 53? incidence angle:\n\n7. The brightness temperature of the snow increases or decreases with the frequency? Why?\n8. The brightness temperature of the deserts increases or decreases with the frequency? Why?\n9. In vegetated regions, which is the dependence of the brightness temperature as a function of the\n\n\u201camount of vegetation\u201d and the polarization? Why?\n10. How does the iced sea is seen from a spaceborne microwave radiometer, for example, at\n\n19 GHz?\n11. The brightness temperature of the sea at vertical polarization increases or decreases with the\n\nwind speed? Why?\n12. In the retrieval of geophysical parameters over the ocean surface, what happens when the\n\npresence of rain is detected? Why?\n13. At 1.4 GHz, the sea surface brightness temperature increases or decreases with the presence of\n\nwaves and salinity? Why?\n14. In plain words, what is a microwave radiometer?\n15. Which measurements are needed to perform the radiometer calibration?\n16. In a TPR with a receiver\u2019s noise temperature of 200K, a bandwidth of 27 MHz, and an\n\nintegration time of 1.2 s, compute the radiometric sensitivity when the antenna temperature is\n100K.\n\n17. If the beam width of a radiometer antenna is 2?, compute the footprint size while pointing to\nnadir from 800 km height.\n\n18. Which type of scanning is performed by the SSM/I family? Which are its advantages from the\nelectrical, mechanical, and emissivity points of view?\n\n19. In which order must the radiometric and geometric corrections be performed?\n20. Taking into account the different footprint size from 69 ? 43 km at the lowest frequency band,\n\nto 15 km ? 13 km at the highest one comment how the scanning of the different channels is\nperformed.\n\n288 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\n21. How is the calibration of the SSM/I sensors performed? What happens when a calibration is\nwrong, and how it does look like in the brightness temperature image?\n\n22. How is the antenna pattern correction implemented for SSM/I?\n23. Comment the geometric correction technique applied to EMSR, SMMR, and SSM/I?\n24. What happens if the time tag of a measurement is wrong? How it does appear in the images?\n25. How can the geolocalization errors associated to imperfect orbit knowledge be reduced?\n26. A spaceborne microwave radiometer at 19 GHz performs a conical scan over the sea surface at a\n\nconstant incidence angle of 53.1?, at vertical and horizontal polarizations. Assuming a flat sea,\nwill the brightness temperatures depend on the polarization? If yes, at which polarization the\nbrightness temperature will be smaller? Which is the dependence of the brightness temperatures\nwith the wind speed?\n\n27. A helicopter-borne noise-injection radiometer operates at 36.5 GHz with 1 GHz bandwidth, and\nperforms a conical scan at 200 rpm and at a constant incidence angle of 50? with respect to the\nvertical at a constant height of 4 km. The antenna beam width is 2.35? in both planes.\na. Discuss the advantages and disadvantages of an NIR versus a TPR.\nb. For the nominal conditions, compute the size of the footprint (major and minor axes) over a\n\nflat surface.\nc. Compute the swath width when the helicopter flies in a straight line at the nominal height.\nd. Compute the maximum speed of the helicopter to measure all pixels over the ground.\ne. Compute the radiometric resolution if the antenna temperature is smaller than 300K, the\n\ntemperature of the internal matched load is 310K, and the receiver\u2019s noise temperature is\n400K.\n\nf. If the range of input temperatures spans from 50K to 300K, compute the minimum number of\nbits in the analog-to-digital converters so that the quantization noise is negligible in front of\nthe radiometric resolution. Compute the amount of information generated.\n\n28. A side-looking push-broom radiometer uses an antenna array and a combining network to create\neight narrow beams in elevation simultaneously. Each beam is connected to a radiometer\nreceiver. The platform height is 1 km over the surface and the ground speed is 50 m/s.\n\nB8\n\nB2B1\n\nData:\nFrequency of operation: 10.68 GHz\nRadiometer type: Dicke\nReceiver bandwidth: 150 MHz\nReference temperature: 300K\nReceivers\u2019 noise temperature: 500K\nAntenna beam width in azimuth and elevation: 4? (each beam)\nPointing angles B1eB8 with respect to nadir: 31?, 35?, 39?, 43?, 47?, 51?, 55?, 59? (\t2?,\nbeam width)\n\n4.7 STUDY QUESTIONS 289\n\n\n\na. Swath width over the surface in a straight line.\nFor B4 beam (43? \t 2?):\n\nb. Pixel dimensions in the along-track and cross-track directions.\nc. Maximum integration time.\nd. Assuming that the antenna temperature is 300K, compute the radiometric resolution, or\n\nminimum input change that can be detected.\nFor the whole radiometer:\n\ne. If the input temperature range spans from 80K to 320K, determine the amount of data\ngenerated by the radiometer assuming all eight receivers are identical.\n\nf. Which factors can create errors in the measurements? Propose a method to compensate for\nthem.\n\ng. In which cases the apparent brightness temperature will significantly differ from the\nsurface\u2019s brightness temperature?\n\n290 CHAPTER 4 MICROWAVE RADIOMETRY\n\n\n\nRADAR 5\nRadar has its earliest origin in observations made by Heinrich Hertz in the late 19th century that radio\nwaves were reflected by metallic objects. Motivated by the studies of James Clerk Maxwell on\nelectromagnetic waves, Hertz demonstrated the reflection of these waves by metallic objects. In 1887,\nHertz further experimented with electromagnetic waves and found that some waves could be trans-\nmitted through some materials while others reflected these waves back to their source.\n\nIn the early part of the 20th century, another German researcher Christian Huelsmeyer built a\nsimple ship detection device to assist in avoiding ship collisions. The term radar itself comes from the\nacronym radio detection and ranging (RADAR), coined by the US navy. Thus, radar must both detect a\ntarget and provide a range to it. In the years before 1934, systems either gave a range estimate and no\ndirection, or provided an estimate of direction, but with no range information. One key development\nwas the introduction of pulsed radar that was timed to provide range while they were sent from large\nantennas that could also provide directional information. Taken together these two components\nprovide us with conventional radar, as we know it today.\n\nThe development of the wireless radio is often attributed to Guglielmo Marconi (1874e1937)\nalthough he was not the first to invent the technology. He was, however, the greatest early promoter of\nthis new technology and its applications. Marconi also saw the potential of using radio waves for ship\nrouting by lighthouses. He said, \u201cI. pointed out the possibility of a lighthouse to use this technology\nto enable vessels to safely navigate coastal waters in foggy weather.\u201d He recognized the all-weather\noperational capability of radio waves over traditional optical detection methods.\n\nIn 1904, Huelsmeyer (1881e1957) demonstrated, in Germany and the Netherlands, the use of radio\nechoes to detect ships so that collisions could be avoided. His device consisted of a spark gap that\ncould generate a signal that was received using a dipole antenna with a cylindrical parabolic reflector.\nWhen a signal reflected from a ship was picked up by a similar antenna, attached to a separate coherent\nreceiver, a bell sounded. During bad weather or fog the antenna was periodically spun to scan for\nnearby ships. Huelsmeyer patented his invention, which he named the telemobiloscope. The name\nnever caught on with naval authorities.\n\nOne of the many ideas that Nikola Tesla (1856e1943) included in his studies on electromagnetic\nwaves was that from a fixed station, we could use these waves to determine the relative position or\ncourse of a moving object such as a ship at sea. He also proposed the use of pulsed radio waves to\ndetermine the relative position, speed, and course of a moving object.\n\nIn the fall of 1922, Albert H. Taylor and Leo C. Young of the US Naval Aircraft Radio Lab were\nconducting communications experiments when they noticed that a wooden ship in the Potomac River\nwas interfering with their signals. In essence they had demonstrated a bistatic radar, which is a system\n\nCHAPTER\n\nIntroduction to Satellite Remote Sensing. http://dx.doi.org/10.1016/B978-0-12-809254-5.00005-1\n\nCopyright \u00a9 2017 Elsevier Inc. All rights reserved.\n291\n\nhttp://dx.doi.org/10.1016/B978-0-12-809254-5.00005-1\n\n\nwhere the radio signals are sent and received from two different and independent antennas. In a future\nsystem, Young suggested trying pulsing techniques to allow a direct determination of both range and\ndirection to the target. Robert Morris Page was assigned to Young to implement these ideas. In\nDecember 1934, they used such an apparatus to detect a plane at a distance of 1 mile flying up and\ndown the Potomac. Although the signals were weak, this demonstrated the first use of a pulsed radar\nsystem. Thus, Page, Taylor, and Young are usually credited with building and demonstrating the\nworld\u2019s first true radar. An important subsequent development by Page was the invention of the\nduplexer, a device that allowed the transmitter and receiver to use the same antenna without over-\nwhelming or destroying the sensitive receiver circuitry. This also solved the problem of synchroni-\nzation of the separate transmit and receive signals that was needed for accurate position determination\nat long ranges.\n\nThere were parallel developments of radio ranging and detection going on in the United\nKingdom, Germany, and the former USSR. Accelerated by the impending World War, radar\ndevelopments were many on both sides of the war. In the United Kingdom, radar was an essential\nadvantage for the country in scrambling its fighters against bombing attacks. Progress would not\nlikely have come so quickly without the motivation of war and its necessities. Today, radar has\nadvanced far beyond those early uses, which emphasized its application to detection and ranging.\nToday we talk of imaging radars that have been extended to use interferometry to improve their\nhorizontal spatial resolution. We have radar altimeters to map the sea surface heights and detect\nsignificant wave heights. We look at the backscatter of the wave signal to compute ocean surface\nwind speed and direction. These various technologies will be discussed in the upcoming sections of\nthis chapter.\n\nActive radio/microwave remote sensing systems are commonly known as radars. A crucial\nadvantage of radio/microwave sensors over optical sensors is their potential of dayenight, all-\nweather operation, a feature of particular relevance for monitoring areas frequently covered by\nclouds or haze, such as tropical rain forests or polar regions. Since their development, starting at\nthe beginning of the 20th century (Hu?lsmeyer, 1904), radars have been frequently used in a number\nof different applications, e.g., military, space and air navigation, air traffic control, ship safety,\npolice enforcement, or planetary observations. In addition to the all-day, all-weather operation\ncapability, radar images contain different information when compared to optical images; radars are\nsensitive to the complex conductivity of the targets and naturally adopt the scattering and prop-\nagation properties of their electromagnetic waves. Radars operating with shorter wavelengths are\nvery sensitive to small geometric structures, whereas the longer wavelengths can penetrate deep\ninto forests and vegetation.\n\nIn addition to other pertinent classifications, remote sensing radars can be divided into imaging and\nnonimaging. Altimeters and scatterometers are examples of nonimaging radars, usually yielding a one-\ndimensional (1D) profile of topography or reflectivity, respectively. Imaging radars, on the other hand,\nperform two-dimensional (2D) measurements resulting in reflectivity images. In remote sensing\napplications, synthetic aperture radars (SARs) are very popular imaging devices because of their\nexcellent geometric resolution, on the order of a few radar wavelengths. This very fine resolution,\ncombined with the maturity of several coherent methods, has transformed SAR remote sensing into a\nleading technology with applications ranging from security to disaster monitoring.\n\n292 CHAPTER 5 RADAR\n\n\n\n5.1 A COMPACT INTRODUCTION TO RADAR THEORY\nThe principle of radar remote detection and ranging is based on a send-and-receive approach, where\nthe transmission of a signal is followed by the subsequent recording of the echoes scattered from the\ntargets in the scene causing this backscatter in the (Skolnik, 1980a). Although radar was the first device\nused for remote detection and ranging, its principle is now shared with other popular systems such as\nsonar (acoustic waves, Urick, 1986; Le Chevalier, 1989) or LIDAR (Smullin and Fiocco, 1962).\n\nAs an example of the simplest radar measurement, let us consider the stationary radar and target\ndepicted in Fig. 5.1.\n\nThe geometry is fairly simple, with the radar illuminating a target located at a distance. This\ndistance is typically called the range in radar jargon. The signal transmitted by the radar is represented\nby s(t), where t is a time variable. Since radio transmitters are band-limited and operate at certain\ncarrier wavelengths, s(t) will be, in general, a band-pass signal, i.e., s(t) can be expressed as (Carlson,\n1986)\n\ns\u00f0t\u00de \u00bc slp\u00f0t\u00de$exp\u00f0 j$u0$t\u00de; (5.1)\nwhere slp(t) is the low-pass equivalent of s(t), j is the imaginary unit\n\n? ffiffiffiffiffiffiffiffiffiffiffiffi\u00f0 ? 1\u00dep ?, and u0 is the central\nangular frequency of the radar. From classical wave theory, we know that the central angular frequency\nwill dictate both the carrier frequency and wavelength in the following manner:\n\nu0 \u00bc 2p$f0 \u00bc 2p$c\nl\n\n; (5.2)\n\nwhere f0 is the central or carrier frequency, c is the velocity of propagation of the transmitted waves in\nthe medium, and l is the central wavelength. In practical terms, however, the signal transmitted by the\nradar is a real signal, i.e.,\n\nsTx\u00f0t\u00de \u00bc <\u00bds\u00f0t\u00de? \u00bc <\u00bdslp\u00f0t\u00de?$cos\u00f0u0$t\u00de ? J\u00bdslp\u00f0t\u00de?$sin\u00f0u0$t\u00de; (5.3)\nwhere <\u00bd$? and J\u00bd$? are the real and imaginary operators, respectively. The complex model of (5.1)\nprovides a representation of the phase of the signal. In addition, radars typically incorporate in-phase\n\nFIGURE 5.1\n\nA sketch of a stationary radar illuminating a stationary target.\n\n5.1 A COMPACT INTRODUCTION TO RADAR THEORY 293\n\nmailto:Image of Figure 5.1|tif\n\n\nand quadrature receivers (Skolnik, 1980a; Smith, 1985) and measure the phase of the received\nechoes. Consequently, after demodulation, the echoes will be complex, which gives the radar ac-\ncurate ranging capabilities on the order of the wavelength. After hitting the target, the transmitted\nenergy is scattered back in the direction of the radar receiver.1 Assuming linearity, the received echo\nmay be approximated as\n\nsRx\u00f0t\u00dez r$s\u00f0t ? s\u00de$exp\u00f0?j$u0$\u00f0t ? s\u00de\u00de; (5.4)\nwhere r is the complex reflectivity of the target, s is the delay from radar to target, and the exponential\naccounts for the basebanding of the signal at the receiver which propagates in the opposite sense as the\nwave in Eq. (5.1). The value of r depends on the frequency of the transmitted signal and incorporates the\nproperties of the electromagnetic interaction between wave and target. The magnitude of r is propor-\ntional to the square root of the ratio between the energy scattered in the direction of the radar receiver and\nthe total amount of transmitted energy (Skolnik, 1980a). Thus, r depends on the carrier frequency, the\nobservation geometry, the polarization of the incidence wave, and the geometrical and dielectric\nproperties of the scene. For the sake of simplicity, power losses, phase rotations, or dispersion effects\noccurred during the propagation and reception of the radar signals has been omitted.\n\n5.1.1 REMOTE RANGING\nFrom the original patent, which was filed for remote detection applications (Hu?lsmeyer, 1904), radars\nsoon evolved to be ranging devices. For this, the information contained in the delay of the transmitted\nsignal (i.e., s) becomes valuable. The variable smeasures the time elapsed between the transmission of\nthe signal and the reception of the echo. By inspecting both (5.4) and Fig. 5.1, the delay of the signal is\nproportional to the distance between the radar and the target r0 (Skolnik, 1980a), i.e.,\n\ns \u00bc 2$r0\nc\n\n; (5.5)\n\nwhere the factor two accounts for the signal traveling the distance r0 back and forth. Fig. 5.2 shows an\nexample of the reception of a single echo over the timescale of the radar.\n\nFIGURE 5.2\n\nRanging of the echo of a single target. In the left figure, the transmitted signal is a spike, which corresponds to an\n\ninfinite bandwidth radar transmitter. In the right figure, the spike gets transformed into its band-limited version and\n\nenergy spills over into adjacent delays.\n\n1Modern radars are typically monostatic, i.e., share the same antenna for transmitting and receiving. For bistatic radars, how-\never, the use of the term backscattering is certainly not exact, but backscattering will be used in the following pages to\ndescribe the energy scattered toward the radar receiver for bistatic cases too.\n\n294 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.2|eps\n\n\nThe example contains several idealizations, i.e., no noise is depicted in the drawing, and the\nreceived signal appears as a spike, which would require an infinite bandwidth. Radars naturally have a\nfinite bandwidth driven by resolution requirements, cost, and technological limits. In the following, we\nwill denote the bandwidth of the radar as Br, where the subscript r refers to ranging. The spike of the\nleft chronogram of Fig. 5.2 becomes the band-limited echo of the right chronogram. Note that some of\nthe echo energy is spilled into delays, i.e., ranges, not corresponding to r0, which introduces uncer-\ntainty into the ranging measurements.\n\nTo further illustrate this effect, we might be interested in the ability of the system to discriminate\ntwo different unknown targets, located at ranges r0 and r1, respectively, as depicted in Fig. 5.3.\n\nA natural question is how close can two targets be (r1 of r0) and still be distinguishable. The right\ndiagram in Fig. 5.3 shows the band-limited version of the two spikes on the left. The ability to identify\nthe two targets peaks is a function of the available bandwidth. In general, the time resolution of the\nradar will be inversely proportional to the signal bandwidth, i.e.,\n\nds \u00bc 1\nBr\n\n; (5.6)\n\nwhere the proportionality factor has been set to 1 for compactness.2 Scaling delay to range, we can\nexpress the range resolution of the radar as\n\ndr \u00bc c\n2\n$ ds \u00bc c\n\n2$Br\n. (5.7)\n\nHence, good range resolution requires a large transmitted bandwidth, which usually comes at the\nexpense of increasing hardware complexity and cost. With the progress in radio and microwave\ntechnology after World War II, the bandwidth limitations for UHF (w90 MHz) to C-band (5.4 GHz)\ncivilian radars are basically due to international radio frequency (RF) allocations.3 For carrier\nfrequencies from X-band (9.6 GHz) and higher, larger bandwidths (above 10%) are available, and\ncosts and technological limits play a more important role.\n\nFIGURE 5.3\n\nRanging of the echo of two close targets. On the left figure, the infinite bandwidth case, with two spikes corre-\n\nsponding to the echoes of two targets. In the right figure, the energy measured by the radar receiver assuming the\n\ntwo targets have the same complex reflectivity.\n\n2The factor 1 roughly corresponds to a single side lobe of the response in Fig. 5.2 assuming the radar has a flat response over\nthe frequency band.\n3The agency in charge of the international regulations for the use of the electromagnetic spectrum is the International Tele-\ncommunication Union (ITU), belonging to the United Nations (UN).\n\n5.1 A COMPACT INTRODUCTION TO RADAR THEORY 295\n\nmailto:Image of Figure 5.3|eps\n\n\n5.1.2 DOPPLER ANALYSIS\nSo far, we have assumed stationarity of both the radar and the target. In practical terms, this stationarity\nis only required in the noninertial frame. We now consider a scenario with a relative motion between\nthe radar and the target. For the sake of simplicity, a linear relative radial motion model (Fig. 5.4) will\nbe used.\n\nThe delay measured by the radar is a function of time, fulfilling the following condition:\n\nc$s\u00f0t\u00de\n2\n\n\u00bc r0 \u00fe v$\n?\nt ? s\u00f0t\u00de\n\n2\n\n?\n; (5.8)\n\nwhere r0 is the range at the start of the measurement and v the relative radial velocity between the radar\nand the target. Note the transmitted signal reaches the target after a time s\u00f0t\u00de=2. After some manip-\nulation, we obtain\n\ns\u00f0t\u00de \u00bc 2$r0\nc\u00fe v\u00fe\n\n2$v\n\nc\u00fe v$t; (5.9)\nBy substituting (5.9) into (5.4), we can express the received echo as\n\nsRx\u00f0t\u00de \u00bc r$slp\u00bdt ? s\u00f0t\u00de?$exp\u00bd?j$u0$s\u00f0t\u00de?\n\n\u00bc r$slp\n??\n\nc? v\nc\u00fe v\n\n?\n$t ? 2$r0\n\nc\u00fe v\n?\n$exp\n\n?\n?j$u0$2$\u00f0r0 \u00fe v$t\u00de\n\nc\u00fe v\n?\n;\n\n(5.10)\n\nwhich is an expression that deserves careful attention. In addition to a constant delay, we observe a\nscaling of the time reference by a factor \u00f0c? v\u00de=\u00f0c\u00fe v\u00de, i.e., the well-known Doppler effect. We\nclearly see that the scaling of the time reference introduces a frequency shift in the received echoes,\ncorresponding to the linear term in the exponential. Fig. 5.5 shows the Doppler shifted echo of the\ntarget of Fig. 5.4, assuming slp is a constant envelope, as depicted in the left figure.\n\nThe analogy with the ranging case depicted in Fig. 5.2 is clear: in real systems, neither the available\nbandwidth, nor the observation time can be unlimited. As it can be seen in the spectrum of the received\necho, the energy corresponding to a single target (i.e., the Doppler frequency) is spread into the\n\nFIGURE 5.4\n\nRadar illuminating a target with relative radial velocity v.\n\n296 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.4|eps\n\n\nadjacent frequencies introducing uncertainty in the measurement. In general, the Doppler resolution of\na radar is inversely proportional to the observation time TD, i.e.,\n\ndfD \u00bc 1\nTD\n\n. (5.11)\n\nThe velocity resolution for the particular case of Fig. 5.4 can be derived from (5.11) in a similar\nmanner as (5.7). In other geometrical configurations, the Doppler shift can be used for the estimation of\nthe angular or azimuth components, as it is the case of synthetic aperture radars.\n\nRadars measuring the relative motion of the targets are known as Doppler radars. The ideal\nwaveform in terms of Doppler resolution is a constant envelope, which becomes a tone after modu-\nlation; note that the constant envelope produces a spike in the frequency domain, an analogous\nsituation to the one we confronted within the analysis of ranging radars.\n\nAt this point, we can draw an important conclusion from the previous analysis of ranging and\nDoppler radars: the requirements imposed on the radar waveform by both measurements are contra-\ndictory. This is in fact no surprise, since it reflects the dual and inverse characters of the time and\nfrequency domains.\n\n5.2 RADAR SCATTERING\nBefore we examine more properties of the radar systems, we want to consider the scattering of the\nradar signals from the target surfaces. The reflected radar signature is the amplitude, phase, and\npolarization characteristics of the radar echoes. These characteristics yield information on the\ngeometrical and electromagnetic properties of the area imaged (Curlander and McDonough, 1991). It\nis only natural that this interaction is conditioned by the spectral and the electromagnetic properties of\nthe area illuminated by the radar. In particular, the carrier frequency and bandwidth of the transmitted\nsignal, its angular characteristics, and its observation geometry relative to the target (i.e., local incident\nand squint angles), along with the polarization of the radar waves, determine the complex reflectivity\nof the scene.\n\nThe scattering process measured by the radar depends on the morphological and dielectric prop-\nerties of the scene\u2019s surface. Among the most relevant morphological properties, we identify the\ndensity and the spatial distribution of the individual scatterers in the scene, their form and orientation,\nthe slope of the terrain, the roughness, and spatial periodicity relative to the wavelength of the radar.\n\nFIGURE 5.5\n\nDoppler analysis of the echo of a single target. The transmitted signal on the left is a constant envelope of limited\n\nduration, which gets delayed and modulated by the relative motion between the target and the radar, yielding the\n\npulsed sinusoid depicted in the figure. The right plot shows the spectra of the two pulses in the frequency domain,\n\nwith energy spilling over adjacent Doppler frequencies due to the limited duration of the transmitted waveform.\n\n5.2 RADAR SCATTERING 297\n\nmailto:Image of Figure 5.5|eps\n\n\nAmong the dielectric properties to which the radar is sensitive, we can list the soil moisture and\nvegetation, the characteristics of the penetration (i.e., attenuation, dephasing, depolarization) into the\nmedium, and the conductivity of the material. The electromagnetic interaction between the radar\nwaves and the scene is a subject of considerable complexity. Depending on the accuracy of the\ndescription of the target scene, different abstraction levels may be used to simplify the interaction with\nthe scene. Wherever possible, we will make an effort to keep our explanations at the level of\ngeometrical optics, which can be understood using the ray tracing analysis of the propagation\nphenomena (Hecht, 1997). This methodology, more stringent than the Born approximation, essentially\nassumes all subwavelength effects in the electromagnetic interaction can be ignored.\n\n5.2.1 RADAR FREQUENCY BANDS\nThe dependence of the radar backscatter on frequency is depicted in Fig. 5.6.\n\nThis figure shows a multifrequency image acquired by the DLR airborne F-SAR system over\nKaufbeuren, Germany. The different carrier frequency images are displayed in the RGB channels as\nfollows: X (red), C (green), and L (blue). The bright white spots correspond to areas with similar\nbackscatter in the three frequency bands. Note the images have been equalized separately and the\ncolors might not represent with fidelity the full dynamic range of each frequency band; nevertheless,\nthe image is illustrative.\n\nRemote sensing radars typically operate at frequencies ranging from some tens of MHz (VHF) to\nsome tens of GHz (W). There exist both technical and scientific reasons for this. The selection of the\nfrequency band of the radar depends mainly on the characteristics of the electromagnetic interaction\nwith the target surface, especially regarding its geometric and dielectric properties. As a general rule,\nthe lower-frequency bands (e.g., roughly below C-band, 4e8 GHz) are typically used for the pene-\ntration into volumetric structures such as forests, snow, ice, dry soil, whereas higher-frequency bands\n(e.g., from C-band and above) typically show little to no penetration capability into natural surfaces\n\nFIGURE 5.6\n\nRadar image acquired by the DLR airborne F-SAR system over Kaufbeuren, Germany. Radar illumination is from\n\nthe top. The different colors of the image correspond to the similarity of the radar backscatter to the different\n\ncarrier frequencies.\n\nCourtesy of DLR.\n\n298 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.6|tif\n\n\nand are used for surface remote sensing. Likewise, the sensitivity to surface roughness also increases\nwith increasing carrier frequency; typically, lower carrier frequencies show larger dynamic ranges in\nthe radar signature of natural scenes than higher carrier frequencies. Table 5.1 shows a list of the\ndifferent radar bandwidths with examples of airborne radars.\n\nA further boundary condition for the usability of a given frequency band in spaceborne radar\nmissions is the effect of the atmosphere on the propagation of the radar signals, which may introduce\nmild to severe attenuation, as well as delays and phase modulations in the received echoes. Lower\nfrequencies are affected by the ionosphere (roughly up to C-band, and below), and higher frequencies\nare attenuated by the troposphere (from Ku band and higher).\n\nIn the previous paragraphs, the importance of the scene characteristics in the choice of the radar\nwavelength has only been indirectly recognized through its semitransparency, roughness, or level of\ndetail. It is in the relationship with these properties that radar characteristics such as penetration into\nthe media, the dynamic range of radar backscatter for a given scene, or the transmitted bandwidth for\nhigher resolution plays a role. In general, the wavelength of the carrier shall be on the same order of\nmagnitude as the dimensions of the structures to be detected by the radar.\n\nToday, spaceborne radars are concentrated in the L to X bands, yielding a reasonable trade-off\nbetween penetration, sensitivity to roughness, geometric resolution, and technological maturity.\nIn the foreseeable future, the bounds on the lower side will be extended to P-band, and on the upper\nside to Ku and Ka bands. All other frequency bands are generally used in airborne systems, because of\nthe better sensitivity and the reduced influence of the atmosphere on radar wave propagation.\n\n5.2.2 NORMALIZATIONS OF THE RADAR REFLECTIVITY\nThe radar cross section (RCS) of a target is the ratio of the power scattered back to the radar receiver\nover the incident radar power density per unit of solid angle on the target as if the radiation were\nisotropic (Skolnik, 1980b), i.e.,\n\nsRCS \u00bc lim\nr/N\n\n4p$r20$\nPRx\nPTx\n\n; (5.12)\n\nTable 5.1 Some Radar Frequency Bands and Typical Applications\n\nCustomized Radar Suite\n\nInstrument Measurement Frequency Platform Resolution\n\nMCoRDS/I Bed topography, bed\nimaging, internal\nlayering\n\n195 MHz DC-8, P-3 4 m\n\nAccumulation radar Internal layering 750 MHz P-3 40 cm\n\nSnow radar Snow thickness, internal\nlayering, topography\n\n2e7 GHz DC-8, P-3 5 cm\n\nKu band altimeter Topography 14 GHz DC-8, P-3 5 cm\n\nFrom Tiwari, A., Airborne Radar and Applications, slide 55. https://www.slideshare.net/anupamtiwari1972/airbone-radar-\napplications-by-wg-cdr-anupam-tiwari.\n\n5.2 RADAR SCATTERING 299\n\nhttps://www.slideshare.net/anupamtiwari1972/airbone-radar-applications-by-wg-cdr-anupam-tiwari\nhttps://www.slideshare.net/anupamtiwari1972/airbone-radar-applications-by-wg-cdr-anupam-tiwari\n\n\nwhere r0 represents the distance between the radar and the target. In this expression, the limit states that\nthe RCS is measured in the far-field. The RCS depends on the frequency and the polarization of the\nradar waves, and also on the form and composition of the target. The computation of the RCS of very\nsimple targets can be approximated analytically and can be found in the classical references on radar\n(Skolnik, 1980b; Rihaczek, 1969). In more complex cases, however, its computation requires the use\nof numerical electromagnetic solvers.\n\nThe RCS describes the power efficiency of the scattering mechanism of a given target, but fails to\ndescribe homogeneous areas without clear boundaries. For these cases, the RCS can be averaged over\nthe surface or volume where the scatterer extends. The average RCS per unit of resolution cell is\ndenoted as sigma naught, and it can be expressed as\n\ns0 \u00bc hsRCSicell\nAcell\n\n; (5.13)\n\nwhere Acell is the area of the resolution cell on the ground, and h$i indicates spatial averaging over a\nmultiplicity of observations. This equation is valid for imaged surfaces and can be consistently\nextended to the case of volumes by swapping the area in the denominator with a volume. However, a\nconstant area on the ground might project differently on the geometry of the image depending on the\nlocal topography of the scene, which results in a terrain-dependent modulation of the scattering\ncoefficient s0. The reflectivity of the scene normalized to the unit area of the slant range resolution cell\nis typically known as radar brightness (Raney et al., 1994), and can be approximated as\n\nb0 \u00bc\nhsRCSicell\nAslant;cell\n\n; (5.14)\n\nwhere the Aslant,cell is the size of the resolution cell in the geometry of the image. The transformation\nbetween the two different areas requires knowledge of the local topography to be able to project\nbetween a slant view and flat ground, i.e.,\n\ns0z\nb0\n\nsin qi\n\u00bc b0\n\nsin\n?\nqi; flat ? aslope\n\n? ; (5.15)\nwhere the qi is the local incident angle depending on look angle and the local slope, qi, flat is the\nincident angle to the flat terrain, aslope is the angle of the ascending slope, and a constant resolution cell\nin Doppler has been assumed. Note that this equation has been derived under the assumption of\ncoplanar slope and incidence.\n\nExpressing the normalized reflectivity relative to the unit area of the incident wave front helps to\nreduce its dependence on the incidence angle, at least for a rough surface. A further discussion on the\ndependence of the radar scattering on slopes and incident angles is given later. The normalization to\nthe area of the wave front, as suggested in Cosgriff et al. (1960), yields gamma naught, which is related\nto b0 as follows\n\ng0z\nb0\n\ntan qi\n. (5.16)\n\nWe illustrate the impact of the different normalizations with Fig. 5.7, which shows two sets of\nTerraSAR-X images scaled according to s0, b0, and g0 from left to right, respectively.\n\n300 CHAPTER 5 RADAR\n\n\n\nThe top image shows a rain forest area in Brazil, which is expected to yield a rather homogeneous\nbackscatter. As expected, both b0 and g0 reflect the rain forest homogeneity with more fidelity than s0,\nwhich in this case was normalized using the ellipsoidal height. The differences between b0 and g0 are\nsmall due to this scene homogeneity and the incidence angle. The bottom image shows an image of\ncentral Denmark, where a similar trend can be observed. In this case, however, the differences between\nb0 and g0 appear clearer due to the scene inhomogeneity and the steeper incidence angle.\n\nFIGURE 5.7\n\nTwo sets of geocoded TerraSAR-X images over the Brazilian rain forest (top) with an incidence angle of 46.5?,\nand over central Denmark (bottom) with an incidence angle of 34.7?. From left to right the normalizations are\nrelative to s0, b0, and g0, where s0 has been computed projected onto the ellipsoid; the other two take into account\n\nthe local topography. As expected, s0 contains a significant modulation caused by the local topography, which is\n\nprogressively reduced in the radar brightness and g0. The differences between these two are more noticeable in the\n\nbottom image due to the inhomogeneity and steeper incidence.\n\nCourtesy of DLR.\n\n5.2 RADAR SCATTERING 301\n\nmailto:Image of Figure 5.7|tif\n\n\n5.2.3 POINT VERSUS DISTRIBUTED SCATTERERS\nOne of the characteristics of the scene is the density of single scatterers within each resolution cell. In\nradar images, single scatterers are those with dimensions on the order of the wavelength. In our single\nscattering approximation, the observed complex reflectivity in a resolution cell can be approximated\nby the coherent superposition of the reflectivities of the individual scatterers within the cell, i.e.,\n\nrz\nX\ni\n\nri$exp\n\n?\n?j$2p\n\nl\n$dri\n\n?\n; (5.17)\n\nwhere the ri are the complex reflectivities of the individual scatterers and dri represents the differential\nrange of the individual targets with respect to the center of the cell. The different cases that will be\nanalyzed in this subsection are illustrated in Fig. 5.8.\n\nThe point target is identified as a dominant single scatterer within a resolution cell. Both the\namplitude and the phase observed by the radar in the corresponding image pixel will be dominated by\nthe response of the point target, which spreads over consecutive resolution cells following the impulse\nresponse of the system. The model for the point target is a Dirac function in space, i.e.,\n\nr\u00f0r; x\u00dez ffiffiffiffiffiffiffiffiffiffisRCSp $a$exp\u00f0 j$f\u00de$d\u00f0r ? r0; x? x0\u00de; (5.18)\nwhere sRCS is the radar cross section of the target, a is a constant with dimensions 1/m to make the\nexpression dimensionally compatible, and f is any constant phase. This model can be used for cali-\nbration targets like trihedral reflectors. A realistic point target of opportunity, however, looks more like\nthe bottom purple scatterer depicted in Fig. 5.8. In addition to the dominant scatterer, the cell includes\ncontributions of a set of smaller scatterers which will cause a slight deviation with respect to the ideal\npoint target response. In any case, a point target is characterized at any instant in time by a single\n\nFIGURE 5.8\n\nA representation of individual scatterers in several resolution cells of the radar image. The purple are dominant\n\nscatterers appearing as point targets in the images. The top purple scatterer appears as an ideal point target,\n\nwhereas the bottom purple is a dominant point surrounded by some additional points. The extended target appears\n\nas a deterministic target occupying several resolution cells. The distributed target is formed by a random\n\ncollection of homogeneous scatterers within the resolution cells. The thickness of the individual scatterers is\n\nintended to represent the magnitude of the reflectivity of the target.\n\n302 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.8|eps\n\n\nfrequency in the Doppler spectrum, which suggests the possibility of using spectral estimation tech-\nniques for enhanced resolution imaging (Salzmann et al., 2004). An example of a point target response\n(e.g., calibration trihedral) in a radar image is shown in Fig. 5.9.\n\nIf the dominant single scatterer extends over several resolution cells, we will speak of an extended\nscatterer, as depicted in Fig. 5.8. The reflectivity model of the extended target extends in both space\nand Doppler domains. Exemplary extended targets in radar images are buildings, as shown in the left\nimage of Fig. 5.10 in a neighborhood of Sevastopol, Russia.\n\nFIGURE 5.9\n\nTerraSAR-X staring spotlight image over the DLR receiving station in the O\u2019Higgins peninsula in Antarctica. The\n\nbright point in the center of the image shows a calibration target, appearing as an ideal point. Radar illumination is\n\nfrom the left. The extension in azimuth of the point target is reduced due to weighting.\n\nCourtesy of DLR.\n\nFIGURE 5.10\n\n(Left) TerraSAR-X staring spotlight image over Sevastopol, Russia. Radar illumination is from the left. The\n\nbuildings in the image appear as extended targets. (Right) TanDEM-X image of savanna area near Kweneng,\n\nBotswana. The area is homogeneous and can be interpreted as a distributed target.\n\nCourtesy of DLR.\n\n5.2 RADAR SCATTERING 303\n\nmailto:Image of Figure 5.9|tif\nmailto:Image of Figure 5.10|tif\n\n\nAn extended target of a stochastic nature is a distributed target: extended because it is not small\nenough to fit the single-scatterer model and stochastic because it is fully characterized by a small\nnumber of statistical descriptors. Distributed targets are usually modeled by the superposition of several\nscatterers with similar RCSs and they are randomly placed within the resolution cell, as depicted in the\nblack areas of Fig. 5.10. Because of the coherent superposition of the backscattered echoes, the\namplitude and phase of the cell reflectivity appear to be random. Depending on whether the coherent\nsignal of the distributed scatterer is the result of constructive or destructive interference, the subject cell\nwill appear bright or dark in the radar image, an effect commonly referred to as speckle. The spectrum\nof the echoes of a distributed scene covers the entire instantaneous Doppler range and basically appears\nas noise in the radar images. The right image of Fig. 5.10 shows a savanna area in Botswana imaged by\nTanDEM-X; the image shows little contrast as expected from an ideal distributed area.\n\n5.2.4 SPECKLE, MULTILOOK, AND RADIOMETRIC RESOLUTION\nIf the size of the resolution cell is much larger than the wavelength, the assumption of a large number\nof scatterers within the cell (i.e., distributed target) is plausible. Under these circumstances, the\ncomplex reflectivity can be assumed to be described as a circular Gaussian process with a zero-mean\nand a probability density function (pdf).\n\npS\u00f0s\u00de \u00bc 1\np$s0\n\n$exp\n\n\"\n? <\u00f0s\u00de\n\n2 \u00fe J\u00f0s\u00de2\ns0\n\n#\n; (5.19)\n\nwhere <\u00bd$? and J\u00bd$? are the real and imaginary parts of the radar image, each having a standard\ndeviation equal to\n\nffiffiffiffiffiffiffiffiffiffi\ns0=2\n\np\n.4 The intensity of the image is computed as the square of the magnitude of\n\nthe complex reflectivity, i.e.,\n\nI \u00bc jsj2; (5.20)\nwhich for an ideal distributed target follows an exponential distribution with pdf\n\npI\u00f0I\u00de \u00bc 1\ns0\n$exp\n\n?\n? I\ns0\n\n?\n. (5.21)\n\nIt follows from the previous expression that both the mean value and standard deviation of I will be\ns0. Fig. 5.11 shows the pdfs of the components of the complex reflectivity and the intensity of the radar\nimages of an ideal distributed scatterer.\n\nThe statistics of the distributed scatterers can be used to separate them from point and extended\nscatterers in radar images. As an example, Fig. 5.12 shows a color-coded TerraSAR-X image over\nBerlin city center. The \u201cdistributed\u201d areas appear bluish in the image, whereas the \u201curban\u201d and\n\u201cdeterministic\u201d areas appear yellowish. The condition of detection of the distributed areas was based\non the assumption that the local average of the reflectivity equals its standard deviation, as predicted\nfrom the exponential distribution above.\n\nAs a consequence of (5.19), the phase of the radar image is uniformly distributed. The coherent\nnature of radar images results in bright and dark intensity pixels due to constructive and destructive\n\n4The normalization with respect to the ground resolution cell is ignored in this derivation for the sake of simplicity.\n\n304 CHAPTER 5 RADAR\n\n\n\ninterference between the echoes of the single scatterers within the resolution cell. The effect is shown\nin the left and right diagrams of Fig. 5.13.\n\nThe situation is exemplified in Fig. 5.13, where the different pixels of the intensity image (bottom)\nappear brighter or darker depending on the constructive or destructive interference of the scatterers of\nthe resolution cells (above). Note that point targets have no speckle, and speckle tends to be reduced\nwith increasing resolution, since a lesser number of scatterers is likely to appear in the resolution cells.\n\nSpeckle has been historically considered as a noise source, with a multiplicative character, i.e.,\nincreasing the transmitted power does not reduce its effect. This consideration is of course unfair, since\nthe coherent character of the system is what gives radars the potential to achieve geometrical\n\nFIGURE 5.11\n\nProbability density functions (pdfs) of the real and imaginary parts of the complex reflectivity (left) and the in-\n\ntensity (right) for the radar image of an ideal distributed scatterer.\n\nFIGURE 5.12\n\nTerraSAR-X image over Berlin city center, Germany. The image shows the Brandenburger Tor and the Central\n\nRailway Station. The distributed areas appear blue, whereas the urban areas are yellow.\n\n5.2 RADAR SCATTERING 305\n\nmailto:Image of Figure 5.11|tif\nmailto:Image of Figure 5.12|tif\n\n\nresolutions on the order of the wavelength. However, the intensity as the estimator of the sigma naught\nis responsible for giving speckle all its bad reputation. To better estimate the backscatter of the scene,\nwe can compute a local average of homogeneous pixels, i.e.,\n\nI \u00bc\nD\njsj2\nE\n. (5.22)\n\nIf the averaging is done over N independent pixels, the distribution of I can be shown to be a\nGamma function (Papoulis, 1965), with a pdf of the form\n\npI\n?\nI\n? \u00bc NN\u00f0N ? 1\u00de! $ I\n\nN?1\n\nI\nN\n0\n\n$ exp\n\n?\n? N $ I\n\nI0\n\n?\n. (5.23)\n\nThe variance of I is reduced by a factor N under the assumption that the samples are statistically\nindependent, i.e.,\n\ns2\nI\n\u00bc s\n\n2\n0\n\nN\n; (5.24)\n\na condition fulfilled by ideally distributed targets provided there is no oversampling, nor weighting.\nThe local averaging of the intensity image is incoherent. The averaged intensity I will then be a much\nbetter estimator of sigma naught than the full resolution intensity. This local averaging is known as\nmultilooking, with N the number of looks. Multilooking can be effected in both the time and frequency\ndomains (Curlander and McDonough, 1991). The improvement in the variance of the estimation after\nmultilooking is only achieved if two conditions are fulfilled: (1) statistical independence of the\nsamples, and (2) the different samples correspond to the same distributed target. The compromise is a\n\nFIGURE 5.13\n\nSpeckle is a consequence of the coherence of radar echoes. The constructive and destructive interference (left and\n\nright) of the scatterers in the different resolution cells (top) results in brighter and darker pixels in the image\n\nintensity (bottom).\n\n306 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.13|eps\n\n\nreduction in the geometrical resolution of the image roughly equal to the gain in the variance of the\nestimator. This effect is illustrated in the left part of Fig. 5.14.\n\nThe image on the left shows the original intensity image with noticeable speckle in the distributed\nareas. The mid-left image shows the multilooked intensity with a 11 ? 11 window. The sigma naught\nvalues appear to be significantly smoothed at the expense of a reduced geometric resolution. A number\nof speckle filters have been designed over the years, all of them with the similar purpose of averaging\nthe homogeneous areas while respecting the edges in the images (Shi and Fung, 1994). Fig. 5.14 shows\ntwo examples of these space-variant approaches on the right-hand side: Lee filter (middle right), and\nan iterative simulated annealing filter (right).\n\nThe sensitivity of the radar system to changes in the received power determines its radiometric\nresolution, which is typically proportional to the ratio of the standard deviation of the image divided by\nits expected value, i.e.,\n\nds0 \u00bc 10$log10\n \n1\u00fe sI\n\nmI\n\n!\n; (5.25)\n\nwhere mI is the mean value of the multilooked intensity, sI is its standard deviation, and the radiometric\nresolution is expressed in decibels. Under the presence of noise, the standard deviation of the image is\ndegraded, and the previous expression can be approximated as follows:\n\nds0z 10$log10\n\n0B@1\u00fe g$\ns0ffiffiffiffi\nN\n\np\ns0\n\n1CA \u00bc 10$log10?1\u00fe 1\u00fe SNRffiffiffiffi\nN\n\np\n$SNR\n\n?\n; (5.26)\n\nwhere the g is a decorrelation factor, well known in the SAR interferometry field. In this case, it is due\nonly to receiver and quantization noise. The previous equation is one of the fundamental expressions\ndriving the design of any remote sensing radar.\n\n5.2.5 RADAR EQUATION\nThe idealized power budget of the radar link (transmitter-target-receiver) is usually known as the radar\nequation. In the case of remote sensing radars, scenes can be assumed to be distributed and not\n\nFIGURE 5.14\n\nOriginal intensity image (left) and the results after several methods of speckle filtering. Multilooking with a\n\n11 ? 11 window (mid-left), 11 ? 11 Lee filter (mid-right), and iterative \u201csimulated annealing\u201d filter after 200\niterations, with a 3 ? 3 box (right). The improvement in the radiometry without loss of resolution is apparent.\n\n5.2 RADAR SCATTERING 307\n\nmailto:Image of Figure 5.14|tif\n\n\ncomposed of isolated targets, and consequently, no integration gain should be assumed. A sketch of the\nmonostatic radar link is shown in Fig. 5.15.\n\nThe radiated power by the antenna is known as the equivalent isotropic radiated power (i.e., EIRP)\nand can be expressed as\n\nPTx \u00bc G$Ppeak; (5.27)\nwhere G is the gain of the transmitter antenna in the look direction and Ppeak is the peak power\ndelivered by the power amplifier applied after the data are received by the antenna. Considering the\nfree-space losses in the one-way path from radar to the scene, the surface power density at the vicinity\nof the scene can be expressed as\n\nxTx \u00bc\nPTx\n\n4p$r20\n; (5.28)\n\nwhere r0 is the distance from radar to scene. The signal power at the receiver can be computed by\nintegrating over the area on the ground, which contributes to a single sample in the radar echoes,\nextending in range the length of the transmitted pulse and the footprint of the antenna in azimuth, as\nshown in Fig. 5.16.\n\nThe shaded area of Fig. 5.16 can be approximated by\n\nAillumz\nc$sp\n\n2$sin qi\n$\nr0$l\n\nLa\n; (5.29)\n\nwhere sp is the duration of the transmitted pulse and La is the length in azimuth of the antenna. The first\nterm of (5.29) is the ground range resolution due to the pulse envelope, and the second term is the\nprojection of the azimuth antenna pattern on the ground. The scene is characterized by its scattering\n\nFIGURE 5.15\n\nSchematic view of a monostatic radar illuminating an area with backscattering cross section s0.\n\n308 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.15|eps\n\n\ncross-section sigma naught value (s0). Under these circumstances, the surface power density at the\nvicinity of the radar antenna can be computed as\n\nxRx \u00bc xTx$\nAillum$s0\n\n4p$r20\n. (5.30)\n\nThe received power is a function of the effective antenna area of the receiver Ae,Rx, which after\nsome recollection of terms becomes\n\nPRx \u00bc xRx$Ae;Rx \u00bc xTx$\nAillum$s0\n\n4p$r20\n$\nl2$G\n\n4p\nz\n\nl3$G2\n\n\u00f04p\u00de3$r30\n$\n\nc$sp\n2$sin qi\n\n$\ns0\n\nLa\n$Ppeak. (5.31)\n\nThe thermal noise power at the end of the receiver chain can then be expressed as\n\nN \u00bc kB$T0$Beq$FRx; (5.32)\nwhere kB \u00bc 1:38064852$10?23 J=K is the Boltzmann constant, T0 \u00bc 290 K is the reference temper-\nature, Beq is the receiver\u2019s equivalent noise bandwidth, and FRx is the receiver\u2019s noise figure.\nRearranging terms and identifying the noise bandwidth as the available transmitted bandwidth of the\nradar, the signal-to-noise ratio (SNR) at the receiver becomes\n\nSNR \u00bc PRx\nN\n\n\u00bc l\n3$G2\n\n\u00f04p\u00de3$r30$k$T0$FRx\n$\n\ndrg\nLa$PRF\n\n$s0$Pavg; (5.33)\n\nwhere the pulse repetition frequency (PRF) allows us to scale the peak power to the average power\ntransmitted by the radar. The sensitivity of a remote sensing radar is typically measured by the noise\nequivalent sigma zero (NESZ) and corresponds to the value of s0 for an SNR of 0 dB, i.e.,\n\nNESZ \u00bc s0\u00f0SNR \u00bc 0 dB\u00de \u00bc \u00f04p\u00de\n3$r30$k$Teq$FRx$La$PRF\n\nl3$G2$Pavg$drg\n. (5.34)\n\nFrom\nradar\n\nFlight track\n\nFIGURE 5.16\n\nArea on the ground contributing to a single echo sample over which the integration of the received power of the\n\nradar shall be carried out.\n\n5.2 RADAR SCATTERING 309\n\nmailto:Image of Figure 5.16|eps\n\n\nAs expected from this definition, the lower this value is, the better the sensitivity of the system. The\nNESZ is one of the driving requirements of any remote sensing radar. High values of NESZ will yield\nnoisy radiometry and location inaccuracy, hence decreasing the quality of the final measurements.\nTypical values of NESZ in spaceborne radar systems are better (lower) than ?20 dB.\n\n5.2.6 RADAR WAVES AT AN INTERFACE\nThe surface of the Earth can be interpreted as a resistive dielectric, whose dielectric constant depends\non factors such as the material, the moisture, and the radar carrier frequency. In the case of a simple\ncarrier wave, the refractive index of the soil can be expressed as\n\nn2 \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n?\n0 ? j$ scond\n\n2p$f $?0\n\nr\n; (5.35)\n\nwhere ?\n0\nis the relative permittivity of the soil, scond its conductivity,\n\n5 f is the frequency, and ?0 is the\npermittivity of a vacuum. The soil will behave as a good conductor when the relative permittivity is\nnegligible with respect to the value of the second term inside the square root, i.e.,\n\nscond\n\n2p$f $?0\n[?0; (5.36)\n\na condition which is naturally more easily fulfilled at lower frequencies.\nLet us first consider a simple example: an incident radar wave impinging on a flat surface sepa-\n\nrating the air from a dielectric soil. A surface will be flat whenever the length of the surface is much\nlarger than the wavelength, i.e., L [ l. As predicted by geometrical optics, the wave will be reflected\nin the specular direction (i.e., qr \u00bc qi), as depicted in Fig. 5.17.\n\nWhen the material is a good conductor, all incident energy is reflected. In the opposite case, some\nof the energy of the incident wave penetrates and is refracted into the dielectric, with the geometry of\nrefraction following Snell\u2019s law.\n\nThe amount of energy reflected and refracted can be computed with help of the Fresnel\u2019s\ncoefficients, derived from the boundary conditions of the electrical and magnetic fields at the interface.\nThe Fresnel coefficients vary depending on the polarization of the incident wave. The reflection\ncoefficients for vertically (V) and horizontally (H) polarized waves take the following forms (Hecht,\n1997)\n\nrVr \u00bc\nEVr\nEVi\n\n\u00bc n2$cos qi ? n1$cos qt\nn1$cos qi \u00fe n2$cos qt ;\n\nrHr \u00bc\nEHr\nEHi\n\n\u00bc n1$cos qi ? n2$cos qt\nn1$cos qi \u00fe n2$cos qt .\n\n(5.37)\n\nWhen jn2j > jn1j, jrHrj > jrVrj, this is a characteristic that will be relevant in the analysis of the\nscattering by rough surfaces. Note that rHr and rVr can take negative values depending on the sign\nof the numerator, which corresponds to a phase shift of 180?. This is the particular case of reflection\n\n5Not to be confounded with the RCS (sRCS) or sigma naught (s0) frequently mentioned throughout this chapter.\n\n310 CHAPTER 5 RADAR\n\n\n\nfrom a good conductor, with rVr \u00bc 1, and rHr \u00bc ?1. The refraction coefficients for the V and H\ncomponents are\n\nrVt \u00bc\nEVt\nEVi\n\n\u00bc 2$n1$cos qi\nn1$cos qt \u00fe n2$cos qi ;\n\nrHt \u00bc\nEHt\nEHi\n\n\u00bc 2$n1$cos qi\nn1$cos qi \u00fe n2$cos qt .\n\n(5.38)\n\nEqs. (5.37) and (5.38) encompass all the necessary information needed to understand the scattering\nprocesses occurring in typical Earth observation radars. Reflection will be the relevant phenomenon in\nthe analysis of simplified targets, such as urban areas and land and ocean surfaces. Refraction will play\na role in the penetration of the radar waves and the imaging of volumetric structures such as forests,\nice, or dry soil.\n\n5.2.7 MULTIPLE REFLECTIONS: DOUBLE BOUNCE, TRIPLE BOUNCE,\nAND URBAN AREAS\n\nSo far, we have considered a simple radar interaction with a dielectric. Sticking to geometrical optics,\nlet us turn to more complicated scenarios that are particularly relevant in artificial targets and urban\nareas: double and triple bounces. The double bounce is characterized by the double reflection\nhappening at a dihedral (e.g., L-formed) target as the one depicted in the left panel of Fig. 5.18.\n\nIn the case of urban areas, the double bounce is combined with the already discussed layover effect.\nAs a consequence, not only do buildings appear laid over in the radar images, but their signatures\n\nFIGURE 5.17\n\nReflection and refraction of an incident wave onto a flat surface, L[ l. The angle of reflection qr is equal to the\n\nincident angle qi. The angle of refraction is subject to Snell\u2019s law. The amplitude and phase balance of the\n\nreflection and refraction effects are described by the Fresnel coefficients.\n\n5.2 RADAR SCATTERING 311\n\nmailto:Image of Figure 5.17|eps\n\n\npresent bright areas at the tops and the bottoms of the structures, as shown in the radar image of\nFig. 5.18. In this figure, the horizontal bright lines along the buildings correspond to the double (or\ntriple) reflections at the vertical edge of the building aligned with the radar line of sight (LOS), i.e., the\nradar signature is capable of discriminating the orientation of the building with respect to the satellite\norbit. Double bounce reflections are also typical in sparsely forested areas.\n\nAs an example of the sensitivity of backscattering to the orientation of the targets, Fig. 5.19 shows a\nmonostatic (magenta) and bistatic (green) TanDEM-X image over Brasilia, Brazil.\n\nThe images are acquired with an angular separation of 2?, enough to gain sensitivity to the\norientation of buildings in the city center. The magenta areas show the buildings oriented relative to the\nmonostatic observation, whereas the green areas show an orientation favorable to the bistatic\nmeasurement. A consequence of the sensitivity to orientation is the loss of the double bounce in the\ngeneral bistatic configurations, as illustrated in Fig. 5.20.\n\nThe square in the middle of the monostatic radar image (left), corresponding to a metallic fence is\nnowhere to be found in the bistatic image. Moreover, the solar panels at the bottom of the crop field,\nappear very bright in the monostatic geometry and very dark in the bistatic one. The sensitivity to the\norientation of the targets can also be observed in natural areas such as crops (rows) or ocean waves.\n\nMore complex targets usually show a more elaborate reflection structure, including three or more\nbounces. A typical example is that of bridges, as the one shown in the left panel of Fig. 5.21. The right\nimage shows a multitemporal image of the Sydney Harbor Bridge acquired by TerraSAR-X in spot-\nlight mode.\n\nThe direct reflection corresponds to the thin arch and deck structures of the bridge. The double\nbounce causes the deck, pillars, and arch to appear a bit thicker to the left. The thicker lines correspond\nto the triple bounce of deck and arch, respectively. A further, better known, example of a triple bounce\n\nFIGURE 5.18\n\n(Left) Double bounce scattering occurs when two reflective surfaces are perpendicular to each other. (Right)\n\nTerraSAR-X image of Guangdong; note the base of the buildings appears much brighter than the rest due to the\n\ndouble bounce.\n\nCourtesy of DLR.\n\n312 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.18|tif\n\n\nFIGURE 5.20\n\nMonostatic (left) and bistatic (center) radar images, and corresponding optical (right) image of some buildings of\n\nKaufbeuren airfield, Germany. The white square in the middle of the monostatic image corresponds to the double\n\nbounce of a metallic fence, which disappears completely in the bistatic geometry.\n\nCourtesy of DLR.\n\nFIGURE 5.19\n\nTanDEM-X overlay of monostatic (magenta) and bistatic (green) images over Brasilia, Brazil. The angular\n\ndifference between the monostatic and bistatic acquisitions is about 2?, enough to separate the monostatic from\nthe bistatic scattering in the city area due to target orientation.\n\nCourtesy of DLR.\n\n5.2 RADAR SCATTERING 313\n\nmailto:Image of Figure 5.20|tif\nmailto:Image of Figure 5.19|tif\n\n\nis the one occurring in trihedrals that are rather insensitive to the azimuthal angle with which they are\nobserved. Trihedral targets, also known as corner reflectors, are commonly used for the calibration of\nradar systems.\n\nSo far, our discussions have dealt with the radar signatures of simplified isolated targets. In the case\nof a city, everything becomes much more complicated because of the more complex reflection\nschemes, the superposition of the signatures of buildings and structures and because of the geometrical\nand dielectric complexity of the individual targets. The previous TerraSAR-X images of Figs. 5.19 and\n5.21 exemplify this complexity.\n\n5.2.8 BACKSCATTERING OF SURFACES\nThe previous sections introduced the radar signatures of some simplified targets (e.g., dihedrals and\ntrihedrals), which are linked to the analysis of multiple reflections and serve to help interpret scattering\nmechanisms in urban areas. We now turn our attention to more homogeneous areas, where the scat-\nterers in the resolution cells are on a surface, and no penetration beyond the interface occurs. The\ndominant phenomenon in the interaction of radar waves and surfaces is reflection, with a spatial\nsensitivity on the order of the wavelength.\n\nWe will focus our consideration of the backscatter on the reflections from the observed surface, and\nstart with a set of simple examples. The basic behavior is described by the reflection model discussed\nearlier under the assumption of an infinite layer boundary. The infinite layer situation is again illus-\ntrated by the left panel of Fig. 5.22, where the incident angle is now assumed to be zero, and the\nreflected energy is scattered back only in this direction.\n\nIf the layer has a finite length (relative to the wavelength), the situation is best described by the\nthree figures on the right of this figure, where in all cases the incident angle is assumed to be zero.\n\nFIGURE 5.21\n\nSchematic description of single, double, and triple bounces occurring in pedestal structures like bridges (left).\n\nTerraSAR-X spotlight image on the right over the bay of Sydney, Australia, showing the single, double, and triple\n\nbounce reflections of the Harbor Bridge.\n\nCourtesy of DLR.\n\n314 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.21|tif\n\n\nLet us start with the one on the right, which represents an isolated infinitely small scatterer. In this case,\nthe target behaves isotropically and scatters the energy in all directions. If a short surface is assumed,\nas it is the case of the two figures in the middle, the surface behaves by showing directivity, the greater\nthe larger the surface. As a consequence, most of the reflected energy follows along the reflection angle\nbut some is scattered in other directions. In general, the aperture angle of the scattering pattern can be\napproximated by\n\nqsz\nl\n\nLs\n; (5.39)\n\nwhere Ls is the length of the segment, in the following facet. The former equation is analogous to that\nof the aperture of an antenna, and the backscattering patterns reminds one of antenna radiation pat-\nterns. For simplicity, the scattering patterns depicted have been set to sinc-forms, basically a funda-\nmental assumption of homogeneity. The model can be assumed to be rotation-invariant; i.e., if the\nangle of incidence of the incoming wave is not zero, the described patterns shall be rotated accord-\ningly. The power return of the segment can be assumed to be a function of the local refractive index of\nthe soil, as in the reflection Fresnel coefficients.\n\nWe can represent any surface as the superposition of rotated and shifted facets of different lengths.\nThe refractive index of the soil under a segment may be allowed to vary, hence modulating the local\nscattering pattern of the facet. Under the geometrical optics approximation, the scattering pattern of\nthe scene will then be the superposition of the patterns of the facets, as shown in Fig. 5.23.\n\nThe facet model is obviously an approximation that may break down in cases where the\nmicroscopic scale of the surface is relevant or a more elaborate electromagnetic interaction between\nthe radar waves and the surface is required. The approximation, however, serves our purposes well\nand helps to illustrate the relationship between the roughness of the surface and the brightness in the\nradar image. As a general rule, the smoother the surface, the more specular it will be. This trend is\nillustrated in the right plot of Fig. 5.23. Another direct consequence is that the radar backscatter will\ndepend on the primary slope of the surface. Ascending slopes will appear brighter than flat areas, and\nthese brighter than descending slopes, especially for smooth areas. This effect can be clearly seen in\nradar images over mountainous areas, such as that in Fig. 5.24. The image shows the s0 normalized\nusing the ground resolution cell on the ellipsoid. Normalizing the image to the area of the wavefront\n\nFIGURE 5.22\n\nBackscatter patterns for facets of different lengths assuming a zero-degree incidence angle. The shorter the facet\n\nrelative to the wavelength, the broader the backscatter pattern.\n\n5.2 RADAR SCATTERING 315\n\nmailto:Image of Figure 5.22|tif\n\n\nusing the information of the local slopes results in a more homogeneous estimate of the radar\nbackscattering.\n\nAs a summary of the previous results, Fig. 5.25 shows a plot of the radar backscatter as a function\nof incidence angle for three different surface roughness.\n\nAs expected, the radar backscatter decreases for increasing incident angles, more steeply for\nsmooth surfaces, which behave in a very specular manner. Rough surfaces show brighter returns for\nshallow incident angles. Conversely, smooth surfaces show much brighter returns for steep incident\n\nFIGURE 5.24\n\nTerraSAR-X staring spotlight image over Mount Bromo, East Java. Radar illumination is from the left. Note that\n\nthe brighter areas correspond to ascending slopes, whereas descending slopes appear darker.\n\nCourtesy of DLR.\n\nFIGURE 5.23\n\nThe left panel shows the approximation of a surface by a collection of shifted and rotated facets. The right panels\n\nshow the resulting scattering diagram for different surface roughness. Increasing roughness results in a more\n\nisotropic scattering and increases the amplitude of the radar backscatter.\n\n316 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.24|tif\nmailto:Image of Figure 5.23|tif\n\n\nangles. It is important to remember that the roughness of the surface is of course relative to the radar\nwavelength. A simplified model for the definition of rough assumes a small phase variation in the radar\ncarrier due to the small height variation within the resolution cell, i.e.,\n\n4p\n\nl\n$cos qi$Dh < k$p. (5.40)\n\nwhere the left part of the equation approximates the phase difference between the bottom and top of the\nrough surface and k is a constant which can be tuned depending on the sensitivity criterion. The case\nwhere k \u00bc 0.5 is known as the Rayleigh criterion, whereas the more stringent k \u00bc 0.125 is known as\nthe Fraunhofer criterion.\n\nSince we have defined the directivity of a facet as a function of wavelength, the same level of\ngeometrical roughness shall be observed differently by radars with different carrier frequencies. In\nparticular, higher frequencies will appear more sensitive to roughness than lower ones. In Fig. 5.26,\nwe observe a large range of radar backscatters for smooth and moderately rough surfaces. The direct\nconsequence may be that a larger dynamic range can likewise be expected for lower carrier\nfrequencies imaging surface areas. As an example, Fig. 5.26 shows two airborne radar images\nacquired by the DLR F-SAR system over Wallerfing, Germany, in X (top) and L-bands (bottom). The\nbottom image shows a larger dynamic range despite the equalization of the histograms prior to the\ndisplay of the files.\n\nTo further illustrate the dependence of the backscatter on the roughness of the surface, Fig. 5.27\nshows a calm sea (left) surrounding the island of Montserrat appearing very dark in the radar image.\n\nFIGURE 5.25\n\nRadar backscatter as a function of the incidence angle for three different values of surface roughness.\n\n5.2 RADAR SCATTERING 317\n\nmailto:Image of Figure 5.25|tif\n\n\nA rougher sea, however, such as the one shown off the coast of Keflavik, Iceland (right), appears\nmuch brighter in the image. Note the runway of Keflavik airport appears very dark due to the\nsmoothness of the asphalt. Fig. 5.28 shows fields in the state of Victoria, Australia, showing very\ndifferent backscatter due to the varying equivalent roughness of the surfaces. Note the lake at the\nbottom of the image appears very dark, which suggests the absence of wind during the acquisition.\n\n5.2.9 PERIODIC SCATTERING: THE BRAGG MODEL\nWe have so far approximated rough surfaces as a collection of translated and rotated facets. The\nscattering diagram of the resulting surface can be well approximated by the superposition of the\nscattering diagrams of the individual facets, which assumes that their combination may be somewhere\nbetween constructive and destructive. We will now turn to the analysis of periodic surfaces which\nyields a resonant (i.e., constructive) scattering mechanism known as Bragg scattering. This scattering\nprocess will be very helpful in the analysis of some agricultural areas, as well as ocean surfaces\ncovered with wind generated waves. This is especially useful at lower frequencies (e.g., L band;\nCaponi et al., 1988).\n\nFIGURE 5.26\n\nX (top), and L (bottom) band radar images over Wallerfing, Germany, acquired by the DLR F-SAR airborne\n\nsystem. Radar illumination is from the top. The larger dynamic range in the bottom image is noticeable despite the\n\nequalization of the histograms performed in the generation of the images.\n\nCourtesy of DLR.\n\n318 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.26|tif\n\n\nIn Fig. 5.29 (top left), we see the geometry of the scattering process, where the returns of the two\npoints on ground add coherently in the received echoes. Note the similarity of the Bragg model with\nthe previous case of an array of antennas.\n\nThe spatial wavelength for Bragg scattering can be approximated as a function of the incident\nangle by\n\nlBz\nl\n\n2$m$cos qi\n; (5.41)\n\nFIGURE 5.28\n\nVarying backscattering in fields in the State of Victoria, Australia, as observed by TerraSAR-X.\n\nCourtesy of DLR.\n\nFIGURE 5.27\n\nCalm sea surface surrounding Montserrat (left) as observed by TerraSAR-X. Rough sea surface near Keflavik,\n\nIceland (right), acquired by TerraSAR-X. Note the reflectivity of the sea increases and a definite pattern can be\n\nobserved. Note the runway of the airport appears black in the image due to the smoothness of asphalt.\n\nCourtesy of DLR.\n\n5.2 RADAR SCATTERING 319\n\nmailto:Image of Figure 5.28|tif\nmailto:Image of Figure 5.27|tif\n\n\nwherem is an integer. The previous condition ensures the coherent interference of the scattered echoes.\nThe scattering diagram of a resonant surface shows an inhomogeneous pattern with periodic peaks, as\npresented here in Fig. 5.29 (top right). If the scene is observed with an appropriate incidence angle, the\nscattering of the scene appears very bright; otherwise, it remains at a lower level. In the case of ocean\nsurfaces, Bragg scattering mainly occurs at shallow incidence angles, whereas the steep incidence\nangles (e.g., smaller than 20?) are dominated by specular reflection.\n\nFIGURE 5.29\n\nThe top left figure presents the basic geometry of resonant or Bragg radar scatter. The top right figure shows the\n\nresulting scatter diagram of a Bragg scatterer, showing an inhomogeneous form with energy being scattered in a\n\nfew different directions. The bottom figure shows an airborne radar image acquired by DLR F-SAR system at\n\nL-band over the Ammer river area, Germany. Bragg scattering occurs in the field in the center showing the white\n\ngeometric pattern. Note the field appears much brighter than the forest, which suggests the presence of a resonant\n\nmechanism.\n\nCourtesy of DLR.\n\n320 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.29|tif\n\n\nThe bottom panel of Fig. 5.29 shows an example of Bragg scattering in an airborne radar image\nacquired by DLR F-SAR system over the Ammer river area, Germany. Bragg scatter appears as the\nwhite pattern in the field in the middle of the image. All other fields appear very dark6 and even the\nforests are darker than the Bragg field, which clearly suggests the presence of a resonant mechanism.\nIn addition to the surface roughness, the dielectric properties of the surface play a role in the effective\nbrightness of the surface. In particular, changes in the permittivity of the soil will be reflected in\nchanges in the brightness of the surface in the radar images. A typical example is humidity and water\ncontent. For the same level of roughness, wet soil appears brighter than dry soil.\n\n5.2.10 BACKSCATTERING OF VOLUMES\nWhenever the scatterers within a resolution cell are not confined to the surface, we speak of a volume\nscatterer. This is the typical case of the radar waves penetrating into a medium, i.e., besides reflection,\na certain amount of refraction also occurs, especially in the case of homogeneous volumes. Volume\nscattering can occur in two different kinds of media (e.g., inhomogeneous forest and homogeneous\nsoil) as illustrated in Fig. 5.30.\n\nIn both cases the radar is assumed to be flying on a line normal to the paper illuminating along the\narrow. The purple circular corona represents the extension of a slant range resolution cell through the\nvolume, and a fair amount of scatterers can be assumed to be present within each cell. The left plot\n\nFIGURE 5.30\n\nIn volumes, the scatterers within the same resolution cell are distributed over a volume. Note the curvature of the\n\nradar wave entering into the second medium has been neglected in the figure for simplicity.\n\n6This is a consequence of the scaling of the image due to the increase in the dynamic range due to the presence of the reso-\nnant mechanism.\n\n5.2 RADAR SCATTERING 321\n\nmailto:Image of Figure 5.30|tif\n\n\nshows a forest, a good example of an inhomogeneous volume scatterer; other examples of inhomo-\ngeneous volume scatterers are natural vegetation and crops. The right panel of the figure shows a\nhomogeneous volume scatterer, which corresponds to snow or ice, sand, or dry soil. For the sake of\nsimplicity, the curvature of the radar waves due to refraction has been neglected in this figure.\n\nAs expected, the scattering patterns are not as easily characterized as in the case of simple artificial\ntargets or surfaces, and they become dependent on parameters such as heterogeneity, local orientation of\ndielectric properties, humidity, or varying refraction indices. Depending on the wavelength of the radar\nand the properties of the medium, the attenuation suffered by the radar waves will vary. Typically, longer\nwavelengths penetrate more than shorter wavelengths, and dense media attenuate more than diffuse\nmedia. Penetration into volumes gives the radar a rather unique capability, i.e., the potential to identify\nthe 3-D distribution of a scatterer, allowing for structure characterization. This property is expected to\nplay a paramount role in future radar missions in which the information of biospheric and cryospheric\nstructures will provide insight into the evolution of climate processes. As an example, the volume\nbackscatter of forests has been suggested to have a direct relationship to biomass (Wang et al., 1995),\nwhich will be operationally measured by the P band Earth Explorer Mission of the European Space\nAgency called Biomass, to be launched in 2020. For this purpose, wavelengths below S band, in\n\nFIGURE 5.31\n\nFully polarimetric P band (top) and L band (bottom) airborne radar images acquired by the DLR F-SAR over Lope?\n\nNational Park, Gabon. The F-SAR illumination is from the top. The color coding represents the different po-\n\nlarizations on the Pauli basis. The red channel represents the double-bounce surface trunks. Note the P band image\n\nappears more reddish due to the deeper penetration of the P band into the forest.\n\nCourtesy of DLR.\n\n322 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.31|tif\n\n\nparticular L band, appear to be particularly well suited. As an example, Fig. 5.31 shows a fully polar-\nimetric airborne radar image acquired with the DLR F-SAR system over Lope? National Park, Gabon.\nThe color coding represents the polarimetric information on the Pauli basis. Significant changes in the\nreflectivity of the forest can be recognized. The red channel roughly reflects the terrain. As expected, the\nred component is stronger in the P band image, which suggests the deeper penetration of the radar waves.\n\nA further example over dry soil area is presented in Fig. 5.32, which shows fully polarimetric C\nband (left) and L band (middle) images acquired with the DLR airborne system F-SAR over Ben\nGardane, Tunisia. The right-hand panel shows the corresponding hyperspectral image acquired using\nthe AVIS instrument of the Ludwig Maximilian University (LMU) in Munich, with the color channels\nof 659, 550, and 447 nm. The color coding of the radar images corresponds to the lexicographic\nchannels, with the cross-pol depicted in green. The top left area shows a plantation of olive trees, which\nappear strikingly different in the C band and L band images. In the C band signature, the volumetric\ncomponent is stronger, while the L band image is a much clearer response of solid terrain. The right\npanel shows an area that contains dry soil, which appears as volume scattering in the C band image.\nThe L band image shows a surface scattering probably due to the solid terrain underneath the sand.\n\nFIGURE 5.32\n\nFully polarimetric DLR airborne E-SAR C band (left), L band (middle), and hyperspectral AVIS instrument\n\n(right) images over Ben Gardane, Tunisia. The hyperspectral image has the RGB channels at 659, 550, and\n\n477 nm, respectively. The color coding of the radar images represents the different polarizations in the lexico-\n\ngraphic basis with the green channel representing the cross-pol. The dotted area on the top left side represents an\n\narea with olive trees, where the C band image indicates volumetric scattering and the L band image indicates\n\nsurface scattering. The right area contains dry soil, and the features repeat, which suggests the penetration of the\n\nradar waves into the dry soil. The data were acquired in 2005 in an ESA-ESRIN project: 18746/05/I-LG. AVIS\n\nhyperspectral data by Ludwig Maximilian University in Munich.\n\nCourtesy of DLR.\n\n5.2 RADAR SCATTERING 323\n\nmailto:Image of Figure 5.32|tif\n\n\nIn Fig. 5.33 we present an even more illustrative result, with three airborne images acquired over ice\nin Qeqertarsuup tunua area, Greenland, by the DLR airborne F-SAR system. The figure shows X band\n(top), C band (middle), and L band (bottom) geocoded images, again with the color coding representing\nthe Pauli components of the RGB channels and northing corresponding to the horizontal. Finer details of\nthe surface appear in the X-band image and get progressively mixed with the structure of the subsurface\n\nFIGURE 5.33\n\nFully-polarimetric geocoded DLR airborne F-SAR X-band (top), C band (middle), and L-band (bottom) images\n\nover an area close to Qeqertarsuup tunua, Greenland. The color coding represents the different polarizations in the\n\nPauli basis. The surface and its detailed structures are clearly visible in the X band image. Some level of detail is\n\nlost in the C band image, and some subsurface structures start to become apparent due to the limited penetration of\n\nthe radar signals. In the L band image, the subsurface structure of ice is more clearly depicted because of the\n\ndeeper penetration of the radar waves.\n\nCourtesy of DLR.\n\n324 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.33|tif\n\n\nin the C and L band images. In the L band image the structure of the subsurface is clearly apparent,\nwhich illustrates the potential of longer wavelengths for imaging volumetric structures.\n\nIn Fig. 5.34 we summarize the effects of radar wavelength on the ability to sense various target\nsurfaces.\n\n5.2.11 OVERALL SUMMARY OF RADAR BACKSCATTER\nIn the previous sections, we have introduced the relevant aspects of radar backscatter mechanisms in\nurban areas, land and ocean surfaces, and inhomogeneous and homogeneous volumes. We have further\nillustrated these effects with real radar images. As a summary of these previous sections, Table 5.2\nshows examples of backscatter of artificial surface, surface scatterers, and volume scatterers.\n\n5.2.12 DEPOLARIZATION OF RADAR WAVES\nDifferent polarizations of the radar waves are affected differently in their interactions with surfaces\nand volumes. Under the Born approximation, we have accepted this depolarization process to be only\ndependent on the geometrical and dielectric properties of the target. Conversely, the use of polarimetric\nradar relies on the implicit assumption that the depolarization of the radar waves yields a better\nunderstanding of the local scattering mechanisms of the scene.\n\nSince depolarization is a relative process, all quantitative polarimetric information is retained in the\namplitudes and phases between the different polarizations (Maitre, 2008). The descriptor of the\nscattering process in polarimetric radar needs to record the interactions between the polarizations\n\nFIGURE 5.34\n\nThe effect of increasing radar wavelength on its ability to sense through a tree canopy.\n\n5.2 RADAR SCATTERING 325\n\nmailto:Image of Figure 5.34|tif\n\n\nunambiguously. In the case of a single scatterer, this can be done with the help of a complex scattering\nmatrix, i.e.,\n\nS \u00bc\n?\nSHH SHV\n\nSVH SVV\n\n?\n; (5.42)\n\nwhere the elements of the matrix represent the response of the scatterer for all combinations of\ninputeoutput polarizations, i.e., the SHV describes the attenuation and dephasing suffered by the incident\nhorizontal component when scattered into the vertical component. The elements of the scattering matrix\ncan be interpreted as the Fresnel coefficients of the target, and need to be squared to observe the power\nefficiency of the scattering mechanism. Assuming transparent atmospheric conditions, the scattered\nelectrical field received by\n\nERxz\nexp ?j$2p\n\nl\n$r0\n\n? ?\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2$p$r20\n\nq $S$E!Tx \u00bc exp ?j$\n2p\n\nl\n$r0\n\n? ?\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2$p$r20\n\nq $ SHH SHV\nSVH SVV\n\n? ?\n$E\n!\n\nTx; (5.43)\n\nwhere E\n!\n\nTx is the transmitted electrical field. This expression characterizes all possible phase and\namplitude changes due to co-polarized (HH, VV) and cross-polarized (HV, VH) scattering.7 In\nmonostatic observations, the reciprocity theorem for electromagnetic waves results in the symmetric\nassumption of the cross-pol channels\n\nSVH \u00bc SHV. (5.44)\nWhile this symmetry assumption is generally valid, there are a few cases when it breaks down,\n\nnotably in bistatic measurement geometries. The propagation through the ionosphere, as already\n\nTable 5.2 Exemplary Values of Radar Backscatter for Typical Artificial Surface, Surface\nScatterers, and Volume Scatterers\n\nRadar\nBrightness s0 (dB) Target Examples\n\nVery high\nbackscattering\n\n>0 Artificial objects and urban areas, ascending terrain slopes, very\nrough surfaces, very steep incident angles\n\nHigh\nbackscattering\n\n?10 to 0 Rough surfaces (e.g., dense vegetation, forests, open water with\nwind), volumes (e.g., multiyear ice, marginal sea ice)\n\nModerate\nbackscattering\n\n?20 to ?10 Moderately rough surfaces (e.g., vegetation, crops, first-year ice,\nopen water with little wind)\n\nLow\nbackscattering\n\n>?20 Smooth surfaces (e.g., calm water, roads, very dry soil, deserts)\n\nNote the values are just representative and will change as a function of several parameters of the acquisition, such as wavelength\nand/or polarization.\n\n7The terms will be in the following abbreviated as co-pol and cross-pol, respectively.\n\n326 CHAPTER 5 RADAR\n\n\n\nhinted, may also affect the measurements of the polarization state of the radar echoes, especially in the\nlower frequencies (e.g., from C band downward).\n\nRadars measuring any two elements of ERx are called dual-polarized (i.e., dual-pol) radars.\nRadars measuring all elements of the ERx matrix are called quad-polarized (i.e., full-pol) radars. Dual-\npolarized radars can be implemented by installing an antenna capable of separately receiving H and V\npolarizations. This architecture is likely to also provide different combinations of transmit polarizations,\nhence allowing the measurement of the following co-pol/cross-pol combinations VV/VH and HH/HV.\nFull-pol radars are typically identical to dual-pol radars from a technological point of view, only they\nneed to be able to switch the transmit polarizations in consecutive pulses. Among the full-pol radar\nsatellites which have been launched in the past years, we can identify TerraSAR-X/TanDEM-X,\nALOS1/2, Radarsat-2, and now Sentinel-1A/B. Full-pol operation is expected to be standard in future\nradar missions.\n\nSince phase and amplitude variations are descriptors of the scattering process, radar polarimetry is\nparticularly sensitive to errors in the system. An accurate, relative calibration of the polarimetric\nchannels is required to be able to effectively exploit the potential of radar polarimetry. In particular,\nchannel imbalances and cross-talk effects (i.e., the contamination of a channel by an adjacent one) must\nbe very accurately characterized in fully polarimetric radars. However, the radar system is not the only\nelement affecting the fidelity of the recorded polarimetric channels. In their propagation through the\nionosphere, the received echoes might appear rotated due to the electronic content of the atmospheric\nlayer. This phenomenon is known as Faraday rotation and changes the distribution of the received\npolarimetric channels. Faraday rotation is typically estimated under the symmetry assumption of the\ncross-pol channels.\n\nUnder the symmetry of the crosspolar channels the scattering matrix becomes redundant, and a\nthree-element vector suffices to describe the scattering properties of the point target. The most\nstraightforward description is the lexicographic one, i.e.,\n\nkL \u00bc\n\n266664\nSHH\n\n1ffiffiffi\n2\n\np $\u00f0SHV \u00fe SVH\u00de\n\nSVV\n\n377775; (5.45)\n\nwhich coincideswith the physical channels recordedby the radar. The lexicographic descriptor is therefore\nparticularly well suited for the identification of residual radiometric calibration errors. The display of the\nreceived images of the polarimetric channels with an RGB-coding will allow for a visual interpretation of\nthe dominant scatteringmechanisms. For the sake of interpretation, the co-pol channels can be associated\nto first-order scattering mechanisms, both odd and even bounce (e.g., reflection, double and triple\nbounces), with the VV polarization being in general more sensitive to roughness than HH. The cross-pol\nchannels, on the other hand, can be related to more complex scattering processes (e.g., volumes).\n\nThe choice of the lexicographic basis seems rather natural, but of course we can express the\npolarimetric information in many different ways. Since the information in the polarimetric descriptor\ndoes not change, the use of a different basis should have no impact on the exploitation of the\n\n5.2 RADAR SCATTERING 327\n\n\n\npolarimetric radar information. One example of particular significance, with a stronger link to the\ntransfer coefficients of simple scattering mechanisms is the Pauli basis, i.e.,\n\nkP \u00bc 1ffiffiffi\n2\n\np $\n\n264 SHH \u00fe SVVSHH ? SVV\nSHV \u00fe SVH\n\n375. (5.46)\nA comparison between the lexicographic and Pauli basis descriptions is provided here in Fig. 5.35.\nThe lexicographic and Pauli representations are themost popular in the radar polarimetric community,\n\nbut of course other representations may be helpful in the visual interpretation of radar images. As an\n\nFIGURE 5.35\n\nExamples of fully polarimetric DLR F-SAR airborne radar images of Wallerfing, Germany, in lexicographic (top)\n\nand Pauli (bottom) color coding. Radar illumination is from the top. According to the definition of the bases in\n\nand, the channel distribution is RGB for lexicographic and BRG for Pauli.\n\nCourtesy of DLR.\n\n328 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.35|tif\n\n\nexample, Fig. 5.36 is a dual-pol image (HH, VV) acquired by TerraSAR-X over the delta of the Lena\nriver, Russia. The image shows the HH, VV, and HH-VV components in the RGB channels.\n\nAs discussed, the scattering matrix can be used to describe the scattering of a point target. For\ndistributed targets, the interactions between the different scatterers within a cell require a statistical\ndescription of the scattering processes. Under the assumption of stationarity, this statistical description\nis fully characterized by the second-order statistics of the received polarimetric components in the\ndesired basis. If the lexicographic basis is used, we speak of the lexicographic covariance matrix, i.e.,\n\nCL \u00bc 1ffiffiffi\n2\n\np $\n\n266666666664\n\nD\njsHHj2\n\nE\nhsHH$\u00f0sVH \u00fe sHV\u00de?i\n\n\t\nsHH$s\n\n?\nVV\n\n\n\n\t\u00f0sVH \u00fe sHV\u00de$s?HH\n\n\nD\njsVH \u00fe sHVj2\n\nE\nffiffiffi\n2\n\np \t\u00f0sVH \u00fe sHV\u00de$s?VV\n\t\nsVV$s\n\n?\nHH\n\n\n hsVV$\u00f0sVH \u00fe sHV\u00de?i DjsVVj2E\n\n377777777775\n; (5.47)\n\nwhere the elements of the matrix are no longer the scattering coefficients but the polarimetric channel\nvalues. In the case that the second-order statistics are expressed in the Pauli basis, we speak of the\nPauli-based covariance (or coherency) matrix, i.e.,\n\nTP \u00bc\n\n2666666666666664\n\nD\njsHH \u00fe sVVj2\n\nE\n2\n\nh\u00f0sHH \u00fe sVV\u00de$\u00f0sHH ? sVV\u00de?i\n2\n\nh\u00f0sHH \u00fe sVV\u00de$\u00f0sVH \u00fe sHV\u00de?i\n2\n\nh\u00f0sHH ? sVV\u00de$\u00f0sHH \u00fe sVV\u00de?i\n2\n\nD\njsHH ? sVVj2\n\nE\n2\n\nh\u00f0sHH ? sVV\u00de$\u00f0sVH \u00fe sHV\u00de?i\n2\n\nh\u00f0sVH \u00fe sHV\u00de$\u00f0sHH \u00fe sVV\u00de?i\n2\n\nh\u00f0sVH \u00fe sHV\u00de$\u00f0sHH ? sVV\u00de?i\n2\n\nD\njsVH \u00fe sHVj2\n\nE\n2\n\n3777777777777775\n.\n\n(5.48)\n\nFIGURE 5.36\n\nDelta of the Lena river in Siberia, Russia, as acquired by TerraSAR-X in dual-pol mode. The RGB channels are\n\nthe HH, VV, and HH-VV components, respectively.\n\n5.2 RADAR SCATTERING 329\n\nmailto:Image of Figure 5.36|tif\n\n\nNote that the elements of the covariance matrix contain the information of the local power transfer\nand dephasing between polarizations. As already discussed, the elements in the diagonal of the\ncovariance matrices are distributed according to the Gamma distribution (Papoulis, 1965). The joint\ndistribution of the covariance matrices can be shown to be of a Wishart class (Maitre, 2008).\n\nA common practice in radar polarimetry consists of decomposing the previous matrices into their\nprincipal components and to associate the resulting values with elementary (orthogonal) scattering\nprocesses within the resolution cell, which helps enhance the performance of classical radar applications\nsuch as classification, target identification, and physical parameter estimation (Maitre, 2008).\n\n5.3 RADAR SYSTEMS\nWe now return to a description of radar technologies concentrating on their various applications for\nremote sensing of the Earth.\n\n5.3.1 RANGE-DOPPLER RADARS\nRange-Doppler radars measure the delay and frequency shift of the received echoes. However, the\nprocessing of radar waveforms is confronted with an apparently unsolvable physical problem, which is\nthe impossibility of providing optimal range and Doppler resolutions. This result, known as the\nHeisenberg-Gabor limit, is true for any radar waveform (Skolnik, 1980a; Le Chevalier, 1989).\n\nThe natural approach to overcome this limitation is to formally split the time coordinate t into two\nseparate scales, one short term to measure delays, and the other one used with a longer timescale to\nmeasure Doppler shifts. In radar terminology, these two separate variables are called fast and slow\ntimes, respectively. The fast or range time, denoted as tr, measures the time elapsed between the\ntransmitted signal and the received corresponding echo. The slow or Doppler time, denoted as tD,\nsenses the Doppler shifts of the radar echoes. In reality, the slow timescale is discrete and artificially\ngenerated by the repetition of the transmitted waveform at a specific rate. The time between\nconsecutive transmit events is called the pulse repetition interval (PRI), and its inverse the pulse\nrepetition frequency (PRF).8 We can rewrite the slow timescale (slp) as a train of pulses in the form\n\nslp\u00f0t\u00de \u00bc\nXI?1\ni\u00bc0\n\nplp\u00f0t ? i$PRI\u00de ;\n\nwith plp\u00f0t\u00de \u00bc plp\u00f0t\u00de$\nY? t\n\nPRI\n\n?\n;\n\n(5.49)\n\nwhere the\nQ\u00f0$\u00de is a rectangular envelope of duration PRI, and plp(t) is a pulsed complex signal of\n\nduration Tp and bandwidth Br. From (5.49), the total observation time TD is\n\nTD \u00bc I$PRI. (5.50)\n\n8To avoid range ambiguities, all echoes must be received between two consecutive pulses, which means that the PRI must be\nlarger than twice the difference between the maximum and minimum ranges, divided by the speed of light.\n\n330 CHAPTER 5 RADAR\n\n\n\nIf the duration of the transmitted signal ( plp) is smaller than the PRI, we will speak of a pulse radar.\nThe duty cycle of a pulse radar is defined as\n\nh \u00bc Tp$PRF; (5.51)\nwhich takes values between 0 and 1. If the duty cycle equals one, i.e., the duration of plp is equal to the\nPRI, which refers to continuous-wave (CW) radars.9 The essential conditions a range-Doppler radar\nwaveform should fulfill are (1) the bandwidth of the signal must be contained within one PRI and (2)\nthe envelope of the signal along the consecutive pulses must be constant. For convenience, (5.49) can\nbe expressed as the discrete-time version of a 2-D continuous-time signal in the new time basis as\n\nslp\u00f0tr; tD\u00de \u00bc plp\u00f0tr\u00de$\nY? tD\n\nTD\n\n?\n. (5.52)\n\nObviously, the division of time into two separate scales is not without cost, and some intrinsic\nlimitations are introduced into the measurement. These limitations are the maximum range and\nDoppler values that can be unambiguously sensed with this approach. These Doppler values can be\nexpressed as\n\nDR ? c$PRI\n2\n\n\u00bc c\n2$PRF\n\n; (5.53)\n\nDf ? PRF \u00bc 1\nPRI\n\n; (5.54)\n\nwhere the time and frequency are again inverses of each other. We can express the 2-D impulse\nresponse of the range-Doppler radar in the new coordinates as\n\nh\u00f0tr; tD\u00de \u00bc plp\u00f0tr ? s\u00f0tr; tD\u00de\u00de$exp\u00bd?j$u0$s\u00f0tr; tD\u00de?$\nY? tD\n\nTD\n\n?\n; (5.55)\n\nwhich equals the echo of a unitary target with a delay s(tr, tD) and describes the behavior of the range-\nDoppler radar as a linear system. Note that the previous impulse response does not necessarily\ncorrespond to a time-invariant system (Oppenheim et al., 1983; Papoulis, 1968). In typical radar cases\nwhere v ? c, we can approximate (5.55) as\n\nh\u00f0tr; tD\u00dez plp\n?\ntr ? 2$r\u00f0tD\u00de\n\nc\n\n?\n$exp\n\n?\n?j$u0$2$r\u00f0tD\u00de\n\nc\n\n?\n$\nY? tD\n\nTD\n\n?\n; (5.56)\n\nwhere 2$r\u00f0tD\u00de=c is the delay history of the target and describes the time elapsed between transmission\nand reception of the echoes from a particular target as a function of the slow time. Whenever this\nassumption is violated, the more general expression of (5.55) should be used.\n\n9The technological implications of this condition are large. Pulse and continuous-wave radars have often been depicted as\nseparate technologies. This approach is in our opinion slightly confusing from the radar engineer point of view, since they\ncan be treated in a similar way. In any case, continuous-wave radars offer a better power budget using similar peak power,\nwhereas pulse radars offer better isolation between transmitter and receiver.\n\n5.3 RADAR SYSTEMS 331\n\n\n\nEq. (5.56) has been derived under the assumption that the effect of the instantaneous Doppler on the\nlow-pass pulse plp can be neglected. This condition can be expressed generally by stating that the\nchange of s within the PRI is negligible, i.e.,\n\nds\u00f0tr; tD\u00de \u00bc vs\nvtr\n\n$dtr \u00fe vs\nvtD\n\n$dtDz\nvs\nvtD\n\n$dtD. (5.57)\n\nBesides this algebraic simplification, the previous approximation has a further geometrical inter-\npretation: between two consecutive transmission events; the model assumes that no relative motion\nbetween the radar and the target occurs. This assumption is known in the literature as stop and go,\nstartestop, or stop and hop, and it is very common in Earth observation radars (Curlander and\nMcDonough, 1991). In the example of Fig. 5.5, the stop-and-go approximation can be reduced to the\nexpression\n\nBr$Tp ? c\u00fe v\n2$v\n\nz\nc\n\n2$v\n; (5.58)\n\nEq. (5.58) helps identify the variables in the validity of the stop-and-go approximation. These are the\ntransmitted bandwidth, the duration of the transmitted pulses, and the speed of the platform. Both the\nbandwidth (Br) and platform speed (v) are bounded by the physical phenomena the radar is designed to\nobserve. These limits are imposed by the geometrical resolution and observational geometry. The impact\nof the pulse duration has not been addressed so far. A smaller value of this impact (Tp) reduces the impact\nof the instantaneous Doppler, at the expense of reducing the overall transmitted energy and sensitivity of\nthe system. A larger Tp, however, increases receiver mismatch which may degrade the SNR of the\ndetected peaks.\n\nThe echo signal received by the radar can be seen as the superposition of the echoes over the\nintegrated surface, which can be expressed as the 2-D integral of (5.56) times a field of complex\nreflectivity, all embedded in noise, i.e.,\n\ne\u00f0tr; tD\u00de \u00bc n\u00f0tr; tD\u00de \u00fe\nZZ\n\ndsr$dsD$r\u00f0sr; sD\u00de$h\u00f0sr; sD; tr; tD\u00de; (5.59)\n\nwhere e(tr, tD) models the radar data for an idealized continuous-time acquisition, n(tr, tD) is a stationary\nrandom process modeling the receiver noise, r(tr, tD) is the map of complex reflectivity of the illuminated\nscene in the radar geometry, and sr and sD are dummy integration variables, which should not be mixed\nup with the previous delay function s(t).\n\nWe can define range-Doppler radar processing of the received echoes as the process of estimating\nthe complex reflectivity map of the imaged scene from the received radar echoes, i.e.,\n\nbr\u00f0tr; tD\u00de \u00bc R?1\u00bde\u00f0tr; tD\u00de?; (5.60)\nwhere R?1\u00bd$? is, the operator effecting the inversion, commonly known as the radar processing\nalgorithm. The development of efficient radar processing techniques in the Fourier domain largely\ndepends on the possibility to express Eq. (5.60) as a convolution.\n\n332 CHAPTER 5 RADAR\n\n\n\n5.3.2 OPTIMAL RECEIVER FOR A SINGLE ECHO: THE MATCHED FILTER\nWe have assumed that the received echo of a single target can be approximated as a delayed, attenuated,\nandphased-shifted replica of the transmitted signal.Thismodel has alsobeendescribed as a simplification,\nwhich neglects further attenuation and dispersive terms due to propagation or reception, as well as any\ninstantaneous Doppler spread, it is nonetheless helpful for the purpose of the analysis. Radar echoes are\nveryweak signals, due to power losses in the two-way propagation path and to the typically small values of\nthe reflectivitymagnitude of the targets. As a sensible extension, wewill be embedding the received signal\nin noise, i.e.,\n\nsRx\u00f0t\u00de \u00bc r$plp\u00f0t ? s\u00de \u00fe n\u00f0t\u00de; (5.61)\nwhere n(t) is assumed to be a stationary random process with a Gaussian distribution which accounts\nfor the thermal noise in the radar. We are interested in deriving an optimal filter for the received echoes.\nIn Fig. 5.37 we present the output of the matched filtered echo that fulfills the conditions discussed\nearlier to achieve good range resolution.\n\nWithout loss of generality, the maximum of the matched filtered echo is assumed to be located at\nt \u00bc s. The problem arises by considering as optimum a system that maximizes the SNR of the received\nsignal (Carlson, 1986; Papoulis, 1965; North, 1963), which at delay s takes the form\n\nSNR \u00bc\njrj2$\n\n???RBrdf $H\u00f0 f \u00de$Plp\u00f0 f \u00de???2R\nBr\ndf $jH\u00f0 f \u00dej2$Sn\u00f0 f \u00de\n\n; (5.62)\n\nwhere the Parseval identity has been used (Oppenheim et al., 1983). In this equation f is the frequency,\nPlp is the Fourier transform of plp, H is the transfer function of the matched filter, and Sn is the power\nspectral density of noise. Using the Cauchy-Schwarz inequality (Bounjakowsky, 1859; Schwarz, 1888)\nand a careful identification of terms, it can be shown that the optimum solution to the problem is given\nby a filter with transfer function (Carlson, 1986)\n\nHmf f\u00f0 \u00de \u00bc K$\nP?lp f\u00f0 \u00de\nSn f\u00f0 \u00de ; (5.63)\n\nwhere K is any complex constant, and the symbol ? indicates the complex conjugate. The magnitude of\nthe matched filter is thus directly proportional to the magnitude of the spectrum of the transmitted\n\nsRx(t)\n\nn (t)\n\nyRx (t)\n\nt\n\nyRx (t)\n\n?? \u00b7 plp (t ? ?) h(t)\n\nFIGURE 5.37\n\nOptimal radar receiver for maximum signal-to-noise ratio (i.e., matched filter), with system model and sample\n\noutput for a received echo.\n\n5.3 RADAR SYSTEMS 333\n\nmailto:Image of Figure 5.37|eps\n\n\nsignal, and inversely proportional to the noise power spectral density, which emphasizes the frequency\nbands with higher SNR and deemphasizes those with lower SNR. The impulse response of the matched\nfilter can be computed as the inverse Fourier transform of (5.63). Particularly for the case of white\nnoise, the impulse response of the matched filter takes the form (Oppenheim et al., 1983)\n\nhmf t\u00f0 \u00de \u00bc F?1 K$Br\ns2n\n\n$P?lp f\u00f0 \u00de\n? ?\n\n\u00bc K 0$p?lp ?t\u00f0 \u00de; (5.64)\n\nwhere s2n is the total noise power, F\n?1\u00bd$? is the inverse Fourier transform operator, and K 0 is another\n\ncomplex constant, which can be ignored in the subsequent analysis. The matched filter has been\ndesigned to provide the best possible SNR at delay s, which maximizes the probability of detection of\nthe target. Using the same optimization approach, the optimal detector is depicted in Fig. 5.38.\n\nAfter the matched filter the instantaneous power is computed and compared to the transmitted\nsignal at a given threshold. This threshold is a function of the expected SNR of the scene. The key\nparameters playing a role in the detection capabilities of the radar are the transmitted signal energy and\nthe sensitivity of the radar receiver, so that the filtered echo needs to exceed the noise floor. The peak\nafter the matched filter will be proportional to\t\n\ns2Rx\n\n \u00bc jrj2$Z\n\nTp\n\ndt$\n??plp\u00f0t\u00de??2. (5.65)\n\nThe value of\n??plp\u00f0t\u00de??2 is bounded by the peak power of the transmitter, which emphasizes the\n\nadvantage of using constant envelope waveforms to maximize power efficiency. Longer pulses (i.e.,\nhigher values of Tp) will increase the SNR of the received echoes and hence the sensitivity of the radar.\n\n5.3.3 MATCHED FILTER VERSUS INVERSE FILTER\nLet us now consider an ideal radar of infinite bandwidth transmitting a short pulse of duration Tp. The\noutput of the matched filter will be a triangular pulse of duration 2$Tp, as depicted in red in the left plot\nof Fig. 5.39.\n\nsRx (t)\nh(t)\n\nn (t)\n\n| \u00b7 |2\nyRx A\n\n?\n\nA\n\nt\n\n|yRx (t)|2\n\ntrue/false? \u00b7 plp (t ?? )\n\nFIGURE 5.38\n\nOptimal maximum likelihood radar detector with the appropriate output for a received echo.\n\n334 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.38|eps\n\n\nNote that the amplitudes of the different waveforms have been normalized for illustration purposes.\nThe triangular waveform after idealized matched filtering becomes in a band-limited radar detector the\nred waveform of the right plot of Fig. 5.39.\n\nThe inversion or compression filter is defined as the filter that concentrates the maximum amount of\nsignal energy around the delay s, hence achieving the best resolution in the delay measurement.\nConsequently, the inverse filter should be able to detect the rising edge of the pulse with a precision\nproportional to its bandwidth, a situation which is depicted in the orange curves of Fig. 5.39. In the band-\nunlimited case, the filter provides the orange spike shown on the left. Note the matched filter does not\nconcentrate so much signal energy around s. This characteristic is independent of the bandwidth and\ndoes not change if a band-limited radar is considered. The detected band-limited spike, depicted in\norange in the right plot of Fig. 5.39, still presents a narrower shape than the output of the matched filter\n(in red). Note that for the particular waveform used in the figure the compression filter does not exist.\n\nThe inverse filter can also be interpreted as equalizing all spectral components of the transmitted\nsignal, i.e., the spectrum of the output signal is flat. All things considered, the transfer function of the\ninversion filter is\n\nHif\u00f0 f \u00de \u00bc K$ 1\nPlp\u00f0 f \u00de ; (5.66)\n\nwhere K is any complex constant. From (5.66) it is easy to see that the filter does not exist for frequencies\nwhere the signal has no energy, as is the case of many pulsed waveforms. In cases where the spectrum of\nthe signal has low values, the inverse filter amplifies the noise energy, hence destroying the SNR and\nruining the sensitivity of the system.\n\nFIGURE 5.39\n\nOutput of the matched filter (red) and of the inverse filter (orange) for a transmitted pulse (black). The left plot\n\nshows the ideal waveforms after filtering. The right plot shows the real waveforms after detection. The amplitudes\n\nof the waveforms have been normalized for illustration purposes.\n\n5.3 RADAR SYSTEMS 335\n\nmailto:Image of Figure 5.39|eps\n\n\nThere exists, however, a class of radar waveforms for which matched filters are also inverse filters,\ni.e., best detectability and resolution are achieved simultaneously at no extra cost. Assuming awhite noise\nenvironment, the waveforms whose matched and inversion filters coincide have a spectrum of the form\n\nHif\u00f0 f \u00de \u00bc Hmf\u00f0 f \u00de/Plp\u00f0 f \u00de \u00bc K 0$\nY? f\n\nBr\n\n?\n$exp\u00bd j$F\u00f0 f \u00de?; (5.67)\n\nwhere K\n0\nagain is any complex constant, and F( f ) is a real function. Radar waveforms fulfilling this\n\ncondition are considered to be spectrally efficient.\n\n5.3.4 OPTIMAL RECEIVER FOR RANGE-DOPPLER RADAR ECHOES:\nTHE BACKPROJECTION OPERATOR\n\nAs just discussed, the matched filter adapts itself to the transmitted waveform, and its impulse response\nequals the complex conjugate of the time-inverted signal itself. In the general range-Doppler case, the\nconstruction of this matched filter is subject to two conditions: (1) the relative motion of the targets is\nknown and (2) the transmitted signal is not affected by the instantaneous Doppler shift. The former\ncondition can only be fulfilled in the case of stationary scenes. In many other cases, e.g., a radar\nmeasuring ocean currents, fast geophysical motions, rain Doppler changes, or moving targets, the lack\nof knowledge of this relative motion may cause filter mismatch. The latter condition imposes a further\nrestriction on the transmitted radar waveform, typically known as Doppler robustness, which can be\nformulated as follows: besides having the full bandwidth within a PRI, the output of the matched filter\nshould be as little unaffected as possible by instantaneous Doppler shifts (Skolnik, 1980a; Woodward,\n1980).\n\nWhen the transmitted signal is Doppler robust, the impulse response of the 2-D matched filter for the\nrange-Doppler radar echoes can be expressed as the time-inverted version of the complex conjugate of\n(5.56), i.e.,\n\nhmf\u00f0tr; tD\u00dez p?lp\n?\n?tr ? 2$r\u00f0?tD\u00de\n\nc\n\n?\n$exp\n\n?\nj$u0$\n\n2$r\u00f0?tD\u00de\nc\n\n?\n$\nY??tD\n\nTD\n\n?\n. (5.68)\n\nUnder these circumstances, we can split the 2-D matched filtering operation into two subsequent\n1-D matched filtering stages, one in fast time usually known as range compression, and a second in\nslow time, usually known as Doppler processing.\n\nIn the general case, the matched filter after range compression, which typically shows a sinc form\nin the fast-time coordinate, is not time-invariant. Note this is not a consequence of the range\ncompression, since this only happens if the filter in (5.68) is also time-variant. The time-invariance\nproperty allows for the efficient implementation of the matched filter correlation in the Fourier\ndomain, with help of the fast Fourier transform (FFT) algorithms (Frigo and Johnson, 1998). If the\nmatched filter is variant in both fast and slow times, radar processing requires a 2-D convolution\nknown, in the field of coherent imaging theory, as a backprojection operator, i.e.,\n\nbr\u00f0tr; tD\u00de \u00bc ZZ dsr$dsD$e\u00f0sr; sD\u00de$hmf \u00f0sr; sD; tr; tD\u00de ; (5.69)\nwhere again the s are dummy integration variables. The computational burden of the matched filter\nassuming 2-D time variance is roughly O(N4), where N is the number of samples in one direction.\n\n336 CHAPTER 5 RADAR\n\n\n\nIn many cases, however, the surveys are invariant in slow time (e.g., SAR), which typically reduces the\nburden of the optimal receiver to O(N3). In many other cases, e.g. weather profilers, time-invariance\ncan be used to further reduce the burden to O(N2).\n\n5.3.5 RADAR WAVEFORMS\nRecollecting the information provided on radar waveforms through the previous subsections, we can\nlist a number of properties a good radar waveform fulfills, i.e.,\n\n\u2022 Power efficiency: improved sensitivity and detectability require a constant envelope in the time\ndomain, i.e.,\n\nplp\u00f0t\u00de \u00bc p0$\nY? t\n\nTp\n\n?\n$exp\u00bd j$f\u00f0t\u00de?; (5.70)\n\nwhere p\n0\nis a real constant and f(t) a real function. This condition can be sacrificed in case the\n\nsensitivity of the system is extremely good. As an example, waveform tapering is frequently used in\nsounding radars to reduce side lobes.\n\n\u2022 Large bandwidth: the bandwidth of plp needs to be contained within one PRI. Whenever\nBr > 1=Tp, as is usually the case, this imposes a condition on the derivative of f(t), i.e.,\n\nd2f\n\ndt2\ns 0: (5.71)\n\nThis condition is generally known in radar theory as pulse compression. Pulse compression has a\ndual character. For a given bandwidth, it allows the improvement of the sensitivity of the system.\nFor a given pulse duration and sensitivity, it allows improvement of the system\u2019s range resolution.\n\n\u2022 Spectral efficiency: good time-localization capabilities and maximal SNR, i.e., the inverse filter is\nalso the matched filter. This condition requires a constant envelope in the frequency domain, i.e.,\n\nPlp\u00f0 f \u00de \u00bc P0$\nY? f\n\nBr\n\n?\n$exp\u00bd j$F\u00f0 f \u00de?; (5.72)\n\nwhere P0 is a constant and F( f ) a real function. Further weight on the compression filter is\ntypically used to reduce side lobes.\n\n\u2022 Doppler robustness: filter mismatch due to instantaneous Doppler does not affect the SNR of the\ndetected peak. Within small PRI values and large transmitted bandwidths, the approximation that\ninstantaneous Doppler is basically a frequency shift of the received echoes is typically good.\n\n5.3.6 A PARADIGMATIC EXAMPLE: LINEAR FREQUENCY MODULATED\nPULSES (CHIRPS)\n\nLinear frequency modulated signals, commonly known as chirps, have been very popular among radar\nengineers due to their advantageous temporal and spectral properties. In particular, chirps fulfill the\nconditions just listed above. The instantaneous frequency of a chirp can be expressed as\n\nfi\u00f0t\u00de \u00bc \tbr$t; (5.73)\n\n5.3 RADAR SYSTEMS 337\n\n\n\nwhere the subscript i refers to the instantaneous, and br is the chirp rate. Depending on whether the\nfrequency variation is positive or negative, refers to up- and down-chirps, respectively. Up- and down-\nchirps show identical time and spectral qualities. For simplicity and without loss of generality, in the\nfollowing we will use down chirps in the derivations. The chirp bandwidth can be straightforwardly\ncomputed as the product of br times the duration of the pulse, i.e., the chirp rate can be expressed as\n\nbr \u00bc\nBr\nTp\n\n; (5.74)\n\nwhere Br is the transmitted bandwidth and Tp is the duration of the pulse. A linear instantaneous\nfrequency results in a quadratic phase, i.e.,\n\ns\u00f0t\u00de \u00bc\nY? t\n\nTp\n\n?\n$exp\n\n?\n?j$2p$\n\nZ\ndt0$fi\u00f0t0\u00de\n\n?\n\u00bc\nY? t\n\nTp\n\n?\n$exp\n\n??j$p$br$t2\n; (5.75)\nwhere t0 is a dummy variable and the integration constant has been neglected for compactness. The left\npart of Fig. 5.40 shows the real (red) and imaginary (orange) parts of a chirp pulse.\n\nThe exact Fourier transform of (5.75) cannot be computed analytically using conventional calculus.\nAn approximate expression can nonetheless be derived using an asymptotic expansion known as the\nprinciple of stationary phase (Bleistein and Handelsman, 1975; Papoulis, 1968). Valid for oscillatory\nintegrands, the principle of stationary phase assumes that the contribution of the high-frequency parts\nof the oscillation cancels out during integration, i.e., the value of the integral can be approximated by\nevaluating the integrand at its zero-frequency crossing, also known as the point of stationary phase.\nUsing the principle of stationary phase, the spectrum of (5.75) can be approximated by\n\nS\u00f0 f \u00de \u00bc F\u00bds\u00f0t\u00de?zC$\nY? f\n\nbr$Tp\n\n?\n$exp\n\n?\nj$p $\n\nf 2\n\nbr\n\n?\n; (5.76)\n\nFIGURE 5.40\n\nThe left plot shows the real (red) and imaginary (orange) parts of a chirp pulse. The right plot shows the spectral\n\nenvelopes of 16 chirp signals with time-bandwidth products increasing linearly from 100 (black) to 10,000\n\n(yellow). The spectrum of chirps with a large time-bandwidth product, tend to be asymptotic.\n\n338 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.40|eps\n\n\nwhere C is a complex constant, and F\u00bd$? is the Fourier transform operator. As expected, the factor\nbr$Tp reduces to the bandwidth of (5.75), i.e., Br. Due to its asymptotic character, Eq. (5.76) works\nbetter for larger time-bandwidth products. The right plot of Fig. 5.40 shows the envelope of the\nspectrum of 16 chirp pulses with time-bandwidth products going linearly from 100 (black) to 10,000\n(yellow). The magnitude oscillations are caused by the harmonic approximation of the time-domain\npulse envelope, i.e., the well-known Gibbs effect (Oppenheim et al., 1983). Larger time-bandwidth\nproducts tend to be asymptotic in (5.76). Since long pulses improve the detectability of the targets\nand wideband signals improve the ranging capabilities of the radar, the approximation in (5.76) is valid\nin most typical radar cases.\n\nAnother advantage of chirpwaveforms is their robustnesswith respect to instantaneousDoppler shifts,\ni.e., those that can be analyzed in terms of receiver mismatch, or segmentation of the receiver (Curlander\nand McDonough, 1991). To simplify the analysis, we will assume the delay to a target takes the form\n\ns\u00f0t\u00dez s0 \u00fe qD $t; (5.77)\nwhere qD is a dimensional and expresses the ratio between the radial relative motion radar target and the\nvelocity of propagation of the radar waves. We have seen that (5.77) is accurate in the case of relative\nlinear radial motion of the target, but it is also a first-order (and good) approximation within one PRI for\neven more complicated motions. We further neglect contributions due to s0 (which the radar measure\nanyway) and any additional attenuation terms. The received chirp echo can be expressed as\n\ns\u00f0t\u00de \u00bc\nY2664t$\n\n?\n1? qD\n\n?\nTp\n\n3775$exp\n\"\n?j$p$br$\n\n?\n1? qD\n\n?2\n$t2\n\n#\n$exp\n\n?\n?j$u0$ qD $t\n\n?\n; (5.78)\n\nassuming (5.77) holds and qD ? 1, the output of the matched filter in (5.78) can be expressed as\n\ny\u00f0t\u00dezF?1\n\n8>>><>>>:\nY? f\n\nBr\n\n?\n$exp\n\n26664?j$p$\n?\nf \u00fe qD $f0\n\n?2\n? f 2\n\nbr\n\n37775\n9>>>=>>>;\n\n\u00bc C$exp\n?\nj$\nu20$q\n\n2\nD\n\n4p$br\n\n?\n$sinc\n\n\"\nBr$\n\n \nt ? u0$ qD\n\n2p$br\n\n!#\n; (5.79)\n\nwhere C is a complex constant and F?1f$g is the inverse Fourier transform. The conclusion is clear:\nother than a constant phase term and a slight delay shift, the form of the signal at the output of the\nmatched filter remains unchanged. This robustness with respect to instantaneous Doppler means its\ndetectability capabilities remain unchanged under certain circumstances. Moreover, chirp waveforms\nare also power efficient, and easy to generate at large bandwidths, i.e., its matched and inverse filters\ncoincide.\n\nThere is an additional reason why chirp signals are the best waveforms for Earth and planetary\nobservation radars. The radar data have been approximated as the superposition of the individual\nechoes of many scatterers in the scene. The scene, consisting of these many scatterers, is randomly\n\n5.3 RADAR SYSTEMS 339\n\n\n\ndistributed, and typically have a wideband character. The radar data as a sort of convolution of the\nreflectivity map and the radar waveform will fill the full spectral support of the system, both in range\nand Doppler, i.e., no information gap will be available within the bandwidth of the system. As a result,\nunder the reasonable assumption of a wide scene spectrum, as it is customary for homogeneous and\ncomplex scenes, chirp signals are the optimal waveforms for remote sensing radars.\n\n5.3.7 GEOMETRICAL DIALECTICS OF REMOTE SENSING RADARS\nAn essential requirement for the correct reconstruction of radar data is the accurate evaluation of the\nplatform, which naturally plays a fundamental role in understanding the operation, analysis, and\ndesign of radar instruments in Earth and planetary missions. We present in this section some basic\ngeometric definitions, combined with a discussion of the several levels of abstraction in the repre-\nsentation of orbital observations. The essential part of the analysis is the identification of the ad-\nvantages and shortcomings of different approaches. We choose to introduce these models in a\ndialectic way to better exemplify their range of applications.\n\nLet us start by considering the lateral view of the spaceborne radar shown in Fig. 5.41. The\ngeometry is simplified, but helps to illustrate the basic elements of the radar acquisition.\n\nThe radar is assumed to be flying in the plane of the paper following the velocity vector described\nby the arrow and the velocity v, the s standing for spacecraft, illuminating targets on the horizontal\nblack line below, which depicts the surface of the illuminated target. The shaded triangle in the figure\nrepresents the azimuth antenna beam of the radar, with aperture Qaz. The thick gray line on the surface\nrepresents the illuminated area or instantaneous footprint of the radar antenna.\n\nAs depicted in the figure, the radar trajectory defines the along-track dimension, which is measured\nwith the helpof the slow (e.g.,Doppler or along-track) timescale.Anew sample is acquiredwith every new\n\n \n\nFIGURE 5.41\n\nSimplified lateral view of a spaceborne radar. In this simplified case, the trajectory of the spacecraft defines the\n\nalong-track coordinate, measured with the slow timescale of the radar. The pointing of the antenna defines the\n\nLOS coordinate, or slant range, measured with the fast timescale of the system.\n\n340 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.41|eps\n\n\ntransmission of the radar pulses. The dashed line between the radar and the center of the footprint\nrepresents an average LOS direction of the acquisition. The plane whose normal vector is the velocity\nvector v!s is called boresight or broadside. The boresight vector results from the intersection\nbetween this plane and the azimuth beam of the antenna, explicitly indicated in the figure. The angle\nbetween this vector and the LOS is called squint, denoted as qsq in the figure. This average LOS forms\nthe (slant) range direction. Delays are measured on the fast timescale during the time elapsed within\ntwo consecutive reception events. Stricto sensu, the range component perpendicular to the along-track\ndirection forms the cross-track direction of the survey. For small squint angles, range and cross-track\ndimensions are usually confounded.\n\n5.3.8 PROFILER VERSUS IMAGING RADARS\nA further classification of remote sensing radars refers to the dimension of the radar measurements.\nRadar profilers yield 1-D measurements (profiles) of range or Doppler maps, as it is the case of radar\naltimeters. Fig. 5.42 shows a topographic profile acquired by ESA\u2019s CryoSat altimeter over Cuba and\nthe Caribbean Sea.\n\nThe vertical scale in this figure corresponds to the height of the surface and is measured by evaluating\nthe positionof the spacecraft, the rangevalues of the received echoes, and the formof the reference surface.\nThe horizontal axis is the along-track position of the spacecraft projected on the Earth\u2019s surface. Radar\nsounders are similar to altimeters, only the transmitted waves penetrate in the surface and image the\nsubsurface. The profiles generated at different depths result in 2-D images as the one shown in Fig. 5.43.\n\nAgain, the vertical scale is measured through ranging from the satellite, whereas the horizontal axis\ncorresponds to the along-track positions of the sensor. Note that the vertical thickness is a consequence of\nthe penetration of the radar waves into the ice, allowing the imaging of the subsurface structure, using\n\nFIGURE 5.42\n\nCryoSat altimeter view of sea level and topography over the Caribbean Sea and Cuba. The image shows radar\n\nreflections that differ in intensity between thewater and elevated land.Near the edges of the island, points of high radar\n\nreflections are depicted in red. This is due to the higher reflectivity of calm waters of the bay and over coral reefs.\n\nFrom ESA-AOES Medialab, http://www.esa.int/spaceinimages/Images/2012/12/Altimeter_reading_over_Cuba.\n\n5.3 RADAR SYSTEMS 341\n\nmailto:Image of Figure 5.42|tif\nhttp://www.esa.int/spaceinimages/Images/2012/12/Altimeter_reading_over_Cuba\n\n\ndedicated processing of the Doppler returns of the radar. In both altimeters and sounders, Doppler\nprocessing (e.g., synthetic aperture) can be used to improve the resolution in the long-track dimension.\n\nOther radars provide 2-D images exploiting the fast-time and angular or slow-time components of\nthe radar acquisitions. This is the case of weather radars or slide-looking radars, both with real and\nsynthetic apertures. In Fig. 5.44 we see a radar image acquired by TerraSAR-X over Mount Okmok, in\nthe Aleutian Islands.\n\nIn this case, the vertical side coincides with the along-track dimension, with the radar illuminating\nfrom the right.\n\n5.3.9 NADIR-LOOKING VERSUS SIDE-LOOKING RADARS\nRadars can also be classified depending on their look direction: nadir and side-looking radars. Nadir-\nlooking radars are looking directly downward, as depicted in the left panel of Fig. 5.45. Side-looking\nradars are looking sideways, as shown in the figure.\n\nAltimeters, scatterometers, and sounders are generally operated in nadir-looking geometries.\nNadir-looking radars usually receive very strong echoes and typically have a much more favorable\npower budget. As can be inferred from the figure, in the nadir-looking configuration the left and right\nareas are indistinguishable for the radar. The solution of the left-right ambiguity in nadir-looking\n\nFIGURE 5.43\n\nExample of a sounder over ice.\n\nFrom NASA.\n\n342 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.43|tif\n\n\nFIGURE 5.44\n\nRadar image of Mount Okmok, United States, acquired by TerraSAR-X. Radar illumination is from the right as\n\nevidenced by the bright returns. Note also thewave trains, and the interference in the upper right corner of the image.\n\nCourtesy of DLR.\n\n \n\nFIGURE 5.45\n\nAlong-track cuts of a nadir-looking (left) and side-looking (right) spaceborne radars.\n\n5.3 RADAR SYSTEMS 343\n\nmailto:Image of Figure 5.44|tif\nmailto:Image of Figure 5.45|eps\n\n\nsystems requires the use of two separate receive beams. These two beams can be achieved either with\ntwo separate antennas or with a single one supported by the use of analog or digital beamforming\ntechniques (Van Trees, 2002). Downward-looking radars with a squint are usually called forward or\nbackward-looking.\n\nFig. 5.46 shows an image of the ice subsurface acquired by the Multichannel Coherent Radar Depth\nSounder (MCoRDS) from the University of Kansas. The vertical scale shows the penetration of the\nradar waves into the media.\n\nAs depicted in the right drawing of Fig. 5.45, side-looking radars point the antenna beam sideways,\nhence avoiding the left-right ambiguity of nadir-looking systems. The backscattered energy in side-\nlooking observations is typically lower than in the nadir-looking radars, i.e., side-looking radars\nrequire in general higher transmit power. Real aperture radars (RARs) and SARs are typically operated\nin side-looking geometries.\n\n5.3.10 DISTORTIONS OF THE RADAR SIDE-LOOKING GEOMETRY\nSide-looking imaging radars exhibit a cylindrical symmetry. The real scenes appear mapped on the slant\nrange plane, approximately formed on the surface of a family of cylinders around the radar trajectory, all\nwith different radii. To illustrate the range projection of the side-looking radar, Fig. 5.47 (left) shows the\nmapping of three targets a,b,c placed on a common ground plane in the radar coordinates. The radar is\nplaced on the gray spot of the figure and a flat-Earth geometry has been assumed for the sake of\nsimplicity. The targets are mapped at slant ranges a0; b0; c0 in the radar image.\n\nIt is easy to see that the radar mapping is nonlinear and the distances between points are not\nmaintained. The natural consequence is the following: the radar images appear distorted with relative\nto their natural projections. To better illustrate this effect, Fig. 5.47 presents (right) an image pattern\nwith several geometric features in the ground plane (top) and in side-looking radar coordinates (right\nbottom). We can see that the distances at near-range shrink, which is the reason for the curvature of the\ngreen line and the deformation of the red circle. In Fig. 5.48 we present an airborne radar image\nacquired by the DLR airborne F-SAR system over Kaufbeuren, Germany. The incidence angle of the\nnear-range area (right top) is roughly 20?. Note the shrinking of the near ranges due to the side-looking\ngeometry of the system.\n\nFIGURE 5.46\n\nIce sounder image over Greenland.\n\nCredits: University of Kansas.\n\n344 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.46|tif\n\n\nFIGURE 5.48\n\nAirborne radar image acquired by DLR F-SAR system over Kaufbeuren, Germany. Radar illumination is from the\n\ntop. Note the shrinking of the near ranges due to the side-looking observation geometry.\n\nCourtesy of DLR.\n\nground range plane\n\nFIGURE 5.47\n\nOn the left is shown the mapping of targets placed on the ground plane onto the radar slant range plane. (right\n\ntop) Mapping of an exemplary scene on a flat surface (top) to side-looking radar coordinates (right bottom).\n\nThe example corresponds to an airborne geometry, with a large change in the incident angle from near to far\n\nrange.\n\n5.3 RADAR SYSTEMS 345\n\nmailto:Image of Figure 5.48|tif\nmailto:Image of Figure 5.47|eps\n\n\nOf course, real scenes are rarely viewed on a ground plane. In 3-D scenarios, the side-looking\ngeometry causes several well-known distortions in the representation of the ground resolution.\nThese distortions are foreshortening, shadowing, and layover, all illustrated in Fig. 5.49.\n\nIn the foreshortening case (left), we assume the target scene has a mountain represented by the red\ntriangle, and we wish to map the base, denoted as a, and the top, coinciding with b0, on the ground plane\nxgyg. In the radar image, however, the base appears mapped at a\n\n0. The distance a0b0 is smaller than ab,\ni.e., the radar image appears foreshortened. Foreshortening is typical of mountainous areas with mod-\nerate heights. Shadowing is also represented in the left panel of Fig. 5.49 by the blue stripe behind the\nmountain. Due to the side-looking geometry, all this area will be invisible to the radar. The shadowed\narea appears in the radar image having zero reflectivity and is full of noise, similar to the reflectivity of\nroads, calm oceans, and lakes. In Fig. 5.50 we show an example of a TanDEM-X image over Re?union\n\nground range plane\n\nShadowed \narea\n\nForeshortening: |\n\nground range plane\n\nLayover: \n\nFIGURE 5.49\n\nSample side-looking geometry illustrating foreshortening, shadowing effects (left), and the layover effect (right).\n\nFIGURE 5.50\n\nTanDEM-Xbistatic imageover thePiton de la Fournaise, onRe?union Island.The dark areas are due to shadowing.The\n\nbright areas correspond to the ascending slopes of mountains illuminated by the radar and appearing foreshortened\n\nin the radar image.\n\nCourtesy of DLR.\n\n346 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.49|eps\nmailto:Image of Figure 5.50|tif\n\n\nIsland, close to the Piton de la Fournaise. The black areas in the image are due to shadowing. The bright\nareas show the ascending slopes of mountains, which appear foreshortened in the image.\n\nLayover is another distortion in which the order of two targets is swapped in the radar image with\nrespect to their positions on the ground plane. The effect is illustrated in the right panel of Fig. 5.51 and\ncan be interpreted as excessive foreshortening. The situation is analogous to the previous one in the\nsense that the ground range coordinate of a is smaller than that of b. However, in this case, the slant\nrange to the top of the mountain is in effect smaller than the range to the point at its base, i.e., the\nmountain appears laid over in the radar image. The mathematical condition is explicitly stated in the\nfigure. Layover is typical of mountainous areas as shown in the left image of Fig. 5.51. The radar\nillumination is from the right, and the mountains of Montserrat appear bent toward the radar.\n\nSince layover is a consequence of the height of the targets, layover also happens in urban areas. An\nexampleof urban layover is shown in the right panel ofFig. 5.51, showing a TerraSAR-X image over Paris\ncity center. The radar illumination is from the left and the Eiffel tower appears bent toward the radar.\n\n5.3.11 FLAT EARTH VERSUS CURVED SURFACE\nThe difference between flat-Earth and curved surface exists between airborne and spaceborne systems.\nA flat-Earth geometry is fairly uncomplicated in that the imaged scene lies in the horizontal plane, and\nthe trajectory of the radar follows rectilinear trajectory.10 This geometry is typically valid for airborne\nradars, which fly low enough that the Earth\u2019s curvature can be neglected. For spaceborne radars, the\n\nFIGURE 5.51\n\nExamples of layover in TerraSAR-X spotlight images in mountainous and urban areas. The left image shows the\n\nIsland of Montserrat; the mountains appear bent toward the radar, a typical sign of layover. The right image shows\n\npart of a Paris metropolitan area, France. The Eiffel tower shown in the middle appears laid over toward the radar.\n\nCourtesy of DLR.\n\n10The flat-Earth approximation only assumes the first condition; the second is usually known as the linear tracks approximation.\nThey are usually combined because their order of accuracy is similar. In the case of airborne radars, the real trajectories are\nusually not rectilinear (even if desired) due to turbulences and aircraft deviations with respect to the reference trajectory.\n\n5.3 RADAR SYSTEMS 347\n\nmailto:Image of Figure 5.51|tif\n\n\nflat-Earth assumption is only used for preliminary and simplified analyses. Fig. 5.52 (left) shows an\nalong-track cut of an aircraft over a flat-Earth geometry.\n\nIn Fig. 5.52 the aircraft flies at a height h over its nadir on the ground, and the antenna beam is\nshown in gray. The elevation aperture of the radar antenna is explicitly written in the drawing,Qel. The\nextension on the ground of the elevation footprint is called the swath. In a flat-Earth geometry, the look\nangle ql, between the pointing direction of the antenna and the nadir vector, coincides with the incident\nangle at the center of the scene, qi, which corresponds to the angle between the direction of propagation\nand the normal to the scene. In a flat-Earth geometry, slant and ground ranges are always part of a\nrectangular triangle and the geometry can be solved using Pythagoras\u2019 theorem, i.e.,\n\nygr\u00f0 p\u00de/r0\u00f0 p\u00de \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nh2 \u00fe ygr\u00f0 p\u00de2\n\nq\n\u00bc h\n\ncos qi\u00f0 p\u00de ; (5.80)\n\nwhere p indicates a point on ground, ygr and r are the ground and slant range coordinates, respectively.\nThe swath of the radar can be expressed as\n\nSw \u00bc h$\n?\ntan\n\n?\nql \u00feQel\n\n2\n\n?\n? tan\n\n?\nql ?Qel\n\n2\n\n??\nz\n\nh\n\ncos qi$sin qi\n$Qel; (5.81)\n\nwhich, as expected, is larger for higher altitudes.\nIn many cases, however, the use of the flat-Earth geometry for spaceborne cases gives only a fair\n\napproximation and a more elaborate model is required. A typical example is that of the computation of\ncoverage, where the flat-Earth approximation will result in erroneous values of orbit cycles to cover the\nglobe. Thus, a local spherical surface is use to approximate the imaged scene, for a radar flying in a\nKeplerian orbit. This model is not necessarily used for real mission analysis and operation, where\ntypically the real topography of the planet and real orbits are used, but it is definitely useful for an\napproximate coverage and performance analysis.\n\nFIGURE 5.52\n\nFlat-Earth representation of a side-looking airborne survey (left) versus a curved Earth representation (right). Flat-\n\nEarth geometries are very good approximations for airborne radar observations, as depicted in the left figure.\n\n348 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.52|eps\n\n\nFig. 5.52 (right) shows an azimuth cut of a spacecraft in spherical geometry.\nThe first obvious difference is that the equality between look and incident angles disappears, with\n\nthe incident angles increasing faster for increasing slant ranges. As a consequence, the slant ranges\nappear compressed with respect to the flat-Earth geometry. The slant range is part of an obtuse triangle\nwhich can be solved with help of the cosine law, i.e.,\n\nr0 \u00bc RP$cos qi ?\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nR2P$cos\n\n2qi \u00fe h$\u00f02$RP \u00fe h\u00de\nq\n\n; (5.82)\n\nwhere RP is the radius of the planet (e.g., the Earth) at the latitude of the scene. In the same manner, the\nincident angle can be solved as a function of the slant range\n\nqi \u00bc arccos\n\"\n\u00f0RP \u00fe h\u00de2 ? r20 ? R2P\n\n2$r0$RP\n\n#\n. (5.83)\n\nThe swath can be approximated in the following manner:\n\nSwz\n\n?\nRP$cos qi ?\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nR2P$cos\n\n2qi \u00fe h$\u00f02$RP \u00fe h\u00de\nq ?\n\n$\nQel\n\nsin qi\n. (5.84)\n\n5.3.12 GROUND VELOCITY\nAn additional consequence of Earth curvature and rotation is that the velocity of the footprint on\nground, typically known as ground velocity, is smaller than the velocity of the spacecraft (Raney, 1986;\nCumming and Wong, 1979). This is natural consequence, since both the radar and its footprint cover\nsimultaneously similar angular spans if no steering of the antenna is required. The situation is better\ndepicted in Fig. 5.53, where the diamonds represent both the radar and its footprint on ground.\n\n \n\n`\n\nFIGURE 5.53\n\nIllustration of the spacecraft and ground velocity in a quasicircular orbital geometry.\n\n5.3 RADAR SYSTEMS 349\n\nmailto:Image of Figure 5.53|eps\n\n\nThe ratio between the ground and spacecraft velocities decreases with higher orbits, increasing\nincident angles, and increasing orbit inclinations. For quasicircular orbits, the ground velocity can be\napproximated by\n\nvg\u00f0r0\u00dez vs$ RP\nRP \u00fe h$cos\u00f0qi ? ql\u00de \t\n\n2p\n\nTrot\n$jRP$cos qlatj$sin 4incl; (5.85)\n\nwhere vs is the velocity of the spacecraft, Trot is the rotation period of the Earth, qlat is the latitude of the\npoint on ground, and 4incl is the inclination of the orbit. The second term approximates the effect of the\nrotation of the planet, and the plus or minus sign discriminates between descending and ascending\npasses, respectively. It is important to note that the ground velocity is changing with range (and\ndecreasing for a flat scene), one crucial difference with respect to the flat-Earth model depicted in\nFig. 5.53, where both the ground and spacecraft velocities are the same.\n\n5.3.13 LOCAL VERSUS GLOBAL COORDINATE SYSTEMS\nThe choice of an appropriate coordinate system to describe the motion of the remote sensing radars is\ntypically influenced by the application of the radar measurements and the personal preference of the\nuser. To analyze the geometry of radar missions, where the computation of distances and angles from\ndifferent points with respect to different planes is required, the use of a Cartesian coordinate system as\na reference appears to be a sensible choice. Further rotations to move within the platform for changing\nthe reference (e.g., phase centers of the antenna of the instrument, the global navigation satellite\nsystem (GNSS), or the communication link) can be easily accommodated.\n\nA local coordinate system, as the one shown on the left of Fig. 5.54, can be either centered on the\ninstrument or on the scene. This choice may help to simplify the analysis of the geometry of the radar\nsurvey.\n\nThese simplified analyses are only typically valid for local scales and start losing either significance\nor illustrative power for national or continental computations. Local coordinate systems are therefore\ntypically only valid for the analysis of airborne surveys. For satellite surveys, they are at best suited for\npreliminary computations.\n\nIn the case of orbital geometries, a global coordinate systemwith an origin at the center of the Earth, as\nthe one depicted in Fig. 5.54 right is preferable. Now we can distinguish between two different solutions\ndepending on whether we focus on the analysis of the orbits or on the radar geometries. The orbits can be\nassumed to be confined to an orbital plane and do not rotate together with the planet. This suggests the use\nof the nonrotating (i.e., inertial) version of the reference frame shown in Fig. 5.54 right for propagating\nthe state vectors of the orbit considered. For the analysis of the radar geometry, however, all computations\nwill be done with respect to scenes rotating with the planet, and the noninertial reference frame of the\nfigure will be preferred (Fig. 5.55). Both the trajectory of the radars and the points of the target scene\nwill be preferably expressed in this reference frame, called Earth-centered Earth-fixed (i.e., ECEF).\n\nThe transformation of the scene into ECEF coordinates is done from a natural geographic coordinate\nsystem, typically in the form of latitude, longitude, and elevation. The elevation is usually given with\nrespect to a well-characterized reference, linked to the Earth, which must describe unambiguously the\ndistance between the point and the center of the Earth. Under this assumption, the transformation of the\ngeographic coordinates (4lat, 4lon, h) into the ECEF frame can be expressed as\n\nx \u00bc\u00bdRP\u00f04lat;4lon\u00de \u00fe h?$cos 4lat$cos 4lon;\ny \u00bc\u00bdRP\u00f04lat;4lon\u00de \u00fe h?$cos 4lat$sin 4lon;\nz \u00bc\u00bdRP\u00f04lat;4lon\u00de \u00fe h?$sin 4lat;\n\n(5.86)\n\n350 CHAPTER 5 RADAR\n\n\n\nFIGURE 5.55\n\nA geocoded airborne radar image acquired by the DLR F-SAR system over Juelich, Germany. The colors show an\n\nRGB representation of the polarimetric channels.\n\nFIGURE 5.54\n\nLocal reference frame (left) and global reference frame (right). The noninertial reference frame shown on the right\n\nis typically used in the analysis of the geometry of radar missions. Note the local model might have problems\n\naccommodating Earth or orbit curvature. Conversely, the linear-track model does not seem appropriate to\n\nrepresent orbital geometry.\n\n5.3 RADAR SYSTEMS 351\n\nmailto:Image of Figure 5.55|tif\nmailto:Image of Figure 5.54|tif\n\n\nwhere the dependence of the radius of the Earth with latitude and longitude accounts for its\nnonspherical form. The transformation between ECEF coordinates and geographic coordinates is done\nby inverting the previous system of equations.\n\n5.3.14 THE RADAR COORDINATES\nAs already discussed, the measurement scales of the radar are the fast and slow times. The fast-time\ncoordinate system represents the two-way travel time of the transmitted signal when the target is\nplaced at the center of the beam, whereas the slow-time coordinate measures the time elapsed from the\nstart of the acquisition to the instant where the target is at the center of the beam. The previous two\ncoordinates can be expressed with arbitrary accuracy by means of the following implicit expression\n\nj pR\u00f0sa\u00de ? pTj \u00fe j pR\u00f0sa ? sr\u00de ? pTj \u00bc c$sr; (5.87)\nwhere pR\u00f0$\u00de is the parameterized trajectory of the radar, pT is the position of the target, and sr and sa\nare the fast- and slow-time coordinates of the target. Note the slow-time coordinate has been defined at\nthe reception of the radar echo, but could have been defined as at the transmission point. Under the\nstop-and-go assumption, i.e., the radar remains stationary between the transmission and reception of\nthe echoes, and the previous expression is typically written as\n\nsrz\n2$j pR\u00f0sa\u00de ? pTj\n\nc\n\u00bc 2$r0\n\nc\n; (5.88)\n\nwhere r0 is the beam-center range, or the equivalent range from the radar to the target when the latter is\nplaced at the center of the beam, and the factor 2 accounts for the two-way propagation time of the\nradar signal. Making the analogy of the considered survey with a linear-track trajectory, the slow-time\ncoordinate can be approximated by\n\nsaz\nxa\nvg\n\n; (5.89)\n\nwhere xa is an effective distance from the start point at range r0 at the start of the acquisition and the\nconsidered target. Eq. (5.89) implicitly assumes the ground velocity is locally constant for the radar\nsurvey.\n\nIn a flat-Earth geometry, the projection between the ground range and the slant range depends only on\nthe ground range, i.e., the ground range projected onto the radar coordinates becomes the slant range\nplane. The term is also used in curved geometries, where its validity holds only as an instantaneous\napproximation.\n\n5.3.15 GEOCODING\nGeocoding is the operation of mapping the radar image from radar coordinates to geographical\ncoordinates on the surface of the Earth (Curlander and McDonough, 1991). This mapping involves the\ncomputation of the transformation between the two sets of coordinates followed by the interpolation of\nthe image itself to fit these map coordinates. Mathematically, geocoding consists of solving a set of\nnonlinear equations, which corresponds to the range and Doppler coordinates measured by the radar\nand the point positioned on the surface of the Earth. As already discussed, these radar coordinates are\n\n352 CHAPTER 5 RADAR\n\n\n\nrelated to the beam-center range and squint of the acquisition. Hence, the geocoding problem is\nequivalent to solving the following set of equations:\n\nj pR\u00f0sa\u00de ? pTj \u00fe j pR\u00f0sa ? sr\u00de ? pTj \u00bc c$sr;\n\u00f0 pR\u00f0sa\u00de ? pT\u00de$vR\u00f0sa\u00de \u00fe \u00f0 pR\u00f0sa ? sr\u00de ? pT\u00de$vs\u00f0sa ? sr\u00de \u00bc 2$vR$r0$sin qsq;\n\npT ? UEarth;\n(5.90)\n\nwhere vs is the velocity vector of the radar, and UEarth is a function mapping the surface of the Earth,\nwhich is assumed known; the unknown is of course the position of the target with the given coordinates\npT. The previous description is a nonlinear system, which is usually solved numerically. Neglecting the\nmotion of the satellite between transmission and reception11 and a locally circular planet, the previous\nset of equations can be further simplified into\n\nj pR\u00f0sa\u00de ? pTj \u00bc r0;\n\u00f0 pR\u00f0sa\u00de ? pT\u00de$vs\u00f0sa\u00de \u00bc vR$r0$sin qsq;\n\nj pTj \u00bc RP;\n(5.91)\n\nwhich also have to be solved numerically. Geometrically, the previous set of equations can be\ninterpreted as the intersection of two spheres, one the planet and the other the iso-range surface\ncentered at the radar, and a cone representing the LOS vector. Errors in the knowledge of the\nobservation geometry (e.g., uncalibrated range delays, orbit inaccuracies, errors in our knowledge of\nthe Earth\u2019s surface) all cause range and azimuth shifts which end up decreasing the geolocation\naccuracy of the radar. Analogously, the operation from regular coordinates to radar coordinates,\ni.e., the inverse operation to geocoding, is known as backgeocoding. It is easy to see that the\nnonlinear system is the same, the only unknowns now ar (r0, fDC).\n\nWe present in Fig. 5.55 a geocoded airborne radar image formed with multiple image strips acquired\nby DLR F-SAR system over Juelich, Germany. The horizontal line corresponds to the north direction in a\ngeoreferenced frame, and the tilt accounts for the inclination of the trajectory of the airplane.\n\n5.3.16 REAL VERSUS SYNTHETIC APERTURE\nA real aperture radar (RAR) is the one whose geometrical azimuth resolution is directly derived from\nits footprint on the ground. The azimuth resolution of a RAR is equivalent to the length on ground of\nthe azimuth footprint and inversely proportional to the antenna length, i.e.,\n\ndxRA z r0$Qaz z r0$\na$l\n\nLa\n; (5.92)\n\nwhere r0 is the slant range to the scene,Qaz is the azimuth aperture of the radar antenna, La is the azimuth\nlength of the radar antenna, and a is a constant, which relates the aperture to the length of the antenna and\nis typically close to unity.12 This value roughly approximates the footprint shown earlier. Typical values\nof azimuth resolutions for current low Earth orbit (LEO) spaceborne RARs are on the order of several\n\n11This motion is fairly space-invariant during the orbit and can be easily compensated using a range-dependent along-track\nshift as explained in (Prats-Iraola et al., 2012).\n12The value of a \u00bc 0.89 corresponds to the normalized 3 dB width of a sinc pattern, which is usually approximated by 1.\n\n5.3 RADAR SYSTEMS 353\n\n\n\nhundreds to thousands of kilometers, which is acceptable to measure large-scale physical phenomena\nsuch as oceans. Medium- or small-scale phenomena, as well as details of artificial or natural surfaces,\nrequire unpractically large antennas, and can therefore only be observed with airborne RAR systems.\n\nThe concept of SAR uses the relative motion of the radar to synthesize a larger antenna size via\ncoherent processing of the received radar echoes. Besides the relative motion of the radar, the\nextension of the footprint on ground is fundamental for the formation of the synthetic aperture. As\ndepicted in Fig. 5.56, the length of the synthetic aperture is approximately equal to the extension of the\nfootprint on ground.\n\nThis length is, however, scaled by a factor of two due to the modulation introduced by the two-way\ntravel of the transmitted signal. Since the synthetic aperture results in a larger effective antenna size,\nthe azimuth resolution appears improved (Curlander and McDonough, 1991), i.e.,\n\ndxSA z r0$\nk$l\n\nLsyn\nz\n\nLa\n2\n; (5.93)\n\nwhere Lsyn \u00bc 2$dxRA is the length of the synthetic aperture. Note that the previous expression is not\ndependent on the range, since the length of the synthetic aperture increases linearly with it. The\nresolution enhancement achieved can be shown to be directly proportional to the ratio between Lsa and\nthe azimuth length of the physical antenna (Curlander and McDonough, 1991), i.e.,\n\nhSA \u00bc\ndxRA\ndxSA\n\nz\n2$r0$l\n\nL2a\n: (5.94)\n\nIn state-of-the-art SAR systems, the values of hSA achieved after SAR processing are easily larger\nthan 30 dB.\n\nFIGURE 5.56\n\nSynthetic aperture radar (SAR) geometry showing the SAR antenna synthesis due to the motion of the spacecraft.\n\n354 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.56|tif\n\n\n5.3.17 THE RADAR AS A COMMUNICATIONS SYSTEM\nAs an active remote sensing device, the radar has the structure of a classical electrical communication\nsystem, including a transmitter for the transmission of the radar waves and a receiver to receive and\nrecord the echoes backscattered by the imaged scene. Fig. 5.57 shows a schematic view of a radar\nilluminating a scene.\n\nThe analogy between the scene observed by the radar and the channel of a communications system\nis unmistakable. In formal terms, the estimation of the reflectivity of the scene is analogous to the\ncharacterization of a time-varying communication channel. As already discussed, the received signal\ncan be expressed, locally and for a given coherence time, as the 2-D convolution of the scene\nreflectivity and the radar impulse response specific for the considered acquisition, i.e.,\n\nsRx tr; tD; sr; sD\u00f0 \u00de \u00bc r sr; sD\u00f0 \u00de ? h tr ? sr; tD ? sD; sr; sD\u00f0 \u00de; (5.95)\nwhere r(sr,sD) has been assumed to be projected onto the geometry of the radar. The radar data can be\nassumed to be the superposition of all these local convolutions. As expounded, the radar behaves like a\nlinear system that is not necessarily invariant in time.\n\nThe present section is divided into three main blocks, which help understand and analyze radar\nsystems. The first subsection presents the block diagram of the radar from a communication electronics\nperspective. The remaining two subsections are dedicated to antennas and propagation of radar signals.\n\n5.3.17.1 Block Diagram\nA schematic diagram of a typical Earth observation radar is presented here in Fig. 5.58. The system\nabstraction in the figure is to some extent arbitrary and might have been done differently; in its present\nform, however, it serves well the purpose of the subsection.\n\nThe figure depicts a transmitter, a receiver, and a digital unit (central electronics) responsible for\nthe operation of the radar and the sampling and storage of the radar echoes. These blocks work\nsynchronously with the same oscillator reference, which guarantees the coherent nature of the system.\nRadar oscillators are usually quartz, due to their good short-time stability, which helps in maintaining\nthe low phase noise figure of the system.\n\n5.3.17.2 Radar Transmitter\nThe particular structure of a radar transmitter changes with the specifics of the system design and is\nsubject to constant technological improvements. Fig. 5.59 shows, as an example, a block diagram of a\nstate-of-the-art radar transmitter. As depicted in the figure, the transmitter consists of a waveform\ngenerator synchronous to an oscillator reference, an up-converting stage, a power amplifier, and an\nantenna.\n\nRxTx\nsRx (t)sTx(t)\n\nscene\n\nFIGURE 5.57\n\nSchematic view of a radar measurement of a scene.\n\n5.3 RADAR SYSTEMS 355\n\nmailto:Image of Figure 5.57|eps\n\n\nModern radar waveforms are generated digitally, as shown in Fig. 5.60, which suggests the idea\nthat this block is shared between the transmitter and the central electronics. The digital generation of\nradar waveforms has the advantage of being flexible, accurate, and simple. A band-pass generation\nmay simplify the up-converting stages of the receiver, thereby reducing cost and improving the\nlinearity of the transmitter.\n\nA waveform generator basically consists of a memory where the samples of the waveform are\nstored, a digital-to-analog converter, and a low-pass/band-pass filter to reduce the generation of\nspurious harmonics at the nonlinear stages of the transmitter (i.e., mixer, power amplifier).\n\nTypically, direct band-pass generation of radar waveforms is possible up to frequencies around\n1 GHz (P-L bands). For higher frequencies (from S band upward), an up-converting stage is necessary\n\n \n\nM\u00d7\n\nHPA\nWaveform\nGenerator\n\nf0\n\nfmaster\n\nFIGURE 5.59\n\nSchematic view of a radar transmitter.\n\n \n\nFIGURE 5.58\n\nSchematic view of a radar system. Besides the antenna, a transmitter, a receiver, and a digital unit responsible for the\n\ngeneration of the radar signal, the storage of the radar echoes, and the synchronous operation of the system are all\n\ndepicted.\n\n356 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.59|eps\nmailto:Image of Figure 5.58|eps\n\n\nto bring the radar waveform to the frequency band of the radar. The band-pass signal goes through a\ntransmission line to the power amplifier, which delivers the signal to be radiated by the antenna. In case\nthe radar uses an active antenna, these two stages are combined. This is the case of many spaceborne\npast radar missions, e.g., SRTM, Envisat ASAR, ALOS1/2, CosmoSkyMed, TerraSAR-X, among\nothers.\n\nPower amplifiers can be solid-state, or traveling wave tubes (TWTs). The former are cheap, but\ndeliver lower power with good linearity and are preferably used in CWor pulse radars with high-duty\ncycles. Active antennas use solid-state high-power amplifiers. TWTs are expensive, nonlinear, and\nwith reduced duty cycles, but typically deliver very high peak powers. TWTs are typically used only in\npulsed radars.\n\n5.3.17.3 Radar Receiver\nAs in the case of the transmitter, radar receivers are subject to technological change and to the specific\ndesign of the particular system. The general structure presented here is in any case representative and\ninstructive for the subsequent analysis. Because of the low SNR of the radar echoes, radars have\ntypically used superheterodyne receivers (Smith, 1985; Pozar, 2000). The technological trend is to\nallow direct digitalization of the signal at higher frequencies, which of course reduces the cost of the\nelectronics and improves the performance and flexibility of the receiver.\n\nA general structure of a typical radar superheterodyne receiver is shown in Fig. 5.61.\n\nM\u00d7\n\nLNA\n\nf0\n\nfmaster\n\nADCLPF\n\nN\u00d7\n\nsRx [n]\n\nFIGURE 5.61\n\nSchematic view of a radar receiver, including a down-conversion stage for low-pass sampling.\n\nMemory DAC\n\nN\u00d7 fmaster\n\nplp [n]\n\nfs\n\nplp (t)LPF\n\nFIGURE 5.60\n\nSchematic view of a radar waveform generator.\n\n5.3 RADAR SYSTEMS 357\n\nmailto:Image of Figure 5.61|eps\nmailto:Image of Figure 5.60|eps\n\n\nThe master oscillator controls the radar receiver too and is used for the demodulation of the radar\nechoes. In monostatic radars, both transmitter and receiver share the same master oscillator, which\nensures perfect synchronization of the radar system. Bistatic radars, however, with spatially separated\ntransmitter and receivers, usually operate with different master clocks, and the synchronization of the\nsystem and the received echoes poses a fundamental challenge for their operation (Auterman, 1984;\nWillis, 1991).\n\nThe first stage after the antenna is a low-noise amplifier (LNA) followed by an RF filter. This structure\nallows to keep a low-noise figure at the receiver (Willis, 1991) and protects the SNR of the receive echoes\nafter demodulation. Low-noise amplifiers are solid-state devices and are incorporated into the antenna\nstructurewhenever the radar uses an active antenna. Some radars, especially airborne, adapt the gain of the\nreceivergradually dependingon the distance to the scene.This approach, knownas automatic gain control,\nallows theuse of the full dynamic rangeof the receiver (Skolnik, 1980a).Adownconverting stage isused to\nbaseband the received echoes followed by a filter and an analog-to-digital converter (ADC).\n\n5.3.17.4 Central Electronics\nThe central electronics system is the digital unit responsible for the generation of the synchronous\nsignals controlling the system, the operations of transmitter and receiver, and the digitization and\nstorage of the received echoes. A block diagram of a simplified central electronics unit with some of its\nfunctionalities is found in Fig. 5.62.\n\nThe main signals generated by the central electronics are the PRF sequence including the start and\nend of the acquisition, the envelope and coding of the transmitted signal, the echo window, and the\nsampling clock. Other ancillary signals and registers like the record of the external GNSS time and\n\nFIGURE 5.62\n\nSchematic view of a radar digital unit. The unit includes a digital waveform generation stage, the digitizer, data\n\npackaging and storage, the controller for the synchronous operation of the system, an internal calibration network,\n\nand a global navigation satellite system (GNSS) receiver for external time and positioning references. ADC,\n\nanalog-to-digital converter; DAC, digital-to-analog converter; PRF, pulse repetition frequency.\n\n358 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.62|eps\n\n\npositioning reference, dedicated weighting coefficients for the radar antenna, or the controlling of the\ncalibration sequences are also produced by the central electronics.\n\nWith the development of digital electronics, onboard processing of the radar signals is becoming\nfeasible. State-of-the-art onboard processing is roughly limited to data compression algorithms\n(e.g., Block Adaptive Quantization or BAQ) to reduce the data volume and improve the data-link\nbudgets of the missions. In the future, onboard processing will allow for the processing and calibra-\ntion of radar data. This feature is of paramount importance in real-time applications (e.g., traffic and\ndisaster monitoring) and planetary observation.\n\n5.3.17.5 Radar Antennas\nAntennas convert the electrical energy from the radar electronics into electromagnetic waves propagating\nin space and capture the electromagnetic energy scattered back by the scene. Antennas are basically\nconductors of a particular form throughwhich a time-varying electrical current is flowing.As predicted by\nMaxwell (Ramo et al., 1994), time-varying currents generate time-varying magnetic and electric fields\nwhich propagate as electromagnetic waves in space.\n\nThe dimensions of the antenna are set proportional to the central radar wavelength. These antennas\nare usually small when compared to the distances over which the antenna must radiate the radar\nenergy. Under this situation, we can identify the antenna as being the origin of a spherical coordinate\nsystem, such as the one depicted in Fig. 5.63. This coordinate system will be shown in the following to\nbe particularly suitable for the characterization of the electrical properties of the antenna.\n\n \n\nr\n\n?\n\n?\nx\n\nz\n\ny\n\nFIGURE 5.63\n\nSpherical coordinate system for the analysis of antennas. The horizontal plane xy is commonly known as the\n\nazimuthal plane, and the vertical plane yz is commonly known as the elevation plane.\n\n5.3 RADAR SYSTEMS 359\n\nmailto:Image of Figure 5.63|eps\n\n\nThe antenna is assumed to be placed at the origin of the coordinate axes. The two angular coordinates\ndefine the planes of the antenna. The horizontal plane (xy) is known as the azimuthal plane, and the\ncoordinate q is known as the azimuth angle. The vertical plane (yz) is known as the elevation plane, and,\nconsequently, the angle f is known as the elevation angle. These terms are commonly used to describe\nthe geometry of remote sensing radars.\n\nIn the region close to the antenna, i.e., the Fresnel region or near-field, the wave fronts can be\nassumed to be spherical, whereas farther away, i.e., the Fraunhofer region or far-field, the radar signal\npropagates as plane waves. The near-field region is defined as a sphere centered at the origin of\ncoordinates, with radius proportional to the antenna size and operating wavelength, i.e.,\n\nrz\n2$D2\n\nl\n; (5.96)\n\nwhere D is the maximum linear direction from the antenna. The far-field region is naturally the space\noutside the near-range sphere. In far-field, the plane wave approximation simplifies the computation\nof the radiated fields.\n\nA technical boundary associated with the carrier of the radar is the size of the antennas, typically\nscaled with the carrier wavelength (Skolnik, 1980a; Thourel, 1971; Cardama et al., 1998). As an\nexample, the surface of the antenna of a spaceborne L-band radar may be about 70 times larger than the\nsurface of the antenna of an X-band radar with similar coverage. Analogously, the size of the microwave\nelectronic components can also be roughly scaled with the wavelength, i.e., in general, radars in higher\nfrequencies tend to be more compact than lower-frequency radars. In terms of available bandwidth, the\nhigher-frequency bands have typically larger available bandwidths. For technological reasons, larger\nradar bandwidths tend to be more expensive than moderate bandwidths. However, the developments in\nRF electronics in the past years have made the previous statement to some extent obsolete, at least in the\ncase of the lower radar frequency bands. In these cases, the strict limit to available bandwidth of remote\nsensing radars is set by international regulations (e.g., in the bands ranging from VHF to C).\n\nThe use of the RF bands is coordinated at an international level by several supranational\norganizations. The most notable one is the International Telecommunication Union (ITU), a United\nNations (UN) agency responsible for the allocation of the RF bands for different applications. The ITU\nreserves a bandwidth for remote sensing in a particular frequency band, which can vary from the\n6 MHz available in P band to the almost 4 GHz in Ka band. A further restriction arises in the case of\nairborne radars due to national regulations, especially in sensitive areas close to airports or military\nfacilities, which typically use wideband surveillance radars. The other side of the coin is the presence\nof RF interference caused by artificial transmitters in the radar frequency range. This interference jams\nthe recorded echoes and typically blurs partially or totally the relevant radar images. As an example, a\nP band mission like ESA\u2019s Biomass will be affected by long-range surveillance radars operating in the\nsame frequency; its use over North America, Europe, and Russia is expected to be severely restricted\nfor this reason. In L band missions such as JAXA\u2019s ALOS-PALSAR and ALOS-PALSAR2 typical\nurban radio interference has been frequently observed. Interference also happens in C and X-band\nsystems, as reported by ESA, ASI, or DLR. In Fig. 5.64 we see an example of RF interference in a\nTerraSAR-X staring spotlight image over Guangdong, China. The interference reduces the contrast of\nthe radar image for a given area hence affecting the applications based on the image analysis.\n\n360 CHAPTER 5 RADAR\n\n\n\n5.3.17.6 Electromagnetic Radiation\nIn the far-field regions, the electrical field radiated by the antenna can be computed as the superposition\nof the coherent contributions of the current density over all the surface of the antenna. To exemplify this\nresult, let us consider an antenna aperture as that depicted in Fig. 5.65. Horns have been among the most\npopular basic radar antennas because of their simplicity of construction, moderate gain, and bandwidths.\n\nIn the case of an antenna aperture significantly larger than the radar wavelength (l), a narrowband\napproximation of the radiated field in the Fraunhofer region is given by the integral of the individual\ncontributions from the current density with a phase term introduced by the path difference along the\nLOS, i.e.,\n\nE\u00f0q;f\u00de \u00bc\n???Eq$uq!\u00fe Ef$ uf?!???\n\n\u00bc\nZ Z N\n\n?N\ndx$dy$A\u00f0x; y\u00de$exp\n\n?\n?j$2p\n\nl\n$\u00f0x$sin q$cos f\u00fe y$sin q$sin f\u00de\n\n?\n; (5.97)\n\nwhere the A(x,y) is the complex current density, which is of course limited to the area of the aperture,\nand uq\n\n! and uf?! are the director vectors of the plane defined by the direction of propagation. Note that\nthe intensity of the radiated electric field as defined in Eq. (5.97) is the Fourier transform of the current\ndensity at the antenna.\n\nAntennas operate in transmission and reception under the far-field assumption as reciprocal elements.\nConsequently, the far-field radiation pattern in reception is exactly the same as the one in transmission,\nwhich simplifies their analysis, synthesis, and characterization.\n\nFrom the previous expression, one could infer one of the fundamental characteristics of antennas:\nthe ability to concentrate or capture the radiated power within a particular part of space, a property\nknown as directivity. The radiated power density in a given angular direction can be expressed as\n\nx\u00f0q;f\u00de \u00bc jEqj\n2 \u00fe ??Ef??2\n120$p\n\n; (5.98)\n\nFIGURE 5.64\n\nATerraSAR-X staring spotlight image of Guangdong, China. The middle-left side of the image shows radio\n\nfrequency interference appearing as stripes over the water.\n\n5.3 RADAR SYSTEMS 361\n\nmailto:Image of Figure 5.64|tif\n\n\nwhere h \u00bc 120p \u00bc ffiffiffiffiffiffiffiffiffiffiffiffim0=?0p is the wave impedance of free space. The radiated power density is a\nvector pointing radially [parallel to the Poynting vector (Ramo et al., 1994)], i.e., the total radiated\npower can be computed by integrating x(q,f) on the surface of a sphere centered at the phase center of\nthe antenna. The special case of an antenna that does not prefer any angular direction is called\nisotropic, which shows a radiated power density at a distance r0 of the form\n\nxiso \u00bc\nprad\n\n4p$r20\n; (5.99)\n\nwhere Prad is the power radiated by the antenna.\nThe previous expressions describe the angular behavior of the antenna, which is a function of its\n\nform and of the current density distribution with which it is fed. The radiation intensity pattern of an\nexample antenna is presented here in Fig. 5.66. Without loss of generality, only a 1-D cut of the\nprevious function is shown, corresponding to any of the angular components (q, f). The angular\ncomponent is noted off-axis to explicitly consider that the antenna might be pointing in a nonzero\nangle. Antenna patterns are commonly given in decibels due to their large dynamic ranges.\n\nFIGURE 5.65\n\nPicture of a horn, patch on Mango satellite, TerraSAR-X (image credit: DLR, EADS Astrium GmbH), reflector\n\nTandem-L.\n\nFrom http://www.dlr.de/hr/en/desktopdefault.aspx/tabid-8113/.\n\n362 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.65|tif\nhttp://www.dlr.de/hr/en/desktopdefault.aspx/tabid-8113/\n\n\nMost of the energy is radiated or captured back through the main lobe, marked in green, which is\ntypically characterized by its beam width. The beam width of the antenna, also called aperture, is the\nangular extension where the antenna pattern falls 3 dB with respect to its maximum (called the half-\npower point) and is in general inversely proportional to the effective length of the antenna Lq, i.e.,\n\nqa \u00bc a$ l\nLq\n; (5.100)\n\nwhere the use of q is arbitrary and does not only refer to the azimuthal plane, and a is a constant close\nto unity, which varies as a function of the amplitude of the current distribution. For an ideal constant\namplitude of A, a z 0.89 as noted earlier.\n\nThe pattern in Fig. 5.66 has been normalized and its maximum is at 0 dB. Some energy, however, is\nradiated in angular directions outside the main lobe. These signals are very much attenuated, on the order\nof tens of decibels, relative to the energy radiated through the main lobe; this energy is transmitted\nthrough the side lobes of the antenna. As depicted in the figure, all lobes are separated by nulls of the\nantenna pattern, corresponding to blind angle through which almost no energy is radiated.\n\n5.3.17.7 Polarization of Antennas\nRadar waves in the far-field can be assumed to be transverse electromagnetic waves, which means the\nelectrical field vector is orthogonal to the direction of propagation. In this plane containing the electric\nfield vector, we can define two perpendicular axes coinciding with elevation and azimuth (or vertical\n\nSidelobes\n\nBeamwidth\n(3-dB)\n\nNull\n\nMain lobe\n\nFIGURE 5.66\n\nRelative radiation pattern in decibels for one of the antenna planes as a function of the angular coordinate. Most of\n\nthe energy is radiated or captured through the main lobe of the antenna, typically characterized by its 3-dB angular\n\nextension called beam width. Spillover energy is also transmitted through the side lobes, though it is usually\n\nhighly attenuated (tens of dB) with respect to the main lobe. The nulls of the antenna are angular blind spots\n\nthrough which almost no energy is radiated.\n\n5.3 RADAR SYSTEMS 363\n\nmailto:Image of Figure 5.66|eps\n\n\nand horizontal) axes of the radar antenna. The polarization of the wave is given by the shape that the\ninstantaneous value of the electrical field projects on this plane.\n\nDue to the periodic character of the electromagnetic fields, this shape can be linear, circular, or\nelliptical, depending on the phase and ratios between the amplitudes of the vertical and horizontal\ncomponents of the field, e.g., EV, EH. The polarization of the antenna refers to the polarization of the\nelectrical field vector of the radiated wave. Typically, antennas are either linearly or circularly\npolarized. Many remote sensing radars (e.g., ERS-1/2, SRTM, TerraSAR-X, COSMOSkyMed,\nSentinel-1, Radarsat-2) have antennas that are able to radiate and receive in both Vand H polarizations.\nThe general case of elliptical polarization is shown in Fig. 5.67.\n\nThe condition of linear polarization can be expressed as follows:\n\nArg\n?\nEH$E\n\n?\nV\n\n? \u00bc m$p (5.101)\nwherem is any integer number and the condition holds at any time. If the previous condition is not met,\nthe polarization will be elliptical, with the special circular case if EH \u00bc EV. Whether the electric field\nvector moves clockwise or counterclockwise (as seen from an advanced position) will indicate,\nrespectively, left and right-hand polarizations.\n\nThe polarization state of the radar waves is expected to change in its interaction with the target\nsurface and consequently, the phase and amplitude differences between the different polarizations of\nthe echoes provides relevant information of the scattering process. For this purpose, radar antennas are\nusually designed to provide a specific polarization of the radiated waves, which will be more sensitive\nto the intended measurement of a target surface.\n\n5.3.17.8 Characterization of Antennas\nOften, the electromagnetic properties of antennas are ignored and antennas are treated as an element\nof a transmitter-receiver chain. The classical literature on antennas identifies several parameters, which\nhelp to characterize its impact on the power budget of the radar link for both transmission and\nreception.\n\nFIGURE 5.67\n\nA polarization ellipse, which is the general polarization state. Both circular and linear polarizations can be\n\ndescribed as elements of the elliptical case. The wave shown is right-hand polarized, assuming the direction of\n\npropagation is emerging from the paper.\n\n364 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.67|tif\n\n\nDue to the mismatch in the electronics, and to ohmic losses in the conductors, the power radiated by\nan antenna is less than the power delivered to it. The efficiency of the antenna is the ratio of the power\nradiated by the antenna to the power entering the antenna, i.e.,\n\nh \u00bc Pout\nPin\n\n; (5.102)\n\nwhich is by definition smaller than unity. The Pout in transmission refers to the power radiated by the\nantenna, and in reception to the power at the input of the line leading to the LNA. The Pin in transmission\nrefers to the power delivered by the amplifier at the end of the reception chain; it is also the power\nscattered by the scene and captured at the antenna.\n\nThe directivity of the antenna is defined as the ratio between its radiated power density, x(q,f), and\nthe power density of an isotropic antenna radiating the same amount of power over a distance r0, i.e.,\n\nD\u00f0q;f\u00de \u00bc x\u00f0q;f\u00de$4p$r\n2\n0\n\nPrad\n; (5.103)\n\nwhere Prad is the power radiated by the antenna. If the direction is not explicitly expressed, the\ndirectivity is assumed to be given as the direction of maximum radiation. The maximum of the\ndirectivity can be approximated for very directive antennas as\n\nD \u00bc 4p\nU3 dB\n\nz\n4p\n\nqa$fa\n; (5.104)\n\nwhere U3 dB is the solid angle of the antenna aperture, and qa and fa are the half-power beam widths of\nthe antenna in elevation and azimuth, respectively. The gain of the antenna is the product of its efficiency\nand its directivity, i.e.,\n\nG\u00f0q;f\u00de \u00bc h$D\u00f0q;f\u00de. (5.105)\nAs in the case of the directivity, if the direction is not explicitly stated, the gain refers to the direction\n\nof maximum radiation and the antenna is basically characterized as an amplifier. The area over which an\nantenna captures its power density is called the effective area. Due to its reciprocal character, the value of\nthe effective area can be expressed as\n\nAe\u00f0q;f\u00de \u00bc l\n2\n\n4p\n$G\u00f0q;f\u00de; (5.106)\n\nThe previous parameters enable the computation of the contributions of the antennas to the power\nbudget of the radar link. At the terminals of the antenna, the radar echoes are heavily embedded in\nnoise. Assuming a noise power of the Nyquist form, the noise temperature of the antenna can be\nexpressed as\n\nTant \u00bc N\nk$Bant\n\n; (5.107)\n\nwhere N is noise power (usually caused by thermal and background noise radiated into the antenna),\nand Bant is its bandwidth, which typically coincides with the bandwidth of the radar. The noise figure of\nthe antenna can be shown to be (Cardama et al., 1998)\n\nF \u00bc 1\u00fe Tamb\nTant\n\n$\n1? h\nh\n\n; (5.108)\n\nwhere Tamb is the temperature (in Kelvin) of the environment of the antenna.\n\n5.3 RADAR SYSTEMS 365\n\n\n\n5.3.17.9 Antenna Basics\nDue to their usually adverse radar link power budgets, remote sensing radar antennas usually have\nmoderate to high gains. The basic antenna technologies are the following:\n\n\u2022 Wire antennas, basically wire dipoles or monopoles, with a length proportional to the central\nwavelength, are low-gain antennas only used for radars at lower frequencies such as UHF, VHF.\nThe use of these antennas is limited to airborne or ground-based systems such as Carabas-II.\n\n\u2022 Aperture antennas, basically the section of a waveguide with a specific form (e.g., rectangular\nhorns, circular horns), achieve larger gains than wire antennas. Aperture antennas have been used\nextensively in airborne radars, e.g., Ramses, E-SAR (Horn et al., 1992; Dubois-Fernandez et al.,\n2005). Slotted waveguides are a particular case of aperture antennas, currently used in spaceborne\nradars such as TerraSAR-X and TanDEM-X (Werninghaus et al., 2010).\n\n\u2022 Patch antennas made by forming a conductor pattern printed on a substrate (e.g., microstrip).\nThese antennas usually have low gains, e.g., the ones used in the PAZ instrument (https://\ndirectory.eoportal.org/web/eoportal/satellite-missions/p/paz).\n\n\u2022 Reflector antennas, consisting of a feed illuminated by a large reflector (e.g., a parabola).\nReflector antennas usually have large gains but are difficult to deploy in space for remote sensing\nsatellites. Reflectors will be used in future missions such as ESA\u2019s Biomass (https://earth.esa.int/\nweb/guest/missions/esa-future-missions/biomass), DLR\u2019s Tandem-L (http://www.dlr.de/hr/en/\ndesktopdefault.aspx/tabid-8113/), or NASA-JPL\u2019s NISAR (https://nisar.jpl.nasa.gov/\nnisarmission/).\n\n\u2022 Antenna arrays are a group of antennas located with a given spatial distribution working together\nfor transmission or reception of the radar signals. The purpose of an array of antennas is to form a\nmore complex radiation pattern resulting from the coherent combination of the single patterns of\nthe antenna elements of the array. Antenna arrays usually have a better directivity than a single\nantenna. In Fig. 5.68, we show a 1-D array of antennas, where the basic elements are depicted as\nthick points on the horizontal line.\n\nLet us assume that the azimuth plane of the antenna coincides with the page, i.e., the antenna shows\na cylindrical symmetry around the x-axis. Under these circumstances, the radiation pattern of the array\nwill not depend on the elevation angle f. Using the parallel rays (far-field) and the narrowband\nassumptions, the pattern of the antenna array of Fig. 5.68 can be expressed as\n\nxarray\u00f0q\u00de \u00bc\nXN?1\nn\u00bc0\n\nxn\u00f0q\u00de$exp\n?\n?j$2p\n\nl\n$drn\n\n?\n\u00bc\nXN?1\nn\u00bc0\n\nxn\u00f0q\u00de$exp\n?\n?j$2p\n\nl\n$dxn$sin q\n\n?\n; (5.109)\n\n?x\n\n??r\n\nx\n\nFIGURE 5.68\n\nDepiction of a 1-D antenna array. The thick dots correspond to the positions of the antenna elements in the array.\n\n366 CHAPTER 5 RADAR\n\nhttps://directory.eoportal.org/web/eoportal/satellite-missions/p/paz\nhttps://directory.eoportal.org/web/eoportal/satellite-missions/p/paz\nhttps://earth.esa.int/web/guest/missions/esa-future-missions/biomass\nhttps://earth.esa.int/web/guest/missions/esa-future-missions/biomass\nhttp://www.dlr.de/hr/en/desktopdefault.aspx/tabid-8113/\nhttp://www.dlr.de/hr/en/desktopdefault.aspx/tabid-8113/\nhttps://nisar.jpl.nasa.gov/nisarmission/\nhttps://nisar.jpl.nasa.gov/nisarmission/\nmailto:Image of Figure 5.68|eps\n\n\nwhere the xn are the azimuth radiation patterns of the single antenna elements, drn is the difference in the\nrange path of the n-th element with respect to a reference, and dxn is the azimuth spacing of the n-th\nelement with respect to the same reference. Under the condition of equidistant identical elements, the\nprevious expression becomes separable and the array pattern becomes the product of the element pattern\nand a sum of the dephasing terms of (5.109), denoted in the following as array factor. The pattern of the\narray becomes the product of the single element, now denoted x, and this array factor, i.e.,\n\nxarray\u00f0q\u00de \u00bc x\u00f0q\u00de$\nXN?1\nn\u00bc0\n\nexp\n\n?\n?j$2p\n\nl\n$n$dx$sin q\n\n?\n\u00bc 9\u00f0q\u00de$AF\u00f0q\u00de. (5.110)\n\nNote that the summands of the array factor coincide with the kernels of a discrete Fourier transform\n(DFT) with a wavenumber sinq=l. Eq. (5.110) exemplifies the advantage of using antenna arrays. The\nshape of the pattern can be modified by changing the geometry of the array and the relative weighting\nof its elements. If the elements of the array have phase and amplitude setting capabilities, the array\nfactor becomes\n\nAF\u00f0q\u00de \u00bc\nXN?1\nn\u00bc0\n\nw\u00bdn?$exp\n?\n?j$2p\n\nl\n$n$dx$sin q\n\n?\n; (5.111)\n\nwhere the w[n] are the excitation coefficients in the array. Eq. (5.111) coincides with the DFT of w[n].\nIn this case, the analogy with apertures is clear, and arrays appear as a sampled version of the antenna\naperture. The ability to excite the elements of the array is essentially the ability to change the pattern of\nthe antenna, a quality known as beamforming.\n\nAs an example, a constant weighting of the elements sharpens the antenna pattern by a factor of\n\nsinc\n?\nN$dx\nl\n$sin q\n\n?\n. We show the effect of this sharpening (Fig. 5.69) for two different classes of arrays.\n\nIn the left plot (Fig. 5.69), the array factor (green) shows a single peak, since the spacing between the\n\nFIGURE 5.69\n\nComponent antenna (blue) and normalized array (red) patterns for the two different antenna array geometries\n\nlisted in Table 5.3. The normalized array factor is plotted in green for illustration purposes.\n\n5.3 RADAR SYSTEMS 367\n\nmailto:Image of Figure 5.69|tif\n\n\nelements is shorter than l=2. Note that we have normalized the array factor to match the dynamic range\nof the component antenna pattern for illustration purposes. We also see that the pattern of the\ncomponent (blue) modulates the array factor to generate the pattern of the array (red). The right plot\nshows the case where the spacing of the elements is larger than l=2. The array factor (green) in this\ncase shows several peaks in the angular span, as a consequence of aliasing in the sampling of the\ndephasing terms. In the array pattern (red), however, these peaks coincide with the nulls of the pattern\nof the component antenna (blue) and appear therefore attenuated (Fig. 5.69).\n\nWe have already seen that the array factor is the Fourier transform of the weighting coefficients of\nthe component antennas. The properties of the Fourier transform provide us with useful information\nfor understanding the relationship between the coefficients and the resulting patterns. In particular, the\nfollowing property will be used extensively in radar antenna arrays: a linear phase in one domain\ntransforms into a shift in the transformed domain, which will provide us with a simple way to create an\nelectronic steering of the radiation pattern. The steering of the beam allows radars to scan different\n\nTable 5.3 Geometry of the Antenna Arrays Used for the Simulations Presented in\nFigs. 5.69 and 5.70\n\nType\nSpacing\n(cm) Total Length (m) Number of Elements\n\nWavelength\n(cm)\n\nArray 1 1 4 32 3.31\n\nArray 2 30 4.7 12 3.31\n\nFIGURE 5.70\n\nElectronically steered element (blue) and normalized array (red) patterns for two different array geometries. The\n\nnormalized array factor is plotted in green for illustrative purposes. The left plot corresponds to the nonaliased\n\narray with a 10-degree steering. The right plot corresponds to the aliased array of Table 5.3 with a 1-degree\n\nsteering. Note the ambiguous peaks of the array factor (i.e., grating lobes) are no longer attenuated by the nulls of\n\nthe element pattern as they were in Fig. 5.69.\n\n368 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.70|tif\n\n\nportions of space. In particular, tracking radars were the driving force in the development of antenna\narray technologies in the middle of the 20th century (Skolnick, 1980). For small angles, the linear\nphase in the spatial domain to steer the pattern an angle dq0 takes the form\n\n4st\u00f0dq0\u00dez\n2p\n\nl\n$n$dx$sin dq0. (5.112)\n\nElectronic steering, unlike the mechanical one, is monochromatic, which can have an impact on the\ntransmission of wideband signals. Fig. 5.70 shows analogous plots to those of Fig. 5.69 with two\ndifferent steering laws of the radiation patterns computed after (5.111). In the left plot, a steering of 10?\nhas been performed. A small increase in side lobe energy (from?30 to ?25 dB) can be noticed. In the\nright plot, a steering of 10? has been carried out. The situation now is dramatically changed, and the\nambiguous peaks of the array factor are no longer suppressed by the nulls of the antenna element\npattern. Moreover, the peak of the main lobe of the array pattern is attenuated by the element pattern.\nAll things considered, the main-to-side lobe ratio is significantly worsened with respect to the no\nsteering scenario. The ambiguous peaks of the array pattern are commonly known as grating lobes.\n\nThe array model used so far does not make any assumption about the reception of the signal. In the\ncase where the received signal is digitized and stored for every single element (or group of them), leads\nto a further advantage: the ability to synthesize a posteriori different receive pattern, which allows for\nthe estimation of the direction of arrival and the use of digital beamforming techniques (Van Trees,\n2002).\n\nIn an analogous way to the 1-D case, the general expression of the array factor of a 2-D array is\n(Cardama et al., 1998; Thourel, 1971),\n\nxarray\u00f0q;f\u00de \u00bc\nXN?1\nn\u00bc0\n\nXM?1\nm\u00bc0\n\nxnm\u00f0q;f\u00de$w\u00bdn;m?$exp\n?\n?j$2p\n\nl\n$\u00f0xnm$sin q$cos f\u00fe ynm$sin q$sin f\u00de\n\n?\n.\n\n(5.113)\n\nIn the case of equidistant spacing in the xy plane, identical elements yield an array factor of the\nform\n\nAF\u00f0q;f\u00de \u00bc\nXN?1\nn\u00bc0\n\nXM?1\nm\u00bc0\n\nw\u00bdn;m?$exp\n?\n?j$2p\n\nl\n$\u00f0n$dx$sin q$cos f\u00fe m$dy$sin q$sin f\u00de\n\n?\n; (5.114)\n\nwhich is again a 2-D Fourier transform of the weighting function of the component antennas of the\narray. If the excitation coefficients are separable, i.e., w\u00bdn;m? \u00bc w1\u00bdn?$w2\u00bdm?, then the array factor can\nbe expressed as the product of the array factors of the horizontal and vertical 1-D subarrays, i.e.,\n\nAF\u00f0q; f\u00de \u00bc AF1\u00f0q; f\u00de$AF2\u00f0q; f\u00de\n\n\u00bc\nXN?1\nn\u00bc0\n\nw1\u00bdn?$exp\n?\n?j$2p\n\nl\n$n$dx$sin q$cos f\n\n?\n$\nXN?1\nn\u00bc0\n\nw2\u00bdn?$exp\n?\n?j$2p\n\nl\n$m$dy$sin q$sin f\n\n?\n.\n\n(5.115)\n\nAs expected, the steering capabilities and limitations of 1-D arrays are maintained in the case of\n2-D arrays.\n\n5.3 RADAR SYSTEMS 369\n\n\n\n5.3.17.10 Propagation of Radar Waves\nRadar waves propagate through one or several media on their two-way path from radar to target and\nback, suffering both attenuation and delays, which affect the detectability of the echoes and their location\naccuracy. This section describes the effects on the propagation in free space and through the atmosphere.\nThe analysis of the propagation through the atmosphere can be further divided into two separate cases:\n(1) the nondispersive troposphere and (2) the dispersive ionosphere.\n\n5.3.17.10.1 Propagation Through the Troposphere\nAs discussed earlier, the troposphere is the lowest part of the Earth\u2019s atmosphere, up to a height of\nabout 16 km at middle latitudes. The thickness of the layer depends on the latitude of the area of\ninterest. The two main effects of the troposphere on the propagation of the radar signals are attenuation\nand refraction.\n\nRadar waves propagating through the troposphere suffer from attenuation caused by two phenomena:\n(1) molecular absorption by tropospheric gases, mainly oxygen and water vapor, and (2) attenuation\n(scattering and absorption) by hydrometeors, especially rain. Molecular absorption is negligible for\ncarrier frequencies under 10 GHz (i.e., X-band) and typically increase for higher frequency bands,\nparticularly at resonance peaks for water vapor and oxygen at 22.3 and 60 GHz, respectively. Typical\nhydrometeors are rain, snow, haze, or hail. Rain causes the most dramatic attenuation, especially for\nfrequencies higher than 1 GHz (L band), and this attenuation depends on factors such as the type or\nintensity of the rain, and the size and speed of the raindrops. Due to the impact of air friction on\nraindrops, raindrops are flattened and the attenuation of the vertical polarization component is smaller\nthan that for the horizontal polarization.\n\nAn example of the attenuation of the radar signals in the troposphere is shown in Fig. 5.71,\ncorresponding to a radar image acquired by TerraSAR-X in ScanSAR mode over the Amazons in\nnorthwestern Brazil. The black spots in the image correspond to the attenuation of the radar echoes\nbelow the noise level due to heavy rain.\n\nThe propagation speed of the radar signal in the medium is inversely proportional to its refractive\nindex nm, i.e.,\n\nc\u00f0nm\u00de \u00bc c0\nnm\n\n. (5.116)\n\nFIGURE 5.71\n\nTerraSAR-X ScanSAR image over the Amazon rain forest in Brazil. The black spots within the image are due to\n\nthe attenuation of the radar waves in heavy rain and clouds.\n\nCourtesy of DLR.\n\n370 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.71|tif\n\n\nwhere c0 is the propagation speed in a vacuum. The atmospheric refractive index is a function of\npressure, temperature, and water vapor content. It decreases with increasing altitude. The velocity of\npropagation of the radar signals in the troposphere depends on the stratification of the layer, which\nintroduces an unknown delay in the measurement of the radar echoes. This delay changes dynamically\nwith the stratification of the atmosphere in time and space and results in a few meters error in typical\nnadir and side-looking acquisitions (e.g., zenith and slant tropospheric delays). In typical cases,\nthe inhomogeneity of the tropospheric layer introduces variable delays and phase changes in the\nacquired radar echoes, which need to be accounted for in applications involving accurate radar ranging\n(e.g., SAR interferometry).\n\nThe refractive index in the troposphere changes with altitude. We look at a model of a wave being\nrefracted at the boundary layer of two isotropic media (e.g., air, water) with different refractive indexes.\nThe geometry of the incident and refracted rays is depicted in Fig. 5.72.\n\nThe refractive index of the bottom layer is assumed to be higher than the refractive index of the top\nlayer (n2 > n1); as a consequence, the angle with respect to the normal of the refracted wave, qi2, is\nsmaller than the angle of the incident wave qi1. The geometry of the process follows Fermat\u2019s principle\nof the least time and its corollary which is Snell\u2019s law, i.e.,\n\nn1$sin qi1 \u00bc n2$sin qi2. (5.117)\nwhereas the previous model describes the interaction at a discrete interface, the change of the refractive\nindex in the troposphere is continuous, and the radar waves are continuously being refracted. A reference\nvalue for the refractive index in the troposphere as provided by the International Telecommunications\nUnion (ITU) is shown in the left plot of Fig. 5.73, where the curve shows an exponential decay.\n\nAs a consequence of the decreasing refractive index with altitude, radar waves do not propagate\nthrough the troposphere along a straight line and become slightly curved while approaching the Earth\u2019s\nsurface. The horizontal offset relative to the straight propagation for an incident angle of 35? and the\nreference refractive index is shown in the previous figure is shown in the right plot of Fig. 5.73 as a\nfunction of altitude. Note, a horizontal offset of about 1 m between the curved and the straight paths\ncan be observed on the Earth\u2019s surface.\n\nFIGURE 5.72\n\nRefraction occurring at the boundary layer of two isotropic media with different refractive indexes.\n\n5.3 RADAR SYSTEMS 371\n\nmailto:Image of Figure 5.72|eps\n\n\n5.3.17.10.2 Propagation Through the Ionosphere\nThe ionosphere is the layer of the Earth\u2019s upper atmosphere between 60 and 1000 km. The ionosphere\nis an ionized layer with a high concentration of ions and free electrons. The ionization of this layer is\nmainly due to high-energy solar (X-rays and UV) and cosmic radiation. The maximum ionization\noccurs at the middle of the layer at altitudes of about 250e400 km. In Fig. 5.74, we show the vertical\ndistribution of electron density in the ionosphere separated between day and night and low to the\ndifference in solar activity.\n\nSince the main cause of ionization in the atmosphere is solar radiation, the behavior of the ionosphere\nfollows the solar cycles: daily, yearly, and 11-yearly, a period related to sunspot activity on the sun.\n\nThe integrated electron density along the path where the radar waves are propagating is called the\ntotal electron content (TEC) and can be obtained by integrating the density of electrons N along the\npath of the radar signal, i.e.,\n\nTEC \u00bc\nZ\nL\nN$dl . (5.118)\n\nTEC is measured in the number of electrons per unit area. The basic unit, called TECU, can be\ndefined as 1016 electrons per square meter. Depending whether the TEC is expressed in its vertical\nform or on the LOS of the radar, refers to either vertical or slant TEC. The available TEC maps of the\nEarth are typically provided by GPS measurements, wherefrom several empirical models can be\nadjusted.\n\nThe TEC is assumed to have two components with different spatial behavior: (1) a large-scale\nbackground value, that is rather stable and (2) a turbulent part with small-scale variations that produce\n\nFIGURE 5.73\n\nOn the left the reference refractive index (provided by International Telecommunications Union) as a function of\n\nthe altitude in the troposphere. (Right) Horizontal offset for an incident ray at 35? between the curved and straight\npaths assuming the reference refractive index profile on the left.\n\n372 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.73|tif\n\n\nthe phase and amplitude scintillations of these rapid variations. The background ionosphere exhibits\nTEC values about one order of magnitude larger at the Equator than the poles. Scintillations, on the other\nhand, are due to changes in the plasma density of the layer. They are typically localized in time after the\nSunset at the Equator and also occur frequently at the poles.\n\nThe plasma frequency is a function of the electron density, i.e.,\n\nfp \u00bc qe\n2p\n\n$\n\nffiffiffiffiffiffiffiffiffiffiffiffi\nN\n\nme$?0\n\nr\n\u00bc k$\n\nffiffiffiffi\nN\n\np\n. (5.119)\n\nwhere qe is the charge of the electron, me is the mass of the electron, ?0 is the permittivity in a vacuum,\nand k is a proportionality constant. The plasma frequency of the ionosphere is usually on the order of a\nfew megahertz. Radio enthusiasts will surely remember that these are the typical frequencies of the\nshortwaves used for continental radio communications, which benefit from ionospheric reflections. The\nwave propagating through the medium causes acceleration of the free charges. Part of the energy\ngenerated is radiated back to the wave and another is partially absorbed by inelastic collisions. The effect\nof these collisions is negligible for typical spaceborne radar frequency bands, i.e., the attenuation caused\nby the ionosphere can be ignored.\n\nFIGURE 5.74\n\nElectron density profiles for day and night ionospheric activity as a function of height for low and high solar\n\nactivity.\n\n5.3 RADAR SYSTEMS 373\n\nmailto:Image of Figure 5.74|tif\n\n\n5.3.17.10.3 Delays, Phase Offsets, and Depolarization Caused by Inhomogeneity\nThe delay and dephasing of the radar signals propagating through the ionosphere is dictated by the\ndispersive character of the medium, which means that the impact on the radar propagation will be\ndifferent for different frequencies. Neglecting both collisions and the influence of the Earth\u2019s magnetic\nfield, the refractive index in the ionosphere is a function of the frequency, i.e.,\n\nn\u00f0N; f \u00de \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? f\n\n2\np\n\nf 2\n\ns\n; (5.120)\n\nwith fp defined in Eq. (5.119). As in the case of the troposphere, the change in the refractive index of\nthe layer will have the effect of curving the path of the radar waves, adding in this case to the dispersive\ncharacter of the medium. The phase velocity of the radar wave can be expressed as\n\ncphase\u00f0N; f \u00de \u00bc c0ffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? f\n\n2\np\n\nf 2\n\ns ; (5.121)\n\nwhich always takes higher values higher than c0. Alternatively, the group velocity can be expressed as\n\ncgroup\u00f0N; f \u00de \u00bc c0$\nffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? f\n\n2\np\n\nf 2\n\ns\n. (5.122)\n\nThe previous values dictate that the phase offset, introduced in the two-way propagation of the\nradar signals, can be approximated by\n\ndfionoz\n4p\n\nl0\n$\n\nZ\nL\nRe n? 1\u00bd ?$dlz ? 4p\n\nc0$f0\n$k2$STEC; (5.123)\n\nwhere the STEC is TEC expressed in the slant geometry of the radar, and a monochromatic\napproximation has been used. The additional delay in the envelope of the received echoes introduced\nby the ionosphere can be computed as\n\ndsionoz 2$\nZ\nL\n\ndl\n\ncgroup\n? 2$\n\nZ\nL\n\ndl\n\nc0\nz\n\n2$k2\n\nc0$f\n2\n0\n\n$STEC; (5.124)\n\nwhere the monochromatic approximation has been used. Unlike the troposphere, the delay and\ndephasing of the radar echoes is not the same, which may have an impact on the Doppler processing of\nthe echoes. Similarly, inhomogeneity in the TEC structure will introduce filter mismatch both in range\nand Doppler, causing signal energy loss, which affects the local accuracy of the system.\n\nA consequence of the combination of ionosphere and the Earth\u2019s magnetic field is that the phase\nvelocity of a circularly polarized wave propagating through the ionospherewill depend on its orientation.\nConsequently, any polarized wave propagating through the ionosphere will suffer a rotation of its\n\n374 CHAPTER 5 RADAR\n\n\n\npolarization state due to the difference between the phase velocities of its left-hand and right-hand basic\ncomponents.13 This effect is known as Faraday rotation and can be approximated as (Gray et al., 2000),\n\nUFz\nk2\n\nme$c0$f\n2\n0\n\n$STEC$\n?\nB\n!\n$uk\n!?; (5.125)\n\nwhere B\n!\n\nis the magnetic field of the Earth, and uk\n! is the unitary wave number vector. The previous\n\nexpression neglects the curvature of the radar waves in their path through the ionosphere.\n\n5.4 SYNTHETIC APERTURE RADAR\nThe SAR principle,14 suggested by Carl Wiley in 1951 (Wiley, 1985), allows an enhancement in the\nalong-track resolution of a conventional RAR by combining the Doppler information of the echoes in a\ncoherent manner (Brown, 1967). While still working for Goodyear, Wiley was able to demonstrate the\nexperimental feasibility of Doppler beam sharpening with the L band DOUSER system flying onboard\na Douglas DC-3 (Willis, 1991). Simultaneously and independently, Sherwin et al. (1962) developed\nthe same idea and promptly proposed a method for SAR image formation. Using an X band radar\ndeveloped at the University of Illinois and operated onboard a US Air Force Curtiss C-46 aircraft,\nKovaly et al. (1952) produced the first SAR image on July 8, 1953 (Skolnik, 1980a). One year later,\nCutrona et al. (1960), from the University of Michigan, started developing fast analog optical SAR\nprocessors (Cutrona et al., 1961). Using the AN/UDP-1 system, developed in cooperation with Texas\nInstruments, they were able to produce SAR imagery by optical means in 1959 (D\u2019Aria et al., 2004).\nAt that time, optical computers offered the only practicable solution for SAR processing, and remained\nso until the end of the 1970s. With the advent of digital computing optical SAR processors started\nbeing replaced by the slower (but more accurate) off-line digital processors (Kirk, 1975a,b). Airborne\nSAR remained mainly a military research tool until the 1980s, when the development of scientific\ncivilian airborne systems started. Due to its low cost and flexibility, airborne SAR has always been the\nideal test bed for the development of new SAR modes, techniques, and applications, some of which\nhave been eventually incorporated into spaceborne missions. Airborne SARs can provide inexpensive\nmulticarrier, multichannel, multipolarization SAR systems while still maintaining decent swath\nwidths, very good resolution, and high sensitivity.\n\nIn 1978, the first spaceborne SAR mission was flown onboard NASA\u2019s Seasat satellite (Evans et al.,\n1988). Seasat\u2019s SAR was an L band instrument conceived for the imaging of ocean surfaces, polar ice\ncaps, and coastal regions. Based on the success of the Seasat mission, NASA started a program to fly\nSARs onboard the Space Shuttle, known as Shuttle Imaging Radar (SIR). All SIR radars used the same\ncarrier frequency as Seasat, orbiting at an altitude of around 250 km. The first and second generations,\nSIR-A and SIR-B, were launched late 1981 and 1984, respectively (Elachi et al., 1982; Cloude and\nPottier, 1997). The two Soviet spacecraft, Kosmos-1870 and Almaz-1a, launched in 1987 and 1991,\nrespectively, provided S band SAR imagery of land and oceans for scientific and commercial\n\n13Any polarization state can be expressed as a linear combination of left-hand and right-hand circularly polarized\ncomponents.\n14Carl Wiley\u2019s name for the principle of synthetic aperture for side-looking radar was Doppler beam sharpening (DBS).\n\n5.4 SYNTHETIC APERTURE RADAR 375\n\n\n\napplications. Russia flew years later the L/S-band SAR system Travers onboard the Priroda module\nof the Mir orbital station. Shortly after the start of the Almaz-1a, ESA launched the Earth observation\nsatellite ERS-1, which included a C band SAR among other instruments (Attema, 1991). ERS-1 was\nfollowed in 1995 by a duplicate satellite ERS-2, ensuring two decades of consistent C band SAR\nobservations which very much helped to consolidate nowmature SAR techniques such as interferometry.\nThe European contribution to SAR remote sensing was continued with ENVISAT\u2019s C band ASAR\ninstrument, launched in early 2002, which offered dual-pol sensing capabilities (Desnos et al., 2000).\nIn 1992, the Japan Aerospace Exploration Agency launched an L band SAR instrument onboard the\nJERS-1 satellite, mainly conceived for land-oriented applications. JERS-1 was followed by ALOS-1,\nstarted in 2006, which included the fully polarimetric L band PALSAR instrument.\n\nBetween JERS-1 and ERS-2, the third SIR mission, known as SIR-C/X-SAR, was flown twice; this\nmission, a joint NASA/DLR/ASI project, consisted of three radars, operating at L/C, and X-bands, fully\npolarimetric at L/C-bands, which provided the first simultaneous multifrequency, multipolarization SAR\nobservations. Reusing hardware from the previous mission, the same three partners of SIR-C/X-SAR\ncarried out a single-pass C/X-band SAR interferometric mission in early 2000 (Werner, 2000);\nthe Shuttle Radar Topography Mission, commonly known as SRTM (Farr et al., 2007), provided a\ndigital elevation model (DEM) of the Earth\u2019s land surface between 60? north and 56? south with a\nvertical accuracy better than 10 m. At the end of 1995, the Canadian Space Agency (CSA) launched the\nC band Radarsat-1, which was followed a decade afterward by the fully polarimetric, C band Radarsat-2.\nIn 2007, the first satellite of the Agenzia Spaziale Italiana (ASI) X band SAR constellation COSMO-\nSkyMed was launched. In the same year, the German X band radar satellite TerraSAR-X was started as a\npubliceprivate partnership between DLR and Astrium GmbH.\n\nThree years later, a duplicate satellite TanDEM-X was launched. These two satellites operating\ncooperatively are the core of the TanDEM-X mission, in which they form a single-pass bistatic X-band\nSAR interferometric system, with the main goal of providing a global DEM with a vertical accuracy\nbetter than 2 m. The Seasat imagery had a resolution of 25 m, with a horizontal image size of 100 km.\nTerraSAR-X in high-resolution mode yields images with a spatial resolution of around 1 m, and a\nswath width of 5 km. Between 1983 and 1984, the Polyus-V SAR onboard Soviet missions Venera-15/\n16 mapped the Venusian surface from the north pole to about a latitude of 30? north, which corre-\nsponds to 25% of the surface of the planet. Between 1990 and 1994, the NASAMagellan SAR mission\nmapped 98% of Venus with a resolution of about 100 m, including repeat-pass interferometric\nacquisitions.\n\nWith increasing performance and flexibility, spaceborne SAR sensors have grown to become very\npowerful tools for both Earth and planetary science, with specific applications in a variety of fields, i.e.,\nagriculture, forestry, cartography, oceanography, urban planning, risk and disastermonitoring, axiological\ndefense, geology, or transportation monitoring.\n\nSAR interferometry, suggested by Graham in 1974 as a tool to retrieve the topographic information\nof the scene, measures the phase difference between two SAR images acquired from different positions.\nBesides topography, SAR interferometry can also be used to measure motion (e.g., moving target\nindication, ocean currents). Using a two-antenna modification of the NASA AIRSAR system, the first\npractical demonstration of (single-pass) SAR interferometry was carried out at JPL by Zebker and\nGoldstein in 1986 (Bamler, 1992). Two years later, Gabriel and Goldstein (1988) demonstrated\nspaceborne, crossed orbit, repeat-pass interferometry using L-band data acquired by SIR-B. Gabriel et al.\n(1989) also demonstrated differential interferometry shortly afterward. This technique, capable of\n\n376 CHAPTER 5 RADAR\n\n\n\ndetecting small topography changes, can be used to measure natural or artificial deformations with an\naccuracy of a fraction of the wavelength. Using differential SAR interferometry (DInSAR), Massonnet\net al. detected and validated in 1993 the signature of a large earthquake using ERS-1 data; roughly at the\nsame time, Goldstein et al. (1993) used SIR-B data to map the flow velocity of the Rutherford ice stream\nin Antarctica. Over the past years, SAR interferometry has become a fundamental remote sensing\ntechnique with numerous applications in many scientific and commercial fields (e.g., glaciology,\noceanography, topographic mapping, etc.).\n\n5.4.1 A COMPACT INTRODUCTION TO SYNTHETIC APERTURE RADAR THEORY\nConsidering the classifications presented earlier in this chapter, SARs are side-looking imaging range-\nDoppler radars with enhanced along-track resolution achieved through synthetic aperture processing.\nA very long antenna, proportional to the distance to the scene, is synthesized by the motion of the\nplatform, which can be airborne or spaceborne. The typical geometry of the SAR is shown in Fig. 5.75,\nwith the along-track and slant range directions of the observation as described earlier.\n\nAs already discussed, the angles with respect to the boresight of the SAR observation in elevation and\nazimuth are called look and squint angles, respectively. The area illuminated on the ground by the\nantenna is called the footprint. The extension of the footprint as the satellite moves is called the swath.\nThis movement of the footprint in azimuth allows the illumination of the targets from different positions\n(angles), a necessary condition for the formation of the synthetic aperture using coherent processing. The\nlength of the synthetic aperture can be shown to be proportional to the distance to the scene, i.e.,\n\nLsyn z 2$r0$\nl\n\nLa\n; (5.126)\n\n \n\nFIGURE 5.75\n\nAcross-track cut of a side-looking radar observation geometry.\n\n5.4 SYNTHETIC APERTURE RADAR 377\n\nmailto:Image of Figure 5.75|eps\n\n\nwhere La is the length of the azimuth antenna, and the factor 2 is due to the two-way travel of the\nsignal. The maximum achievable azimuth resolution is then roughly half the length in azimuth of the\nantenna:\n\n4syn z r0$\nl\n\nLsyn\n\u00bc La\n\n2\n. (5.127)\n\n5.4.1.1 Range and Azimuth Resolutions\nThe range resolution of the SAR is inversely proportional to the transmitted bandwidth of the system, i.e.,\n\ndr \u00bc c\n2$Br\n\n(5.128)\n\nThis resolution is given in the slant range direction, which does not, in general, coincide with the\norography of the scene. The projection from the LOS onto flat ground is depicted in Fig. 5.76. Note the\nrange resolution on ground is coarser than the slant range resolution.\n\nThe ground range resolution can be approximated as (Cantalloube and Koeniguer, 2008)\n\ndrgz dr$\nVr\n\njVrj2 ; (5.129)\n\nwhere the Vr represents the gradient of the slant range between the radar and the scene. For the simple\ncase of a flat area, Eq. (5.129) can be approximated by\n\ndrgz\nc\n\n2$Br$sin qi\n; (5.130)\n\nwhere the qi is the incident angle. Typical values of range resolutions are in the metric scale for\nfrequency bands up to C band (w5.5 GHz), and decimetric scales for X band, and higher bands.\n\nThe derivation of the azimuth resolution in SAR presented earlier was based on a geometrical\nargument. Let us use now present a derivation based on the Doppler frequency analysis of the SAR\n\nFIGURE 5.76\n\nSlant and ground range resolutions for a side-looking imaging geometry. Note the ground range resolution is\n\ncoarser than the slant range resolution.\n\n378 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.76|eps\n\n\nmeasurement. As discussed, the Doppler frequency is proportional to the radial relative velocity\nbetween radar and target, which in the SAR case becomes\n\nfDop\u00f0asq\u00de \u00bc ?2$vs\nl\n\n$sin asq; (5.131)\n\nwhere vs is the spacecraft velocity, asq is the instantaneous squint angle and the factor 2 is due to the\ntwo-way propagation of the signal. For small squint angles, the previous expression is roughly linear\nwith asq. The Doppler support of the observation corresponds to an angular extent equal to the azimuth\naperture of the antenna qa around the average squint angle of the observation qsq, i.e.,\n\nBa \u00bc\n???? fDop?qsq \u00fe qa2\n\n?\n? fDop\n\n?\nqsq ? qa\n\n2\n\n? ????z 2$vs$qal z 2$vsLa ; (5.132)\nwhere the approximation is again valid for small qa and qsq. The azimuth resolution projected on the\nground can now be expressed as\n\ndx \u00bc vg\nBa\n\nz\nLa$vg\n2$vs\n\n; (5.133)\n\nwhich can be greatly simplified whenever the speed of the platform equals the ground velocity vg.\nTypical values for the azimuth resolution are again in the metric scale for lower-frequency bands and in\nthe decimetric scale for higher-frequency bands.\n\nThere are some interesting conclusions that can be drawn from (5.133). The first and most coun-\nterintuitive, is that the smaller the antenna of the radar, the better the resolving power of the SAR. This is\nof course due to the larger Doppler effect given by thewider the antenna beam. Second, the SAR azimuth\nresolution is independent of the distance at which the radar observes the scene. Last, but not least, the\nazimuth resolution appears to be independent of the wavelength. This is of course only partially true,\nsince the value of La will be proportional to some extent to the wavelength. A further limitation to the\nachievable resolution is linked to the sensitivity of the system. As discussed during the derivation of the\nradar equation, larger antennas yield better gains, effective areas, and sensitivity values.\n\nThe limit for the SAR azimuth resolution is obtained after evaluating Eq. (5.132) when qa\napproaches p, i.e.,\n\ndxSAR \n l\n4\n; (5.134)\n\nwhich is the theoretical limit of the integration over an infinitely linear survey or a circular one for an\nisotropic target. Approaching such a limit, in any case, would require the targets in the scene to remain\ncoherent for a wide angular span (hence a longer illumination time), a very restrictive condition in\nnatural targets. As with any other signal, the Nyquist sampling of the SAR data accommodates the\ntransmitted bandwidth and the Doppler effect of the received echoes, which sets the minimum value\nfor the sampling frequency and the PRF of the SAR as\n\nfs \n Br;\n\nPRF \n Baz 2$vs\nLa\n\n;\n(5.135)\n\nwhere again both fs and PRF tend to be higher for systems operating in higher-frequency bands.\n\n5.4 SYNTHETIC APERTURE RADAR 379\n\n\n\n5.4.1.2 Ambiguities and Doppler Centroid\nSARs transmit pulses at a rate (i.e., PRF) high enough to sample the imaged scene. These phase-encoded\npulses are received by the radar and can be through processing using their corresponding range and\nDoppler coordinates. As discussed earlier, the unambiguous range and Doppler bands, which can be\nscanned by the SAR, are limited. Beyond these bands, targets appear warped both in time and frequency,\ni.e., replicated at the wrong radar coordinates. Depending on whether or not the echoes correspond to\nreturns in time or frequency, yields ambiguities in range or azimuth. Ambiguities are rarely a problem in\nairborne SAR, but pose one of the major challenges in the design of spaceborne SAR systems.\n\nRange ambiguities are returns from previous or future15 pulses into the desired echo window,\ntypically arriving through side lobes of the SAR antenna. The left side of Fig. 5.77 shows a transverse\ncut of the SAR acquisition with the main beam in yellow and the ambiguous areas coming through the\npurple beams pointing at different incident angles and corresponding to far- and near-range ambi-\nguities. As depicted, the ambiguous signal corresponds to the echoes of previous and posterior pulses\ntransmitted by the SAR.\n\nAssuming a reference target placed at range r0, the ambiguity of order k arrives at the radar from\nrange\n\nramb\u00f0k\u00de \u00bc r0 \u00fe m$ c\n2$PRF\n\n; (5.136)\n\nwhere m is an integer number describing the distance in pulses of the ambiguous echoes. Typical range\nambiguities arrive from several tens of kilometers away from the illuminated swath area and effectively\nreduce the contrast in the image. Since there is a direct correspondence between slant range and look\nangle, range ambiguities are typically suppressed through an optimization of the elevation antenna\npattern, and the PRF of the system (Curlander and McDonough, 1991). We present such an optimization\nin Fig. 5.78, which is an image of Naples, Italy.\n\nFIGURE 5.77\n\nRange (left) and azimuth (right) ambiguities in gray. Range ambiguities are caused by echoes of previous or future\n\npulses overlapping in time and illuminated through the elevation side lobes of the synthetic aperture radar (SAR)\n\nantenna. Azimuth ambiguities are caused by echoes overlapping in frequency, which are illuminated through\n\nazimuth side lobes of the SAR antenna.\n\n15In spaceborne observations, the travel time of the radar signals is typically in the order of several PRIs.\n\n380 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.77|tif\n\n\nThe figure of merit that describe the sensitivity of the radar to range ambiguities is the range\nambiguity to signal ratio (RASR), which can be expressed as the integrated ambiguous power over the\nuseful signal power, i.e.,\n\nRASRz\n\nR\nqe;amb\n\ns0;amb\u00f0qe\u00de$r0\u00f0qe\u00de?3$Ge\u00f0qe\u00de$dqeR\ns0$r0\u00f0qe\u00de?3$Ge\u00f0qe\u00de$dqe\n\n; (5.137)\n\nwhere Ge is the gain pattern of the antenna in elevation and the integration is carried out over the\nelevation angles that correspond to the extension of the radar signal on the ground. The cube of the\n\nFIGURE 5.78\n\nSuppression of ambiguities by pulse repetition frequency (PRF) optimization. Azimuth antenna pattern and\n\nambiguous bands (A) TerraSAR-X quad-polarized acquisitions over Naples acquired with PRF of 5267 Hz\n\n(B) and optimized PRF of 6395 Hz (C). Ambiguities are clearly visible in (B).\n\nCourtesy of DLR.\n\n5.4 SYNTHETIC APERTURE RADAR 381\n\nmailto:Image of Figure 5.78|tif\n\n\nrange is analogous to the one obtained in the derivation of the radar equation, due to the combined\neffect of the two-way travel and the extension of the azimuth footprint of the antenna. By construction,\nsmaller RASR values are better. A good RASR should be consistent with the dynamic range of the\nreceived SAR echoes, i.e., typically larger in lower-frequency bands. Good ambiguity to signal ratios\nare commonly better than ?25 dB.\n\nRange ambiguities appear unfocused in the SAR images due to the range mismatch of the processing\nkernel and appear attenuated by the suppression of the elevation pattern. As a consequence, range\nambiguities may only be visible to the eye in low backscatter areas (e.g., coastal), but definitely degrade\nthe radiometric and interferometric information of the images.\n\nSimilarly, azimuth ambiguities result from echoes in ambiguous frequency bands aliased into the\nDoppler effect of the measurement and arriving through azimuth side lobes of the antenna, as depicted in\nthe right drawing of Fig. 5.77. The figure shows an elevation cut of a SAR acquisition with the footprint\nbeam in yellow and the angular areas contributing to left and right azimuth ambiguities in purple.\n\nTo derive the location of azimuth ambiguities, we need to first introduce the Doppler centroid\n(acronym DC), or the Doppler frequency of the mean squint angle of the acquisition, i.e.,\n\nfDC \u00bc ?2$vs\nl\n\n$sin qsq. (5.138)\n\nThe acquired energy in the Doppler spectrum is concentrated around fDC. Azimuth ambiguities are\nreturns at Doppler frequencies offset from the DC of the acquisition a whole number of PRFs, i.e.,\nazimuth ambiguities of order k appear around Doppler frequency\n\nfDop\u00f0k\u00de \u00bc fDC \u00fe n$PRF; (5.139)\nwhere again n is an integer number. The previous expression can be used to compute the angular\nlocation of azimuth ambiguities, i.e.,\n\nqsq;amb\u00f0k\u00dez qsq ? n$l$PRF\n2$vs\n\n; (5.140)\n\nwhich can be translated into a shift in azimuth of the form\n\nDxamb\u00f0k\u00dez n$l$r0$PRF\nvs\n\n. (5.141)\n\nAzimuth ambiguities appear shifted on the order of several kilometers for state-of-the-art SAR\nsystems and, like range ambiguities, reduce the contrast in the image. However, azimuth ambiguities\nare only slightly defocused and perfectly visible in medium to low backscattering areas (e.g., coastal).\nAzimuth ambiguities not only degrade but also bias the radiometric and interferometric information of\nthe images. Fig. 5.79 shows an example of azimuth ambiguities in a TerraSAR-X image contaminating\nthe backscattering signature of a lake in Russia.\n\nAs shown in Fig. 5.77, azimuth ambiguities are received through the side lobes of the azimuth\npattern, which should be designed so as to suppress these side lobes. The figure of merit to evaluate this\nambiguity is the ratio of the azimuth ambiguity to signal ratio (AASR), which gives the ratio between\nthe ambiguous power and the signal power received through the main lobe of the antenna, i.e.,\n\nAASRz\n\nR\nqa;amb\n\ns0;amb\u00f0qa\u00de$Ga\u00f0qa\u00de$dqaR\ns0$Ga\u00f0qa\u00de$dqa\n\n; (5.142)\n\n382 CHAPTER 5 RADAR\n\n\n\nwhere the integration is carried out over the azimuth angles corresponding to the extension of the radar\nsignal on ground. Since the ranges of the azimuth ambiguities are very similar to the ranges of the valid\nechoes we can neglect them, including the integral of the free-space attenuation. As in the case of the\nRASR, AASR values should be similar to the dynamic range of the radar backscatter, e.g., typically\nvalues greater than ?25 dB are used in the specifications of SAR missions. The total ambiguity to\nsignal ratio (TASR) is the sum of the range and azimuth ratios, i.e.,\n\nTASR \u00bc RASR\u00fe AASR. (5.143)\nAs in the case of the azimuth and range ambiguities, good values of TASR are typically better\n\nthan ?25 dB.\n\n5.4.1.3 An Important Synthetic Aperture Radar Choice: Swath Versus Azimuth\nResolution\n\nThe time and frequency measurements of a SAR impose conflicting requirements on the radar: range\nambiguities lessen as azimuth ambiguities increase and vice versa. The relationship between the\navailable swath width and the Doppler bandwidth is related to the size of the SAR antenna. A small\nazimuth antenna size requires a high PRF, which dictates a small swath width and thus a large antenna.\nThis relationship can be approximated by\n\nSwz r0$\nl\n\nLe\n? c\n\n2$PRF\nz\n\nc$La\n4$vs\n\n; (5.144)\n\nwhere the swath width has only been coarsely approximated and the influence of the pulse duration\nhas been neglected. Similarly, a small elevation antenna illuminates a large swath, which requires a\nsmall PRF requiring a large antenna in azimuth. Eq. (5.144) illustrates the trade-off between the\nswath width and azimuth resolution. In general, the better the azimuth resolution of the SAR, the\nnarrower the swath it covers. Conversely, the wider the swath, the poorer the azimuth resolution.\nThis trade-off is valid even when the antenna is steered in elevation or azimuth. By further\n\nFIGURE 5.79\n\nTerraSAR-X image of a lake in Russia. The white area on the lake is due to azimuth ambiguities. Radar illumination\n\nis from the right.\n\nCourtesy of DLR.\n\n5.4 SYNTHETIC APERTURE RADAR 383\n\nmailto:Image of Figure 5.79|tif\n\n\nrearranging Eq. (5.144), we can derive the minimum size of the SAR antenna as the product of La and\nLe in the following form (Freeman, http://citeseerx.ist.psu.edu/viewdoc/download?doi\u00bc10.1.1.424.\n2154&rep\u00bcrep1&type\u00bcpdf):\n\nASAR \u00bc Le$La \n 4$l$r0$vs\nc\n\n. (5.145)\n\nLarger antennas have reduced swath widths, or azimuth resolutions, but of course they improve the\noverall sensitivity of the system.\n\n5.4.1.4 Synthetic Aperture Radar Imaging Modes\nSo far, we have assumed that the antenna of the radar is not steered during the data acquisition, which\ncorresponds to the natural SAR acquisition mode called stripmap. The stripmap mode has some ad-\nvantageous properties such as an invariant azimuth of the survey, which typically extends for a few\nseconds along the orbit, antenna pattern, and radar mapping coordinates. Other SAR imaging modes\nallow by steering in azimuth or elevation of the antenna pattern a selectable trade-off between azimuth\nresolution and scene size.\n\n5.4.1.4.1 High Azimuth Resolution Modes: Spotlight\nIn the spotlight modes, the antenna is linearly steered in azimuth to illuminate a spot on the ground for\na longer period of time (Carrara et al., 1995). The situation is depicted in Fig. 5.80.\n\nThe simplest spotlight mode is called staring, the center of the rotation of the antenna pattern\ncoincides with the center of the imaged scene, hence maximizing both illumination time and azimuth\nresolution. The size of the scene roughly coincides with the footprint of the radar antenna, as depicted\nin Fig. 5.80A. As a way to overcome the short extension of the staring spotlight scenes, the sliding\n\n(A) (B)\n\nFIGURE 5.80\n\nSteering laws, footprints, and scene size for staring (A) and sliding (B) spotlight acquisition modes. In the sliding\n\nconfiguration, a longer azimuth scene size is traded off for a coarser illumination time and azimuth resolution.\n\n384 CHAPTER 5 RADAR\n\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.424.2154&amp;rep=rep1&amp;type=pdf\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.424.2154&amp;rep=rep1&amp;type=pdf\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.424.2154&amp;rep=rep1&amp;type=pdf\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.424.2154&amp;rep=rep1&amp;type=pdf\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.424.2154&amp;rep=rep1&amp;type=pdf\nmailto:Image of Figure 5.80|eps\n\n\nspotlight mode was developed (Fig. 5.80B). The rotation center is placed at a further range, usually\noutside the imaged scene, i.e., the steering rate is smaller than in the staring case. The targets are\nilluminated for a shorter time than the duration of the acquisition, which allows for a larger extension\nin azimuth of the imaged scene. The larger size of the scene is traded off in the sliding spotlight mode\nfor a decrease in azimuth resolution, as depicted in the right drawing of Fig. 5.80.\n\nAs a consequence of azimuth steering, the DC of the targets changes linearly with the along-track\nposition within the scene. This variation is in any case smaller than the azimuth bandwidth of\nthe scene, but needs to be accommodated by the image formation kernel (Carrara et al., 1995). The\nspotlight mode allows the improvement of the azimuth resolution without reducing the size of\nthe antenna. As a consequence, the PRF of the spotlight acquisitions is only marginally higher than the\nstripmap PRF, with the slight increase used to accommodate the migration of the DC along the scene.\n\nTerraSAR-X was the first operational civilian SAR mission to acquire images in both staring and\nsliding spotlight modes, achieving azimuth resolutions of 25 and 50 cm, respectively. Many examples\nof both sliding and staring spotlight images can be found throughout this chapter. Fig. 5.81 (top) shows\nan example of two geocoded TerraSAR-X images over the Atacama Desert, Chile, in stripmap (A) and\nsliding spotlight (B) modes, respectively.\n\n5.4.1.4.2 Wide-Swath Modes: ScanSAR and TOPS\nWide-swath modes are operated in bursts shorter than the stripmap illumination time of the SAR\nantenna, i.e., the available (integration) time is multiplexed for the scanning of different swaths\naccessed with a short number of steering in elevation of the SAR antenna beam (Cumming and Bennet,\n1979; Moreira and Huang, 1994). In Fig. 5.82A, we show an example of a ScanSAR acquisition with\nthree subswaths.\n\nThe consecutive ellipses represent the footprints of the antenna at different acquisition times. The\nnumber of subswaths can be extended, at the cost of each having a smaller portion of the available\nillumination time, hence degrading the azimuth resolution of the final images. As in the spotlight case,\nthis degradation does not imply a decrease in the PRF as compared to stripmap, since the instantaneous\nDoppler bandwidth is the one imposed by the size of the antenna. A further condition of the duration of\nthe bursts is imposed by the continuity of the images of consecutive bursts, as shown in the figure.\n\nDepending on their azimuth position on the ground, the targets are observed with different portions of\nthe azimuth pattern, which has two main consequences: (1) the DC of the targets changes linearly with\nthe azimuth position (Cumming and Bennet, 1979; Moreira and Huang, 1994) and (2) a modulation\nof the amplitude of the images corresponding to the integrated pattern, with which the targets are\nobserved, appears in the image. This modulation known as scalloping, is usually small, on the order of\n1e2 dB, but introduces an inhomogeneity which affects both the radiometric and interferometric quality\nof the images. In Fig. 5.83, we present an image which shows a noise scaling effect in lake Qinghai,\nChina, due to scalloping. In the image, acquired by TerraSAR-X in ScanSARmode, azimuth ambiguities\nare also visible in the lake. The ScanSAR mode in TerraSAR-X has a swath of about 100 km with an\nazimuth resolution of 15 m.\n\nScanSAR was first used in ERS-1, and it now plays a fundamental role in the popularization of\nrepeat-pass interferometric applications.\n\nA way to overcome the azimuth inhomogeneity of the pattern, the TOPS (i.e., terrain observation\nby progressive scans) mode was suggested. The discrete scanning in elevation and burst operation of\n\n5.4 SYNTHETIC APERTURE RADAR 385\n\n\n\nScanSAR are maintained, but a linear steering in azimuth of the antenna is done at the burst level to\nequalize the tapering of the azimuth pattern for all targets. The steering, as depicted in Fig. 5.82B is\ninverse with respect to the spotlight steering. The scalloping is reduced, typically to about 0.5 dB. A\nmore homogeneous performance is achieved, at the expense of higher DCs within the acquisitions as it\ncan be observed in Fig. 5.82. The Terrain Observation with Progressive Scans (TOPS) mode was\ndemonstrated for the first time on-orbit with TerraSAR-X (F. De Zan, http://elib.dlr.de/61807/1/dezan.\npdf) and has become standard for Sentinel-1 Interferometric Wide Swath (IWS) and Extra Wide Swath\n(EWS) modes. The first SAR images acquired by TerraSAR-X (left) and Sentinel-1 (right) in the TOPS\nacquisition mode are included here in Fig. 5.84.\n\nFIGURE 5.81\n\nGeocoded TerraSAR-X images over the Atacama Desert, Chile. Stripmap (A), sliding spotlight (B), ScanSAR\n\n(C), and terrain observation by progressive scans (TOPS) modes (D). The vertical direction corresponds to north.\n\n386 CHAPTER 5 RADAR\n\nhttp://elib.dlr.de/61807/1/dezan.pdf\nhttp://elib.dlr.de/61807/1/dezan.pdf\nmailto:Image of Figure 5.81|tif\n\n\n(A) (B)\n\nFIGURE 5.82\n\nSteering laws, footprints, and scene size for ScanSAR (A) and terrain observation by progressive scans (TOPS)\n\n(B) acquisition modes. The azimuth steering of the TOPS mode allows for the illumination of the scene with more\n\nhomogeneous radiometric qualities.\n\nFIGURE 5.83\n\nTerraSAR-X ScanSAR image over Qinghai Lake, China. The periodic horizontal white stripes in the lake are due\n\nto a noise scaling effect due to scalloping. The distance between the stripes corresponds to the duration of the radar\n\nbursts. Note azimuth ambiguities can also be observed in the lake.\n\nCourtesy of DLR.\n\n5.4 SYNTHETIC APERTURE RADAR 387\n\nmailto:Image of Figure 5.82|eps\nmailto:Image of Figure 5.83|tif\n\n\n5.4.1.4.3 Circular Synthetic Aperture Radar\nOne specific airborne SAR acquisition mode consists of surveys with circular flight paths. The targets\nin the scene are observed over an angular span of 360?, which allows for both very high-resolution\nimaging and angular discrimination. Over isotropic targets, the impulse response of circular SAR\nshows a polar symmetry with the best achievable SAR resolution of dx ? l=4. This resolution appears\nto be independent of the transmitted bandwidth. Such a theoretical result would require an idealized\nisotropic target infinitely thin, not found in real life. Nevertheless, circular SAR images show a very\nhigh-resolution character with reduced speckle and a higher level of detail, as it can be seen in\nFig. 5.85.\n\nThe swath shows a circular shape, generated after rotation of the footprint on the ground. The\nsurvey is space-variant and very sensitive to topography and motion compensation. This sensitivity to\ntopography is at the core of the tomographic potential of circular SAR surveys. In Fig. 5.86, we show\nan example of a complete circular SAR image over Kaufbeuren, Germany, with the color coding\ncorresponding to the different L band polarimetric channels in the Pauli basis is presented here in\nFig. 5.85. The SAR image is overlaid on the Google Earth image of the area.\n\nFIGURE 5.84\n\nFirst synthetic aperture radar images acquired by (A) TerraSAR-X and (B) Sentinel-1 in the terrain observation by\n\nprogressive scans (TOPS) acquisition mode. TerraSAR-X image acquired over the south Russian Steppes about\n\n500 km northeast of the Black Sea and about 50 kmwest of Volgograd. Sentinel-1A mosaic of the first S-1ATOPS\n\ninterferogram (two slices) in IW mode around the Gulf of Genoa, Italy, acquired on August 7 and 19. Range\n\nextension, 250 km; azimuth extension, 340 km.\n\nCourtesy of DLR.\n\n388 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.84|tif\n\n\n5.4.1.4.4 Synthetic Aperture Radar Image Calibration\nCalibrated SAR images show radiometric values close to the actual radar brightness of the scene, with\na high-fidelity location of the scatterers, and an accurate representation of the complex ratios between\nthe polarimetric channels over the entire image. Furthermore, the times of the images in both range and\nazimuth accurately represent the radar observation geometry. These aspects are discussed in the\nfollowing paragraphs.\n\nFIGURE 5.85\n\nComparison of stripmap (left) and circular (right) synthetic aperture radar (SAR) images acquired with DLR\n\nairborne system F-SAR in L-band over Kaufbeuren, Germany. The circular SAR images show a higher level of\n\ndetail and reduced speckle.\n\nCourtesy of DLR.\n\n5.4 SYNTHETIC APERTURE RADAR 389\n\nmailto:Image of Figure 5.85|tif\n\n\nSince the propagation losses can be, on average, estimated with a very good accuracy, the radiometric\nfidelity of the SAR system depends on a good characterization of the antenna patterns, SAR pointing, and\nthe payload electronics of the transmitter and the receiver (e.g., transmitted power and transfer functions,\nreceiver gain, anomalies and drifts). For the radiometric calibration of SAR systems, external targets with\nhigh radar cross sections, typically transponders, are used. Observations over homogeneous areas (e.g.,\nrain forest for higher-frequency bands) are used to observe the average elevation patterns of the system.\nTypical values for the absolute radiometric fidelity of aSARsystemhavevalues better than30%, i.e., 1 dB.\n\nThe second aspect mentioned above is the accurate locations of the image pixels, which strongly\ndepends on the knowledge of the observation geometry, and also on the delays of the radar signals and\nechoes occurring in the atmosphere and in the payload electronics. A good knowledge of the radar\nobservation geometry depends on a precise knowledge of the orbit ephemeris data, and of the pointing\nattitude of the radar antenna, which includes spacecraft attitude knowledge. The delays in the propagation\nof the radar signals through the atmosphere can be estimated from meteorological models. The\ncharacterization of the internal delays of the payload electronics can be accomplished with the help of\nexternal targets, typically trihedrals, whose positions are very accurately known. Typical values of\ngeolocation accuracies are better than the range resolution of the system. A further step in the accurate\nlocation of the scatterers is the relative accuracy between several acquisitions, which will be crucial for\nSAR interferometric applications. The relative accuracy typically depends on the separation between\nthe available ephemeris (i.e., baseline), which should be typically kept better than a fraction of the\nwavelength.\n\nFIGURE 5.86\n\nL-band polarimetric circular synthetic aperture radar (SAR) image acquired over Kaufbeuren, Germany, with\n\nDLR\u2019s airborne F-SAR system. The full-resolution image has a Cartesian sampling of 6 cm in both directions and\n\nis overlaid over the Google Earth image of the area.\n\nCourtesy of DLR.\n\n390 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.86|tif\n\n\nThe third element, which outlined above, is the accurate representation of the polarimetric ratios,\nwhich suggests accurate relative radiometric and interferometric information between the channels.\nThe polarimetric calibration requires the accurate characterization of transmitter and receiver,\nincluding the antenna patterns and both horizontally and vertically polarized receive channels in terms\nof geometry, imbalances, and cross-talk. Moreover, the Faraday rotation, caused by the propagation of\nthe radar signals through the ionosphere, needs to be estimated and compensated. Typical values for\nthese ratios are below 30% in terms of amplitude deviation and a few degrees in phase.\n\n5.4.2 SYNTHETIC APERTURE RADAR SYSTEMS AND MISSIONS\nTable 5.4 shows a list of all spaceborne SAR missions over the past 40 years since the flight of NASA/\nJPL Seasat.\n\n5.4.3 FUNDAMENTALS OF SYNTHETIC APERTURE RADAR PROCESSING\nThe difference between real and SARs lies in the coherent processing of the received echoes. Processing\nplays a fundamental role in SAR. SAR data acquisition is illustrated in Fig. 5.87 along with the SAR\nimage formation process. The satellite is depicted flying from right to left and represents different\n\nTable 5.4 List of All Spaceborne Synthetic Aperture Radar Missions Over\nthe Past 40 years\n\nSensor\nFrequency Band/\nPolarization Agency\n\nSeasat L/HH NASA/JPL\n\nERS-1/2 C/VV ESA\n\nJERS-1 L/HH JAXA\n\nSIR-C/X-SAR L/quad, C/quad, X/VV NASA/JPL, DLR, ASI\n\nRadarsat-1 C/HH CSA\n\nSRTM C/HH \u00fe VV, X/VV NASA/JPL, DLR, ASI\nENVISAT/ASAR C/dual ESA\n\nALOS/PalSAR L/quad JAXA\n\nTerraSAR-X/TanDEM-X X/quad DLR/Astrium\n\nRadarsat-2 C/quad CSA\n\nCOSMOSkyMed-1/4 X/dual ASI/MiD\n\nRISAT-1 C/quad ISRO\n\nHJ-1C S/VV\n\nKompsat-5 X/dual KARI\n\nPAZ X/quad CDTI\n\nALOS-2 L/quad JAXA\n\nSentinel-1a/1b C/dual ESA\n\nRadarsat constellation-1/2/3 C/quad CSA\n\nSAOCOM-1/2 L/quad CONAE/ASI\n\n5.4 SYNTHETIC APERTURE RADAR 391\n\n\n\nilluminations of the radar. The data matrix shows in black the collected echoes of a single scatterer\nplaced at the center of the survey where all dashed lines converge. The delay of the received echoes,\nmeasured in fast time, represents the instantaneous distance to the target, which is larger at the edges of\nthe survey. The envelope of the SAR echomigrates along the convex black line shown in the figure. After\npulse compression, the echoes show envelopes similar to the one depicted on the left side of the image.\n\nIn slow or azimuth time, the slant range is shown as the phase of the received signal, which possesses\nthe roughly quadratic (e.g., chirp) form of the bottom signal in the figure. The modulation of the\namplitude of the azimuth signal is mainly due to the antenna pattern. The SAR image formation process\nbasically retrieves the energy corresponding to a small area on the ground of the corresponding pixel,\nwhich in the case of a single scatterer shows the band-limited shape of the focused envelope at the top of\nthe figure. As discussed earlier, the focused SAR image will be the coherent superposition of the\nresponses of the individual scatterers in the scene.\n\nThis process can be represented in a compact way. The SAR impulse response is the 2-D signal\ndescribing the echoes received from a single unitary point target, and it can be approximated as\n\nh\u00f0tr; ta\u00dez plp\n?\ntr ? 2$r\u00f0ta\u00de\n\nc\n\n?\n$exp\n\n?\n?j$u0$2$r\u00f0ta\u00de\n\nc\n\n?\n$want\n\n?\nta\nTint\n\n?\n; (5.146)\n\n \n\nFIGURE 5.87\n\nSynthetic aperture radar (SAR) data acquisition model and image formation process. The satellites show the\n\ndifferent positions of the radar during the synthetic aperture. The data matrix shows the migration of the radar\n\nechoes, and the bottom and left figures show the real part and envelope of the echoes of a single scatterer in\n\nazimuth and range after pulse compression. The top image shows the envelope of the azimuth signal after SAR\n\nprocessing.\n\n392 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.87|eps\n\n\nwhere the Doppler time tD has been replaced by the azimuth time ta, and the rectangular antenna\npattern has been substituted by a real one denoted as want\u00f0$\u00de.16 The signal plp is typically a chirp. Eq.\n(5.146) represents a fairly general expression of the SAR impulse response, which can in many\npractical cases be written for the linear-track case by using hyperbolical range histories, i.e.,\n\nr\u00f0ta\u00de \u00bc\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nr2bc \u00fe v2e$\u00f0ta ? tbc\u00de2\n\nq\n; (5.147)\n\nwhere tbc is the time at which the Doppler history equals the fDC, and the subscript bc stands for beam\ncenter. The ve is the effective velocity of the survey, which can be approximated by the geometric mean\nof the spacecraft and ground velocities, i.e.,\n\nv2e\u00f0r0\u00dez vs$vg. (5.148)\nAs with the ground velocity, the effective velocity also varies along the swath. The model of\n\nhyperbolical surveys is very helpful in both airborne and spaceborne SAR, since it provides an exact\nanalytical model for the SAR transfer function. In the spaceborne case, the hyperbolic model is only\nlocally valid in range and needs to be updated along the orbit. The hyperbolic model breaks down\namong others in very high squint, very high-resolution, or bistatic SAR systems.\n\nFig. 5.88 shows the real part of the SAR raw data of four different target responses with different\nDCs embedded in noise.\n\nFor simplicity, a rectangular antenna pattern has been assumed. The vertical axis describes near to\nfar ranges from top to bottom. The left side of Fig. 5.88 shows the responses of two targets acquired in\na zero-Doppler geometry. The center of the circles represents the phase center in range and azimuth of\n(5.146). The right side shows the responses of the same point targets acquired in a squinted geometry.\nAs expected, the phase center no longer appears symmetrical.\n\nThe Doppler history of the target is the instantaneous Doppler with which the target is seen at any\ntime instant. It can be computed as\n\nfDop\u00f0ta\u00de \u00bc ?2\nl\n$\ndr\n\ndta\n\u00bc 2$v\n\n2\ne$\u00f0ta ? tbc\u00de\n\nl$\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nr2bc \u00fe v2e$\u00f0ta ? tbc\u00de2\n\nq ; (5.149)\nwhere the first equation is general and the second is particular to the hyperbolic case. For a short\namount of time (r0 [ vSAT$(ta? tbc)), the Doppler history can be linearized, and the proportionality\nfactor can be expressed as\n\nbaz\n2$v2e\nl$rbc\n\n; (5.150)\n\nwhich is usually referred to as the Doppler rate. Essentially, this linearization is at the basis of the\nquadratic approximation of SAR range histories, which allows the expression of the azimuth modulation\n\n16The stop-and-go approximation will be maintained in the entire derivation, which suggests small to moderate values of the\nproduct chirp bandwidth pulse duration (cf. Section 5.1). In the cases where this approximation does not hold (e.g., very\nhigh-resolution SAR or continuous-wave SAR), this approximation leads to defocusing, positioning, and phase errors of\nthe resulting SAR images. Prats-Iraola et al., 2014 shows an easy way to model the effect (and correct for) of the continuous\nmotion of the spacecraft in case the reader is interested.\n\n5.4 SYNTHETIC APERTURE RADAR 393\n\n\n\nof the SAR impulse response as a chirp. This approximation, while rarely used in reality, is very useful to\nunderstand the fundamentals of SAR. As an example, we can rewrite Eq. (5.133) with help of the\nDoppler rate as\n\ndxgz\nvg\n\nba$Tint\n\u00bc l$rbc\n\n2$vSAT$Tint\n; (5.151)\n\nwhere the Tint is the illumination or integration time. Eq. (5.151) provides an estimate of the azimuth\nresolution for the cases in which the integration time does not coincide with the full illumination time\nof the antenna, such as the high-resolution or wide-swath modes (e.g., spotlight, scanSAR, TOPS).\n\n5.4.3.1 Exact Synthetic Aperture Radar Image Formation: The Backprojection Integral\nThe optimal radar receiver, in terms of maximizing the SNR of the received echoes, is the matched\nfilter. For the shape of the SAR impulse response discussed above, the matched filter coincides with the\ninversion filter, and hence achieves the compression of the SAR echoes. In terms of system theory,\nSAR image formation is effected via a range-variant filter with an impulse response time-inverted and\nconjugated using Eq. (5.146).\n\nFIGURE 5.88\n\nReal part of the synthetic aperture radar raw data of four targets with different Doppler centroids embedded in\n\nnoise. The bottom corresponds to the far range of the swath. The left side shows the responses of two targets\n\nacquired in a zero-Doppler geometry. The right side shows the same two targets acquired in a squinted geometry.\n\n394 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.88|tif\n\n\nThe most general expression of exact SAR image formation is the direct backprojection algorithm\n(DBP). This algorithm can be interpreted as a range and azimuthevariant correlation in the time\ndomain based on the backprojection integral, i.e., which can be expressed as\n\ni\u00f0r0; x0\u00de \u00bc\nZ\nTint\n\nsRC\u00f0r0; ta\u00de$exp\n?\nj$\n4p\n\nl\n$dr\u00f0ta; r0; x0\u00de\n\n?\ndta; (5.152)\n\nwhere sRC(r0, ta) are the range-compressed data, i.e., the raw data after pulse compression. The\nbackprojection algorithm is the most flexible SAR image formation algorithm since it accommodates\nin an exact way, unlike its Fourier-domain counterparts, any space-variance present in the range\nhistory of the survey and can accommodate nonlinear, circular, or bistatic surveys.\n\nThe DBP algorithm is an attractive option for low to medium resolution experimental systems, and it\nis very appropriate for parallelized implementations with moderate memory storage. It is usually\nimplemented using an echo-based approach, discarding the echoes once they have been backprojected\nonto the final image. The computational complexity of the algorithm is O\n\n?\nNr$N\n\n2\na\n\n?\n, i.e., all samples in\n\nazimuth need to be backprojected to the final image. This computational burden is acceptable for small\nintegration times but becomes impracticable in most general SAR cases, where efficient implemen-\ntations in the time and frequency domains are preferred.\n\n5.4.3.2 Spectral Properties of Synthetic Aperture Radar Images\nSAR signal properties are illustrated in different frequency and time domains in Fig. 5.89.\n\nAssuming there is no steering in azimuth of the antenna, the spectral support of the raw data has a\nsquare shape as shown in the top left quadrant of Fig. 5.89, where range is the transmitted bandwidth,\n\nFIGURE 5.89\n\nSynthetic aperture radar (SAR) signal properties in different frequency and time domains. The top left figure\n\nshows the raw data in wave number (range frequency-Doppler) domain. The top right figure shows two target\n\nresponses of the raw data in the time (range-azimuth) domain. Note the extent of the azimuth of the near-range\n\ntarget is shorter to represent the same angular extent as seen from the radar. The bottom left figure shows the same\n\ntwo targets in their range-Doppler domain; note the Doppler support of the two targets is the same. The bottom\n\nright figure shows the spectrum of the SAR image (i.e., after SAR image formation) in the wave number domain.\n\nNote the shape of the spectrum is distorted in range with respect to the spectral support of the raw data in the top\n\nleft figure.\n\n5.4 SYNTHETIC APERTURE RADAR 395\n\nmailto:Image of Figure 5.89|eps\n\n\nBr, and for azimuth it is the bandwidth of the antenna Ba around the DC, fDC. The top right figure shows\nthe envelopes of the raw data of two target responses in the time (range-azimuth) domain. The azimuth\nextension of the near-range target is shorter to represent the same angle as seen by the radar. Moreover,\nthe curvature of the near-range targets is greater, as expected from Eq. (5.150). The bottom left figure\nshows the same two targets in the range-Doppler (time, azimuth frequency) domain. Note the Doppler\neffect of the two targets is now the same, and the curvature of the envelope (i.e., range cell migration)\nof the far-range target is greater.\n\nAfter SAR image formation, the spectrum on the top left becomes the one shown on the bottom right,\ncorresponding to a focused SAR image. The curvature of the spectrum is due to the range-variance of the\nSAR focusing kernel. The 2-D frequency domain is usually known in the SAR literature as the wave\nnumber domain.\n\n5.4.3.3 Synthetic Aperture Radar Transfer Function\nThe SAR transfer function can be computed by transforming the SAR impulse response in the 2-D\nfrequency (i.e., wave number) domain. Eq. (5.146) is transformed into range frequency by using\nthe delay property of the Fourier transform (Oppenheim et al., 1983; Papoulis, 1965), i.e.,\n\nHr\u00f0 fr; ta; r0\u00de \u00bc want\n?\n\nta\nTint\n\n?\n$PTx\u00f0 fr\u00de$exp\n\n?\n?j$4p\n\nl\n$\u00f0 fr \u00fe f0\u00de$r\u00f0ta\u00de\n\n?\n; (5.153)\n\nwhere PTx is the Fourier transform of the transmitted signal, fr denotes the range frequency, and r(ta) is\nthe range history of the target. The suffix r inHr is used to explicitly state that the Fourier transform has\nbeen computed only in the range variable.\n\nThe Fourier transform in azimuth is computed using the principle of stationary phase (Papoulis,\n1968; Bleistein and Handelsman, 1975; Cumming and Wong, 1979), according to which only the low-\nfrequent parts of the time-domain signal contribute to the value of this Fourier transform. For the\nprevious expression, the principle of stationary phase can be mathematically expressed as\n\n? c\n2\n$\n\nfa\nfr \u00fe f0 \u00bc\n\ndr\u00f0ta\u00de\ndta\n\n/ t?a \u00bc ?r0$\nc$fa\n\n2$v2e$\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\u00f0 fr \u00fe f0\u00de2 ?\n\n?\nc$fa\n2$ve\n\n?2s ; (5.154)\nwhere fa is the azimuth frequency, t\n\n?\na is the slow time of the stationary phase and the right part of\n\n(5.154) already assumes the hyperbolic range history model in (5.147). By evaluating the kernel of the\nazimuth Fourier transform in t?a , the SAR transfer function can be approximated by\n\nH\u00f0 fr; fa; r0\u00dezC$want\n?\n\nt?a\nTint\n\n?\n$PTx\u00f0 fr\u00de$exp\n\n?\n?j$4p\n\nl\n$\u00f0 fr \u00fe f0\u00de$r\n\n?\nt?a\n?? 2p$fa$t?a?\n\n\u00bc C$want\n?\nt?a\u00f0fa\u00de\nTint\n\n?\n$PTx\u00f0 fr\u00de$exp\n\n24?j$4p\nl\n$r0$\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\u00f0 fr \u00fe f0\u00de2 ?\n\n?\nc$fa\n2$ve\n\n?2s 35; (5.155)\nwhere C is a complex constant, and the argument of want\u00f0$\u00de has been maintained for compactness.\nNote that the azimuth antenna pattern modulates, conveniently scaled, the Doppler spectrum of the\nreceived echoes. The matched filter used in the SAR image formation process is the complex conjugate\n\n396 CHAPTER 5 RADAR\n\n\n\nof Eq. (5.155). Note the SAR matched filter changes with range, which constitutes a paramount\nchallenge for the derivation of efficient implementations.\n\nEq. (5.155) is a very accurate approximation of the SAR transfer function for the linear-track\nmodel and is the basis of efficient SAR image formation algorithms in the Fourier domain. In general,\n(5.155) can be typically used in both airborne and spaceborne radar with moderate to moderately high\nresolution. In very high-resolution and bistatic systems, however, the range history model should\npreferably be approximated differently, which leads to different results in the final parts of (5.154) and\n(5.155). The first elements of these equations, however, are general and approximate well high-\nresolution and bistatic sampling.\n\n5.4.3.4 Efficient Synthetic Aperture Radar Image Formation\nAs already pointed out, SAR image formation can be interpreted as the range-variant implementation\nof the complex conjugate of Eq. (5.155). Efficiency in the SAR image formation process is gained via a\nfast convolution in azimuth, be it in the Fourier frequency or in the time domain. The improvement in\nthe computational efficiency of SAR image formation algorithms with respect to DBP is analogous to\nthe jump between DFTand FFT. The efficiency improvement in SAR image formation follows the rule\n\nO\n?\nN2a\n?\n/O\u00f0Na$log2Na\u00de. (5.156)\n\nThere are a number of efficient SAR image formation algorithms available in the literature, which\nare in principle equivalent for low to medium resolutions and small to medium swath widths. We will\ndivide them into two main categories. Depending on whether or not the matched filter carries its\ncorrections to the full transmitted bandwidth or only to the carrier frequency, we will speak about\npolychromatic and monochromatic algorithms, respectively.\n\nThe paradigm of monochromatic SAR image formation algorithms is the range-Doppler (Cumming\nand Wong, 1979; Cumming and Bennett, 1979), with its fast, interpolation-free version of chirp scaling\n(Raney et al., 1994; Moreira et al., 1996; Cumming and Wong, 1979). Polychromatic algorithms can be\nsymbolized by two conjugate approaches in the time and frequency domains: the fast-factorized back-\nprojection (FFBP) and the range-migration or Uk algorithm (Cafforio et al., 1991; Milman et al., 1993).\nIn general terms, monochromatic algorithms, especially chirp scaling, are faster than polychromatic\nalgorithms, naturally at the expense of higher approximation errors. In general terms, time-domain\napproaches are insensitive to temporal and spectral folding and are better suited for space-variant\ncorrections such as motion compensation. They also allow for dynamic memory management.\n\nThe final choice of a SAR image formation algorithm requires a formal evaluation of the system\nrequirements.However,most state-of-the-art civilian spaceborne systems usemonochromatic approaches\nsuch as range-Doppler or chirp scaling. With the increasing performance of spaceborne SAR systems of\nthe next generation, both theUk and FFBPalgorithms are expected to be playing amore significant role in\nthe future.\n\n5.4.3.5 Monochromatic Synthetic Aperture Radar Image Formation\nMonochromatic SAR image formation is based on a Taylor expansion of the phase of (5.155) around\nthe carrier frequency, i.e.,\n\nH\u00f0 fr; fa; r0\u00dezWant\n?\nfa\nBa\n\n?\n$PTx\u00f0 fr\u00de$exp\u00f0?j$fAC\u00de$exp\u00f0 ?j$2p$fr$tRCM\u00de$exp\u00f0?j$fSRC\u00de; (5.157)\n\n5.4 SYNTHETIC APERTURE RADAR 397\n\n\n\nwhere fSRC is a polynomial containing the higher-than-order-two terms of the expansion\n(SRC \u00bc secondary range compression). The different phase terms can be interpreted in the following\nmanner:\n\n\u2022 an azimuth compression phase, fAC, responsible for the modulation in azimuth of the echoes;\n\u2022 a range cell migration delay, tRCM, responsible for the spread of the phase center of the scattered\n\nechoes in the range-Doppler, domain;\n\u2022 a secondary range compression term,17 fSRC, which modifies the modulation of the received\n\nchirps for higher Dopplers.\n\nFor hyperbolic surveys, the expressions of the terms can be shown to be (Carrara et al., 1995;\nCurlander and McDonough, 1991; Cumming and Wong, 1979),\n\nfAC\u00f0 fa; r0\u00de \u00bc ?\n4p\n\nl\n$r0$\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1?\n\n?\nl$fa\n2$ve\n\n?2s\n;\n\ntRCM\u00f0 fa; r0\u00de \u00bc 2$r0\nc\n\n$\n\n\"\n1?\n\n?\nl$fa\n2$ve\n\n?2#?1=2\n;\n\nfSRC\u00f0 fa; r0\u00de \u00bc ?\n2p$v2e\nl$r0\n\n$\n\n\"\n1?\n\n?\nl$fa\n2$ve\n\n?2#?3=2\n$ f 2r \u00fe\n\nX\ni\n3\n\ngSRC\u00f0 fa; r0; i?$f ir .\n\n(5.158)\n\nThe range-Doppler algorithm is the standard SAR image formation monochromatic algorithm.\nDeveloped at the time of NASA/JPL\u2019s Seasat mission (Cumming and Bennett, 1979), the range-\nDoppler algorithm remains the most popular SAR image formation algorithm due to its simplicity\nand performance, which is acceptable for moderate to moderately high resolutions and swaths. A\nfurther advantage of range-Doppler is that it is capable of accommodating range-varying effective\nvelocities with good accuracy, something required for spaceborne SAR systems. In Fig. 5.90 the left\npanel shows the block diagram of the range-Doppler algorithm.\n\nAfter a 2-DDFT, the data are bulk focused to a reference range, usually in themiddle of the scene. The\nbulk focus accounts for an exact SRC and the range compression measurement (RCM) correction for the\nreference range.After bulk focusing, the data are brought into the range-Doppler domain,where a residual\nRCM correction (RCMC) is carried out. This RCMC is computed using an interpolation, which can be\ndone with arbitrary accuracy. After RCMC, the curvatures of the envelopes in the range-Doppler domain\nare straight, as shown in the figure. The last stage is the azimuth compression, which compensates the\nazimuthmodulation of the signal and restores the interferometric phase.After an inverseDFT, the image is\nfocused.\n\nThe primary error of the algorithm is due to the range-invariant SRC approximation, which\nbasically accounts for its monochromatic character. Of smaller order is the RCMC, which can be tuned\nwithin the limits of the Taylor approximation to any arbitrary accuracy. This RCMC is, however, the\ncomputational bottleneck of the algorithm. Typically, it reduces the efficiency by about 10% or 15%\n\n17The term secondary range compression is due to the historical expression of the term as fSRCzp$bSRC$f\n2\nr . In this case,\n\nthe chirp rate of the received echoes is clearly modified for higher Doppler frequencies.\n\n398 CHAPTER 5 RADAR\n\n\n\nwith respect to its interpolation-free version: the chirp scaling algorithm, whose block diagram is\nshown Fig. 5.90B.\n\nThe algorithm is a simplified version of the range-Doppler algorithm with the following\napproximations:\n\n\u2022 quadratic SRC, which means slight filter mismatch even at the reference range;\n\u2022 quadratic interpolation for RCMC using chirp signals (Papoulis, 1968);\n\u2022 phase-center correction of the scaling function.\n\nIn practical terms, however, the algorithm performs almost as well as range-Doppler in many cases\nwhere monochromatic approximation is acceptable.\n\nThe principle of the algorithm is to perform an equalization of the RCM for all ranges through chirp\nscaling, a multiplication in the range-Doppler domain with a phase function, as shown in the figure. In\nthe case of the linear-tracks model, this function can be approximated by\n\n4CS\u00f0 fa\u00de \u00bc p$br$\nbSRC\n\n?\nfa; r0;ref\n\n?\nbr \u00fe bSRC\n\n?\nfa; r0;ref\n\n?$\n2664tr ? 2$\n\n?\nr0 ? r0;ref\n\n?\nc$\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1?\n\n?\nl$fa\n2$ve\n\n?2s\n3775\n2\n\n; (5.159)\n\nwhere br is the chirp rate of the transmitted signal, and r0,ref is the reference range typically set as the\nmiddle of the swath. After chirp scaling, all ranges show the same RCM and it can be compensated for\nwithout the need of interpolation by multiplying by a linear phase in the range frequency domain. After\nthis, the azimuth compression is common in the flow of the range-Doppler algorithm, with a residual\nphase compensation step to correct for the effect of the previous scaling (Raney et al., 1994; Moreira\net al., 1996).\n\n2D-DFT\n\nRCMC\n\nRange-iDFT\n\nAzimuth-iDFT\n\nAzimuth-DFT\n\nRange-DFT\n\nAzimuth-iDFT\n\nRange-iDFT\n\n(A) (B)\n\nFIGURE 5.90\n\nBlock diagrams of the range-Doppler (A) and the chirp scaling (B) algorithms. DFT, discrete Fourier transform;\n\nRCMC, residual RCM correction.\n\n5.4 SYNTHETIC APERTURE RADAR 399\n\nmailto:Image of Figure 5.90|eps\n\n\n5.4.3.6 Polychromatic Synthetic Aperture Radar Image Formation\nAs already discussed, polychromatic SAR image formation reproduces the exact matching of the SAR\nimpulse response or matched filter over the entire available bandwidth. The most popular polychromatic\nalgorithms are range-migration, also known as Uk, in the wave number domain and FFBP in the time\ndomain. The block diagram of the algorithms is shown in Fig. 5.91.\n\n5.4.3.7 The Range-Migration Algorithm\nThe Uk algorithm was imported from geophysical imaging techniques in seismic applications by\nCafforio et al. (1991) and Milman (1993). The algorithm is based on an interpolation in the wave\nnumber domain, known as Stolt mapping, which transforms the spectrum of the raw data into the\nspectrum of the final image thus achieving wideband RCMC and SRC. The flow of the algorithm is\nshown on the left part of Fig. 5.89.\n\nFor linear tracks, the Stolt mapping takes the following form:ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\u00f0 fr \u00fe f0\u00de2 ?\n\n?\nc$fa\n2$ve\n\n?2s\n/ fr \u00fe f0; (5.160)\n\nwhich already hides the main weakness of its canonical version for spaceborne applications. The\ninterpolation is not able to accommodate the variation of ve with range in a precise manner. There are\nways to overcome this limitation for high-resolution or wide-swath cases in which a decomposition of\nthe SAR transfer function is achieved via a single-value approach. In terms of computational cost, Uk\nshows a similar behavior as range-Doppler, which as the Stolt interpolation is the computational\nbottleneck. If space-variant corrections are required, e.g., motion compensation, Uk typically requires\nadditional Fourier transformations with respect to range-Doppler, making it the less efficient of the\nclassical Fourier-based solutions.\n\n2D-DFT\n\n2D-iDFT\n\nStolt\nmapping\n\nStop split?\n\nDBP\n\nSplit data\n\nFFBP recursive \nkernel\n\nInterpolate \nsubimages\n\nFFBP recursive \nkernel\n\n(A) (B)\n\nFIGURE 5.91\n\nBlock diagrams of theUk (A) and the fast-factorized backprojection (FFBP) (B) algorithms.DFT, discrete Fourier\n\ntransform; DBP, direct backprojection.\n\n400 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.91|eps\n\n\n5.4.3.8 Fast-Factorized Backprojection\nThe FFBP algorithm can be seen as a time-domain counterpart of Uk. The algorithm possesses,\nhowever, a natural ability to accommodate any spatial variance in the sample (e.g., range-varying\neffective velocities or DC, motion compensation) without a significant modification of flow or\ncomputational efficiency. The price to pay is a larger computational burden than inUk due to the use of\n2-D (instead of 1-D) interpolations. The algorithm was developed for low-frequency SAR with large\nintegration times where very accurate motion compensation was required.\n\nAs depicted in the right panel of Fig. 5.91, FFBP is based on a divide and conquer approach\nanalogous to the butterfly FFT algorithm. The full aperture of the data is recursively split in two (or\nanother factor) until it reaches a sufficiently small number of pulses. The small subapertures are\nprocessed into coarse resolution images in a convenient polar geometry which minimizes the Nyquist\nsampling requirements. Once the images are computed, the algorithm goes back one step in recursion\nand computes a finer resolution image (e.g., twice the subaperture) through interpolation, as shown in\nFig. 5.91. The accommodation of the spatial variance is accommodated with finer resolution at every\nstep of recursion. At the final stage, the full-resolution images may be interpolated to the more natural\nradar coordinates.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY\nRadars measure the amplitude and delay of the backscattered echoes. As discussed earlier, the delay\ninformation is stored in the phase of the received signal with subwavelength accuracy. Unfortunately,\nthe ranging accuracy of the phase measurement can hardly be exploited in regular SAR images because it\nappears mixed with many other components of the measurement, in particular, with the phase pattern\nresulting from the coherent combination of the scatterers distributedwithin the resolution cell (as we have\nseen, in a uniformly distributed phase). All systematic components of the phase of the SAR images cancel\nout if themeasurement is performed differentially, e.g., by combining two SAR complex images acquired\nat different times or from different positions. This unique differential ranging potential of SAR systems,\nknown as SAR interferometry, yields access to a number of applications including 3-D realization,motion\ndetection, or vertical deformation monitoring.\n\nTo remove the geometrical phase caused by speckledand other systematic components of the\nmeasurementdwe need to access the differential phase of the two SAR images acquired from different\ntimes or from different positions. These two images are known as an interferometric pair, and their\ntemporal or geometrical spacing is called the baseline. The two images of the interferometric pair are\ntypically known as master and slave. A very deficient terminology, since both images are needed\nequally to generate the desired output. We will speak about first and second acquisitions. The two\nimages are combined as follows:\n\ni\u00f0r; x\u00de \u00bc s1\u00f0r; x\u00de$s?2\u00f0r; x\u00de; (5.161)\nwhere i is called the interferogram of images s1 and s2. If both individual observations are simultaneous,\nwe speak about single-pass interferometry. Single-pass interferometric systems are expensive since at\nleast two receive channels are needed, a very stringent requirement in space. The only two spaceborne\nsingle-pass interferometric SAR missions so far have required very sophisticated configurations: (1) the\nuse of a boom on the Space Shuttle Endeavour (e.g., SRTM) and a two-spacecraft constellation\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 401\n\n\n\n(e.g., TanDEM-X or COSMOSkyMed). The alternative to the two-receive channel payload is to have\nthe second image acquired by the same radar a number of orbit cycles afterward. This scenario is known\nas repeat-pass interferometry, which is of course affected by temporal changes in the imaged scene. A\ngeometric baseline in this case is naturally achieved by the tolerances in both the orbit control of the\nspacecraft and our knowledge of this orbit.\n\nThe phase of the interferogram is called the interferometric phase, i.e.,\n\nfi\u00f0r; x\u00de \u00bc :fig \u00bc :\n?\ns1\u00f0r; x\u00de$s?2\u00f0r; x\u00de\n\n?\n; (5.162)\n\nwhere the :f$g extracts the angle between 0 and 2p of the input complex number. As already\nhinted, the interferometric phase contains the subwavelength information of the differential ranging\nmeasurement between the two observations. However, it is not directly observable due to the\nwrapping of fi, which poses a major problem in the unambiguous recovery of the phase changes\ncaused by the different observation geometry. The wrapped (left) and unwrapped (right) phases of a\nTanDEM-X interferogram over the Atacama Desert, Chile, are presented here in Fig. 5.92.\n\nThe jumps between 0 and 2p, called fringes, typically correspond to areas of phase continuity,\nappearing wrapped in the interferometric phase in the left figure. In this case, the fringes represent the\nslopes (rather than sudden jumps) due to the topography of the scene. This continuity is shown in the\nright unwrapped interferometric phase of Fig. 5.92, where the color scale has been changed with\nrespect to the figure on the left.\n\nFIGURE 5.92\n\nWrapped (left) and unwrapped (right) interferometric phases of an interferometric pair acquired with TanDEM-X\n\nover the Atacama Desert, Chile.\n\nCourtesy of DLR.\n\n402 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.92|tif\n\n\n5.5.1 GEOMETRICAL MODELS\nAs already discussed, SAR interferometry is a differential ranging technique with subwavelength\naccuracy. Depending on the observation geometry, this property will allow for the estimation of\ndifferent magnitudes of the imaged scene, exemplified in the across-track cuts of Fig. 5.93.\n\nThe left panel of the figure shows the cross-track interferometric configuration for a stationary\nscene.The two images are acquired fromslightly different positionswith different observation angles. The\ntriangulation of the delays to the top of the TV tower from the two observation centers allows its locali-\nzation in space, i.e., the height information of the scene can be estimated.Thephase difference between the\ntwo images can be expressed as a function of the height of the scatterer in the following form:\n\nfi \u00bc m$\n2p\n\nl\n$\n?\nr0;2 ? r0;1\n\n?\n; (5.163)\n\nwhere m is a constant which describes whether the same transmitter path is shared by both\ninterferometric channels. If it is like a single-pass system, m \u00bc 1; if it is not and instead is similar to a\n\nFIGURE 5.93\n\nTypical configurations for synthetic aperture radar interferometry. The spacecraft are flying along an orbit normal\n\nto the page. The drawing on the left shows a stationary scene; the different ranges are due to the change in\n\nthe observation geometry. The drawing on the right shows the observation from a stationary position of a\n\nmoving scene.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 403\n\nmailto:Image of Figure 5.93|tif\n\n\nrepeat-pass system, m \u00bc 2; and in single-pass cases operated in ping-pong mode, the value of m is\nalso 2. Under the parallel-ray approximation,18 the differential range can be approximated as\n\nfizm$\n2p\n\nl\n$b$sin\u00f0a? ql\u00de; (5.164)\n\nwhere the last two terms are the projection of the baseline on the LOS, also called the parallel baseline.\nThe height of the scatterer can be straightforwardly computed as\n\nh \u00bc H$\u00f01? cos ql\u00de; (5.165)\n\nThe previous expression is accurate but rarely useful. In real systems, a true evaluation of the actual\nranges of the scene via geocoding/backgeocoding is preferable. For a fast analysis, however, the\nangular information in (5.164) is usually too detailed to be interpreted by eye. By further simplifying\nthe geometry of Fig. 5.93 to the flat-Earth approximation, we can express the interferometric phase as a\nfunction of the height of the scatterer as follows:\n\nfizm$\n2p\n\nl\n$\n\nbperp\nr0$sin qi\n\n$h; (5.166)\n\nwhere the bperp is the projection of the baseline perpendicular to the LOS, following the purple vector of\nFig. 5.93, qi is the incident angle, and h is the height of the scatterer. The sensitivity of the interferometric\nphase to topography can be straightforwardly computed from the previous expression, i.e.,\n\nvfi\n\nvh\nzm$\n\n2p\n\nl\n$\n\nbperp\nr0$sin qi\n\n; (5.167)\n\nwhere the bprepzb$cos\u00f0a? ql\u00de is the projection of the baseline perpendicular to the LOS, following the\npurple vector of Fig. 5.93, and qi is the incident angle. In the expression above, the simplification of the\ngeometry of Fig. 5.93 to the flat-Earth case has been implicitly made. From Eq. (5.167) it becomes\napparent that larger perpendicular (hence cross-track) baselines give more sensitivity to topographic\nchanges. The former statement is true, but limited by two other effects. With increasing cross-track\nbaselines (1) the quality of the phase of the interferogram degrades due to the increasing dissimilarity\nof the images (i.e., geometric decorrelation) and (2) the unwrapping of the interferometric phase\nbecomes more intricate due to an increase in the frequency of the fringes. As an example of the latter,\nFig. 5.94 shows two interferograms over the Turrialba volcano, Costa Rica, acquired by TanDEM-X in\nan experimental bistatic \u201cping-pong\u201d mode with an along-track separation of 20 km (Rodriguez-Cassola\net al., 2012).\n\nThe left interferogram corresponds to themonostatic (or full) baseline,whereas the right interferogram\ncorresponds to the bistatic (or half) baseline. Note the frequency of the fringes is reduced (about halved) in\nthe bistatic interferogram due to the shorter effective baseline of the acquisition.\n\n18The parallel-ray approximation is valid whenever the range is several orders of magnitude larger than the baseline, a\ntypical scenario in space borne SAR interferometric systems. Note the rays in Fig. 5.91 are not depicted parallel because\nof an intentioned distortion of the geometry for illustration purposes.\n\n404 CHAPTER 5 RADAR\n\n\n\nEq. (5.168) provides the solution to the linearization of the interferometric phase as a function of\nthe height h of the considered resolution cell, i.e.,\n\nfiz\nvfi\n\nvh\n$h \u00bc 2p$ h\n\nhamb\n\u00bc m$2p\n\nl\n$\n\nbperp\nr0$sin qi\n\n$h. (5.168)\n\nThe hamb, called the height of ambiguity, is a descriptor of any cross-track interferometric observation\nand approximates the topographic height, which causes a cyclic change in the interferometric phase. As\ncan be inferred from the previous discussion, the height of ambiguity is related to both the sensitivity of\nthe interferometer and the difficulty in unwrapping the phase. Higher values of hamb result in lesser\nsensitivity to topography and a reduced challenge in phase unwrapping and vice versa.\n\nIn the right panel of Fig. 5.94, the situation is inverted, and the two images are acquired from the\nsame position. In this case, the differential path is due to a motion of areas or targets within the scene.\nThe two images must be obviously acquired at different times if motion is to be captured. The\ninterferometric phase in this case can be expressed as\n\nfi \u00bc m$\n2p\n\nl\n$drLOS \u00bc m$2p\n\nl\n$vLOS$dt; (5.169)\n\nwhere drLOS is the displacement in LOS, vLOS can be interpreted as an equivalent radial velocity\ndescribing the motion of the scene as linear, and dt is the time interval between the two radar\nacquisitions, typically denoted as temporal baseline.\n\nFIGURE 5.94\n\nTanDEM-X monostatic (left) and bistatic (right) interferograms (over the corresponding reflectivity image)\n\nacquired in an experimental bistatic \u201cping-pong\u201d mode over the Turrialba volcano, Costa Rica (Rodriguez-\n\nCassola et al., 2012). Note the frequency of the topographic fringes is reduced in the bistatic interferogram due to\n\nthe reduced size (about half) of the effective baseline. The interferograms shown correspond to the first bistatic\n\ninterferometric acquisition of TanDEM-X.\n\nCourtesy of DLR.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 405\n\nmailto:Image of Figure 5.94|tif\n\n\nMoving targets (e.g., vehicles, ships, airplanes) or sea ice and ocean currents must be observed\nwithin short-time intervals up to a few seconds (and shorter), which typically require two (or more)\nantennas mounted on the same platform with an along-track separation between them. Such systems\nare obviously single-pass interferometers commonly described in the community as along-track\ninterferometric systems. In Fig. 5.95, we show an example of the detection and estimation of the\nvelocity of ships in the Strait of Gibraltar using along-track interferometry with TanDEM-X.\n\nAlong-track interferometry can also be used for the estimation of fast movements of natural surfaces.\nAs an example, Fig. 5.96 shows the estimation of the 2-D Doppler component, related to the wind, of the\nsea surface in the Arctic regions (Lopez-Dekker et al., 2014). The data are part of an experiment\nconducted with TanDEM-X in a bistatic, bidirectional (Bi-Di) mode (Mittermayer et al., 2013) to\nemulate the measurements suggested in Frasier and Camps (2001).\n\nA further example of the use of SAR interferometry for measuring motion is presented in Fig. 5.97.\nThe figure shows the interferometric signature of rotating sea ice in the Arctic regions as observed by\n\nFIGURE 5.95\n\nSingle-channel TerraSAR-X image over the Strait of Gibraltar. The ships in the image have been detected using\n\nalong-track synthetic aperture radar interferometry.\n\nCourtesy of DLR.\n\n406 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.95|tif\n\n\nTanDEM-X in ScanSAR pursuit monostatic mode with a temporal baseline of 3 s. The rotating ice\npieces show vertical fringes with spacing proportional to the velocity of rotation (Zebker and Rosen,\n1994). The nonrotating parts show conventional topographic fringes.\n\nSlowermotions such as those of glaciers, ice fields, or lava flows require time intervals of several hours\nor even several days and are typically observed by repeat passes of the same satellite. In repeat-pass\nscenarios, the cross-track baseline between acquisitions is usually nonzero, which adds an additional\n\nFIGURE 5.97\n\nRotating sea ice in the Arctic observed with TanDEM-X in ScanSAR pursuit monostatic mode with a temporal\n\nbaseline of roughly 3 s. Radar illumination is from the bottom. The rotating ice can be identified by vertical\n\nfringes, whose frequency is proportional to the rotational speed of the ice. The nonrotating ice (bottom and top\n\nareas) show the usual topographic fringes.\n\nCourtesy of DLR.\n\nFIGURE 5.96\n\nEstimated line-of-sight (LOS) Doppler velocity (top) and equivalent azimuth velocity (bottom). Positive LOS and\n\nazimuth velocities imply motions away from the radar and in the along-flight direction (i.e., right to left),\n\nrespectively.\n\nCourtesy of DLR.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 407\n\nmailto:Image of Figure 5.97|tif\nmailto:Image of Figure 5.96|tif\n\n\ntopographic component to the interferometric phase. This topographic component is a nuisance for the\nestimationofmotionwithin the images.A standard technique for the removal of the topographyconsists of\nusing two consecutive interferograms to form a differential interferogram in which the systematic\ntopography disappears. This principle is known in the literature as differential SAR interferometry,\nacronym DInSAR (e.g. Zebker and Rosen, 1994). In the cases of very slow motions such as terrain\nsubsidence, artificial structure deformations, seismic and volcanic activities, the observation time intervals\ntypically require days to years, andmore than two images of the scene should be available.A set of images\nto that will be combined in an interferometric manner is called an interferometric stack. The processing\nof an interferometric stack can exploit the information of several image pairs to derive very accurate\ninformation of the temporal evolution of the observed scene. Differential interferometry will be analyzed\nlater in greater detail.\n\n5.5.2 COHERENCE, EFFECTIVE NUMBER OF LOOKS, AND DECORRELATION SOURCES\nThe model of SAR interferometry discussed above implicitly assumes that s1 and s2 only differ in a\nphase term proportional to the ranging difference between the two observations. In reality, both the\ninstrument and the response of the scene to the two observations introduce further differences in the\ndata, which reduce the resemblance of the images and degrade the quality of the interferometric\nphase. A measurement of the similarity of the interferometric pair is given by the interferometric\ncoherence, essentially a local correlation factor of the image pair, which can be estimated in the\nfollowing manner:\n\ng \u00bc E\n?\ns1$s\n\n?\n2\n\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nE\nh\njs1j2\n\ni\n$E\nh\njs2j2\n\nir z\n\t\ns1$s\n\n?\n2\n\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiD\njs1j2\n\nE\n$\nD\njs2j2\n\nEr ; (5.170)\nwhere the mathematical expected values are approximated by spatial averages or any other averaging\nover a multiplicity of observations, an explicit acceptance of ergodicity.19 The magnitude of the\ncoherence approaches one when the variance of the interferometric phase is small, and tends to zero\nwhen it becomes large. If N independent samples are averaged, the variance of the estimation is\nnaturally reduced by a factor N. Multilooking interferograms is a standard procedure to improve the\nquality of the interferometric phase, at the expense of decreasing the geometrical resolution. Averaging\nover N samples only means a factor N improvement in the variance if samples are independent. Factors\nsuch as the spectral weighting or oversampling introduce correlation between samples, and the\neffective number of independent samples Ne may be smaller than N. The standard deviation of the\nestimate of the multilooked interferometric phase can be approximated as (Miller and Rochwarger,\n1972):\n\nsfz\n1\n\njgj$\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n1? jgj2\n2$Ne\n\ns\n; (5.171)\n\n19In the case of spatial averages, typically five to seven independent pixels are used.\n\n408 CHAPTER 5 RADAR\n\n\n\nwhich provides good estimates for values of Ne higher than four.\n20 The previous expression plotted\n\nagainst the interferometric coherence for different values of the effective number of looks is presented\nhere in Fig. 5.98.\n\nThe sources of decorrelation degrade the coherence of the scene and the quality of the interferometric\nmeasurement. If we assume that the useful signals are formed by the sum of two statistically independent\ncomponents, let us call them coherent and incoherent, respectively, the coherence can be expressed in the\nfollowing manner:\n\ng \u00bc E\u00bd\u00f0s1c \u00fe s1i\u00de$\u00f0s2c \u00fe s2i\u00de\n??ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\nE\nh\n\u00f0s1c \u00fe s1i\u00de2\n\ni\n$E\nh\n\u00f0s2c \u00fe s2i\u00de2\n\nir \u00bc E\n?\ns1c$s\n\n?\n2c\n\n\n$E\n?\ns1i$s\n\n?\n2i\n\n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nE\n?\ns21c\n\n$E\n?\ns22c\n\n$E\n?\ns21i\n\n$E\n?\ns22i\n\nq \u00bc gc$gi; (5.172)\n\nwhere the subscripts c and i represent the coherent and incoherent components of the images, and by\nconstruction E\n\n?\ns$c$s\n\n?\n$i\n\n\n \u00bc E?s$i$s?$c\n \u00bc 0. Note the coherence in this case can be expressed as a\nproduct of coherent and incoherent components. The term jgij; always smaller than one, can be seen as\na source of decorrelation, which degrades the coherence of the interferometric pair. Analogously, we\ncan write the interferometric coherence as the product of several decorrelation factors in the following\nmanner:\n\ngzgSNR$gamb$gproc$ggeo$gtemp; (5.173)\n\nFIGURE 5.98\n\nApproximation of the Crame?reRao bound given by Eq. (5.171) of the phase estimator as a function of the\n\ninterferometric coherence for different number of effective looks.\n\n20The exact expression can be numerically computed using the pdf of the phase estimator as discussed in Oppenheim and\nSchafer (1975).\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 409\n\nmailto:Image of Figure 5.98|tif\n\n\nwhere the separation of the contributions is linked to different physical sources (Bamler and Hartl,\n1998). The suffixes describe the effects of noise, ambiguities, processing errors, as well as geometrical\nand temporal changes.\n\nThe first obvious cause of decorrelation is noise, which is independent in the two images. Its main\ncontributor is the thermal noise of the receiver. A smaller contribution is due to quantization noise,\nmainly caused by different effective dynamic ranges, DC bias and the nonlinearity of the ADC, and\ndata compression distortions. Under the assumption of identical SNRs for s1 and s2, the value of the\nSNR decorrelation term can be approximated as follows:\n\ngSNR z\nSNR\n\n1\u00fe SNR ; (5.174)\n\nwhere the SNR may include additional contributions than those above described earlier.21\n\nThe second term in Eq. (5.173) describes the impact of range and azimuth ambiguities. Provided they\nare not coherent in the two images,22 ambiguities appear uncorrelated in the interferogram. In these\ncircumstances, they have a similar effect to noise, and the decorrelation factor can be approximated\nlikewise as\n\ngambz\n1\n\n1\u00fe TASR ; (5.175)\n\nwhere again a similar TASR for both observations has been assumed.\nThe third source of decorrelation listed above is processing, which accounts for phase and localization\n\nerrors introduced in the interferometric processing. In airborne SAR, decorrelation due to processingmay\nbe caused by significant residual motion errors of the platform. In spaceborne missions, processing errors\narise from coregistration errors induced by errors in pointing, orbit knowledge, and the topographic\ninformation of the scene. For a homogeneous scene, coregistration errors introduce a decorrelation factor\napproximated by (Zebker and Villasenor, 1992)\n\ngprocz sinc\n\n?\nDrproc\ndr\n\n?\n$sinc\n\n?\nDxproc\ndx\n\n?\n; (5.176)\n\nwhere Drproc and Dxproc are the range and azimuth coregistration errors introduced during processing,\nrespectively, and no weighting of the images has been assumed.\n\nThe fourth term in Eq. (5.173) describes the impact of the change of the observation geometry, which\nresults in a different result of the coherent superposition of the scatterers on ground. This geometric\ndecorrelation factor can be decomposed in two surface and one purely volumetric components (Moreira\net al., 2013), i.e.,\n\nggeo \u00bc gr$gD$gvol; (5.177)\n\n21In the case the SNR of the two images is different, the value of gSNR can be straightforwardly derived from (5.172) as\n\ngSNRz\u00bd 1\u00fe SNR?11\n? ?\n\n$ 1\u00fe SNR?12\n? ???1=2, which collapses to (5.174) when SNR1 \u00bc SNR2 (Kay, 1993).\n\n22Azimuth ambiguities might be correlated if the PRF and the pointing of the acquisition is the same, and the baseline is\nsmall, but decorrelate rapidly resulting in small changes in the PRF.\n\n410 CHAPTER 5 RADAR\n\n\n\nwhere the subscripts r, D, and vol stand for range, Doppler, and volume, respectively. Neglecting the\ninstantaneous Doppler scaling, the carrier wavelength of the radar gets projected onto the different\ngeometrical resolution dimensions of the SAR images. The received echoes can be interpreted as the\nsample of the scene spectrum in the projected wave number (Gatelli et al., 1994). In elevation, the\ndifference between the projected wave numbers of the interferometric pair is known as spectral shift\n(Gatelli et al., 1994), which can be approximated by\n\nDkr \u00bc 2p\nl\n$\n\n?\n1\n\nsin qi1\n? 1\nsin qi2\n\n?\n; (5.178)\n\nwhere kr is the range wave number, and the angles qi1 and qi2 refer to the local incident angle for the\nconsidered pixel. The previous expression can be interpreted as a shift in the range frequency domain\nof the form\n\nDBr \u00bc c$Dkr\n2p\n\n; (5.179)\n\nwhich typically becomes larger for larger (perpendicular) baselines and defines the portion of the\nspectrum appearing as noise in the interferogram. Having exact knowledge of the observation geometry,\nthe decorrelation factor of the spectral shift can be kept at one by filtering the common part with a band-\npass filter, at the expense of reducing the spatial resolution of the interferogram. The Doppler term is\nanalogous to the spectral shift, only in the azimuth plane, where the wave number shift due to two\ndifferent squint angles qsq1 and qsq2 is\n\nDka \u00bc 4p\nl\n$\u00f0sin qsq2 ? sin qsq1\u00de; (5.180)\n\nwhere ka is the azimuth wave number, and the 4p is due to the two-way propagation of the signal.\nAgain, this expression can be scaled in the frequency domain, yielding the difference between the DCs\nof the two acquisitions. As in the case of the spectral shift, the Doppler decorrelation term can be set to\nonedwithin the pointing accuracy of the systemdby common band filtering of the spectral support, at\nthe expense of reducing the available resolution of the resulting interferograms. In the case of\nScanSAR and TOPS interferometry, with an azimuth-varying DC and typically small Doppler support,\nthe orbit control and the pointing accuracy of the system need be controlled very tightly, since any\nerror in the long-track position of the data-take results in spectral decorrelation of the interferometric\npairs.\n\nThe volumetric decorrelation is due to the change in the signatures of volumetric structures when\nimaged from different observation angles (Kay, 1993). Volumetric decorrelation increases with the\npenetration into the media and with increasing cross-track baselines. Volumetric decorrelation cannot\nbe neutralized through processing and can only be minimized by carefully choosing (typically\nreducing) the baseline of the acquisition. To illustrate the impact of volume decorrelation in the pursuit\nmonostatic and one single-pass bistatic acquisitions, Fig. 5.99 presents an example acquired with\nTanDEM-X during its pursuit monostatic commissioning phase in a forest area North of Turrialba\nvolcano, Costa Rica.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 411\n\n\n\nThe image corresponds to the first bistatic interferometric acquisition of the mission, in which\nsimultaneously full-baseline (m \u00bc 2) pursuit monostatic and half-baseline (m \u00bc 1) interferograms\nwere acquired (Rodriguez-Cassola et al., 2012). The figure shows the reflectivity image (left) and\ninterferometric coherences (middle-pursuit monostatic; right-single-pass bistatic). The forested area in\nthe middle of the crop shows a lower coherence in the middle crop (pursuit monostatic, full-baseline)\ndue to volumetric decorrelation.\n\nThe last decorrelation term of (5.173) is due to temporal effects. Temporal decorrelation is caused by\nthe dynamics of the scene with time, due to changes in the structure, motion, or the dielectric properties\nof the scene (Zebker and Villasenor, 1992). Temporal decorrelation poses a fundamental limit to\ninterferometry using repeat passes and can only be minimized by minimizing the temporal baseline\nbetween the acquisitions. As in the case of the geometric decorrelation, temporal decorrelation\nalso scales with the carrier frequency, affecting more the shorter wavelengths. Although temporal\n\nFIGURE 5.99\n\nForest area North of Turrialba volcano, Costa Rica, as acquired in the first bistatic interferometric acquisition of\n\nTanDEM-X during its pursuit monostatic commissioning phase (Rodriguez-Cassola et al., 2012). Radar illumination\n\nfrom the left. The left plot shows the bistatic intensity image of the area. The middle and right plots show the pursuit\n\nmonostatic (m \u00bc 2) and single-pass bistatic (m \u00bc 1) interferometric coherences, respectively. Note the decrease in\nthe coherence of the middle crop with respect to the right crop, caused by volumetric decorrelation.\n\nCourtesy of DLR.\n\n412 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.99|tif\n\n\ndecorrelation is in many cases seen as noise in the interferometric measurement, it may also give\nvaluable information as the signature of a physical change. A series of interferograms computed with\ntemporal baselines ranging from 1 to 13 days using L-band data acquired by DLR airborne E-SAR\nsystems are shown in Fig. 5.100. Note the coherence decreases for increasing temporal baselines as\nexpected.\n\n5.5.3 INTERFEROMETRIC PROCESSING\nThe block diagram of an interferometric SAR processor taking the observation geometry of s1 as a\nreference is shown in Fig. 5.101.\n\nThe first step of the flow is the coregistration of image s2 in the geometry of s1, a step typically done in\nboth airborne and spaceborne systems using the trajectories, timing values, and an external topographic\nmap of the scene (e.g., SRTM) (Sansosti et al., 2007). Fig. 5.102 shows an airborne bistatic cross-\nplatform interferometric pair before (left) and after (right) coregistration.\n\nThe red represents the monostatic SAR image acquired by DLR\u2019s E-SAR system over Garonnes,\nFrance. The blue and green represent the bistatic channel acquired by ONERA\u2019s RAMSES. Note the\npixels of both images coincide after coregistration.\n\nThe second step is the band-pass filtering of both images to the common range and azimuth bands of\nthe scene, to reduce the spectral decorrelation, i.e., gr$gD/1, and hence increase the overall coherence.\n\nFIGURE 5.100\n\nInterferometric coherence computed with L-band repeat-pass interferograms for temporal baselines between 1\n\nand 13 days over Traunstein, Germany. The data have been acquired with DLR airborne E-SAR system.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 413\n\nmailto:Image of Figure 5.100|tif\n\n\nAfter this, the interferogram is computed. As hinted earlier, the resolution of the interferogram is now\nproportional to the common bandwidth of the observation. The next step is typically the removal of a\nsynthetic phase component computed with whichever a priori information we may have on the scene.\nIn the case of a cross-track interferometric acquisition, flattening typically consists of removing the\n\nFIGURE 5.102\n\nAirborne bistatic cross-platform synthetic aperture radar (SAR) interferometric pair over Garonnes, France,\n\nbefore (left) and after (right) coregistration. The red channel shows the monostatic SAR image acquired by DLR\u2019s\n\nE-SAR system, whereas the blue and green channels show the bistatic image acquired by ONERA\u2019s RAMSES.\n\nThe darker areas are due to echo power fading caused by abrupt antenna deviations caused by turbulence during\n\nthe data collection flight (Dubois-Fernandez et al., 2005).\n\nCoregistration\n\nFlattening\n\nBPF\n\nMultilook\n\nBPF\n\nUnwrapping\n\nArg\n\nFIGURE 5.101\n\nBlock diagram of a synthetic aperture radar interferometric processor in the reference observation geometry of s1.\n\nBPF, band-pass filter.\n\n414 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.102|tif\nmailto:Image of Figure 5.101|eps\n\n\ninterferometric phase expected from the ellipsoid or the available DEM.23 Two interferograms computed\nwith a TanDEM-X interferometric pair over the desert of Atacama, Chile, can be found in Fig. 5.103.\n\nThe periodic fringes of the left interferogram are the ellipsoidal fringes caused by the increase of\nlook angle within the swath. The topographic fringes appear on top of them, typically visible to the\ntrained eye. The right interferogram shows the topographic fringes after removal of the ellipsoidal (flat\nEarth) synthetic phase. As shown in the figure, the removal of the synthetic phase usually reduces the\nfrequency of the fringes, hence simplifying subsequent averaging and phase unwrapping.\n\nOnce flattened, the interferogram is \u201cmultilooked\u201d to the desired averaging factor. As already\ndiscussed, multilooking consists of a low-pass filtering followed by a downsampling to accommodate\nthe final bandwidth of the resulting interferograms. The low-pass filtering stage can be done either in\n\nFIGURE 5.103\n\nInterferometric fringes computed with a TanDEM-X interferometric pair over the Atacama Desert in Chile. Radar\n\nillumination is from the left. The left interferogram shows the flat-Earth fringes along the range dimension. The\n\nright interferogram shows the fringes with the topographic information of the scene after removal of the flat-Earth\n\nfringes. The remaining fringes show the topographical information in Atacama.\n\nCourtesy of DLR.\n\n23This step has been typically known in the community as (flat) Earth removal. The term flat Earth obviously refers to the\nremoval of the fringes introduced by the Earth\u2019s ellipsoid and can be extensively used to describe the removal of any a priori\nexpected interferometric phase.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 415\n\nmailto:Image of Figure 5.103|tif\n\n\nthe time or in the frequency domain. The step prior to unwrapping is the computation of the phase of\nthe interferogram as shown in (5.162). After this operation, the interferometric phase is wrapped in a\n2p interval.\n\nPhase unwrapping consists of finding the most likely solution to a matrix of multiples of 2p\nvarying for every pixel of the interferogram. Spatial continuity and energy preservation can be\nimposed on the solution, but it is in general an ill-conditioned problem. From vector field theory, the\nsolution must fulfill the following condition:\n\nV? Vfi \u00bc 0; (5.181)\nwhere fi represents the unwrapped phase of the interferogram. The most popular phase unwrapping\nalgorithms are branch-cut, region growing, and least squares estimation. Errors in unwrapping typically\noccur due to the high frequency of the fringes, due to low SNR, or to spatial discontinuities in the\ninterferogram. An example of the latter is shown in Fig. 5.104.\n\nFig. 5.104 shows three interferograms generated from F-SAR airborne data over Jade Bight,\nGermany. The top and bottom interferograms show the wrapped and correctly unwrapped phases. The\ninterferogram in the middle shows an unwrapping error on the left side. The unwrapping algorithm\n(in this case of the region growing class) has failed to ensure the spatial continuity of the phase due to\nthe diagonal water structure in the middle of the interferogram. Unwrapping errors can be identified\nand corrected with the help of redundancy, i.e., a second (or more) observation(s) of the same inter-\nferometric phase with different sensitivity, be it baselines or wavelengths (Kay, 1993). With enough\ndifference in sensitivity, phase jumps will distribute spatially in a different manner, which provides\n\nFIGURE 5.104\n\nWrapped (top) and unwrapped (bottom) interferometric phases of an interferometric pair acquired with the\n\nairborne F-SAR system of DLR over the Jade Bight, Germany. The middle figure shows an unwrapping error on\n\nthe left of the image, where the phase continuity at both sides of the river is not maintained.\n\nCourtesy of DLR.\n\n416 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.104|tif\n\n\nreliable information for robust estimation. The unwrapping error in Fig. 5.104 (middle plot) has been\ndetected and corrected with the help of a dual-frequency, dual-baseline technique.\n\n5.5.4 DIFFERENTIAL SYNTHETIC APERTURE RADAR INTERFEROMETRY\nAs already discussed, the interferometric phase between two SAR images acquired at different times\nencompasses information about the dynamics of the scene itself. The general approach of DInSARwill\nbe the combination of the two effects described in Fig. 5.93, and the interferometric phase will have\ncontributions from any difference in the observation of the scene, be it cross-track baseline or motion\nwithin the scene. Without loss of generality, the interferometric phase of any repeat-pass acquisition\ncan be expressed as the sum of a topographic and a differential component, i.e.,\n\nfi \u00bc ftopo \u00fe fdiff ; (5.182)\nwhere the topographic component will increase for increasing cross-track baselines, and the differential\ncomponent will account for any dynamic change in the observation. In the simplified model of Fig. 5.93,\nthe differential phase was entirely attributed to displacements of the scene. This is hardly the case in\nreality, and even under error-free calibration, unwrapping, and topography removal, the differential\ninterferometric phase is contaminated by atmospheric propagation and noise, i.e.,\n\nfdiff \u00bc fdisp \u00fe fatm \u00fe n; (5.183)\nwhere n is a phase noise process. The atmospheric term is due to uncompensated delays and defocusing\nintroduced by the propagation of the radar waves through the ionosphere and the troposphere. As already\ndiscussed, the troposphere tends to affect shorter wavelengths (typically from C-band and above).\nResidual atmospheric fringes are typically caused by changes in the local water vapor pressure of the\nlayer, which introduces residual delays in the centimetric scale. For lower-frequency bands (e.g.,\nL and P bands), changes in the TEC introduce typical delays in the centimeter scale and high-frequent\nvariations within the aperture during scintillations, which may account for further atmospheric phase\ncomponents.\n\nTo illustrate the previous discussion, Fig. 5.105 shows repeat-pass interferometry over Mexico City\nusing two Sentinel-1 images with a temporal separation of about 6 months from August 2015 to April\n2016. All images are geocoded and the vertical component of the bottom interferograms corresponds\nto the north direction. Note the top images are rotated 90? with respect to the bottom ones.\n\nThe two top images show the reflectivity of the scene (left) and interferometric coherence (right). The\nbottom images correspond to the repeat-pass interferogram (left) and the differential interferogram\n(right) after subtraction of the topographic fringes estimated using the SRTMmodel. Note the areas with\nlow coherence (darker) correspond to noisier fringes in the interferograms. When comparing the two\ninterferograms, one can readily identify most of the topographic signature disappearing in the center, left\npart, and bottom of the images. Most of the remaining (low-pass) fringes are due to changes in the water\nvapor of the troposphere between the two acquisitions. The band-pass fringes at the top of the inter-\nferogram are due to subsidence caused by water extraction in Mexico City.\n\nAnother example of the applications of DInSAR is shown in Fig. 5.106.\nThe image shows the fringes caused by the Illapel earthquake of September 16, 2015, Chile, as seen\n\nby Sentinel-1 images. The images were acquired in August and September of 2015. The top area of the\nimage depicting the Pacific coast, where the epicenter of the earthquake was located, appears as noise\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 417\n\n\n\nin the interferogram. The interferometric fringes appear roughly centered around the epicenter of the\nearthquake, located at about 46 km offshore of Illapel.\n\nThe differential interferometric fringes follow the displacement measured in the LOS of the radar. If\nseveral acquisitions with different lines of sight are used, the different projections of the displacements\ncan be used to estimate more than one component of the motion of the scene. The situation is illustrated\nin Fig. 5.107 for the cases of one (left) and two (right) lines of sight, respectively.\n\nFIGURE 5.105\n\nRepeat-pass interferometric acquisitions overMexicoCity observed by Sentinel-1. The north direction corresponds to\n\nthe vertical axis of the interferograms (bottom). The top images, representing the reflectivity (left) and interferometric\n\ncoherence (right) are rotated 90? with respect to the interferograms to save space. The bottom images show the repeat-\npass (left) and differential (right) interferograms showing the different contributions of the interferometric phase. The\n\nlow-pass fringes in the differential interferogram correspond to the differential tropospheric delays. The high-pass\n\nfringes at the top of the interferogramare caused by subsidence inMexicoCity caused bywater extraction. The repeat-\n\npass interferogram shows the topographic fringes in addition to the atmospheric and subsidence components.\n\n418 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.105|tif\n\n\nThe accuracy of the estimation of the 2-D components will depend on the accuracy of the differential\ninterferometric phase, the thermal and atmospheric noise variance, and the angle between the LOS\nvectors. The closer they are to being orthogonal, the less noise scaling occurs during the inversion.24\n\nThe two different LOSs can be realized in many different ways, the most common being the use of\n\nFIGURE 5.106\n\nGeocoded differential interferogram computed using two Sentinel-1 acquisitions in the vicinity of Illapel, Chile.\n\nThe horizontal dimension from left to right shows the north direction of the scene. The fringes are due to the\n\ndeformation caused by the earthquake occurred in September 16, 2015. The geometric disposition of the\n\ninterferometric fringes shows the epicenter of the earthquake.\n\nAlong-track\n\nDisplacement\nDisplacement\n\nin LOS\n\nAlong-track\n\nDisplacement\nDisplacement\n\nin LOS1\n\nDisplacement\nin LOS2\n\nFIGURE 5.107\n\nLine-of-sight (LOS) displacements as measured in two cases. In the second LOS case (right), 2-D displacements\n\nwithin the scene can be estimated. The accuracy of the estimation will depend on signal-to-noise ratio, the\n\nvariance of the atmospheric perturbations, and the angular separation between the LOS.\n\n24The estimation of the displacement is done on the equivalent slant range planes of the acquisitions. The angle of incidence\ncan be used to further decompose the motion in ground (e.g., northing and easting) and vertical components.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 419\n\nmailto:Image of Figure 5.106|tif\nmailto:Image of Figure 5.107|eps\n\n\nascending and descending passes, left and right looking acquisitions, diversity in squint, or along-track\nseparation in bistatic acquisitions.\n\nFig. 5.108 shows an example of the measurement of the 2-D displacement caused by the Central\nItaly Earthquake in August 2016 computed using differential interferometry with ascending (top row)\nand descending (middle row) passes of Sentinel-1 over the Accumoli area.\n\nFIGURE 5.108\n\n2-D displacement measurements (easting bottom left, northing bottom right) caused by the Central Italy\n\nearthquake of August 2016 using differential interferometry with ascending (top) and descending (mid) passes\n\nof Sentinel-1. The first two rows show the reflectivity images (left), differential interferograms (center), and\n\nline-of-sight displacements (right).\n\n420 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.108|tif\n\n\nAll images are geocoded, with the vertical dimension oriented towards the north. The images of the\nfirst two rows correspond to the radar reflectivity (left), differential interferograms (center), and LOS\ndisplacements (right) for the ascending (top) and descending (mid) passes, respectively. The bottom\nimages correspond to the 2-D displacement measurements, eastward (left) and northward (right),\ninverted using the information of the two passes. As expected from the configuration, the sensitivity in\nthe eastward measurement is significantly better due to the high inclination of the Sentinel-1 orbit.\n\nSensitive to deformations on the order of the wavelength, DInSAR can also be used to detect\nchanges in the dielectrical properties of volumes via changes in the phase center of the return of the\nvolumes. An example of this is the model for the relationship between the differential interferometric\nphase and the differential moisture of the soil. These changes can also be due to changes in the humidity\nof forests, in the structure of snow and ice. Such an example is presented here in Fig. 5.109, which is a\ndifferential interferometric measurement of differential moisture donewith DLR E-SAR system over the\nDemmin region, Germany.\n\nThe left figure shows an L band differential interferogram of the area. The right figure shows the re-\nsidual phase (i.e., closure phase) after combining the interferograms generated with three images\nacquired at different weeks in the year. The combination was done in such a way as to expect a zero phase\nfor unchanged terrain.The red and blue areas of the right figure showchanges in themoisture of the terrain.\n\nDInSAR has been extensively used for over two decades for observing strong deformation signatures\nsuch as landslides, volcanic eruptions, or earthquakes. However, as illustrated in the previous figures,\nerrors in the removal of the topographic and atmospheric information limit the accuracy of DInSARwith\nonly two images. The effects contaminating the DInSARmeasurement, e.g., atmospheric influences and\nDEM errors, can be estimated if a large stack of interferograms is available. The basic idea is that the\natmospheric phase errors are expected to be uncorrelated between consecutive passes and will be\naveraged out if a large number of acquisitions are combined.\n\nStack-based DInSAR is an analysis of areas that remain coherent through the stack. Depending on\nthe content of the scene, the use of point-like targets or distributed areas will be used. The former are\nparticularly prevalent in urban areas. Another target may be very stable natural surfaces (e.g., rocky\nareas). The persistent scatterers (PS) technique allows for a full-resolution amplitude-based detection\n\nFIGURE 5.109\n\nDifferential interferometric phase (left) and closure phase (right).\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 421\n\nmailto:Image of Figure 5.109|tif\n\n\nof these targets. Distributed areas are typically detected using interferometric coherence, which\naverage adds to the robustness of the detection at the expense of reducing the geometrical resolution of\nthe areas (Franceschetti and Lanari, 1999; Graham, 1974). A combination of both amplitude and\ncoherence-based detections, as suggested in Barnes et al. (1971), may extend the area where the\nmeasurements can be effected. The subsequent unwrapping of the phase of the detected areas helps\nidentify false alarms. This unwrapping is effected on a 3-D sparse grid (i.e., azimuth, range, time) and\ncan be addressed as the 2-D unwrapping of every sparse interferogram (Basu and Bresler, 2000;\nFranceschetti and Lanari, 1999), using phase difference between the coherent areas as in Graham\n(1974) and Bauck and Jenkins, (1989), or with help of 3-D unwrapping techniques as in Bleistein and\nHandelsmann (1975) and Braubach and Voelker (2007). Once the differential unwrapped phase is\navailable, the different components of the differential phase can be estimated in a pixel-wise manner,\nyielding values for the error of the DEM, the atmospheric phase screen, and the linear and nonlinear\ncomponents of the deformation. The example in Fig. 5.110 shows the geocoded mean deformation\nvelocity map obtained with 45 Sentinel-1 images acquired from October 3, 2014 until May 1, 2016 over\nMexico City using the PS technique. The deformation pattern is caused by ground water extraction.\n\n5.5.5 SYNTHETIC APERTURE RADAR TOMOGRAPHY\nThe model of 3-D localization presented in Fig. 5.111 implicitly assumes that there exists only one\nscatterer within a resolution cell. This is typically not the case in surface areas with layover (e.g., urban\nareas) or volumetric areas with semitransparent media such as forests, snow areas, and ice sheets.\n\nFIGURE 5.110\n\nGeocoded mean deformation velocity map obtained with 45 Sentinel-1 images acquired from October 3, 2014\n\nuntil May 1, 2016 over Mexico City using the persistent scatterers technique. The vertical dimension corresponds\n\nto the northing of the image.\n\n422 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.110|tif\n\n\nIn these cases, several scatterers are usually present in the resolution cells as depicted in Fig. 5.111, and\nthe interferometric phase is the result of a weighted mean height of the scatterers within the slant\nrange resolution cell.\n\nThis limitation can be overcome by using different passes over the same area to build a synthetic\naperture in elevation achieving resolution within the slant range resolution cell following the direction\nof re, as shown in Fig. 5.111. Assuming the maximum cross-track baseline in the tomographic aperture\nis be, the resolution in elevation gained via tomographic SAR processing is (Evans et al., 2005; Ender\net al., 2006)\n\ndrez r0$qez\nl$r0\n2$be\n\n; (5.184)\n\nwhere again the factor of 2 is due to the two-way propagation path of the SAR signals. As expected, the\ntomographic resolution improveswith increasing cross-trackbaselines,which should typically takevalues\none to two orders ofmagnitude smaller than the orbit height to yield resolutions of a fewmeters. Projected\nonto the vertical direction, the vertical resolution of the tomographic SAR can be approximated by\n\ndhz\nl$r0\n\n2$be$cos qi\n. (5.185)\n\nThe minimum value of the cross-track baseline between passes defines the sampling of the\ntomographic aperture. To fulfill Nyquist, the minimum cross-track baseline between passes shall be\nsmaller than the following value (Evans et al., 2005; Ender et al., 2006):\n\nbmin ? l$r0\n2$hV$cos qi\n\n; (5.186)\n\nFIGURE 5.111\n\nGeometrical model of a tomographic synthetic aperture radar acquisition. Resolution along re is achieved via\n\nconstruction of the tomographic aperture. Height resolution is the projection of dre onto the vertical direction.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 423\n\nmailto:Image of Figure 5.111|tif\n\n\nwhere hV is the maximum expected height of the scene. If the true maximum height exceeds the value\nof hV, aliasing will occur. On the other hand, a conservative value of hV results in expensive over-\nsampling of the tomographic aperture. In the frame of SAR tomography, a better resolution implies\nmore passes, hence increasing the complexity of the whole acquisition geometry if a cubic volume\nresolution is to be obtained without undesired artifacts.\n\nAs an example, the first experimental demonstration of SAR tomography (Ender et al., 2006) used\n13 passes with an equidistant separation of 20 m, reaching a resolution in elevation of 2.9 m at\nmidrange. The data were acquired in 1998 by DLR\u2019s airborne SAR system E-SAR. Some of the\nresulting tomograms are shown in Fig. 5.112.\n\nThese tomograms have been computed using four different processing methods: Fourier or matched\nfilter (top left), Capon (top right), MUSIC with the assumption of one scatterer in the resolution cell\n(bottom left), and MUSIC with the assumption of five scatterers in the resolution cell (bottom right). The\ntomograms show a forest area on the left, followed by a building (whose roof appears as a horizontal line\nin all four cases, and a surface area including one corner reflector to the right of the building. The\nmatched filter approach has a limited resolution and strong side lobe contributions.\n\nFIGURE 5.112\n\nDLR airborne E-SAR tomograms over Oberpfaffenhofen, Germany. The plots show the results of four different\n\ntomographic imaging techniques, e.g., matched filter or Fourier (top left), Capon, (top right), MUSIC with the\n\nassumption of a single scatterer in the resolution cell (bottom left), and MUSIC with the assumption of five\n\nscatterers in the resolution cell (bottom right). As expected, the superresolution approaches exhibit improved\n\nresolution and reduced side lobes, at the expense of a less predictable energy distribution.\n\nCourtesy of DLR.\n\n424 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.112|tif\n\n\nIn Fig. 5.113, we present a tomogram with some optical images of the targets being captured in the\ntomogram.\n\nIn the use of state-of-the-art missions to generate tomography, especially of urban areas, super-\nresolution approaches like Capon, MUSIC, and compressive sensing may benefit from a multidi-\nmensional signal framed in the sparse information paradigm (Aguttes, 2003; Attema, 1991).\n\nAll threemethods are super-resolution approaches: Capon is nonparametric andMUSIC is parametric,\nwhich causes the results to be sensitive to the models assumed at the focusing stages. As an example, the\nbuilding, the surface, and the corner reflector appear better focused in the bottom left tomogram, whereas\nthe forest appears better characterized by the bottom right tomogram.\n\nAlso, both Capon and MUSIC require the estimation of the covariance matrix, implying a resolution\nloss due to the averaging operation. On the other hand, compressive sensing (CS) works at full resolution\nand can reconstruct nonuniformly sampled sparse signals, the latter meaning that the elevation profile to\nbe estimated must be discrete. If the signal of interest is indeed sparse, the CS theory guarantees the\npossibility to obtain it at a rate significantly below the Nyquist (Moreira et al., 1996).\n\nThe use of CS in the frame of urban monitoring in combination with PS has been a topic of research\nin recent years. Indeed, differential SAR tomography (Cantalloube and Koeniguer, 2008) allows the\ndiscrimination of multiple scatterers in layover, e.g., ground and building facades, and at the same time\nthe retrieval of their respective deformation velocities. These approaches have been mainly exploited\nusing current high-resolution spaceborne sensors (e.g. Horn, 1996), becoming a powerful tool for\nurban monitoring (Fig. 5.114). However, in the frame of forest monitoring, CS as such does not apply\n\nFIGURE 5.113\n\nA tomogram containing different realizations of a covered truck either from the side or from the front. The truck\n\nshows the proper orientation in the optical images.\n\nCourtesy of DLR.\n\n5.5 SYNTHETIC APERTURE RADAR INTERFEROMETRY 425\n\nmailto:Image of Figure 5.113|tif\n\n\nas well, as the elevation profile is indeed not sparse on the Fourier basis. One possible solution is to\nmake use of a wavelet transform to obtain a sparse representation of the vertical structures, hence\nallowing the use of CS also for the imaging of forested areas.\n\nOne of the most appealing applications of SAR tomography is the imaging of volumetric structures,\nsuch as forests or ice. Typically, lower frequencies appear to be particularly well suited due to their\npenetration capabilities. The following two figures show two tomographic examples with DLR\u2019s\nairborne system F-SAR. Fig. 5.115 shows two tomograms in P (top) and L (bottom) bands computed\nwith 10 baselines in a forest area over Lope?, Gabon.\n\nFIGURE 5.114\n\nThree-dimensional absolutely positioned TomoSAR point clouds in 3-D (top) and 2-D (bottom). The absolute\n\nheight values are color-coded and range between 70 m and 110 m. Clearly, the fusion of multitrack point clouds\n\nallow for a very detailed representation of the city where most of the structures can be easily recognized.\n\nFIGURE 5.115\n\nP-band (top) and L-band (bottom) tomograms acquired with DLR airborne F-SAR system in a forest area close to\n\nLope, Gabon. Note the P-band tomogram shows more bottom signature due to the higher penetration of the radar\n\nwaves.\n\nCourtesy of DLR.\n\n426 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.114|tif\nmailto:Image of Figure 5.115|tif\n\n\nThe structure of the forest is clearly recognizable, with a more transparent signature in P band than\nin L band, supported by the stronger contribution of the ground.\n\nBy combining circular SAR with a tomographic aperture, as shown in the left plot of Fig. 5.116, the\npossibility of combining tomographic imaging with the multiangular observation of circular SAR\nallows for holographic SAR. The image on the right of Fig. 5.116 shows a holographic SAR image of a\nforest acquired at L band by DLR\u2019s airborne F-SAR system as the result of the coherent combination of\ndifferent tomograms acquired from the different angles of the circular trajectory.\n\nA further example over ice is shown in Fig. 5.117, acquired with a similar acquisition as the one\nshown in Fig. 5.116. The figure shows the hologram from different angles acquired at L band over K\ntransect, Greenland, with the blue channel showing the co-pol HH data and the white channel showing\nthe cross-pol HV data.\n\nThe tomographic apertures have been processed using a compressive sensing approach. The\nstructure of the subsurface is clearly recognizable from the different observation angles.\n\n5.6 FUTURE SYNTHETIC APERTURE RADAR SYSTEMS\nFuture SAR systems are expected to become more cost-effective and capable of offering a higher\ndegree of performance and flexibility when compared to today\u2019s systems. We list in this subsection,\nwithout a claim on being comprehensive, some of the technological trends which are expected to play a\nsignificant role in future Earth observation missions.\n\nFIGURE 5.116\n\nCircular tomographic acquisition trajectory (left). The geometry allows for the angular generation of tomograms,\n\nwhich can be combined in holographic representations of semitransparent media, such as the forest depicted in the\n\nright plot.\n\nCourtesy of DLR.\n\n5.6 FUTURE SYNTHETIC APERTURE RADAR SYSTEMS 427\n\nmailto:Image of Figure 5.116|tif\n\n\n5.6.1 HIGH-ORBIT (MEDIUM EARTH/GEOSYNCHRONOUS) SYNTHETIC\nAPERTURE RADAR\n\nAs already discussed, SAR systems have been flying in LEO over the past few decades. The use of\nhigher orbits such as medium Earth (MEO) or geosynchronous (GEO) opens the door to increased\ncoverage and reduced revisit times, which can be of paramount importance in interferometric,\ntomographic and polarimetric applications. MEO SAR was first suggested by Edelstein et al. (2005)\nfor tectonic applications. With orbital altitudes between 1500 and 30,000 km, MEO offers a wide\nrange of advantages for SAR remote sensing ranging from global coverage with one- or two-day revisit\nperiods to continental coverage with daily multirevisit. The idea of GEO SAR first appeared in the\nliterature in 1983 (Tomiyasu and Pacelli, 1983). GEO SAR orbits offer persistent continental coverage.\nWith integration times on the order of several hundreds of seconds, GEO SAR systems are very much\naffected by atmospheric propagation due to their much higher orbital altitude.\n\nIn Fig. 5.118 we present the swaths (between 20? and 60? incidence) for one revolution of LEO\n(blue), MEO (green), and GEO (red) orbits.\n\nNote the significant increase of the swath with the orbit height, which helps reduce the revisit times\nof these satellites. Note also, that GEO does not offer global coverage. In both MEO and GEO cases,\n\nFIGURE 5.117\n\nHolographic, i.e., circular tomographic image acquired at L band over the Ktransect, Greenland, by DLR airborne\n\nsystem F-SAR. The blue channel shows the co-pol HH data, whereas the white channel shows the cross-pol HV data\n\n428 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.117|tif\n\n\nthe power budget of the radar link becomes less favorable, due to their higher altitudes, and larger\nantennas and transmit powers are required. Moreover, integration times become larger on the order of\ntens and even hundreds of seconds, which make the systems extremely sensitive to environmental\nchanges within the synthetic aperture, be it atmospheric turbulences, radio frequency interference\n(RFI), or changes in the reflectivity of the scenes (e.g., ocean surfaces).\n\n5.6.2 MULTICHANNEL SYNTHETIC APERTURE RADAR SYSTEMS\nMultichannel SAR systems allow for the simultaneous acquisition of several samples at the same time\nallowing for additional beam shaping (e.g., digital beamforming) techniques. The main advantage of\nmultichannel systems is that they help relax the timing constraints of single-channel SAR systems,\nand consequently, decouple the available swath and Doppler requirements for the radar to observe\nphenomena unambiguously. In this manner, the number of independent pixels of the SAR images can\nbe increased by one or two orders of magnitude.\n\nDepending on the distribution of the channels, we can differentiate between systems with multiple\nchannels in elevation and azimuth. As a rule of thumb, the multiple channels in elevation help improve\nthe sensitivity of the system by digitally narrowing the receive elevation beams, whereas the multiple\nchannels in azimuth help improve the synthetic resolution of the system by digitally narrowing the\nreceive azimuth beams.\n\nThis narrow beam can point to different areas of the wide swath or can be steered to follow the\nreturns of the transmitted chirp on the ground. This approach was first suggested by Krieger et al.\n(2008) and has been known in the literature as scan on receive (i.e., ScORe). The equivalent approach\n\nFIGURE 5.118\n\nSwaths (between 20? and 60? incidence) for one revolution of low Earth (blue), medium Earth (green), and\ngeosynchronous (red) orbits.\n\n5.6 FUTURE SYNTHETIC APERTURE RADAR SYSTEMS 429\n\nmailto:Image of Figure 5.118|tif\n\n\nfor reflector arrays, depicted in Fig. 5.119, is known in the literature as SweepSAR the standard\noperation mode foreseen for both JPL\u2019s NISAR and DLR\u2019s Tandem-L.\n\nOne problem of ScORe in single platform systems is the impossibility of receiving echoes during the\ntransmission events, which results in gaps (e.g., blind ranges) in the resulting images. Beamforming in\nelevation requires a precise calibration of the antenna pattern in which some pointing accuracy can be\ntraded off for a bit of gain of the receive beams, which makes it a reasonably robust technique in terms of\nimplementation. One clear drawback of elevation digital beamforming (DBF) techniques is the\ncomparatively high levels of signal to interference ratios in environments with large RFI.\n\nDBF in azimuth follows a similar pattern and is based on an effective sharpening of the azimuth\nreceive beam after synthetic aperture processing. The basic idea is based on the possibility of reducing\nthe PRF of the system, hence widening the unambiguous accessible swath, while collecting enough\nsamples through the different azimuth channels for Nyquist sampling the Doppler bandwidth of the\nantenna. The solution is little more than a system concept in which the physical separation of the\nchannels is such that the samples of the different channels roughly correspond to the original sampling\nof a single-channel system with N times the PRF. A generalization of the approach using a dedicated\nDBF algorithm is presented in Kim et al. (2013). Fig. 5.120 shows the basic channel distribution of a\nsystem example including DBF in azimuth and elevation, the high resolution wide swath (HRWS)\nsystem.\n\nIn the original HRWS concept, the increase of the number of independent pixels with respect to\nTerraSAR-X is about a factor 20.\n\nFIGURE 5.119\n\nDigital beamforming in elevation using a reflector array, i.e., SweepSAR. The narrower receive beam follows the\n\npropagation of the transmitted signal on the ground, hence improving the sensitivity of the system.\n\n430 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.119|tif\n\n\n5.6.3 ONBOARD PROCESSING FOR DATA REDUCTION IN EARTH AND\nPLANETARY SYNTHETIC APERTURE RADAR MISSIONS\n\nWith increasing performance (e.g., wider swaths and better geometric resolution) and increasing orbit\nduty cycles, the data volume of SAR missions shall be increasing proportionately. Traditionally, the\nprocessing of the SAR data has been conducted on ground, after the downlink of the radar raw data,\nand all necessary ancillary information (e.g., instrument settings, internal calibration). If things in the\nfuture are expected to remain the same, the capacity of the downlinks must grow to accommodate the\nincreasing data volumes. However, this need not be the only solution to the problem. In many cases,\nthe increase in the downlink capacity can be offset by the use of dedicated onboard systems for\ndata reduction (including the SAR retrieval), which are expected to largely benefit from the fast\ndevelopments in digital electronics.\n\nExcluding the original optical SAR processors, onboard processing in spaceborne SAR has been\ntraditionally limited to the bit adaptive quantization (BAQ) of the raw data. BAQ algorithms are\nadaptive quantizers capable of locally accommodating the number of bits to the apparent SNR of the\nreceived echoes. Typical BAQ ratios for current SAR missions (e.g., TerraSAR-X, Sentinel-1) yield\neffective reductions in the number of bits slightly better than 50% (e.g., 8:4, 8:3).\n\nFIGURE 5.120\n\nBasic channel distribution of the high resolution wide swath (HRWS) system for high-resolution and wide-swath\n\nimaging. Digital beamforming (DBF) in elevation for increased sensitivity and DBF in azimuth for high-\n\nresolution imaging.\n\n5.6 FUTURE SYNTHETIC APERTURE RADAR SYSTEMS 431\n\nmailto:Image of Figure 5.120|tif\n\n\nThe first obvious field for the use of spaceborne onboard SAR processing techniques is planetary\nobservation, in which the effective data transfer capacity is very limited due to the lack of direct visibility\nof the ground stations and the delay of the radio link over great distances. In these cases, full SAR/InSAR\nonboard processing followed by multilooking of the reflectivity images and interferograms may yield\ndata reduction rates larger than one order of magnitude, as was the baseline for Veritas, a JPL-ASI-DLR\nmission proposal for the interferometric mapping of Venus. The use of further image compression\ntechniques for images and interferograms may help relax the data volume bottlenecks.\n\nThe argument for planetary observations is also valid for the Earth. In the case of single-pass\ninterferometric and tomographic systems, the additional baselines do not yield, in general, signifi-\ncant changes in the image reflectivities, and the changes of the observation geometry appear all packed\nin the phases of the images. SAR/InSAR processing may be used onboard, and then only one raw data\nset and the corresponding multilooked-interferograms need to be transferred to ground. As long as no\nsignificant decorrelation is artificially introduced at the processing stages the residual errors in the\nobservation geometry and the system may be expected to be accurately calibrated on ground. Another\ncase in favor of the use of onboard processing for data reduction is multichannel SAR, where the\ncombination of the channels onboard may result in a reduction in the number of effective data streams.\nRegarding the implementation of onboard DBF algorithms, the calibration requirements (e.g., channel\nbalancing, lever arms, antenna patterns) are in general more stringent if effected in azimuth than in\nelevation.\n\n5.6.4 BISTATIC AND MULTISTATIC SYNTHETIC APERTURE RADAR\nCONSTELLATIONS\n\nAs previously defined, bistatic SAR has separate antennas for transmitting and receiving, which\nprovides spatial flexibility and the possibility of achieving high isolation in the payload electronics.\nThese attributes make them particularly well suited for CW operation which improves somewhat\n(e.g., 4 or 5 dB) the power budget of the radar link. In practical terms, bistatic SARs also have different\nmaster clocks in the transmitter and the receiver, which changes the time and phase references of the\nsystem and becomes a challenge for precise SAR imaging and interferometry. Fig. 5.121 shows the\ncolor composite of three airborne bistatic SAR images acquired in 2003 with the airborne systems of\nDLR (E-SAR) and ONERA (RAMSES) over Garonnes, France.\n\nThe colors represent different bistatic elevation angles: 0 (red), 10 (blue), and 20 (green) degrees,\nwhich reveal different characteristics of the scene in both urban and natural areas. Accurate bistatic\nradiometry depends on the accurate characterization of the bistatic joint patterns and the combined\neffect of transmitter and receiver, which raises interesting challenges in the calibration of the systems.\nThis figure is a very good example of the potential of bistatic SAR for applications involving change\ndetection and image classification techniques.\n\nArguably, more important than the additional observation angle, bistatic SAR systems offer a\nstraightforward path to generate sufficient angular diversity in the coherent combination of two or more\nobservation geometries. This has been, in fact, the main feature of the first bistatic SAR in space, the\nTanDEM-X constellation that will also be used in the future Tandem-L mission. In fact, bistatic SAR\nbecomes an essential method for the generation of single-pass interferometric, tomographic systems, as\nwell as for systems with distributed radar systems. Such systems pave the way for applications such as\n\n432 CHAPTER 5 RADAR\n\n\n\nthe generation of digital elevation and surface models, fast moving target detection and tomographic\nimaging, together with very high-resolution imaging. These applications require different levels of time\nand phase coherence between the data. As an example, Fig. 5.122 shows two enhanced resolution images\nin range (top) and azimuth (bottom) computed by merging the monostatic and bistatic TerraSAR-X and\nTanDEM-X data, respectively.\n\nThe images show two urban areas in Sydney, Australia (top), and Neustrelitz, Germany (bottom),\nand have been generated by coherently combining the spectral supports of the different images.\n\nThe coherent combination of bistatic SAR data requires, in general, an accurate synchronization\nof time and phase references of the raw data, which typically requires accuracies of a few pico-\nseconds and degrees, respectively. An example of the lack of phase synchronization on the bistatic\ndata is shown here in Fig. 5.123.\n\nThe figure shows the first bistatic repeat-pass interferograms acquired by TanDEM-X over the\nBrasilia area, Brazil, with (left) and without (right) clock phase errors. The horizontal fringes of the left\ninterferogram, which should be interpreted as a horizontal slope in a single-pass scenario, are caused\nby a difference of about 1 Hz in the carrier offsets between the two acquisitions.\n\nThe time and phase synchronization of bistatic SAR data requires the incorporation of dedicated\nhardware and precise algorithms in the ground software. The current options encompass a hardware-\ndriven and a software-driven one:\n\n1. A dedicated synchronization link between the transmitter and receiver, like in TanDEM-X.\nWithin the accuracy of the orbits and baselines, the direct or synchronization link must provide\nabsolute time and phase referencing between transmitter and receiver, at the cost of dedicated\nhardware, and constraints in the angular relative position between the spacecraft and in the\nnumber of synchronization events. A duplex (e.g., two-way) link may be more robust to\nreciprocal errors in the system, but its accuracy is limited by the accuracy in knowledge of the\nbaseline and the lever arms of the system.\n\nFIGURE 5.121\n\nColor composite of three bistatic airborne synthetic aperture radar (SAR) images acquired with DLR\u2019s E-SAR and\n\nONERA\u2019s RAMSES systems over Garonne area, France. The colors represent different bistatic angles in\n\nelevation, i.e., 0 (red), 10 (blue), and 20 (green) degrees, showing clear relative variations within the scene.\n\nCredits: DLR and ONERA\n\n5.6 FUTURE SYNTHETIC APERTURE RADAR SYSTEMS 433\n\nmailto:Image of Figure 5.121|tif\n\n\nFIGURE 5.122\n\nEnhanced resolution in range (top) and azimuth (bottom) computed after merging the monostatic and bistatic\n\nimages acquired by TerraSAR-X and TanDEM-X satellites over Sydney, Australia, and Neustrelitz, Germany,\n\nrespectively.\n\nCourtesy of DLR.\n\nFIGURE 5.123\n\nFirst bistatic repeat-pass interferograms computed with TanDEM-X over Brasilia, Brazil. The horizontal fringes\n\nin the left interferogram correspond to a residual carrier offset of about 1 Hz between the two acquisitions. The\n\nright interferogram is the one generated after accurate phase synchronization.\n\nCourtesy of DLR.\n\nmailto:Image of Figure 5.122|tif\nmailto:Image of Figure 5.123|tif\n\n\n2. A model-based (interferometric) map-drift autofocus approach known as autonomous\nsynchronization, e.g., AutoSync. AutoSync is based on the inversion of the relative distortion\nintroduced in the bistatic SAR image by the local changes in the clock carrier frequency, and\ndelivers relative time and phase referencing with an accuracy dependent on the similarity\n(e.g., coherence) between the bistatic and the reference images. AutoSync was used to generate\nthe first bistatic single-pass interferograms of the TanDEM-X mission computed with the\nsatellites separated by an along-track baseline of 20 km presented earlier in Fig. 5.94. Because of\nthe experimental commanding of the acquisition and the long along-track baseline (w20 km), the\nbistatic image had to be synchronized with the help of an AutoSync algorithm.\n\nIn future systems, the radar oscillator may be merged with the navigation unit of the satellite, thus\nenabling a solution of the clock time and phase errors for transmitter and receiver as a direct product of\nthe standard precise orbit determination (POD) algorithms. Effective L band accuracies of a few\ndegrees with a second rate may be expected, which suggests validity for the approach up to X-band\nsystems.\n\nWe finish this subsection with a few comments on bistatic SAR image formation. In the general\ncase, bistatic SAR, unlike monostatic surveys, have the following properties: (1) they are in general\nnonhyperbolical, (2) they show a higher dependence on topography, and (3) they do not follow an\nazimuth-invariant model, especially in the case where the baseline is changing with time. Bistatic SAR\nimage formation algorithms need to accommodate the previous characteristics and must be imple-\nmented in both time and Fourier domains. The same algorithms described earlier for monostatic radars\nare available in the bistatic case, with the difference that the processing functions in the general bistatic\ncase are best computed numerically. Most of the bistatic TanDEM-X SAR images shown throughout\nthis chapter have been computed with numerical bistatic versions of the range-Doppler and chirp\nscaling algorithms. For more demanding scenarios, a numerical Uk approach based has already been\nsuggested for the SAOCOM-CS mission proposal.\n\nWhenever the baseline is changing with time, the bistatic, fast-factorized, backprojection (BFFBP)\nmodel appears as the most natural solution. Finally, Fig. 5.124 shows a bistatic airborne SAR image\nacquired by DLR\u2019s E-SAR and ONERA\u2019s RAMSES over Garonnes, France, processed using the\nBFFBP algorithm.\n\nBistatic SAR can also be seen as the basic unit of multistatic SAR constellations, which multiply the\npotential capabilities of bistatic systems. Multistatic constellations offer an increase in the coverage and\nrevisit times with respect to single-receive channel systems, as well as the potential to adapt the\nobservation geometry to several specific applications. Multistatic SAR constellations are configurable,\nscalable, and offer interesting options for the simplification of hardware and the improvement in the\nperformance. Potential applications encompass single-pass tomography or multibaseline interferometry,\nvery high geometric and radiometric resolution imaging, or multiaspect reconstruction.\n\n5.7 RADAR ALTIMETERS\nRadar altimeters are typically nadir-looking, ranging radars used for the measurement of the surface\u2019s\nheight to centimetric accuracy. Initially conceived to measure the surface topography of the ocean,\nradar altimeters typically operate at higher-frequency bands (Ku and Ka bands) and have also been\n\n5.7 RADAR ALTIMETERS 435\n\n\n\nused to measure the marine geoid, wave heights and wind speeds, the topography of ice polar caps,\nsurface roughness, as well as low-incidence radar backscatter. As already mentioned, sounders are a\nparticular case of radar altimeters operating in lower-frequency bands and imaging the vertical profiles\nof volumetric structures such as ice or snow.\n\nThe history of space borne radar altimetry starts in the 1970s with two experimental missions,\nSkylab and Geos-3, conceived as technology demonstrations and not designed with systematic\nobservation capabilities and hence were not sufficiently accurate to enable a scientific use of the data.\nThe first operational radar altimeter in space was designed as part of the Seasat mission in 1978. The\nSeasat-ALT instrument, even for the short lifetime of the mission, demonstrated the value of sea level\nmeasurements obtained through radar altimetry. Years went by until the mid 80s and Geosat was\nlaunched, initially conceived as a classified military mission to measure the marine geoid, making the\ndata unavailable for the public use. After completing its goals over the year and a half year geodetic\nmission, US scientists Jim Mitchell and George Born convinced the US. Navy to put Geosat in the\nSeasat orbit and allow it to measure ocean surface variability. This move provided useful data for many\nresearch projects and set the stage for future dedicated altimeter missions such as TOPEX/Poseidon.\n\nThe TOPEX/Poseidon mission was dedicated to observing the ocean surface variability and using\nthese observations to study variations in geostrophic ocean surface currents, waves and tides. Thismission\noperated for a total of 13 years long past its design life of 7 years. It provided increasingly accurate\nmeasurements of the ocean\u2019s surface as the altimetry science community developed new calibration\nprocedures and refined the processing of the data to achieve higher accuracy in the measurements. One\nyear prior to the launch of TOPEX/Poseidon (TP), the European Space Agency (ESA) launched its first\nradar altimeter (e.g., RA) onboard ERS-1, followed a few years later by its twin ERS-2. TOPEX/\nPoseidon managed to continue operating into the lifetime of the follow-on mission Jason-1. In fact, both\n\nFIGURE 5.124\n\nBistatic airborne synthetic aperture radar (SAR) image over Garonnes, France, acquired by DLR\u2019s E-SAR and\n\nONERA\u2019s RAMSES. The bistatic angle of the observation was about 20?, and the baseline was kept stable during\nthe flight. The image was generated using a dedicated bistatic, fast-factorized, backprojection kernel.\n\nCourtesy of DLR and ONERA.\n\n436 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.124|tif\n\n\nradar altimeters were operated in the same orbit some 90 s apart for 6 months in 2001, revealing a\ncentimetric agreement between the measurements of the two instruments (Haines et al., 2003a,b). After\nthis calibration period (TP) was moved over between the orbits of Jason-1, which remained in the same\norbit as the previous 13-years of TP measurements. This increased the spatial coverage of the combined\nJason-1, TP measurement pair.\n\nThe launch of ERS-2 was followed shortly by another US navy mission known as Geosat Follow-On\n(GFO), which started a golden decade for spaceborne radar altimetry. The launch of ESA\u2019s large\nENVISAT satellite in 2002, with its RA-2 altimeter, provided continuity for ERS-1 and 2. Jason-2,\nlaunched in 2008, continued the mission of Jason-1 flying again in the 10-day repeat Seasat orbit. In\nmid-2012 Jason-1, almost at the end of its lifetime, wasmoved from its exact repeat orbit to a geodetic one\nwith a very long repeat, thus compromising its ability tomeasure oceanvariability, but putting it in a better\nposition tomeasure ocean bottom effects. Slightly later, ENVISAT suddenly ceased to communicatewith\nthe ground, thus losing two instruments for ocean observations over a short period of time.\n\nIn 2010, the SIRAL-2 instrument onboard ESA CryoSat-2 mission introduced the first delay-\nDoppler, or SAR altimeter as suggested in (Raney, 1998). With its far better along-track resolution,\nCryoSat-2 has been used for monitoring the polar ice caps and for tracking the changes in the ice\nthickness, yielding valuable data for understanding the warming of the planet.\n\nThe Chinese National Space Administration (CNSA) launched in 2011 the HY-2A satellite\nincluding the RA altimeter, still in operation in 2016. In another launch in 2013 by the French Center\nNational d\u2019E?tudes Spatiales (CNES) and the Indian Space Research Organization (ISRO) the Saral\nsatellite carries the radar altimeter ALtiKa, which is the first altimeter operated at Ka band, which\nimproves the accuracy of the system by a factor of three over most of its predecessors. In addition, the\nimprovement in the spatial resolution better resolves coastal areas, continental rivers and lakes. The\nESA mission Sentinel-3, launched in 2015, includes a SAR altimeter (SRAL) derived from CryoSat\u2019s\nand Poseidon for ocean observations. Jason-3, launched in early 2016, shares with its predecessors the\nsame instrument, orbit and objectives.\n\nFuture planned missions include Jason-CS/Sentinel 6 and the surface water ocean topography\n(SWOT), all to be launched around 2020. The former will fly a SAR altimeter derived from Sentinel-3\nflying in the Jason orbit at 1336 km height. The latter uses a wide-swath altimetry concept with low-\nincidence side-looking interferometric observations. Table 5.5 is a list of radar altimetry missions over\nthe past 40 years.\n\n5.7.1 GEOMETRICAL MODELS\nAltimeters cannot be classified in the same way as SAR systems and other satellite radars. Most\nsatellite altimeters are nadir pointing (Fig. 5.125).\n\nIn the nadir-looking geometry, topography is derived from the measurement of the delay of the\nradar echoes, the position of the radar, and the calibration of the range of the system. The resolution on\nthe ground is given by the footprint of the altimeter antenna in the real aperture case. Early suggested\nby Raney (1998), delay-Doppler or SAR altimeters benefit from the synthetic aperture principle to\nimprove the along-track resolution of the system, like in the case of ESA CryoSat-2, CNES ALtiKa,\nand Copernius Sentinel-3.\n\nA newer generation of wide-swath altimeters like SWOT (Fig. 5.126) (Fu et al., 2009), deviate\nfrom the strictly nadir-looking to a low-incidence side-looking observation geometry and provide a\n\n5.7 RADAR ALTIMETERS 437\n\n\n\nTable 5.5 List of Spaceborne Radar Altimetry Missions Over the Past 40 years\n\nSensor Operation Frequency Band Orbit Height (km) Agency\n\nSkylab (S193) 1973 Ku 435 NASA/JPL\n\nGeos-3 1975e1978 Ku 845 ESA\n\nSeasat (ALT) 1978 Ku 800 NASA/JPL\n\nGeosat 1985e1989 Ku 800 US Navy\n\nERS-1 (RA) 1991e1996 Ku 785 ESA\n\nTOPEX/Poseidon 1992e2005 S, Ku 1336 NASA/CNES\n\nERS-2 (RA) 1995e2011 Ku 785 ESA\n\nGFO 1998 Ku 800 US Navy\n\nJason-1 (SSALT) 2001 C, Ku 1336 NASA/CNES\n\nENVISAT (RA-2) 2002e2012 S, Ku 785 ESA\n\nJason-2 (SSALT) 2008- C, Ku 1336 NASA/CNES\n\nCryosat-2 (SIRAL-2) 2010- C, Ku 717 ESA\n\nHY-2A (ALT) 2011- C, Ku 963 SOA\n\nSaral (ALtiKa) 2013- Ka 785 ISRO/CNES\n\nSentinel-3 (SRAL) 2015 C, Ku 814 ESA\n\nJason-3 (SSALT) 2016 C, Ku 1336 NASA/CNES/Eumetsat/\nNOAA\n\nFIGURE 5.125\n\nNadir-looking geometry of a conventional radar altimeter.\n\nmailto:Image of Figure 5.125|tif\n\n\nhigh-resolution scan of a wide swath on the ground (Fig. 5.126). Wide-swath altimetry is linked with\nthe synthetic aperture principle, which allows us to obtain height accuracies typical of nadir-looking\naltimetry with the help of SAR interferometry.\n\n5.7.2 ILLUMINATED AREA AND ECHO SIGNAL POWER\nThe illumination of a flat scene by the radar altimeter in its nadir oriented geometry is depicted in Fig.\n5.127\n\nThe figure shows top-down views of the observation geometry, including the beam; the shaded\nrings represent the transmitted pulse radiated in all angular directions. The mid circular areas represent\nthe area on the ground contributing to the received echo. Note in this idealized case the power of the\necho increases linearly with time as the pulse illuminates a wider area, reaching its peak after the delay\nof first impact plus the chirp duration as shown in the top middle figure. Any radar altimeter whose\nfootprint is smaller than the area covered by the pulse on ground is denoted as beam-limited.\nConversely, if the footprint is larger than the area covered by the pulse on ground the system will be\npulse-limited, and the situation is the one depicted in the top right figure, i.e., the area on ground\ncontributing to the echo becomes an annulus, whose thickness is proportional to the duration of the\ntransmitted chirp.\n\nFIGURE 5.126\n\nSurface water ocean topography measurements concept.\n\nFrom http://swot.jpl.nasa.gov/gallery/galleryImages/index.cfm?FuseAction\u00bcListPhotoGallery&CatID\u00bc1.\n\n5.7 RADAR ALTIMETERS 439\n\nmailto:Image of Figure 5.126|tif\nhttp://swot.jpl.nasa.gov/gallery/galleryImages/index.cfm?FuseAction=ListPhotoGallery&amp;CatID=1\nhttp://swot.jpl.nasa.gov/gallery/galleryImages/index.cfm?FuseAction=ListPhotoGallery&amp;CatID=1\nhttp://swot.jpl.nasa.gov/gallery/galleryImages/index.cfm?FuseAction=ListPhotoGallery&amp;CatID=1\n\n\nThe temporal distributionof the area contributing to the received echoes is depicted in the bottomof the\nfigure. Under the assumption of an isotropic scene, the power of the received echoes is proportional to this\narea. The transmitted signal hits the surface at delay t0. The echo power increases linearly as described\nearlier covering a circular area until t0 \u00fe s, with s being the duration of the transmitted signal. This\narea of linear increase corresponds to the one covered by beam-limited altimeters. Afterward, the area\nremains constant until it is finally limited by the antenna beam. In terms of power, the energy decreases\nslowly in this area due to several causes, e.g., antenna patterns, increasing free space losses, etc.\n\nFor an arbitrary surface, the illuminated area can be characterized statistically. The average value\nof the illuminated area can be approximated as the result of the following convolution (Brown, 1977).\n\nAeff tr\u00f0 \u00dez pH tr\u00f0 \u00de$hradar tr\u00f0 \u00de$Aflat tr\u00f0 \u00de; (5.187)\nwhere the pH(tr) is the pdf of the surface, hradar(tr) is the normalized impulse response of the instrument,\nand Aflat(tr) is the area illuminated by the pulse on the mean flat surface. As expected, the previous\nexpression collapses to Aflat(tr) under the assumption of a flat surface, i.e., pH(tr) \u00bc d(tr?t0). For\ngeneric rough (flat) surfaces, the central limit theorem allows the approximation of the surface height\nusing a Gaussian variable with a pdf\n\npH\u00f0tr\u00dez 1ffiffiffiffiffiffi\n2p\n\np\n$sH\n\n$exp\n\n\"\n? c\n\n2\n0$t\n\n2\nr\n\n2$s2H\n\n#\n; (5.188)\n\nwhere s2H is the variance of the height of the surface, and c0 the velocity of propagation of the radar\nwaves. If no weighting is assumed, the impulse response of the instrument typically has a sinc form.\nOnce weighting and the frequency response of the instrument are incorporated, hradar can also be\napproximated with a Gaussian, i.e.,\n\nhradar\u00f0tr\u00dez exp\n?\n? B\n\n2\nr $t\n\n2\nr\n\n2\n\n?\n; (5.189)\n\nwhere the Br is the available bandwidth of the system. The power of the received echo can be\napproximated by integrating the power density multiplied by the effective illuminated area over the\niso-ranges (Fig. 5.127) which for an ideal nadir-looking geometry can be further approximated as\n\nPalt\u00f0tr\u00dezPTx$l\n2\n0$G\u00f0tr\u00de\n\n\u00f04p\u00de3$r4\u00f0tr\u00de\n$s0$Aeff\u00f0tr\u00de; (5.190)\n\nwhere PTx is the transmitted peak power, G(tr) is the antenna gain projected on the fast time, r is the\nslant range, and s0 is the average normalized RCS over the footprint (Fig. 5.127).\n\nTo compute the received echo power, tr is the fast-time impulse response of the radar altimeter.\nActually, we never deal with flat surfaces and the measurement is an average. The previous discussion\nis of course only valid in the case of an isotropic surface. The altimeter measures the mean surface\nheight.\n\n5.7.3 RADAR ALTIMETRY OVER THE OCEAN\nThe principle of measurement of the radar altimeter over the sea surface is sketched in Fig. 5.128.\n\nThis figure shows the different surfaces relevant to the altimetric measurement. The quantity of\nprime interest to oceanographers is the sea level with respect to the reference ellipsoid, the horizontal\n\n440 CHAPTER 5 RADAR\n\n\n\nFIGURE 5.128\n\nA schematic of the radar altimeter measurement scheme. Also shown are orbit reference elements of GPS ranging,\n\nlaser tracking, and DORIS radio tracking. The contributions to the altimeter measurements are also included in the\n\nfigure.\n\nFrom NASA website, 2009.\n\nFIGURE 5.127\n\nPower of received echoes over a flat surface (left) shortly after first reflection (mid), once the complete pulse has\n\nimpacted the illuminated scene and (right) the pulse is illuminating an area toward the edges of the footprint. The\n\ndashed beam in the middle figure represents a beam-limited altimeter. The right figure represents a pulse-limited\n\naltimeter.\n\n5.7 RADAR ALTIMETERS 441\n\nmailto:Image of Figure 5.128|tif\nmailto:Image of Figure 5.127|tif\n\n\ngradient of which is proportional to the geostrophic ocean current. The sea surface topography\nmeasured by a satellite altimeter can be expressed as\n\nSSH\u00f0x; ta\u00de \u00bc j pA\u00f0ta\u00de ? pU\u00f0x; ta\u00dej \u00fe j pA\u00f0ta ? sr\u00de ? pU\u00f0x; ta\u00dej ? c0$sr \u00bc hG\u00f0x\u00de \u00fe h\u00f0x; ta\u00de \u00fe ?\u00f0x; ta\u00de;\n(5.191)\n\nwhere SSH is the surface height, x is the along-track nadir coordinate, ta is the azimuth time, pA is the\nephemeris of the altimeter, pU(x, ta) is the parametrization of the ellipsoidal surface in the altimeter\ncoordinates, sr is the two-way delay of the radar signal, hG is the height of the marine geoid, h is the\ndynamic topography, and ? are measurement errors. Let us ignore the latter for the present discussion,\nsince it will be addressed in further detail later (Le Traon and Morrow, 2001b).\n\nThe marine geoid is the local surface of the planet in absence of marine perturbations; the latter are\nbasically attributed to the dynamic topography, which describes the variation of the sea surface due to\ndynamic processes in the ocean. The dynamic topography can be further decomposed as the superposition\nof a permanent and a variable component,\n\nh\u00f0x; ta\u00de \u00bc hperm\u00f0x\u00de \u00fe ht\u00f0x; ta\u00de; (5.192)\nwhere the former is due to permanent circulation and the second is caused by variable geostrophic\nocean currents (tides, mean currents, mesoscale eddies, etc.).\n\nThe estimation of h requires the knowledge of hG, which is not available with sufficiently high-\nresolution on a global scale and with sufficient accuracy. An estimation of the variable part of the\ndynamic topography is however possible by combining the data of several altimetric surveys to\ncompute a mean sea surface to use as a reference. The average over several realizations of the sea\nsurface height will be defined as the mean sea surface, i.e.,\n\nMSSH\u00f0x\u00de \u00bc hSSHita z hG \u00fe hperm\u00f0x\u00de; (5.193)\nwhere the operator h$it refers to temporal averaging over a representative period. The mean sea surface\nheight can be combined with models of hG to compute a low-pass estimate of hperm. The model derived\nfrom the GOCE mission (i.e., Gravity field and steady-state Ocean Circulation Explorer), provides\ncentimetric accuracy with 100 km sampling (Fig. 5.129).\n\nThe estimation of the variable part of the dynamic topography can be straightforwardly expressed as\n\nht\u00f0x; ta\u00dez SSH\u00f0x; ta\u00de ? hSSHita. (5.194)\nNear the coast the altimeter data becomes less useful. First the passive microwave radiometer used\n\nfor tropospheric water vapor radar path delays, has inherently large spot sizes, which are compromised\nwhen they encounter land eliminating the water vapor path length correction. In addition, the altimeter\nwaveform is altered by the presence of land in the altimeter footprint. Here it is important to point out\nhow the SSH and other parameters are retrieved from the altimeter waveform. The waveform\n(Fig. 5.130) indicates the SSH from the midpoint of the leading edge at least for the open ocean\nretrieval (Brown, 1977). The y-axis offset from zero indicates the instrument noise level while the\nwaveform maximum is a measure of the s0 backscatter, which is related to the wind speed. The slope\nof the leading edge is inversely proportional to the significant wave height (SWH) and the slope of the\ntrailing edge reflects and antenna mispointing.\n\n442 CHAPTER 5 RADAR\n\n\n\nFIGURE 5.130\n\nRadar altimeter return echo. The altimeter waveform is labeled for geophysical parameter retrievals (http://www.\n\naltimetry.info/html/alti/principle/waveform/ocean_en.html).\n\nCredits AVISO\u00fe/CNES 2017.\n\nFIGURE 5.129\n\n3-D representation of the Gravity field and steady-state Ocean Circulation Explorer geoid with variations\n\nfrom ?100 to \u00fe 60 m.\n(http://www.esa.int/Our_Activities/Observing_the_Earth/GOCE)\n\n5.7 RADAR ALTIMETERS 443\n\nmailto:Image of Figure 5.130|tif\nhttp://www.altimetry.info/html/alti/principle/waveform/ocean_en.html\nhttp://www.altimetry.info/html/alti/principle/waveform/ocean_en.html\nmailto:Image of Figure 5.129|tif\nhttp://www.esa.int/Our_Activities/Observing_the_Earth/GOCE\n\n\n5.7.4 ERROR CORRECTION AND CALIBRATION\nThe calibration of radar altimetry data encompasses the following terms: (1) instrument, (2) atmospheric\npropagation, (3) sea state bias, (4) tides, and (5) inverse barometer corrections. In this section, we will\ndiscuss the contributions of every component of the list.\n\nInstrument errors are mainly due to internal delays of the instrument, but can also be caused by\nattitude errors. These can be calibrated out using measurements of external targets. Other contributions\nfrom the instrument include (long-term) oscillator drifts and Doppler shifts. Another source of errors is\nthe tracking system of the spacecraft for the improvement of the ephemeris determination on the ground.\nOrbital errors remain the largest contribution to the range error budget of radar altimeters. Orbital errors\ncan be approximated using a sinusoidal model with a fundamental frequency being the instantaneous\nargument of latitude of the orbit plus some high-frequency noise. Currently POD algorithms supported\nby accurate error models and differential GNSS measurements achieve accuracies in the order of a\ncouple of cm (w2 cm). By supporting POD with external tracking systems (e.g., GPS, radio, and laser)\nthese accuracies are consistently 1 or 2 cm, as was the case of TOPEX/Poseidon. TOPEX/Poseidon\nprovided a huge improvement relative to the \t10 cm orbital accuracy associated with the ERS-1,2\nsatellites.\n\nAs discussed earlier in this chapter, the propagation through the atmosphere introduces additional\ndelays on the radar echoes which bias the range measurements. Ionospheric variability can also\nintroduce range errors from 1 to 20 cm, which have been traditionally calibrated out exploiting\nthe dispersive character of the volume. Dual-frequency altimeters benefit from the frequency\ndependence of the group delays to correct the ionospheric perturbations down to 0.5 cm. The\ntroposphere introduces biases of about 2e3 m, due to the hydrostatic and wet contributions. Each\nmodern altimeter also carries a bore-sighted multichannel microwave radiometer to expressly\ncorrect for tropospheric water vapor (Brown et al., 2004, 2009). The accuracy of the correction of the\nwet tropospheric delay can be assumed to be in the order of 1 cm. If the data from the radiometer are\nmissing, the wet tropospheric delay can be estimated from atmospheric climate models.\n\nAtmospheric variations have a further impact other than the additional delays on the propagation\npath. Spatial and temporal variations of the surface pressure result in changes of the sea level on the\norder of 1 cm/mbar. In addition, wind and pressure forcing creates a higher-frequency barotropic\nresponse at periods shorter than 20 days (Le Traon and Morrow, 2001b). Tidal variations can result in\nsea surface height changes in open ocean up to 60 cm, and take even larger values in coastal areas\nwhere tides become highly nonlinear.\n\nProbably the most obscure bias to compensate for in correcting an altimetry measurement is the\none due to the sea state. The sea state bias is due to the response of the wave covered sea surface to the\nspherical wave fronts of the radar waves, much better reflected in wave troughs than in wave crests.\nThe sea state tends to shift the sea surface height away from the mean sea surface toward the troughs\nand can take values of about 2 cm (Fu et al., 2010). We present the error budget for some radar\naltimetry missions (Le Traon and Morrow, 2001b) in. Fig. 5.131.\n\nIn their review of these errors Le Traon and Morrow (2001b) also presented these errors as a\nfunction of altimeter mission stratified with time (Fig. 5.131), which clearly demonstrates the decrease\nof the overall budgets with time resulting in making satellite altimetry a measurement that can be used\noperationally.\n\n444 CHAPTER 5 RADAR\n\n\n\nFrom the mid-1990s to early 2012 there were multiple altimeter satellites operating providing the\nreal golden age of altimeter data availability. During this period researchers were able to merge these\ndifferent altimeter data together to improve the space-time coverage. To merge multisatellite altimeter\ndata one must first create homogeneous and intercalibrated data sets. A method to achieve this is to use\nthe most precise mission as a reference for the other satellites (Le Traon and Ogor, 1998). During this\nperiod, the best references were TOPEX/POSEIDON or Jason-1,2. Further to compute the SLA it is\nbest to use a common reference surface to get the SLA relative to the same ocean mean.\n\n5.8 RADAR SCATTEROMETRY FOR OCEAN WIND VECTOR OBSERVATIONS\nScatterometers are unique among satellite remote sensors in their ability to determine wind speed and\ndirection over water. These wind observations have a wide variety of applications including weather\nforecasting, marine safety, commercial fishing, El Nino prediction and monitoring of long-term\nclimate fluctuations (http://coaps.fsu.edu/scatterometry/about/overview.php).\n\nA radar scatterometer does not directly measure the wind, but rather the radar backscatter (Bragg\nscatter) from the ocean\u2019s surface that is caused by the small capillary waves that form when the wind\nbegins to blow across the sea surface. These capillary waves have the surface tension of water as their\nrestoring force that balances the initial displacement by the wind. These are the very first responses to\nthe wind forcing on the water and hence can be used as a very good proxy for the wind itself.\n\nTo measure this backscatter the scatterometer transmits a pulse of RF and measures the back-\nscattered power from this pulse as compared with the transmitted signal. Using the radar equation, it is\npossible to compute the normalized radar cross-section of the ocean\u2019s surface. This estimate is then\n\nFIGURE 5.131\n\nError budget for altimetric missions from Geos-3 to Jason-1.\n\n5.8 RADAR SCATTEROMETRY FOR OCEAN WIND VECTOR OBSERVATIONS 445\n\nhttp://coaps.fsu.edu/scatterometry/about/overview.php\nmailto:Image of Figure 5.131|tif\n\n\nconverted into the near-surface wind speed using a geophysical model function, which relates the\nbackscatter intensity to the wind stress. Due to the biharmonic dependence of the model function on\nwind direction, multiple colocated measurements from different azimuth angles are required to\ndetermine the wind vector. Even then, there is usually a 180? ambiguity that needs to be resolved with\nexternal wind or atmospheric pressure measurements.\n\nThe wind direction is found by determining the angle that is most likely to be consistent the\nbackscatter observed from multiple angles. In roughly 5 min, a satellite in a low polar orbit will move\nfar enough to view a point on water surface from angles spanning 90?. The mathematical function\ndescribing the fit of the observed backscatter (as a function of the wind direction) usually has multiple\nminima (ambiguities). Ideally, the best fit corresponds to the true direction of the wind. Typically, the\nnext best fit is in approximately the opposite direction, and the next two minima are in directions\nroughly perpendicular to the wind direction. The process of selecting the direction from among the\nmultiple minima is called ambiguity selection. Noise in the observations can change the quality of fit\nand thereby cause incorrect directions (also known as aliases) to be chosen. NSCAT ambiguity\nselection has proven to be much better than previous scatterometers, with roughly 90% successful\nselection of the correct ambiguity. Most of the problems with ambiguity removal occur for low wind\nspeeds, where the signal is weak and easily confounded by noise. For wind speeds greater than 8 ms?1\n\nsuccessful ambiguity removal is near certain (http://coaps.fsu.edu/scatterometry/about/overview.php).\nThe backscatter measurements can also be used to map the extent and motion of sea ice, track\n\nicebergs, monitor snow melt-accumulation, global rain measurement (at Ku band), and track global\nchange. It should be noted that unlike other space borne instruments, scatterometers observe the same\nlocation at multiple azimuth angles. Required for ocean vector wind retrieval, this capability can be\nexplored for the use of scatterometer data in the mapping of the Earth\u2019s surface in regions such as the\ncryosphere, deserts, and tropical vegetation.\n\n5.8.1 BRIEF HISTORY OF SCATTEROMETRY\nHistorically weather data and in particular wind data could only be observed over land. Geostrophic\nwinds computed from atmospheric pressure fields could only be computed for areas where atmospheric\npressure was measured and that was primarily over land. There are occasional reports from ships at sea,\nbut these are very sparse when compared with the network of weather stations scattered over the land\u2019s\nsurface. Scatterometry has its very early origins in the radar developed and used in World War II. Early\nradar measurements over the oceans were corrupted with sea clutter particularly in the region closest to\nthe radar. It was not realized at this time that this \u201cclutter\u201d was the radar\u2019s response to winds over the\nocean. Radar backscatter was directly related to wind in the late 1960s.\n\nThe first real scatterometers flew on the Skylab missions in 1973 and 1974, which demonstrated that\nspaceborne scatterometers were indeed feasible. As discussed above the Seasat-A satellite scatterometer\n(SASS, http://nasascience.nasa.gov/missions/seasat-1/?searchterm\u00bcseasat) was the first instrument\ndedicated to a wind vector measurement, which lasted over the short life of Seasat. The subsequent\nNASA scatterometer (NSCAT, http://winds.jpl.nasa.gov/missions/nscat/index.cfm) was launched aboard\nJapan\u2019s ADEOS-Midori satellite in August 1996. It was the first dual-swath, Ku-band scatterometer to\nfly since Seasat although the European Space Agency (ESA) flew a single-swath scatterometer on the\nERS-1 and ERS-2 missions. It operated well over the short 10-month life of the ADEOS satellite\nproviding comprehensive mapping of the ocean wind vector over the globe. The success of NSCAT\n\n446 CHAPTER 5 RADAR\n\nhttp://coaps.fsu.edu/scatterometry/about/overview.php\nhttp://nasascience.nasa.gov/missions/seasat-1/?searchterm=seasat\nhttp://nasascience.nasa.gov/missions/seasat-1/?searchterm=seasat\nhttp://winds.jpl.nasa.gov/missions/nscat/index.cfm\n\n\nprompted the acceleration of the follow-on mission which was SeaWinds carried on the QuikSCAT\nsatellite launched in June 1999. This was only 2 years after the failure of the ADEOS satellite and the\ntermination of the NSCATobservations, but QuikSCAT carried the new NASA SeaWinds scatterometer.\n\n5.8.2 SCATTEROMETER ANTENNA TECHNOLOGY\nDifferent scatterometers have employed various types of antenna systems to collect the information\nneeded. The original Seasat scatterometer (SASS) used a very simple pair of \u201cfan-beam\u201d antennas\n(Fig. 5.132), which were both crosspolarized. This pair of fan beams gave the required two looks at a\nsurface location, but could not scan more locations than were possible to view with the orientation of\nthese antennas. Fan beam antennas were also used on ERS-1,2 satellites (Fig. 5.132), but the antennas\nwere oriented in a slightly different configuration from SASS. The NASANSCATalso used a fan beam\nantenna system much like SASS, but it added another beam to provide a better geometrical solution to\nthe direction resolution problem by resolving the 180? ambiguity mentioned earlier when having only\ntwo fan beam antennas.\n\nFIGURE 5.132\n\nVarious scatterometer antennas and their coverages.\n\n5.8 RADAR SCATTEROMETRY FOR OCEAN WIND VECTOR OBSERVATIONS 447\n\nmailto:Image of Figure 5.132|tif\n\n\nFinally, NASA SeaWinds used a completely new concept, which was a scanning pencil beam that\nthen retrieved ocean surface wind vectors for a rather wide swath beneath the satellite. SeaWinds used\na rotating dish antenna (Fig. 5.130) with two spot beams that sweep in a circular pattern. The antenna\nradiates microwave pulses at a frequency of 13.4 GHz across broad regions on Earth\u2019s surface. The\ninstrument collects data over ocean, land, and ice in a continuous, 1800-km-wide band, making\napproximately 400,000 measurements and covering 90% of Earth\u2019s surface in 1 day (http://winds.jpl.\nnasa.gov/missions/quikscat/index.cfm).\n\n5.8.3 SEAWINDS A SCATTEROMETER EXAMPLE\nAs the scatterometer that produced the longest global record we will consider NASA\u2019s SeaWinds scat-\nterometer flown on the QuikSCAT satellite as an example of overall scatterometer technology. The\nSeaWinds scatterometer consists of threemajor subsystems: the electronics subsystem (SES), the antenna\nsubsystem (SAS), and the command and data subsystem (CDS, http://winds.jpl.nasa.gov/aboutScat/\nindex.cfm).\n\nThe SES is the heart of the scatterometer and it contains a transmitter, receiver, and digital signal\nprocessor. It generates and sends high RF waves to the antenna. The antenna transmits the signal to the\nEarth\u2019s surface as energy pulses. When the pulses hit the surface of the ocean, it causes a scattering\naffect referred to as backscatter. A rough ocean surface returns a stronger signal because the waves\nreflect more of the radar energy back toward the scatterometer antenna. A smooth ocean surface\nreturns a weaker signal because less of the energy is reflected. The echo or backscatter is routed by the\nantenna to the SES through waveguides (rectangular metal pipes that guide RF energy waves from one\npoint to another). The SES then converts the signals into digital form for data processing.\n\nThe CDS is essentially a computer housing the software that allows the instrument to operate. It\nprovides the link between the command center on the ground, the spacecraft and the scatterometer. It\ncontrols the overall operation of the instrument, including the timing of each transmitted pulse and\ncollects all the information necessary to transform the received echoes into wind measurements at a\nspecific location on Earth. To locate the precise position on Earth at which the echo was collected, the\nCDS samples (for each pulse) the antenna rotational position, spacecraft time, and an estimate of the\nspacecraft position. The CDS also collects instrument temperature, operating voltages and currents, so\nthat the overall health of the instrument can be monitored. It is through the CDS that the other two\nsubsystems receive the commands that control all of their functions.\n\nThe SAS consists of a 1-m parabolic reflector antenna mounted to a spin activator assembly, which\ncauses the reflector to rotate at 18 rpm\u2019s (revolutions per minute; Fig. 5.133).\n\nThe activator assembly provides very accurate spin control and precise position or pointing\ninformation to the CDS. Optical encoders, glass disks with small patterns printed on the surface, tell\nthe CDS exactly where the antenna is pointing to about 10/1000 of a degree. The antenna spins at a\nvery precise rate, and emits two beams about 6? apart, each consisting of a continuous stream of pulses.\nThe two beams are necessary to achieve accurate wind direction measurements. The pointing of these\nbeams is precisely calibrated before launch so that the echoes may be accurately located on the ground\nfrom space.\n\nThe SeaWinds radar operated at 13.4 GHz transmitting 110W pulses at 189 Hz PRF. It weighed\n200 kg and consumed 220 Wof power during steady-state operation. The average data rate was 40 kbits/\ns. It has an 1800 km swath, which provided nearly 90% coverage of the world\u2019s ocean each day. Wind\n\n448 CHAPTER 5 RADAR\n\nhttp://winds.jpl.nasa.gov/missions/quikscat/index.cfm\nhttp://winds.jpl.nasa.gov/missions/quikscat/index.cfm\nhttp://winds.jpl.nasa.gov/aboutScat/index.cfm\nhttp://winds.jpl.nasa.gov/aboutScat/index.cfm\n\n\nspeeds between 3 and 20 m/s (for wind speeds less than 3 m/s the scatterometer winds were unreliable)\nwere accurate to 2 m/s in magnitude and \t20? in direction. The wind vector spatial resolution was\n25 km. These accuracies are similar to the wind vector accuracies measured in situ by a moored buoy.\nThe QuikSCAT satellite was a small spacecraft built by Ball Aerospace which was 3-axis stabilized\nusing a star tracker and RU reaction wheels and a C/A Code GPS. This resulted in a pointing\naccuracy <0.1? absolute per axis. Pointing knowledge was even better at <0.05? per axis. The satellite\nweighed 970 kg and could generate an average power of 874 W.\n\n5.8.4 SCATTEROMETER LIMITATIONS\nWhile scatterometer wind vector retrievals are a unique source of ocean wind vector information, they\nare not without problems. In the presence of rain wind vector estimation reliability is diminished. As\ndiscussed earlier the wind direction estimates are not unique and require some independent method of\nselecting the right direction in the face of multiple direction possibilities. Also, as discussed before, for\nwind speeds less that 3 m/s the scatterometer wind vectors are not reliable. In fact, the lower the wind\nspeed, the less reliable the wind direction estimate.\n\n5.8.5 EXAMPLES OF SCATTEROMETER MEASUREMENTS\nA good example of global SeaWinds is shown here in Fig. 5.134 where the colors indicate the wind\nspeed (as indicated by the legend on the right) and the lines denote the atmospheric circulation or the\nocean wind pattern. This is a very early result of the SeaWinds mission. Later SeaWinds images and data\nbecame very important for the mapping and monitoring of hurricanes, typhoons and tropical storms. One\nvery well-known event was hurricane Katrina that was responsible for significant devastation in the\nstates bordering the northern Gulf of Mexico. In Fig. 5.135 from Liu et al. (2008) we present the\nQuikSCAT image for Hurricane Katrina for August 28, 2005. Here the color indicates the wind\n\nFIGURE 5.133\n\nBlock diagram of the SeaWinds scatterometer.\n\n5.8 RADAR SCATTEROMETRY FOR OCEAN WIND VECTOR OBSERVATIONS 449\n\nmailto:Image of Figure 5.133|tif\n\n\nFIGURE 5.134\n\nOcean surface wind from QuikSCAT.\n\nCourtesy of NASA/JPL. From https://www.jpl.nasa.gov/spaceimages/details.php?id\u00bcPIA01346.\n\nFIGURE 5.135\n\nHurricane Katrina seen in QuikSCAT data on August 28, 2005 (Liu et al., 2008).\n\nCredits: NASA/JPL.\n\n450 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.134|tif\nhttps://www.jpl.nasa.gov/spaceimages/details.php?id=PIA01346\nhttps://www.jpl.nasa.gov/spaceimages/details.php?id=PIA01346\nmailto:Image of Figure 5.135|tif\n\n\nmagnitude as indicated by the color scale at the bottom of the image. Wind direction is indicated by the\nwhite barbs superimposed on the colors of the wind magnitudes. The eye of the hurricane is clearly\nevident both as a change in color and as the centroid of all the wind barbs in the core region of the storm.\n\nA combination of NSCATwind vectors and a visible image from the advanced very high resolution\nradiometer (AVHRR) is shown in Fig. 5.136 for typhoon Violet off the southern coast of Japan.\nNSCAT wind directions are indicated by the wind vectors and wind magnitudes are revealed both by\nthe size of the vectors and by their color. There is an excellent correspondence between the NSCAT\nwind vectors and the AVHRR cloud image.\n\nFinally, the image in Fig. 5.137 is a combination of various sampling periods of the SeaWinds\nscatterometer. Over the ocean, the colors indicate wind speed with orange as the highest wind speeds\nand blue as the lowest speeds. The white streamlines indicate the coincident wind direction. These\nwind measurements were made by SeaWinds on September 20, 1999. The large storm in the Atlantic\noff the coast of Florida is Hurricane Gert and the high wind region in the Gulf of Mexico is the\nexpression of Tropical Storm Harvey. Further west in the eastern Pacific one can see Tropical Storm\nHillary. There is also a very strong storm system in the south Atlantic approaching Antarctica.\n\nThe land portions of this image were made from four days of SeaWinds data with the aid of a\nresolution enhancement algorithm developed by Dr. David Long at Brigham Young University (BYU).\nThe lightest green areas correspond to the highest radar backscatter and indicate dense vegetation. You\ncan compare the bright Amazon and Congo rain forests to the dark Sahara desert. The Amazon River\ncan be seen as a dark line running horizontally through the bright South American rain forest. Cities\nappear as bright spots on the image particularly in the US and Europe. Greenland and the north polar\nice cap were generated from SeaWinds data collected on a single day. Here white corresponds to the\nlargest radar return while purple is the lowest. These changes in color reveal variations in the local ice\nsheet and snow cover conditions.\n\nFIGURE 5.136\n\nQuickSCAT wind vectors overlain on a visible advanced very high resolution radiometer image. Vector colors\n\nindicate wind speed as given in the color bar at the top.\n\n5.8 RADAR SCATTEROMETRY FOR OCEAN WIND VECTOR OBSERVATIONS 451\n\nmailto:Image of Figure 5.136|tif\n\n\n5.9 STUDY QUESTIONS\nA SAR operating at a central frequency of 1257.5 MHz, with a bandwidth of 80 MHz. In the ascending\npasses, the SAR is pointing to the west of the satellite\u2019s ground-track, and the swath is determined by\nincidence angles from 12? up to 45?.\n\nFIGURE 5.137\n\nComposite SeaWinds scatterometer image.\n\n452 CHAPTER 5 RADAR\n\nmailto:Image of Figure 5.137|tif\n\n\n1. Compute the maximum PRF so that there are no ambiguities (take into account Earth\u2019s\ncurvature).\n\n2. Compute the antenna dimensions (length lx and height ly).\n3. Compute the achievable spatial resolution in the azimuth direction.\n4. Compute the spatial resolution in the range direction at the edges of the swath.\n5. Assuming that s0 is not dependent with the incidence angle, which will be the difference in\n\ndecibels (ratio in linear units) between the SNRs at the edges of the swath?\n6. To have roughly square pixels, a number of consecutive pixels in the range direction can be\n\naveraged. How many of them can be averaged at the edge of the swath, and by which factor the\nSNR will improve?\n\n7. To form a 400-km long image, how long the data must be recorded so that all pixels in the image\ncan be focused to achieve the maximum azimuth resolution?\n\n8. If the complex I/Q samples are acquired at the Nyquist rate (no oversampling), and they are\nstored in 1 byte each, please compute the amount of data to be stored to form the image.\n\n9. Please provide the name and comment each of the following phenomena that occur in SAR\nimagery, making a drawing on how some representative points will appear in the SAR image.\n\n10. The scattered power is stronger in a nadir looking, a side-looking, or in a bistatic configuration.\nWhy? Does it depend on the surface roughness? And on the dielectric constant of the surface? If\nthere is vegetation on top of the surface, which phenomena will take place?\n\n5.9 STUDY QUESTIONS 453\n\n\n"}