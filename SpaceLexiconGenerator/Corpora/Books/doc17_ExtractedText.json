{"content": "\nSpace Technology Library\n\nOptimal Control \nwith Aerospace \nApplications\n\nJames M. Longuski\nJos\u00e9 J. Guzm\u00e1n\nJohn E. Prussing\n\n\n\nOptimal Control with Aerospace Applications\n\n\n\nSPACE TECHNOLOGY LIBRARY\nPublished jointly by Microcosm Press and Springer\n\nThe Space Technology Library Editorial Board\n\nManaging Editor: James R. Wertz, Microcosm, Inc., El Segundo, CA\n\nEditorial Board: Roland Dore?, Professor and Director International Space Univer-\nsity, Strasbourg\nTom Logsdon, Senior member of Technical Staff, Space Division,\nRockwell International; ret.\nF. Landis Markley, NASA, Goddard Space Flight Center; ret.\nRobert G. Melton, Professor of Aerospace Engineering, Pennsyl-\nvania State University\nKeiken Ninomiya, Professor, Institute of Space & Astronautical\nScience\nJehangir J. Pocha, Letchworth, Herts.\nRex W. Ridenoure, Jet Microcosm, Inc., Torrance\nGael Squibb, Jet Propulsion Laboratory, California Institute of\nTechnology\nMartin Sweeting, Professor of Satellite Engineering, University of\nSurrey\n\nFor further volumes:\nhttp://www.springer.com/series/6575\n\nhttp://www.springer.com/series/6575\n\n\nJames M. Longuski \u2022 Jose? J. Guzma?n\nJohn E. Prussing\n\nOptimal Control with\nAerospace Applications\n\nTTSL\nPublished jointly by\nMicrocosm Press\nEl Segundo, California\n\n123\n\n\n\nJames M. Longuski\nPurdue University\nLafayette, IN, USA\n\nJohn E. Prussing\nUniversity of Illinois\n\nat Urbana-Champaign\nUrbana, IL, USA\n\nJose? J. Guzma?n\nOrbital Sciences Corporation\nChantilly, VA, USA\n\nISBN 978-1-4614-8944-3 ISBN 978-1-4614-8945-0 (eBook)\nDOI 10.1007/978-1-4614-8945-0\nSpringer New York Heidelberg Dordrecht London\n\nLibrary of Congress Control Number: 2013949151\n\n\u00a9 Springer Science+Business Media New York 2014\nThis work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of\nthe material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation,\nbroadcasting, reproduction on microfilms or in any other physical way, and transmission or information\nstorage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now\nknown or hereafter developed. Exempted from this legal reservation are brief excerpts in connection with\nreviews or scholarly analysis or material supplied specifically for the purpose of being entered and executed\non a computer system, for exclusive use by the purchaser of the work. Duplication of this publication or\nparts thereof is permitted only under the provisions of the Copyright Law of the Publisher\u2019s location, in its\ncurrent version, and permission for use must always be obtained from Springer. Permissions for use may be\nobtained through RightsLink at the Copyright Clearance Center. Violations are liable to prosecution under\nthe respective Copyright Law.\nThe use of general descriptive names, registered names, trademarks, service marks, etc. in this publication\ndoes not imply, even in the absence of a specific statement, that such names are exempt from the relevant\nprotective laws and regulations and therefore free for general use.\nWhile the advice and information in this book are believed to be true and accurate at the date of publication,\nneither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or\nomissions that may be made. The publisher makes no warranty, express or implied, with respect to the\nmaterial contained herein.\n\nPrinted on acid-free paper\n\nSpringer is part of Springer Science+Business Media (www.springer.com)\n\nwww.springer.com\n\n\nPreface\n\nOptimal control theory has become such an important field in aerospace engineering\nthat no graduate student or practicing engineer can afford to be without a working\nknowledge of it. Unfortunately, there is no modern text which begins from scratch\nto teach the reader the basic principles of the calculus of variations, to develop the\nnecessary conditions step-by-step, and to introduce the elementary computational\ntechniques of optimal control.\n\nOur book assumes that the reader has only the usual background of an under-\ngraduate engineering, science, or mathematics program, namely, calculus, differential\nequations, and numerical integration.\n\nWe assume no other knowledge. We do not require the reader to know what calculus\nof variations is, what necessary conditions mean, nor what a two-point boundary-value\nproblem entails. It does not matter if the reader has never heard of the Euler-Lagrange\ntheorem, the Weierstrass condition, Pontryagin\u2019s Minimum Principle, or Lawden\u2019s\nprimer vector.\n\nOur goal is to provide the reader with sufficient knowledge so that he or she\ncannot only read the literature and study the next-level textbook (such as Bryson and\nHo\u2019s Applied Optimal Control) but also apply the theory to find optimal solutions in\npractice.\n\nTo accomplish the goals of this introductory text, we have incorporated a number\nof features as follows. Several theorems are presented along with \u201cproof outlines\u201d\nthat favor a heuristic understanding over mathematical rigor. Numerous rigorous\ntreatments are cited in the references and the book bibliography to support the reader\u2019s\nadvanced studies.\n\nIn presenting the Euler-Lagrange theorem, we treat two different versions which\nappear in the literature. In the first method (followed by Bryson and Ho [1975]),\nwe adjoin terminal constraints to the cost functional through the use of additional\nLagrange multipliers. We refer to this approach as the \u201cadjoined method\u201d and note\nthat it has become a sort of gold standard in the literature since the revised printing\nof Bryson and Ho\u2019s Applied Optimal Control in 1975. This approach leads to a\nform of the transversality condition which we refer to as the \u201calgebraic form.\u201d In\npublications prior to 1975, a number of authors use an approach which we refer to\n\nv\n\n\n\nvi Preface\n\nas the \u201cun-adjoined method\u201d which does not adjoin the terminal constraints to the\ncost functional and hence does not introduce any additional multipliers to be solved.\nThe un-adjoined method leads to a \u201cdifferential form\u201d of the transversality condition\nas given by Citron [1969], Hestenes [1966], Kenneth and McGill [1966], and Pierre\n[1969]. The un-adjoined method is particularly amenable to simple problems in which\nthe terminal constraints are algebraically eliminated from the transversality condition.\nEach method has its strengths and weaknesses as observed by Citron [1969], who\nis one of the few authors who discuss both methods. Introducing the reader to both\nmethods, with applications to current aerospace problems, is an important feature of\nthe present text.\n\nThroughout the book, we make use of the time-optimal launch of a satellite into\norbit as an important case study, and we provide a detailed analysis of two examples:\nlaunch from the Moon and launch from the Earth. In the Moon-launch case, we\nassume constant acceleration (from thrusters), no drag, and uniform flat-Moon gravity.\nFor Earth launch we include time-varying acceleration, drag from an exponential\natmosphere, and uniform flat-Earth gravity. Appendices A and B provide MATLAB\ncode to solve the resulting two-point boundary-value problems. In Appendix C, we\nalso set up and provide MATLAB code to solve a geocentric low-thrust transfer\nproblem.\n\nA modern approach to Lawden\u2019s primer vector theory is presented for optimal\nrocket trajectories. The important special cases of constant-specific impulse and\nvariable-specific impulse are treated in detail.\n\nAn extensive annotated book bibliography lists the references we found most useful\nin the preparation of this text. These sources range from highly pragmatic application\napproaches (for engineers) to rigorous, theoretical treatments (for mathematicians).\nThe second bibliography lists numerous papers and reports that demonstrate the vast\nrange of related aerospace applications.\n\nFinally, for the weary and the worried, we provide a few \u201cCurious Quotations\u201d\n(in Appendix D) to let the reader know that many great minds and renowned authors\nhave expressed their own concerns, often in humble and humorous ways, about the\nvast challenges that the calculus of variations and optimal control present to all of us.\n\nLafayette, IN, USA James M. Longuski\nChantilly, VA, USA Jose? J. Guzma?n\nUrbana, IL, USA John E. Prussing\n\n\n\nAcknowledgments\n\nFirst and foremost I thank Dr. William F. Powers, who taught me his graduate course\non optimization of space trajectories in the winter of 1974 when he was a professor of\naerospace engineering at the University of Michigan. Dr. Powers has had an illustrious\ncareer as a leader in the application of control theory, as a professor, as a NASA\nconsultant for the Space Shuttle, and as the vice president of research for the Ford\nMotor Company. He is a member of the National Academy of Engineering, the Royal\nSwedish Academy of Engineering Sciences, and the University of Florida Foundation\nBoard of Directors.\n\nThis book is largely based on the lecture notes I obtained from Dr. Powers, and\nI have received his permission and encouragement to flesh out those notes to form\nthe present text. I have extended the material over my years of teaching optimization\nof space trajectories. In my effort to teach and learn more about this fascinating and\nimportant subject, I have often marveled at what an excellent course Dr. Powers taught\nme. I hasten to add that any errors in the text are entirely my own\u2014and should not\nreflect in any way on Dr. Powers.\n\nI thank my colleagues, my doctoral students, the graduate and undergraduate\nstudents who took my course on Optimization in Aerospace Engineering (AAE 508),\nand the staff at Purdue University who helped in many significant ways to make the\nfinal manuscript as clear, accurate, and useful as possible.\n\nIn particular I thank Prof. Mohammad Ayoubi, Dr. Julia L. Bell, Ms. Nicole\nBryan, Ms. Erin Calderwood, Ms. Jasmine Cashbaugh, Mr. Alan Castillejo Robles, Dr.\nK. Joseph Chen, Dr. Diane Craig, Mr. Michael Croon, Ms. Ashwati Das, Ms. Meredith\nEvans, Lt. Jennifer Fuka, Mr. Giacinto Genco, Mr. Filippo Genco, Mr. Seung\nYeob Han, Mr. Adam Harden, Mr. Patrick Hayes, Mr. Evan Helmeid, Mr. Gregory\nHenning, Mr. Kyle Hughes, Mr. Junichi Kanehara, Ms. Aizhan Kinzhebayeva,\nMr. Michael Kean, Dr. Kevin Kloster, Mr. Richard Lang, Mr. Frank Laipert, Mr. Karl\nMadon, Mr. Nicholas Makarowski, Dr. Belinda Marchand, Ms. Kaela Martin (nee\nRasmussen), Dr. T. Troy McConaghy, Mr. Wesley McDonald, Prof. Ken Mease,\nMr. James Moore, Ms. Bhuvi Nirudhoddi, Dr. Jeffrey Onken, Mr. Jose? F. Paz Solda?n\nGuerra, Dr. Anastassios Petropoulos, Ms. Lucie Poulet, Mr. Blake Rogers, Mr. Saverio\nRotella, Mr. Sarag J. Saikia, Dr. Oleg Sindiy, Ms. Nissa Smith, Ms. Tracey Smith,\n\nvii\n\n\n\nviii Acknowledgments\n\nMr. Christopher Spreen, Mr. Nathan Strange, Prof. Dengfeng Sun, Prof. Steven G.\nTragesser, Prof. Brad Wall, Dr. Geoff Wawrzyniak, Ms. Rozaine Wijekularatne, Mr.\nAndy Wiratama, and Dr. Chit Hong \u201cHippo\u201d Yam.\n\nSpecial thanks go to Mr. Peter Edelman, Mr. Rob Falck, Dr. Joseph Gangestad,\nMr. Kshitij Mall, Dr. George E. Pollock IV, and Prof. Marc Williams.\n\nThanks to the Purdue physics librarians, Ms. Lil Conarroe and Ms. Donna Slone,\nfor their professionalism and their patience in helping me find important references.\nI also thank Ms. Karen Johnson, Ms. Jennifer LaGuire, and Ms. Vickie Schlene for\ntheir secretarial assistance.\n\nI thank the editorial staff at Springer for their professional and unswerving support,\nin particular Dr. Harry (J.J.) Blom, Ms. Maury Solomon, and Ms. Nora Rawn. Thanks\nalso to my friend and colleague, Dr. James R. Wertz of Microcosm Press for co-\npublishing our book.\n\nFinally my most grateful thanks to my wife and best friend, Holly, for her\nunwavering support, her enthusiastic encouragement, and especially for her love.\n\nI apologize to any contributor I should have acknowledged\u2014please let me know\nwho you are so I can thank you in a future edition.\n\nJ.M. Longuski\n\n\n\nAcknowledgments ix\n\nIt is often difficult for the working engineer to use calculus of variations (COV) in\nthe normal course of business. We hope that this book makes that process easier and\nfaster for problems amenable to the application of COV. For example, for continuous\nthrust-steering systems encountered during powered ascent (launch), powered descent\n(landing), and low-thrust trajectories, COV can provide a great set of tools for the\nmission analyst. The material presented in this book and in the extensive list of\nreferences will guide the engineer in using the theory for practical problems. Perhaps\nmore importantly, the practicing engineer could use this book to understand the\nsoftware tools available for trajectory optimization and to provide these software\ntools with initial approximations that will speed up the convergence process. I would\nlike to thank the professors that inspired me to pursue trajectory optimization: Dr.\nKathleen C. Howell, Dr. James M. Longuski, Dr. Stephen J. Citron, and Dr. Martin J.\nCorless. I would like to thank a.i. solutions (Mr. Daryl Carrington, Mr. Jeff Dibble,\nDr. Conrad Schiff, Dr. Ariel Edery, Dr. Peter Demarest, and Mrs. Laurie Mann\n(nee Mailhe)) and NASA Goddard Space Flight Center (Mr. David Folta, Mr. Mark\nBeckmnan, Mr. Steven Cooley, and Mr. Steven Hughes) all with whom I worked and\ndiscussed many challenging optimization problems. I would like to thank the Johns\nHopkins Applied Physics Laboratory (APL) for providing funding under the Stuart\nS. Janney program (spring 2005). This funding allowed the development of some\nof the numerical work and illustrations in the book. Also at APL, I would like to\nthank Dr. Robert W. Farquhar, Dr. David W. Dunham, Mr. Peter J. Sharer, Mr. James\nT. Kaidy, Dr. J. Courtney Ray, Dr. Uday Shankar, and Dr. Thomas E. Strikwerda\nfor invaluable discussions on mission design, trajectory optimization, and attitude\ncontrol. While at APL, I also had a chance to work with Mr. Jerry L. Horsewood\nfrom SpaceFlightSolutions. Working with Jerry allowed me to understand some of the\nfiner points of low-thrust trajectory optimization. Also, many thanks to Dr. Gregory\nChirikjian and Dr. Joseph Katz from the Johns Hopkins University and to Dr. Chris\nD. Hall from Virginia Tech for part-time teaching opportunities at their respective\ninstitutions. I would like to thank Orbital Sciences and Dr. James W. Gearhart for\nproviding a challenging work environment and great applied problems to work on.\nFinally, I\u2019d like to thank my wife, Natalia, and my daughter, Sofia, for their love and\npatience.\n\nJ.J. Guzma?n\n\n\n\nx Acknowledgments\n\nFirst, my thanks to three giants in the field of spacecraft trajectory optimization:\nJohn V. Breakwell, Theodore N. Edelbaum, and Derek F. Lawden. They had profound\ninfluences on my education and my career.\n\nProf. Breakwell\u2019s pioneering 1959 article The Optimization of Trajectories\nlaunched the sustained exploration of that field in the USA. I was fortunate to know\nJohn and interact with him at conferences. Ted Edelbaum was my doctoral thesis\nresearch advisor, even though he did not have a PhD and was not at that time affiliated\nwith MIT. He started me on an interesting and productive lifelong journey. Prof.\nLawden\u2019s 1963 book Optimal Trajectories for Space Navigation was for many years\nthe only book in the field and it inspired many to apply and extend his results through\nthe 1960s, continuing to this day. I was fortunate to correspond with Derek after his\nretirement in England.\n\nI also thank my colleagues in the field, my doctoral and master\u2019s thesis students,\nand all the students who took optimal control theory from me and those who took my\nsecond-level graduate course Optimal Space Trajectories, offered every other year\nsince 1988 and continuing in my retirement. (What a great way to \u201cflunk retirement!\u201d)\nTheir observations and comments have been invaluable, and Chap. 10 in this book is\nbased on that course and on my research over the years.\n\nFinally, my heartfelt thanks to my wife, Laurel, currently Mayor of Urbana, Illinois,\nfor her steadfast support over our 48 years together.\n\nJ.E. Prussing\n\n\n\nAbout the Authors\n\nJames M. Longuski, PhD\nAfter completing his doctoral dissertation, Analytic Theory of Orbit Contraction and\nBallistic Entry into Planetary Atmospheres, at The University of Michigan in 1979,\nDr. Longuski (lo?ng-gu?s\u2019-ske?.) worked at the Jet Propulsion Laboratory as a Maneuver\nAnalyst and as a Mission Designer.\n\nIn 1988 he joined the faculty of the School of Aeronautics and Astronautics at\nPurdue University where he teaches courses in astrodynamics, trajectory optimization,\nand spacecraft and mission design. Dr. Longuski is coinventor of a \u201cMethod of\nVelocity Precision Pointing in Spin-Stabilized Spacecraft or Rockets\u201d and is an\nAssociate Fellow of the American Institute of Aeronautics and Astronautics (AIAA).\n\nDr. Longuski has published over 200 conference and journal papers in the area\nof astrodynamics on topics that involve designing spacecraft trajectories that explore\nthe Solar System and a new idea to test Einstein\u2019s General Theory of Relativity.\nHe also coauthored several papers with Dr. Buzz Aldrin on a human Earth-to-Mars\ntransportation system, known as the \u201cAldrin Cycler\u201d.\n\nHe has published two other books, Advice to Rocket Scientists (AIAA, 2004) and\nThe Seven Secrets on How to Think Like a Rocket Scientist (Springer, 2007). In 2008\nDr. Longuski was inducted into Purdue University\u2019s Book of Great Teachers.\n\nxi\n\n\n\nxii About the Authors\n\nJose? J. Guzma?n, PhD\nDr. Guzma?n obtained his Aeronautical and Astronautical Engineering BS, MS and\nPhD degrees from Purdue University. He joined a.i. solutions in 2001 and was a\nmember of the NASA\u2019s Wilkinson Microwave Anisotropy Probe (WMAP) trajectory\ndesign and maneuver team. WMAP is the first spacecraft to be stationed in the vicinity\nof the Sun-Earth L2 point for its complete science mission duration. The trajectory\nincluded Earth phasing loops (highly eccentric orbits) with maneuvers that boosted\nthe spacecraft to lunar orbit distance. A lunar flyby was then performed to insert the\nspacecraft into a Lissajous orbit.\n\nFrom 2004 to 2009, Dr. Guzma?n was a senior member of the technical staff at the\nJohns Hopkins University Applied Physics Laboratory (APL). At APL, he enjoyed\nworking on low-thrust trajectories to comets and on lunar mission studies. He was\nalso in the trajectory design and analysis team for the STEREO (Solar TErrestrial\nRElations Observatory) mission. STEREO is the first mission to use Earth phasing\nloops and lunar swingbys for two spacecraft simultaneously. The paper \u201cSTEREO\nTrajectory and Maneuver Design,\u201d written by Dr. David W. Dunham, Dr. Guzma?n,\nand Mr. Peter Sharer in the Johns Hopkins APL Technical Digest, 28(2):104\u2013125, won\nthe 2009 Walter G. Berl Award for Outstanding Paper in the APL Technical Digest.\n\nDr. Guzma?n is currently a principal senior engineer at Orbital Sciences Corpora-\ntion. At Orbital he has worked on the mission design and planning for cargo missions\nto the International Space Station. Dr. Guzma?n has also helped with several orbit\ntransfers to the Geosynchronous belt and has provided expertise for proposals and\nnew business opportunities.\n\nDr. Guzma?n is a member of the American Astronautical Society and a senior\nmember of the American Institute of Aeronautics and Astronautics. He has been a\nlecturer at The Johns Hopkins University and the Virginia Polytechnic Institute and\nState University and has served as associate editor for The Journal of the Astronautical\nSciences.\n\n\n\nAbout the Authors xiii\n\nJohn E. Prussing, ScD\nDr. Prussing received his SB, SM, and ScD degrees in aerospace engineering from\nMIT, culminating in his 1967 doctoral thesis, Optimal Multiple-Impulse Orbital\nRendezvous. He accepted a postdoctoral position at the University of California at\nSan Diego and in 1969 joined the faculty of aerospace engineering at the University\nof Illinois at Urbana-Champaign. His primary teaching and research areas are\nastrodynamics, optimal control theory, and optimal spacecraft trajectories.\n\nPrussing is a Fellow of the American Institute of Aeronautics and Astronautics\n(AIAA), a Fellow of the American Astronautical Society (AAS), and has received the\nAIAA Mechanics and Control of Flight Award and the AAS Dirk Brouwer Award for\nhis research contributions. His research has been referenced in 62 archival journals in\nEnglish, and also in Russian, Chinese, French, and Portuguese journals.\n\nIn 1993 Prussing and Bruce A. Conway published their textbook Orbital Mechan-\nics (Oxford University Press), which is available in 300 public and university libraries\nworldwide and is in its second edition.\n\n\n\nAdvance Praise for\nOPTIMAL CONTROL WITH AEROSPACE APPLICATIONS\n\nOptimal Control with Aerospace Applications fills a huge void between Derek\nLawden\u2019s dated but classic 1963 text, Optimal Trajectories for Space Navigation and\nthe exhaustive, and exhausting, treatment in Applied Optimal Control by Bryson and\nHo. Modern in its approach and in its treatment of applications, this thorough but very\naccessible text is destined to become an instant classic.\n\nMichael D. Griffin, Ph.D.\nNASA Administrator 2005\u20132009\nAuthor (with James R. French) of Space Vehicle Design\n\nThis book represents a new approach to the teaching of optimal control theory; it is\nmuch more accessible than extant texts but does not omit any of the important subjects.\nThe critical theorems are accompanied with proofs but these are clearly presented\nand explained. The classic, historical examples are included but many new solved\nproblems, especially relevant to space trajectory optimization, are also included. As a\n\u201cbonus\u201d it also has the most complete list of relevant books and journal articles that\nI\u2019ve ever seen collected in one source.\n\nBruce A. Conway. Ph.D.\nProfessor of Aerospace Engineering\nUniversity of Illinois at Urbana-Champaign\nCo-author of Orbital Mechanics\nEditor of Spacecraft Trajectory Optimization\n\nOptimal Control with Aerospace Applications is a clear and concise treatment of\noptimal control theory and its application to spacecraft trajectories. The authors use\na conversational tone to successfully explain the challenging mathematics behind\noptimal control and therefore demystify the associated theorems and necessary\nconditions. This textbook updates the classic optimal-control examples (such as\nlaunch trajectories and orbit transfers) by presenting the practical issues associated\nwith their numerical solution and by providing the MATLAB code to obtain their\nnumerical solution. I found this textbook to be an excellent introduction to optimal\ncontrol theory which I believe will serve the student as well as the practicing engineer.\n\nCraig A. Kluever, Ph.D.\nC.W. LaPierre Professor\nMechanical and Aerospace Engineering\nUniversity of Missouri-Columbia\n\n\n\nAn instant neo-classic on the calculus of variations for the rocket scientist! Scratch\nthat. The optimization of space trajectories starts here!\n\nI. Michael Ross, Ph.D.\nAuthor of A Primer on Pontryagin\u2019s Principle in Optimal Control\n\nThis is a long-overdue text that comprehensively covers optimal control as applied\nto aerospace vehicle (i.e., aircraft and spacecraft) trajectories, replacing the combined\nclassical treatises by Lawden, Vinh and Marec. The authors cover the essential topics\nand applications in this field with a unique combination of rigor and readability that\nis generally lacking in optimal control texts. I intend to use this book in my graduate-\nlevel optimal trajectories class.\n\nDaniel J. Scheeres, Ph.D.\nA. Richard Seebass Endowed Chair Professor\nDepartment of Aerospace Engineering Sciences\nThe University of Colorado\nAuthor of Orbital Motion in Strongly Perturbed Environments: Applications to\nAsteroid, Comet and Planetary Satellite Orbiters\n\nThis book is an introductory treatment of optimal control (particularly with regard\nto aerospace vehicles), presenting the essence of a highly mathematical subject in\na simplified and easily understood manner. The book is clearly written, focuses on\npractical applications, and includes numerous examples. It can serve quite effectively\neither as a first textbook on aerospace optimal control for those who will later explore\nthis field in greater depth or as the only textbook for those interested just in gaining\nsome exposure to this area.\n\nLincoln J. Wood, Ph.D.\nDr. Wood is currently a Principal Engineer at the Jet Propulsion Laboratory, California\nInstitute of Technology\n\n\n\n\n\nContents\n\n1 Parameter Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 Introduction .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Parameter Optimization with Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n\n1.2.1 Lagrange Multipliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2.2 Parameter Optimization: The Hohmann Transfer (1925) . . . 5\n1.2.3 Extensions of the Hohmann Transfer (1959) .. . . . . . . . . . . . . . . 10\n1.2.4 The Bi-parabolic Transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n\n1.3 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\nReferences .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n\n2 Optimal Control Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.1 Optimal Launch of a Satellite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.2 General Form of the Problem .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.3 The Problems of Bolza, Lagrange, and Mayer . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n2.3.1 Transformation from Lagrange to Mayer. . . . . . . . . . . . . . . . . . . . 27\n2.3.2 Transformation from Mayer to Lagrange.. . . . . . . . . . . . . . . . . . . 27\n\n2.4 A Provocative Example Regarding Admissible Functions .. . . . . . . . . . 28\n2.5 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n2.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\nReferences .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n\n3 The Euler-Lagrange Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.1 The Variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.2 The Euler-Lagrange Equation and the Brachistochrone Problem .. . . 41\n3.3 The Euler-Lagrange Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n\n3.3.1 Proof Outline of the Euler-Lagrange Theorem .. . . . . . . . . . . . . 46\n3.3.2 Summary of the Euler-Lagrange Theorem . . . . . . . . . . . . . . . . . . 52\n3.3.3 Alternate Form of the Transversality Condition . . . . . . . . . . . . 52\n\n3.4 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n3.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\nReferences .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n\nxvii\n\n\n\nxviii Contents\n\n4 Application of the Euler-Lagrange Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n4.1 Introduction .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n4.2 Two-Point Boundary-Value Problem (TPBVP) . . . . . . . . . . . . . . . . . . . . . . . 61\n4.3 Two Approaches to Terminal Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n4.4 Transversality Condition .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n\n4.4.1 Case 1 Final Time Specified . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n4.4.2 Case 2 Final State Specified. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n4.4.3 Case 3 Final Endpoint Specified . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n\n4.5 General Case of Supplying Needed B.C.s . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n4.5.1 Adjoined Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n4.5.2 Un-adjoined Method.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n\n4.6 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n4.7 A \u201cCookbook\u201d for Optimization Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n\n4.7.1 Examples of Step 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n4.8 Constant Hamiltonian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n4.9 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n4.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n\n5 The Weierstrass Condition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n5.1 Introduction .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n5.2 Statement of the Weierstrass Necessary Condition . . . . . . . . . . . . . . . . . . . 95\n5.3 Proof Outline of the Weierstrass Necessary Condition .. . . . . . . . . . . . . . 96\n5.4 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n5.5 True or False Quiz for Chaps. 1\u20135 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n\n6 The Minimum Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n6.1 Statement of the Minimum Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n\n6.1.1 Problem Statement. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n6.1.2 Pontryagin\u2019s Minimum Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n6.1.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n\n6.2 Legendre-Clebsch Necessary Condition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\n6.3 Notes on Necessary and Sufficient Conditions . . . . . . . . . . . . . . . . . . . . . . . 112\n6.4 Weak and Strong Extremals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n6.5 An Example of a Weak but Not Strong Minimum .. . . . . . . . . . . . . . . . . . . 116\n6.6 Second-Order Necessary and Sufficient Conditions .. . . . . . . . . . . . . . . . . 121\n6.7 Examples Illustrating the Concept of a Conjugate Point . . . . . . . . . . . . 122\n6.8 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n6.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n\n7 Some Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n7.1 Aircraft Performance Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n\n\n\nContents xix\n\n7.2 Maximization of the Range of a Rocket. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\n7.2.1 Integration of Equations of Motion When f Is Constant . . . . 145\n7.2.2 The Optimal Trajectory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\n7.2.3 Maximum Range Equation .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n\n7.3 Time Optimal Launching of a Satellite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\n7.3.1 Integration of the EOMs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\n7.3.2 TPBVP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\n7.3.3 Flat-Earth Launch Including Atmospheric Drag . . . . . . . . . . . . 157\n\n7.4 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\n7.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\nReferences .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\n\n8 Weierstrass-Erdmann Corner Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n8.1 Statement of the Weierstrass-Erdmann Corner Conditions.. . . . . . . . . . 167\n8.2 Proof Outline of Weierstrass-Erdmann Corner Conditions.. . . . . . . . . . 168\n8.3 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\nReferences .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\n\n9 Bounded Control Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\n9.1 Optimal Control Problems with Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . 175\n9.2 Examples of Bounded Control Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176\n9.3 Singular Arcs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\n9.4 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190\n9.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190\nReferences .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\n\n10 General Theory of Optimal Rocket Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n10.1 Introduction .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n10.2 Equations of Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n10.3 High and Low-Thrust Engines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n10.4 Cost Functionals for Rocket Engines.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n10.5 First-Order Necessary Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\n\n10.5.1 Optimal Constant Specific Impulse Trajectory .. . . . . . . . . . . . . 198\n10.5.2 Optimal Impulsive Trajectory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\n10.5.3 Optimal Variable Specific Impulse Trajectory . . . . . . . . . . . . . . 204\n\n10.6 Optimal Trajectories in a Uniform Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\n10.7 Summary.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\n10.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\n10.9 True or False Quiz for Chaps. 6\u201310 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\nReferences .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\n\nAppendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\nA Time-Optimal Lunar Ascent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\n\nA.1 MATLAB\u2019s Two-Point Boundary-Value Solver . . . . . . . . . . . . 215\nA.2 Solution Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\nA.3 MATLAB Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217\n\n\n\nxx Contents\n\nB Time-Optimal Launch of a Titan II . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\nB.1 Scaling the TPBVP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\nB.2 Solution Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\nB.3 Results. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\nB.4 MATLAB Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n\nC Optimal Low-Thrust LEO to GEO Circular Orbit Transfer . . . . . . . . . . 234\nC.1 Optimization Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\nC.2 Scaling the Equations of Motion .. . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\nC.3 Applying the Euler-Lagrange Theorem . . . . . . . . . . . . . . . . . . . . . 237\nC.4 Boundary Conditions and the TPBVP . . . . . . . . . . . . . . . . . . . . . . . 238\nC.5 Results. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\nC.6 MATLAB Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\n\nReference .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\nD Curious Quotations .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\n\nBibliography (Books) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249\n\nBibliography (Aerospace Applications Papers and Reports) . . . . . . . . . . . . . . . . . . 255\n\nIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\n\n\n\nChapter 1\n\nParameter Optimization\n\n1.1. Introduction\n\nTwo major branches of optimization are: parameter optimization and optimal control\ntheory. In parameter optimization (a problem of finite dimensions, that is, where the\nparameters are not functions of time) we minimize a function of a finite number of\nparameters. We only provide an overview of parameter optimization in this chapter,\nsince the main topic of this book is optimal control theory. Optimal control (a problem\nof infinite dimensions where the parameters are functions of time) seeks x(t), an\nn-vector, that minimizes something called a functional, which will be defined in\nChap. 2.\n\nParameter optimization, the theory of ordinary maxima and minima, is based on\ncalculus. In general, the (unconstrained) problem could be stated as:\nFind:\n\nx\n\nto minimize:\n\nJ = f (x) (1.1)\n\nwhere J is the scalar cost function or index of performance and x is a constant n-vector.\nIf the xi are independent and all the partial derivatives of f are continuous, then a\n\nstationary solution, x?, is determined by\n\n? f\n?xi\n\n= 0, i = 1, 2, 3, . . . , n (1.2)\n\nEquation (1.2) is a necessary condition for an extremum (a maximum or a\nminimum). We note that f can be maximized by minimizing ?f.\n\nThe stationary point x? is a local minimum if the matrix formed by the components,\n?2f\n?xi?xj (evaluated at x\n\n?), is a positive-definite matrix, which provides a sufficient\ncondition for a local minimum. To ensure that the matrix is well defined, all the second\npartials of f must be continuous.\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 1,\n\u00a9 Springer Science+Business Media New York 2014\n\n1\n\n\n\n2 Chapter 1. Parameter Optimization\n\nf\n\nx2\n\nx1 minimum\nFigure 1.1. The minimum of a function where x is a 2-vector.\n\nIn Fig. 1.1 we illustrate an example where x is a 2-vector. In this case, for\nmin f(x1, x2), the necessary and sufficient conditions are:\n\n? f\n?x1\n\n= 0 (1.3a)\n\n? f\n?x2\n\n= 0 (1.3b)\n\nand\n\n[\n?x1 ?x2\n\n]\n?\n?\n\n?2f\n?x1?x1\n\n?2f\n?x1?x2\n\n?2f\n?x2?x1\n\n?2f\n?x2?x2\n\n?\n?\n??????\nx?\n\n[\n?x1\n?x2\n\n]\n> 0 (1.4)\n\nwhere ?x1 and ?x2 are infinitesimal arbitrary displacements (variations) from x?1 and\nx?2. The inequality must hold for all ?x1, ?x2 ?= 0 (then by definition the matrix is\npositive definite). For the 2 \u00d7 2 matrix, Eq. (1.4) is satisfied if both of the leading\nprincipal minors are positive:\n\n?2f\n?x1?x1\n\n> 0 (1.5a)\n\n\n\n1.2. Parameter Optimization with Constraints 3\n\n?2f\n?x1?x1\n\n?2f\n?x2?x2\n\n?\n[\n\n?2f\n?x1?x2\n\n]2\n> 0 (1.5b)\n\nwhere the left-hand side of Eq. (1.5b) is the determinant of the matrix in Eq. (1.4).\nWe note that we can write the \u201cvariation\u201d:\n\n?J =\n? f\n?x1\n\n?x1 + \u00b7 \u00b7 \u00b7 + ? f\n?xn\n\n?xn (1.6)\n\nfor an infinitesimal, arbitrary displacement ?x and conclude that at a stationary point\n(i.e., Eq. (1.2)): ?J = 0. In the general case when x is an n-vector, the matrix (formed\nby ?\n\n2f\n?xi?xj ) is positive definite if all n of the leading principal minors are positive.\n\n1.2. Parameter Optimization with Constraints\n\nTo include constraints in the optimization problem, it is necessary to describe them\nalgebraically. For example, to describe the condition that a point (x1, x2) is constrained\nto lie on a circle of radius R and centered at the origin, we write\n\nx21 + x\n2\n2 ? R2 = 0 (1.7)\n\nThis statement can be generalized as follows. The n variables x1, x2, . . . , xn may be\nsubject to certain relations, called constraints, of the form:\n\n?1(x1, . . . , xn) = 0\n... (1.8)\n\n?m(x1, . . . , xn) = 0\n\nwith m < n so there are n ? m independent variables. Of course if m = n then the\nproblem is so constrained that there is only one possible solution (or there may be no\nsolution) and we have no optimization problem.\n\n1.2.1. Lagrange Multipliers\n\nThe n variables x1, x2, . . . , xn can be treated as if they are \u201cindependent\u201d by introducing\na set of m constants ?1, ?2, . . . , ?m, called Lagrange multipliers. With the Lagrange\nmultipliers we can couple the constraints to the cost function. Explicitly, we consider\nthe augmented function, F:\n\nF(x1, . . . , xn, ?1, . . . , ?m) = J + ?1?1 + . . . + ?m?m (1.9)\n\nAs long as the xi satisfy the constraints (?j = 0), a stationary value of J corresponds to\na stationary value of F. We are led to a problem of unconstrained optimization, ?F = 0,\n\n\n\n4 Chapter 1. Parameter Optimization\n\nwhere:\n\n?F\n?x1\n\n= 0\n\n... (1.10)\n?F\n?xn\n\n= 0\n\n?F\n??1\n\n= ?1 = 0\n\n... (1.11)\n?F\n??m\n\n= ?m = 0\n\nThus, there are n + m equations and n + m unknowns (n x\u2019s and m ?\u2019s). Introducing\nm more unknowns (the ?j) seems counterproductive. In principle we could solve the\nconstraints?j = 0 for m of the xi, leaving only n?m of the xi to be solved for. However,\nthe resulting equations\u2014while fewer\u2014are in practice usually more complicated than\nEqs. (1.10) and (1.11), so it is easier to solve the n + m equations.\n\nExample 1.1 Application of Lagrange multipliers.\n\nDetermine the rectangle of maximum perimeter that can be inscribed in a unit circle.\nLet the center of the circle lie at (x, y) = (0, 0) and locate the corners of the rectangle\nat (\u00b1x, \u00b1y). The problem is to minimize\n\nJ = f (x, y) = ?4(x + y) (1.12)\n\nsubject to the constraint\n\n?(x, y) = x2 + y2 ? 1 = 0 (1.13)\n\nTo solve the problem using the Lagrange multiplier method we construct the aug-\nmented function F:\n\nF(x, y, ?) = f (x, y) + ? ?(x, y)\n\n= ?4(x + y) + ? (x2 + y2 ? 1) (1.14)\n\nThe first-order necessary conditions are\n\nFx =\n?F\n?x\n\n= ?4 + 2?x = 0 (1.15)\n\n\n\n1.2. Parameter Optimization with Constraints 5\n\nFy =\n?F\n?y\n\n= ?4 + 2?y = 0 (1.16)\n\nand the constraint\n\nF? =\n?F\n??\n\n= x2 + y2 ? 1 = 0 (1.17)\n\nwhere we introduce the subscript notation for partial derivatives. Equations (1.15)\u2013\n(1.17) are easily solved to yield\n\nx? = y? =\n?\n\n2\n2\n\n(1.18)\n\n? = 2\n?\n\n2 (1.19)\n\nwhere Eq. (1.18) indicates that the rectangle of maximum perimeter is a square.\nTo check that our stationary solution (x?, y?) = (\n\n?\n2\n\n2 ,\n?\n\n2\n2 ) is a minimum we note\n\nthat there are two variables and one constraint, leaving one free variable. Arbitrarily\nchoosing y as the free variable, we calculate the constrained second derivative of our\nfunction (see Sect. 1.3 of Bryson and Ho [1975]):\n\n(\n?2f\n?y2\n\n)\n\n?=0\n= Fyy ? Fyx??1x ?y ? ?y??1x Fxy + ?y??1x Fxx??1x ?y (1.20)\n\n= 4\n?\n\n2 ? 0 ? 0 + 4?2 = 8?2 > 0\n\nThis constrained second derivative being positive (positive definite in the multi-\ndimensional case) satisfies the sufficient condition for a minimum of J, resulting in\na maximum perimeter of 4\n\n?\n2.\n\n1.2.2. Parameter Optimization: The Hohmann Transfer (1925)\n\nAs an important example in parameter optimization, we present the Hohmann transfer.\nIn 1925, Walter Hohmann introduced a two-impulse scheme to transfer a spacecraft\nfrom a lower circular orbit to a higher circular orbit. (In 1960, NASA published\na Technical Translation, NASA TT F-44 of Hohmann\u2019s original work titled, \u201cThe\nAttainability of Heavenly Bodies.\u201d See Hohmann [1960].) In Soviet literature the\ntransfer is sometimes referred to as the Hohmann-Vetchinkin transfer orbit to credit\nthe Russian mathematician who presented lectures on the transfer in the early 1920s.\n(See Ulivi and Harland [2007].)\n\nThe assumptions Hohmann made were:\n\n1. There is a central gravitational field that obeys Newton\u2019s law, F = G(Mm)/r2,\nwhere F is the force of gravity, G is Newton\u2019s universal constant, M is the mass\nof the central body, m is the mass of the spacecraft, and r is the distance from the\ncenter of the central body to the spacecraft.\n\n\n\n6 Chapter 1. Parameter Optimization\n\nrf\n\nro\n\n?Vf\n\n?Vo\n\nFigure 1.2. General two-impulse transfer geometry from one coplanar circular orbit to\nanother. In this case ?Vo and ?Vf are not necessarily tangent to the orbits.\n\n2. The thrust level is unlimited, therefore the change of velocity can be instantaneous.\nThis is known as the impulsive?V assumption. Only two impulsive?V maneuvers\nare allowed; together they must minimize the propellant consumed during the orbit\ntransfer.\n\n3. The initial and final orbits are circular and coplanar.\n\nFigure 1.2 depicts the two impulsive ?V\u2019s: the initial ?Vo at radial distance ro and\nthe final ?Vf at radial distance rf. We note that Fig. 1.2 illustrates the general case, not\nthe Hohmann transfer.\n\nThe ?V\u2019s could be oriented arbitrarily in space. A more general problem allows for\nmultiple ?V\u2019s, which if extended to large numbers could approximate a continuous\nthrusting problem.\n\nBy fixing the number of impulses, the problem is reduced to one of parameter\noptimization. The Hohmann transfer is a two-impulse, time-free (i.e., unconstrained\nduration) transfer between circular, coplanar orbits. Therefore, the problem can be\nstated as:\n\nMinimize:\n\nJ = |?Vo| +\n???Vf\n\n?? (1.21)\n\n\n\n1.2. Parameter Optimization with Constraints 7\n\n?Vf\n\n?Vo\n\nro\n\nrf\n\nFigure 1.3. Hohmann transfer, in which ?Vo and ?Vf are tangential to the circular orbits\nat ro and rf , respectively, and are 180\n\n? apart.\n\nsubject to:\n\n?1(?Vxo,?Vyo,?Vxf,?Vyf) = Vxf = 0 (1.22a)\n\n?2(?Vxo,?Vyo,?Vxf,?Vyf) = Vyf ? Vcf = 0 (1.22b)\n\nwhere ?Vxo and ?Vyo are the components of the initial impulsive ?V along the\nradial and tangential directions, respectively. Likewise, the subscript f corresponds\nto the final impulsive ?V. The velocity components Vxo, Vyo, Vxf, and Vyf are defined\nsimilarly; Vco and Vcf are circular speeds at ro and rf, respectively. Equations (1.22a)\nand (1.22b) merely state that the final orbit (of Fig. 1.2) must be circular. We note that\nminimizing the sum of the ?V magnitudes provides the minimum-propellant cost (as\ndiscussed in Prussing and Conway [2013]).\n\nBy parameter optimization, it can be shown (see Prussing and Conway [2013]) that\nJ is minimized when\n\n?Vxo = ?Vxf = 0 (1.23)\n\ni.e., all impulses are tangential (as shown in Fig. 1.3).\n\n\n\n8 Chapter 1. Parameter Optimization\n\nTo calculate ?Vyo and ?Vyf for the Hohmann transfer we start from an initial\ncircular orbit of radius ro. We know the circular speed from\n\nVco = Vo =\n?\n?\n\nro\n(1.24)\n\nwhere ? = GM and where the mass of the spacecraft is neglected. We wish to end up\non a final circular orbit of radius rf. Again, we know the required speed\n\nVcf =\n?\n?\n\nrf\n(1.25)\n\nThe Hohmann transfer is achieved by performing a thruster burn at ro for a change\nof velocity,?Vo. This maneuver places the spacecraft on an elliptical orbit which has\na periapsis speed of\n\nVp = Vo +?Vo (1.26)\n\nat radius ro and an apoapsis speed of\n\nVa = Vf (1.27)\n\nat radius rf, both of which are unknown. We do, of course, know the circular speed of\nthe final orbit from Eq. (1.25):\n\nVcf =\n?\n?\n\nrf\n= Vf +?Vf (1.28)\n\nbut Vf and ?Vf are, so far, unknown. We note that when apoapsis is reached, a ?Vf\nmust be performed to circularize the orbit (at rf). Our problem is to find?Vo and?Vf.\nWe have two unknowns so we need two equations to solve for them.\n\nThe problem can be solved by determining the transfer orbit. To do this, we\nuse two equations corresponding to the conservation of angular momentum and\nthe conservation of total mechanical energy. From conservation of specific angular\nmomentum we have:\n\nro(Vo +?Vo) = rfVf (1.29)\n\nso that\n\nVf = (ro/rf)(Vo +?Vo) (1.30)\n\nFrom conservation of specific energy we have:\n\n1\n2\n\n(Vo +?Vo)2 ? ?ro =\n1\n2\n\nV2f ?\n?\n\nrf\n(1.31)\n\n\n\n1.2. Parameter Optimization with Constraints 9\n\nwhere the left hand side of Eq. (1.31) gives the energy at periapsis, while the right hand\nside gives the energy at apoapsis. Next, we substitute the expression for Vf, Eq. (1.30),\ninto Eq. (1.31):\n\n1\n2\n\n(Vo +?Vo)2 ? ?ro =\n1\n2\n\n(\nro\nrf\n\n)2\n(Vo +?Vo)2 ? ?rf (1.32)\n\nBy solving for the unknown, Vo +?Vo, in Eq. (1.32):\n\n1\n2\n\n(Vo +?Vo)2\n(\n\n1 ? r\n2\no\n\nr2f\n\n)\n=\n?\n\nro\n? ?\n\nrf\n(1.33)\n\nwe obtain\n\nVo +?Vo =\n\n????2\n(\n?\n\nro\n? ?\n\nrf\n\n)( r2f\nr2f ? r2o\n\n)\n(1.34)\n\nNoting that\n\n(\n1\nro\n\n? 1\nrf\n\n)( r2f\nr2f ? r2o\n\n)\n=\n\nrf\nro\n\n1\n(rf + ro)\n\n(1.35)\n\nwe have, from Eq. (1.34):\n\nVo +?Vo =\n\n?\n2?\n\nrf\nro\n\n1\n(rf + ro)\n\n(1.36)\n\nSubstituting for Vo from Eq. (1.24) into Eq. (1.36), we obtain the solution for ?Vo:\n\n?Vo =\n\n?\n2?rf\n\nro(rf + ro)\n?\n\n?\n?\n\nro\n\n=\n?\n?\n\nro\n\n(?\n2rf\n\nrf + ro\n? 1\n\n)\n(1.37)\n\nWe can find ?Vf from Eq. (1.28), but first we must find Vf from Eqs. (1.30) and\n(1.36):\n\nVf =\nro\nrf\n\n(Vo +?Vo) =\nro\nrf\n\n?\n2?\n\nrf\nro\n\n1\n(rf + ro)\n\n(1.38)\n\n\n\n10 Chapter 1. Parameter Optimization\n\nso that\n\nVf =\n\n?\n2?\n\nro\nrf\n\n1\n(rf + ro)\n\n(1.39)\n\nFrom Eqs. (1.28) and (1.39):\n\n?Vf =\n?\n?\n\nrf\n? Vf\n\n=\n?\n?\n\nrf\n?\n\n?\n2?\n\nro\nrf\n\n1\n(rf + ro)\n\n(1.40)\n\nSo we have the solution for?Vf:\n\n?Vf =\n?\n?\n\nrf\n\n(\n1 ?\n\n?\n2ro\n\nrf + ro\n\n)\n(1.41)\n\n1.2.3. Extensions of the Hohmann Transfer (1959)\n\nIn the Hohmann transfer, only two impulses are applied. Can the total cost (?V) be\nreduced with more impulses? Edelbaum [1967] discusses extensions of the Hohmann\ntransfer such as the bi-parabolic and bi-elliptic transfers and other minimum-\npropellant, impulsive transfers. In 1959 three articles appeared independently by\nEdelbaum, Hoelker and Silber, and Shternfeld which showed that if the radius ratio\nrf/ro is sufficiently large, other transfers exist which require less propellant than the\nHohmann transfer.\n\nThese other transfers are based on the three-impulse, bi-elliptic transfer shown in\nFig. 1.4. Now, in addition to the two?Vs employed by the Hohmann transfer, we have\nan intermediate?V performed at a radial distance, ri. The value of ri is typically much\nlarger than the outer circular orbit. We can imagine the limiting case where ri ? ?\nso that ?V ? 0 to achieve any desired periapsis value rf. This case is referred to as a\nbi-parabolic transfer.\n\nUsually we assume that rf > ro so that we have the following interpretation of\nFig. 1.4:\n\n1. ?Vo is applied tangentially and forward (to increase the velocity).\n2. ?V is applied tangentially and forward (to increase the velocity).\n3. ?Vf is applied tangentially and backwards (to decrease the velocity).\n\nWhen we have the problem of transferring from an initial larger orbit to a final\nsmaller orbit, then rf < ro and Fig. 1.4 can be interpreted by \u201crunning time backwards\u201d\nso that the orbits run clockwise. In this case, the three ?Vs have the same values as\nbefore, but we are now interpreting rf to be the initial radius and ro to be the final\n\n\n\n1.2. Parameter Optimization with Constraints 11\n\nro\n\n?Vf\n\n?V\n\n?Vo\nrf\n\nriSecond elliptic arc First elliptic arc\n\nFigure 1.4. Three-impulse, bi-elliptic transfer from circular orbit of radius ro to circular\norbit of radius rf . If ri is large enough, the total ?V cost can be less than that\nof the Hohmann transfer depending on the ratio rf /ro.\n\nradius of the circular orbits. A similar interpretation can be made for the Hohmann\ntransfer when the initial orbit is the larger orbit.\n\nNow, let us summarize what is known about the Hohmann and the bi-elliptic\ntransfers, i.e., which is more economical depending on the ratio ? = rf/ro. Here we\nassume that rf > ro and note that both the bi-elliptic and bi-parabolic are three-impulse\ntransfers.\n\n1 < ? < 11.94 The Hohmann transfer is the most economical.\n11.94 < ? < 15.58 A bi-elliptic transfer is more economical if ri (the radius\n\nof the intermediate?V) is sufficiently large.\nThe bi-parabolic transfer provides the lowest cost,\nbut is impractical. (See Sect. 1.2.4.)\n\n\n\n12 Chapter 1. Parameter Optimization\n\nro\n\n?Vf\n\n?Vo\nrf\n\nparabolic\narc\n\nparabolic arc\n\nSecond\n\nFirst\n\nFigure 1.5. The limiting case of the bi-elliptic transfer is the bi-parabolic transfer, in which\nthe ?V at an infinite distance is infinitesimally small. The solution is not\nconsidered a true minimum since it requires an infinite transfer time.\n\n15.58 < ? Any bi-elliptic transfer for which ri > rf is more\neconomical than a Hohmann transfer. The bi-parabolic\ntransfer provides the lowest cost.\n\nThe bi-elliptic transfer is significantly more advantageous for a non-coplanar\ntransfer and is an interesting example of a minimum-propellant transfer that requires\nmore impulses than are necessary to satisfy the boundary conditions. (See Prussing\nand Conway [2013].)\n\n1.2.4. The Bi-parabolic Transfer\n\nThe bi-parabolic transfer (Fig. 1.5) is the limiting case of a bi-elliptic transfer as ri ?\n?. It consists of two finite impulses, ?Vo and ?Vf, and a third infinitesimal ?V at\n\u201cinfinity\u201d which facilitates the transfer from the first parabola to the second parabola.\n\nThis transfer is of no practical use since the transfer duration is infinite. However,\nfor 11.94 < ? and ri large enough, a bi-elliptic transfer can be found that is better than\na Hohmann but worse than a bi-parabolic transfer.\n\n\n\n1.3. Exercises 13\n\n1.3. Exercises\n\n1. Find the minimum of f (x) = x2.\n2. Let f (x) = x4. Is f (0) = 0 the minimum value? Is the second-order sufficient\n\ncondition for a minimum satisfied? What can you conclude from this example?\n3. The rocket equation is\n\n?V = c ln m?\n\nwhere?V is the change in velocity, c is the effective exhaust velocity, and\n\nm? = mo/mbo\n\nis the ratio of initial mass to burnout mass. We note that c is related to specific\nimpulse, Isp, by\n\nc = Ispg\n\nwhere g is standard free fall:\n\ng ? 9.80665 m/s2\n\nAssume that the burnout mass consists of the structural mass of the stage, ms,\nand the payload mass, P:\n\nmbo = ms + P\n\nAlso, the initial mass is the burnout mass plus the propellant mass, mp:\n\nmo = mbo + mp = P + ms + mp\n\nThe structural factor, ?, is defined as\n\n? =\nms\n\nmp + ms\n\nwhich is the mass ratio of the empty stage (structure alone) to the loaded stage\n(propellant plus structure). Note that this implies that\n\nms = ?(mo ? P)\n\n3a. Derive an equation which provides the ratio of the initial mass, mo, to the\npayload mass, P:\n\nmo/P = f (?V, c, ?)\n\n\n\n14 Chapter 1. Parameter Optimization\n\nMake sure your final solution contains only ?V, c, and ? on the right hand\nside.\n\n3b. In order to launch a payload from the surface of the Earth to Mars, the ?V\nis approximately 11.6 km/s. Assuming the Isp is 300 s and ? is 0.100, will the\nrocket be able to achieve the required velocity? Explain your answer.\n\n3c. If ? = 0.0100 and all other values are the same, what is the mass ratio mo/P?\n3d. Is ? = 0.0100 a practical value for the structural factor? (That is, does it\n\ncorrespond to launch vehicles being used today? Give an example.)\n3e. If the answer to 3 is no, how can the payload be launched to Mars?\n\n4. The rocket equation for a multistage rocket of N stages is\n\n?VTOT =\nN?\n\ni =1\nci ln m?i (1.42)\n\nwhere?VTOT is the total velocity change, ci is the effective exhaust velocity of the\nith stage, and m?i = (mo/mbo)i is the mass ratio of the ith stage.\n\nOur goal is to find the mass ratios, m?i, which minimize the overall mass ratio,\nmo1/P:\n\nMin J =\nmo1\nP\n\n(1.43)\n\nwhere mo1 is the takeoff mass, P is the payload mass, and where ?VTOT is given\n(as the final constraint). We will assume that the ci and ?i are given parameters of\nthe problem.\n\nWe note that\n\nmo1\nP\n\n=\n(\n\nmo1\nmo1 ? mp1 ? ms1\n\n)(\nmo2\n\nmo2 ? mp2 ? ms2\n)\n\n\u00b7 \u00b7 \u00b7 moN\nP\n\n(1.44)\n\nwhere the mass of the second stage is\n\nmo2 = mo1 ? mp1 ? ms1 (1.45)\n\nwhere mp1 is the propellant mass of the first stage and ms1 is the structural mass\nof the first stage. An example of the nomenclature is illustrated for a three-stage\nrocket in Fig. 1.6.\n\n4a. Show that if\n\nm?i =\nmoi\n\nmoi ? mpi (1.46)\n\nand\n\n?i =\nmsi\n\nmpi + msi\n(1.47)\n\n\n\n1.3. Exercises 15\n\nms3\n\nms2\n\nmp1\n\nms1\n\nmp2\n\nmp3\n\nP\n\nmo2\n\nmo1\n\nFigure 1.6. Nomenclature applied to 3-stage rocket: P is the payload mass, mo1 is the total\nmass at takeoff, mp1 is the mass of propellant in first stage, ms1 is the mass of\nstructure in first stage, mo2 is the total mass at ignition of second stage after\ndropping first stage, and N is number of stages, three.\n\nwhere ?i are the structural factors, then the ratios in Eq. (1.44) can be written as\n\nmoi\nmoi ? mpi ? msi =\n\nm?i(1 ? ?i)\n1 ? m?i?i (1.48)\n\nThus, Eq. (1.45) can be put in the form\n\nmo1\nP\n\n=\nm?1(1 ? ?1)\n(1 ? m?1?1)\n\nm?2(1 ? ?2)\n(1 ? m?2?2) \u00b7 \u00b7 \u00b7\n\nm?N(1 ? ?N)\n(1 ? m?N?N) =\n\nN?\ni =1\n\nm?i(1 ? ?i)\n1 ? m?i?i (1.49)\n\n\n\n16 Chapter 1. Parameter Optimization\n\n4b. To minimize mo1/P, we may also minimize ln(mo1/P), so we can write\n\nMin J =\nN?\n\ni =1\nln\n\n[\nm?i(1 ? ?i)\n(1 ? m?i?i)\n\n]\n\n=\nN?\n\ni =1\n[ln m?i + ln(1 ? ?i) ? ln(1 ? m?i?i)] (1.50)\n\nEquation (1.50), by itself, does not contain the constraint imposed by the\nspecified velocity as given by Eq. (1.42). Following the Lagrange multiplier\napproach (in Sect. 1.2.1), we write\n\nMin J = ln\nmo1\nP\n\n=\nN?\n\ni =1\n{ln m?i + ln(1 ? ?i) ? ln(1 ? m?i?i) + ?[ci ln m?i ??VTOT]} (1.51)\n\nIn Eq. (1.51) we have multiplied the constraint equation (ci ln m?i ??VTOT = 0)\nby a constant, ?, which is equivalent to adding zero to the equation.\n\nUse the differentiation process given in Eqs. (1.10) and (1.11) to obtain\n\nm?i =\n1 + ?ci\n?ci?i\n\n(1.52)\n\n4c. We see that by substituting Eq. (1.52) into Eq. (1.42) that\n\n?VTOT =\nN?\n\ni =1\nci ln\n\n(\n1 + ?ci\n?ci?i\n\n)\n(1.53)\n\nWe can solve for the constant, ?, since?VTOT, ci, and ?i are known. The value\nof ? determines the mass ratios, m?i, of each stage by Eq. (1.52). Show that for\nthe special case where all the ci (specific impulses) are the same\n\nm?i =\n1\n?i\n\nexp\n\n[\n1\nN\n\n(\n?VTOT\n\nc\n+\n\nN?\ni =1\n\nln ?i\n\n)]\n(1.54)\n\n(Here we are assuming that c1 = c2 = \u00b7 \u00b7 \u00b7 = cN = c and thus ?Ni =1 ci = Nc. We\nalso note that ln\n\n(\n1\n\nci?i\n\n)\n= ln\n\n(\n1\nci\n\n)\n? ln ?i.)\n\n4d. Show that if ci and ?i are the same for each stage, the optimal mass ratios, m?i,\nare\n\nm?i = exp[?VTOT/(Nc)] (1.55)\n\n\n\nReferences 17\n\n4e. A two-stage rocket must attain a maximum speed of 7,925 m/s with Isp = 300 s\nfor both stages and ?1 = ?2. Determine the mass ratio of each stage (m?1, m?2)\nto minimize mo1/P.\n\n4f. For 4e, determine the propellant mass per stage in terms of the initial mass of\nthe stage. Also determine the structural factors ?i, assuming msi = 0.15moi,\nand show that the optimal overall mass ratio is mo1/P = 82.6.\n\n4g. In designing a two-stage rocket for a maximum speed of 7,925 m/s, assume\nthat Isp = 250 s for both stages and ?1 = 0.180 and ?2 = 0.150. Show that it is\ncapable of boosting a payload of 0.00169 mo1.\n\n5. In solving the following orbit transfer problems, put all of your solutions in terms\nof the ratios: ? ? rf/ro and ?VTOT/??/ro. Simplify your algebraic results to the\nmost compact form.\n\n5a. Describe the Hohmann transfer between circular coplanar orbits and derive\na formula for the total velocity change, ?VTOT = ?Vo + ?Vf. Assume that\nrf ? ro.\n\n5b. Derive a formula for?VTOT for the bi-parabolic transfer.\n5c. Make a plot of ?VTOT/\n\n?\n?/ro versus ? showing both types of transfer. Let\n\n1 ? ? ? 40.\n5d. For what values of ? is the bi-parabolic transfer more economical?\n\n6. Determine the rectangle of maximum area with a specified perimeter, p. Use\na Lagrange multiplier to incorporate the perimeter constraint and apply the\nconditions of Sect. 1.2.1.\n\n7. A spacecraft approaches a planet on a hyperbolic trajectory with a given V? (that\nis, the specific energy is 12 V\n\n2?). A ?V is to be applied at an unspecified periapsis\nradius rp to capture the spacecraft into a circular orbit. Assume the ?V is applied\nalong the velocity vector at periapsis and determine the value of rp that minimizes\n?V in terms of V? and the gravitational parameter, ?.\n\nReferences\n\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing Corporation, Washing-\nton, DC, 1975)\n\nT.N. Edelbaum, How many impulses? Astronautics and Aeronautics 5, 64\u201369 (1967). (now named\nAerospace America)\n\nW. Hohmann, Die Erreichbarkeit der Himmelsko?rper (1925) (The attainability of heavenly bodies).\nNASA Technical Translation F-44, National Aeronautics and Space Administration, Washington,\nDC, Nov 1960\n\nJ.E. Prussing, B.A. Conway, Orbital Mechanics, 2nd edn. (Oxford University Press, New York, 2013)\nP. Ulivi, D.M. Harland, Robotic Exploration of the Solar System (Springer, New York, 2007)\n\n\n\nChapter 2\n\nOptimal Control Theory\n\n2.1. Optimal Launch of a Satellite\n\nWe start this chapter with what might be called the fundamental trajectory optimiza-\ntion problem: launching a satellite into orbit. Before setting up the mathematical model\nfor this problem, let us first discuss in words what the problem entails.\n\nIt is very expensive to launch a satellite into orbit about the Earth because of the\ntremendously high speed required to achieve a low circular orbit. The lowest energy\norbit must be high enough above the sensible atmosphere to avoid immediate dissi-\npation of its energy and subsequent orbit decay and reentry. The lowest \u201csustainable\u201d\norbit is about 160 km (100 miles) above the Earth\u2019s surface. At this altitude the satellite\nmust travel at 7.9 km/s (5 miles/s) to stay in circular orbit. In its final flight in 2011,\nthe cost of reaching circular orbit with the United States Space Shuttle was about\n$22,000/kg ($10,000/lb). So if we can save a few kilograms on the way into orbit, we\ncan save a lot of money.\n\nLet\u2019s consider what our choices are in launching a satellite into circular orbit. To\nmake things easier, we will cheat a little and ignore atmospheric drag during launch.\nLet us also assume that the launch vehicle has a predetermined amount of propellant\nand that it burns the propellant at a constant rate. Then, if the specific impulse is\nconstant, the thrust of the engine, F, is constant. To further simplify, we assume the\nrocket has a single stage. (There is, of course, a great advantage to staging the engines,\nbut that is a parameter optimization problem as discussed in the exercises in Chap. 1.)\n\nLet us also assume: the Earth is not rotating (so we do not get a boost from\nthe rotation), the circular orbit plane contains the launch site (so there is no out-of-\nplane dog-leg maneuver), the Earth is flat (we tip our hats to the Flat Earth Society),\nand the acceleration due to gravity is a constant equal to standard free fall (i.e.\ng = 9.80665 m/s2).\n\nOne might well ask, \u201cWhat is there left to do?\u201d It turns out that we have one control\nvariable. In Fig. 2.1, we illustrate our flat-Earth problem of launching a satellite into\ncircular orbit. The orbital plane is in the xy plane, and the altitude we wish to achieve\ncorresponds to a radial distance from the center of the Earth, rc. The one control\nvariable we have is the steering angle of the thrust, ?.\n\nConsider what happens when a rocket is launched into orbit. First, the rocket lifts\noff the pad and rises vertically, which corresponds to a steering angle of 90?. Then, as\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 2,\n\u00a9 Springer Science+Business Media New York 2014\n\n19\n\n\n\n20 Chapter 2. Optimal Control Theory\n\nrc\n\nF\n?\n\ng\n\ny\n\nx\n\nFigure 2.1. Problem of finding the steering law, ?(t), to maximize satellite mass.\n\nthe rocket achieves higher altitudes, it begins to pitch over so that ? is less than 90?.\nEventually, the rocket is traveling with ? near zero (or even negative to cancel upward\nmomentum).\n\nHere we note that actual launches from the Earth have to contend with air drag so\nthat ? remains near 90? longer than would be necessary if there were no atmosphere.\nIn launching astronauts from the Moon, the steering angle ? approached zero (and\nbelow) much more rapidly, because there was no atmosphere to clear (just high lunar\nmountains).\n\nThe time function ?(t) could follow an infinite number of profiles that would\nachieve circular orbit. For every steering profile, there is a corresponding path of the\nrocket given by x(t) and y(t).\n\nOur problem is to find ?(t) such that the maximum payload is delivered into a\nprescribed circular orbit. We are maximizing final mass, which for a constant burn\nrate means we are minimizing the time to get into orbit. If we minimize the time for a\ngiven burn rate, we minimize the propellant burned. Our infinite-dimensional problem\nis: find the steering law, ?(t), which is a function of time (an infinite number of points)\nto minimize the final time to orbit, tf.\n\nExample 2.1 Launch into circular orbit.\n\nWe assume that at the initial time, to, we know the position and velocity components,\nxo, yo, vxo, and vyo. However, we do not know the final time, tf, nor the final value, xf,\nbut we do know the final velocity components vxf = vc and vyf = 0, which are specified\nfor the circular orbit at the known altitude, yf = rc ? rEarth, where rEarth is the radius of\nthe Earth.\n\n\n\n2.1. Optimal Launch of a Satellite 21\n\nThe mass of the rocket is\n\nm(t) = mo + m?o(t ? to) (2.1)\n\nwhere m?o is a negative constant.\nFor our \u201cflat-Earth\u201d problem in Fig. 2.1, the governing differential equations are\n\nx? = vx (2.2a)\n\ny? = vy (2.2b)\n\nv?x =\nF\nm\n\ncos? (2.2c)\n\nv?y =\nF\nm\n\nsin ? ? g (2.2d)\n\nwhere Eqs. (2.2c) and (2.2d) are from Newton\u2019s second law. In our problem we must\nfind ?(t) to minimize the time.\n\nNext, we introduce standard nomenclature from the literature. We write state\nvariables as:\n\nx1 = x (2.3a)\n\nx2 = y (2.3b)\n\nx3 = vx (2.3c)\n\nx4 = vy (2.3d)\n\nFor our control variable we use:\n\nu = ? (2.4)\n\nUsing vector notation (indicated by bold) we can write our differential equations,\nEqs. (2.2), and initial conditions as follows:\n\nx? = f(t, x, u) (2.5a)\n\nx(to) = xo (2.5b)\n\nwhere x and f are 4-vectors in this problem (and n-vectors in general).\nFor our final boundary conditions, we have the components\n\n\t1 ? x2(tf) ? rc + rEarth = 0 (2.6a)\n\t2 ? x3(tf) ? vc = 0 (2.6b)\n\t3 ? x4(tf) = 0 (2.6c)\n\n\n\n22 Chapter 2. Optimal Control Theory\n\n?(t)\n\nt\ntf\n\nFigure 2.2. A possible steering law for minimum time to orbit.\n\nor\n\n?(tf, xf) = 0 (2.7)\n\nwhere ? is a 3-vector (q-vector in general).\nFor the cost functional (or performance index) to be minimized we have:\n\nJ = tf (2.8)\n\nwhich minimizes the time (and maximizes the payload). Figure 2.2 shows a repre-\nsentative plot of the optimal steering law. Sometimes the steering law can look that\nsimple. In Chap. 3 we develop the theory and in Chap. 4 we apply the theory to find\nsuch control laws.\n\n2.2. General Form of the Problem\n\nThe general form for the optimal control problem is expressed as:\n\nMinimize:\n\nJ = ?(tf, xf) +\n? tf\n\nto\nL(t, x, u)dt (2.9)\n\nsubject to:\n\nx? = f(t, x, u) (2.10a)\n\nx(to) = xo (2.10b)\n\nu ? U (2.10c)\n?(tf, xf) = 0 (2.10d)\n\nwith a possible state variable inequality constraint:\n\nS(x) ? 0 (2.11)\n\n\n\n2.2. General Form of the Problem 23\n\nHere U is the set of admissible controls, which we will discuss later, and S(x) ? 0\nis an inequality constraint which, for example, may require a spacecraft or aircraft to\nnever fly below the surface of the Earth.\n\nAt this point it is useful to formalize our notation according to standard notation.\nLower case letters in bold denote a vector\n\nx =\n\n?\n??????\n\nx1\nx2\n...\n\nxn\n\n?\n??????\n\n(2.12)\n\nA superscript T indicates the transpose of a vector or matrix:\n\nxTy = x1y1 + x2y2 + \u00b7 \u00b7 \u00b7 + xnyn (2.13)\n\nso that xTy represents the scalar product of vectors x and y.\nThe gradient of a scalar function, J, is defined to be a row vector:\n\n???J = Jx = ?J\n?x\n\n=\n[\n?J\n?x1\n\n?J\n?x2 \u00b7 \u00b7 \u00b7 ?J?xn\n\n]\n\n=\n[\nJx1 Jx2 \u00b7 \u00b7 \u00b7 Jxn\n\n] (2.14)\n\nThe second derivative of a scalar function with respect to vector arguments is:\n\nJxy =\n?\n\n?y\n(JTx)\n\n=\n\n?\n???\n\n?2J\n?x1?y1\n\n?2J\n?x1?y2 \u00b7 \u00b7 \u00b7 ?\n\n2J\n?x1?ym\n\n...\n?2J\n\n?xn?y1 \u00b7 \u00b7 \u00b7 ?\n2J\n\n?xn?ym\n\n?\n???\n\n(2.15)\n\nExample 2.2 The brachistochrone problem.\n\nIn 1696, Johann Bernoulli posed and solved the brachistochrone problem (see Bell\n[1965]). He originally created the problem as a challenge to his brother, Jacob, who\nalso solved it. Figure 2.3 illustrates the problem. The xy plane is vertical, in a uniform\ngravity field, where the x axis points downward in a uniform gravity field. A particle\nof mass m is placed (motionless) on a frictionless track that connects the origin to\na given point (xf, yf). The shape of the track, y = y(x), must be found such that the\nparticle takes the shortest time to travel from the origin to (xf, yf). A straight line (i.e.,\na ramp) does not provide the quickest trajectory.\n\n\n\n24 Chapter 2. Optimal Control Theory\n\n(xo, yo)\n\nx\n\nmg (xf, yf)\n\ny\n\nFigure 2.3. The brachistochrone problem: find y = y(x) to minimize the time for the particle\nto slide in the vertical plane from (xo, yo) to (xf , yf ). Note that the straight line\nsolution is not the minimum-time path\n\nIn fact, the fastest trajectory starts with a steeper slope than the ramp to gain speed\nearly and the extra speed more than makes up for the longer path. Since the initial\nspeed of the particle is zero and it falls in a uniform gravity field, its velocity is known\nfrom the conservation of total mechanical energy:\n\nv =\n?\n\n2gx (2.16)\n\nThe infinitesimal distance, ds along the track can be given as\n\nds =\n?\n\n(dx)2 + (dy)2 =\n?\n\n1 + (dy/dx)2 dx =\n?\n\n1 + y?2 dx (2.17)\n\nThus, the time to travel from x = 0 to x = xf is:\n\nt =\n? xf\n\n0\n\n?\n1 + y?2?\n\n2gx\ndx (2.18)\n\nThe problem is to find the path, y = y(x), to minimize the time given by\nEq. (2.18). This problem of quickest descent baffled the mathematicians of Europe\nfor 6 months. Eventually several correct solutions were sent to Johann Bernoulli\nincluding an anonymous one from Isaac Newton, who solved the problem in one day.\nUpon receiving Newton\u2019s solution, Bernoulli exclaimed, \u201ctanquam ex ungue leonem,\u201d\nloosely translated by Bell [1965] as \u201cI recognize the lion by his paw print!\u201d\n\nIt turns out that the solution is a cycloid, but much more important results ensued.\nThe general problem could be written as\n\nJ =\n? xf\n\nxo\nF[y(x), y?(x), x]dx (2.19)\n\n\n\n2.3. The Problems of Bolza, Lagrange, and Mayer 25\n\nwhere J is a scalar, F is known, but y(x) is unknown. The general problem is to find\ny(x) that makes J stationary (such that small changes in y(x) make no change in J).\nThis was a new type of problem. How does one go about finding y(x)? How can we\nsolve for an entire function?\n\nIt was discovered that y(x) must satisfy the Euler-Lagrange equation:\n\n?F\n?y\n\n? d\ndx\n\n(\n?F\n?y?\n\n)\n= 0 (2.20)\n\nEquation (2.20) is a differential equation, and we know how to solve this type of\nproblem. Solving a differential equation is tantamount to finding a function, which can\nbe very difficult if the equation is nonlinear. [The derivation of Eq. (2.20) is given in\nSect. 3.2.]\n\nThe brachistochrone problem led to a more general optimization problem and to\na field of mathematics called the calculus of variations. The problem of launching a\nsatellite into orbit is closely related to the brachistochrone problem. For the launch\nproblem we must find the trajectory x(t), y(t) which gives the shortest time to orbit.\nThe launch problem is an example of an optimal control problem in which we must\nfind the steering law, ?(t), to minimize the time.\n\nJohann Bernoulli\u2019s discovery also led to the realization that dynamical motion\nobeys Lagrange\u2019s equations. That is, the functional\n\nJ =\n? tf\n\nt0\nL dt (2.21)\n\nhas a stationary value. The integrand, L, in Eq. (2.21) is referred to as the Lagrangian,\nwhich is equal to the difference between the kinetic and potential energies of the\nsystem.\n\nThis idea is known as Hamilton\u2019s principle which indicates that nature obeys\nan optimization principle. Such concepts occupied the minds of mathematicians\nand philosophers for several centuries. (For more information see the enthusiastic\npresentation given by Lanczos [1986]).\n\n2.3. The Problems of Bolza, Lagrange, and Mayer\n\nThroughout this text, we will be mainly concerned with the Problem of Bolza:\n\nMinimize:\n\nJ = ?(tf, xf) +\n? tf\n\nto\nL(t, x, u)dt (2.22)\n\n\n\n26 Chapter 2. Optimal Control Theory\n\nsubject to:\n\nx? = f(t, x, u) System or Process Equations (2.23a)\n\nx(to) = xo Initial Conditions (I.C.s) (2.23b)\n\n?(tf, xf) = 0 Terminal Constraints (2.23c)\n\nwhere,\n\nx is an n-vector\n\nu is an m-vector\n\n? is a q ? n vector\n\nand J is the scalar cost to be minimized. (See Bolza [1961], Bryson and Ho [1975], and\nHull [2003].) The scalar J is called a functional because it maps functions [the path\nx(t) and control u(t)] into a single number. The functional is also called the cost index,\nthe performance index, or sometimes the cost function (though cost functional is more\nprecise). As we have seen, typical examples for J are the propellant used to launch\na spacecraft into orbit or the time for a particle to travel between points. Besides the\nProblem of Bolza, there are two other forms that appear in the literature.\n\nIn the Problem of Lagrange we have:\n\nMinimize:\n\nJ =\n? tf\n\nto\nL(t, x, u)dt (2.24)\n\nsubject to the same conditions as the Problem of Bolza.\nEquation (2.24) consists of what is sometimes referred to as the \u201cpath cost\u201d which\n\nis the same form as we saw in the brachistochrone problem [Eq. (2.19)]. We will find\nthis integral form useful when we explore the effect of variations of the path x and\nthe control u from the optimal, which will lead us to the Euler-Lagrange equation,\nEq. (2.20). In Eq. (2.24) the integrand, L, is called the Lagrangian. (We note for those\nfamiliar with Lagrangian dynamics that the integrand of Eq. (2.24) is more general\nand may have nothing to do with dynamics.)\n\nIn the Problem of Mayer we have:\n\nMinimize:\n\nJ = ?(tf, xf) (2.25)\n\nsubject to the same conditions as the Problem of Bolza.\nEquation (2.25) is sometimes called the \u201cterminal cost.\u201d It has the same form as\n\nEq. (2.8) where we considered the problem of minimizing the final time to launch a\nsatellite into orbit.\n\n\n\n2.3. The Problems of Bolza, Lagrange, and Mayer 27\n\nExample 2.3 Interchangeability of forms.\n\nThe three forms (Bolza, Lagrange, and Mayer) are equally general and interchange-\nable. (See Bliss [1968], Hull [2003], and Vagners [1983].) As a trivial example,\nconsider:\n\nMayer: Min. J = tf (2.26)\n\nLagrange: Min. J =\n? tf\n\n0\ndt (2.27)\n\nBolza: Min. J =\n1\n2\n\ntf +\n1\n2\n\n? tf\n0\n\ndt (2.28)\n\n2.3.1. Transformation from Lagrange to Mayer\n\nLet us consider in general how to transform the Problem of Lagrange into the Problem\nof Mayer. In the Problem of Lagrange we have:\n\nMinimize:\n\nJ =\n? tf\n\nto\nL(t, x, u)dt (2.29)\n\nLet us define a new variable with zero initial condition:\n\nx?n+1 = L(t, x, u) (2.30a)\n\nxn+1(to) = 0 (2.30b)\n\nSince xn+1(t) =\n? t\n\nto L(t, x, u)dt + xn+1(to), the problem becomes:\n\nMinimize:\n\nJ = xn+1(tf) (2.31)\n\nwhich is in Mayer form.\n\n2.3.2. Transformation from Mayer to Lagrange\n\nNext we show how to transform a Mayer problem into a Lagrange problem. For the\nProblem of Mayer we have:\n\nMinimize:\n\nJ = ?(tf, xf) (2.32)\n\n\n\n28 Chapter 2. Optimal Control Theory\n\nTo transform Eq. (2.32) into a Lagrange problem we write:\n\nMinimize:\n\nJ =\n? tf\n\nto\n\nd?(t, x)\ndt\n\ndt (2.33a)\n\nsubject to:\n\n?(to, xo) = 0 (2.33b)\n\n2.4. A Provocative Example Regarding Admissible Functions\n\nExample 2.4 Admissible functions.\n\nIn this example we demonstrate how the class of functions being considered (for the\nstate and the control) can affect the optimal solution we obtain.\n\nMinimize:\n\nJ =\n? 3\n\n0\nx2dt (2.34)\n\nsubject to:\n\nx? = u (2.35a)\n\nx(0) = 1 (2.35b)\n\n?(tf, xf) = x(3) ? 1 = 0 (2.35c)\n\nwhere x and u are scalars.\nProblem: Determine u(t) ? P.C. [0,3] which causes x(t) ? C0 [0,3].\nThat is, our problem is to find a scalar control, u(t), that is piecewise continuous\n\nover the closed time interval from t0 = 0 to tf = 3 such that x(t) is continuous over the\nsame time interval and such that Eq. (2.34) is minimized. The problem turns out to be\na trick question, because there is no such control.\n\nThe point of this example is to emphasize the importance of the class of functions\nwe are considering. The class of functions that we allow can have a dramatic effect on\nthe solutions we obtain. For example, in Chap. 1 where we considered two impulsive\n?V maneuvers for orbit transfer between two circular coplanar orbits, we had the\nHohmann transfer to minimize the total ?V. However, when we allowed three\nimpulses, we found it sometimes provided a lower total ?V. Thus the type of control\nthat we permit (i.e., what we call an admissible control) can affect the optimal solution.\n\nA nice aspect of the problem we are now considering is that we don\u2019t need any\ntheorems from optimal control to understand the problem. We can deduce all of our\nresults by inspection. Upon examining the cost functional of Eq. (2.34), we see that\n\n\n\n2.4. A Provocative Example Regarding Admissible Functions 29\n\nx\n\nt0 3\n\nu(t) = 0\n\n1\n\ngo to 90 degrees\n\nFigure 2.4. A provocative example regarding admissible functions. As the slope of x\napproaches vertical, the cost, Eq. (2.34), decreases until the slope is vertical\nwhen the control consists of Dirac delta functions\n\nthe value of x must be as close to zero as possible over the time interval. However,\nfrom the initial and final conditions [Eqs. (2.35b) and (2.35c)] the value of x must be\nunity at t = 0 and tf = 3.\n\nFigure 2.4 illustrates the solution for u(t) ? 0 where x(t) ? 1 is indicated by a\ndotted line. Clearly this is not the optimal. We note in the figure that if the value of x\nslopes downward near t = 0 and upward near tf = 3 then the value for J will be small.\nIf we consider the extreme case then x will discontinuously drop to zero at t0 = 0 and\nwill discontinuously jump to unity at tf = 3. This corresponds to the 90? case indicated\nin Fig. 2.4.\n\nIf we allow these discontinuities then x(t) will not be a continuous function as we\noriginally assumed. Furthermore, u(t) will not be a piecewise continuous function,\nbut will instead appear as illustrated in Fig. 2.5, where we represent a Dirac delta\nfunction by the vertical arrows. On the other hand, if we allow the slope of x(t) to\napproach 90? at the initial and final times, but to not actually reach 90?, then x(t) will\nbe continuous and u(t) will be piecewise continuous. However, no optimal solution\nexists within these classes of functions because for any given slope near 90? there is\nalways a steeper slope which gives a lower cost. When no unique solution exists, the\nproblem has no optimal solution for the given class of functions.\n\nWe now provide more formal definitions of some classes of functions.\nPiecewise Continuous: x(t) ? P.C. [to, tf\n\n]\nif x(t) is continuous at each open\n\nsubinterval and if x? has finite limits at the ends of the intervals. (See Fig. 2.6.)\nm Continuously Differentiable: x(t) ? Cm [to, tf\n\n]\nif all derivatives of x(t) of order\n\n? m exist and are continuous. We note that Cm ? Cm?1 and that C1 ? C0 ? P.C.\nIn Fig. 2.7, we show an example where x is continuous (x ? C0) and x? is piecewise\n\ncontinuous (x? ? P.C.). The point on x with the jump is called a corner; the class is also\nreferred to as piecewise smooth.\n\n\n\n30 Chapter 2. Optimal Control Theory\n\nu(t) = x?\n\n0 3 t\n\nFigure 2.5. The control for Fig. 2.4, u(t) = x?(t). The downward and upward arrows represent\nDirac delta functions, ??(t) and ?(t ? 3), which are considered inadmissible.\n\nx(t)\n\nto tf t\n\nFigure 2.6. An example of a piecewise continuous function\n\nThe Dirac delta (or unit impulse) function has the properties:\n\n?(t) = 0 ? t ?= 0 (2.36)\n\nthat is, the delta function is zero for all time not equal to zero and\n? ?\n\n??\n?(t)dt = 1 (2.37)\n\nThis function has no definitive value at t = 0. According to Kaplan [1962], \u201c. . .no\nordinary function can have the properties mentioned. The situation is similar to that\nencountered in algebra: The equation x2 = ?1 can be satisfied by no real number.\n\n\n\n2.4. A Provocative Example Regarding Admissible Functions 31\n\nx\n\nt\n\nx?\n\nt\n\nContinuous\n\nPiecewise\nContinuous\n\nFigure 2.7. An example of a continuous function, x ? C0, and its derivative which is\npiecewise continuous, i.e. x? ? P.C. Continuous functions that have corners\n(discontinuous jumps in slope) are also called piecewise smooth\n\nHence we invent an \u2018imaginary number i\u2019 which has this property: i2 = ?1. In the\nsame way we invent an \u2018imaginary\u2019 or \u2018ideal\u2019 function ?(t) to have the properties\nabove.\u201d Kaplan goes on to develop a class of generalized functions that include ?, ??,\n??? etc. There is no mechanical way to generate such generalized functions and so they\nare not considered admissible.\n\nNow, let us reconsider our problem given in Eqs. (2.34) and (2.35) in which we\nimpose a new condition: |u| ? 1. Then, the solution shown in Fig. 2.8 is obtained\nwhere x(t) ? C0[0, 3] and u(t) ? P.C.[0, 3], which is admissible. We have achieved\nour goal by simply adding a constraint on the control.\n\n\n\n32 Chapter 2. Optimal Control Theory\n\nx(t)\n\nu(t) = x?\n\nt\n\nt\n\nt = 1 t = 2 t = 3\n\nFigure 2.8. By limiting the magnitude of u: |u| ? 1, an admissible control to minimize\nEq. (2.34) can be found\n\nNext we consider yet another version of our problem. Suppose for some physical\nor mechanical reason that P.C. functions are inadmissible for the control. We assume\nin this case that u ? C0 is admissible.\n\nLet us define the following state and control variables:\n\nx1 = x (2.38a)\n\nx2 = u (2.38b)\n\nu? = u? (2.38c)\n\n\n\n2.4. A Provocative Example Regarding Admissible Functions 33\n\nx?1 x2\n\nt t\n\nx1 x3\n\nto t1 tf t to t1 tf t\n\nFigure 2.9. Example of classes of functions: ?(t ? t1), P.C., C0, and C1 over [to, tf ].\n\nand recalling from Eq. (2.35) that x? = u we obtain\n\nx?1 = x2 (2.39a)\n\nx?2 = u? (2.39b)\n\nBy constraining |u?| ? k (the slope of u), and |x2| ? 1 (the slope of x1), we keep\nu ? C0[0, 3].\n\nExample 2.5 Classes of functions.\n\nIn the following example let\n\nx?1 = ?(t ? t1) for to ? t ? tf (2.40a)\nx?2 = f(x1) (2.40b)\n\nx?3 = f(x2) (2.40c)\n\nwhere f ? C?[to, tf], which means that f is continuous (infinitely continuously\ndifferentiable) for all partial derivatives. What class is each of x1, x2, and x3?\n\nWe can most easily visualize the solution by letting f(x) = x in Eq. (2.40). Then\nFig. 2.9 shows plots of x?1, x1, x2, and x3 and we have the result that\n\n\n\n34 Chapter 2. Optimal Control Theory\n\ny\n\nx\n\nV\n?\n\nFigure 2.10. Zermelo\u2019s problem: a boat crosses a river in minimum time using ? as a control\nwhile V is a constant magnitude.\n\nx1(t) ? P.C.[to, tf] (2.41a)\nx2(t) ? C0[to, tf] (2.41b)\nx3(t) ? C1[to, tf] (2.41c)\n\nReinstating the function f into Eqs. (2.40) does not alter the conclusions of Eqs. (2.41).\n\nExample 2.6 Zermelo\u2019s problem.\n\nThis problem involves minimizing the time required for a boat to cross a river, as\nillustrated in Fig. 2.10. In this example we assume the velocity V, is constant and that\nthe control is the steering angle, ? .\n\nMinimize:\n\nJ = tf (2.42)\n\nsubject to:\n\nx? = V cos ? (2.43a)\n\ny? = V sin ? (2.43b)\n\nwith B.C.s:\n\nx(0) = xo (2.44a)\n\ny(0) = yo (2.44b)\n\n\n\n2.4. A Provocative Example Regarding Admissible Functions 35\n\ny\n\nx\n\nu? = ?? = 45 degrees\n\n(1, 1)\n\nFigure 2.11. Solution to simplified Zermelo\u2019s problem: ?? = 45?.\n\nx(tf) = xf (2.44c)\n\ny(tf) = yf (2.44d)\n\nWe can simplify the problem further by assuming\n\nx0 = y0 = 0 (2.45a)\n\nxf = yf = 1 (2.45b)\n\nThis version of Zermelo\u2019s problem gives the optimal solution ?? = 45?, as shown in\nFig. 2.11.\n\nA more difficult problem considers currents, p and q, in the river, where the state\nequations are\n\nx? = V cos ? + p (2.46a)\n\ny? = V sin ? + q (2.46b)\n\nand where p and q may be functions of time and of the state variables. We will return to\nexamples of Zermelo\u2019s problem later in the text. We note in passing that an aerospace\napplication of Zermelo\u2019s problem is the problem of an aircraft flying in a crosswind.\n\nExample 2.7 The Lotka-Volterra model for the predator-prey problem.\n\nThe Lotka-Volterra model can be used to study population dynamics problems as well\nas more general problems (such as chemical and nuclear reactions and game theory\nproblems).\n\n\n\n36 Chapter 2. Optimal Control Theory\n\nLet:\nx1 ? number of prey (scaled, dimensionless)\nx2 ? number of predators (scaled, dimensionless)\n\nThis system can be modeled as:\n\nx?1 = x1 ? x1x2 (2.47a)\nx?2 = x1x2 ? kx2 (2.47b)\n\nIn these equations the product x1x2 can be considered to represent a \u201ccollision\u201d\nbetween predator and prey. When collisions occur the prey decrease and the predators\nincrease in number. Without collisions, the prey increase exponentially while the\npredators decrease exponentially with time constant k. This is actually a dynamics\nproblem but it can be turned into an optimization problem.\n\nLet us imagine the problem of a farmer raising crops (i.e. prey, x1) which are\ndamaged by insects (i.e. predators, x2). The farmer wants to maximize profit, which\ndepends on the crops produced at the end of the season, say 100 days. The farmer may\nelect to introduce insecticide to kill off the insects, but insecticide costs money.\n\nLet the control variable be\n\nu ? rate of insecticide introduction\nThen,\n\nx?1 = x1 ? x1x2 (2.48a)\nx?2 = x1x2 ? kx2 ? lx2u, (0 ? l ? 1) (2.48b)\n\nwhere l is considered the insecticide effectiveness. The farmer\u2019s cost function can then\nbe stated as:\n\nMinimize:\n\nJ = ?x1f +\n? tf\n\n0\na1u dt (2.49)\n\nwhere a1 > 0 (a constant), l, and tf are given. (Here we use the negative sign with x1f\nbecause the farmer wants to maximize crop output.)\n\nTo complete the setup of this optimization we need to specify I.C.s x1(0) and x2(0)\nas well as the final B.C.s:\n\n\t1 = tf ? 100 = 0 (2.50)\nA similar biological population dynamics problem is discussed in Stengel [1994].\n\n\n\n2.6. Exercises 37\n\n2.5. Summary\n\nThe brachistochrone problem presented by Johann Bernoulli at the end of the\nseventeenth century was a new mathematical problem which required that a path (i.e.,\na function) be found to minimize a scalar function of that path. In the middle of the\ntwentieth century a closely related problem to the path of quickest descent presented\nitself: the problem of finding the propellant-optimal trajectory for launching a satellite\ninto orbit. Such problems that map functions (paths) into a scalar are called optimal\ncontrol problems. They can be expressed generally in three forms: the Mayer problem\n(a function of the final time or final state), the Lagrange problem (a definite integral\nover time which includes the path function in the integrand), and the Bolza problem\n(which is a combination of the Mayer and the Lagrange problems). The three forms\nare equivalent; the text adopts the Problem of Bolza which most often appears in the\nliterature.\n\nThe allowable (or admissible) class of functions for the control or for the trajectory\ncan alter the solution obtained. What is admissible due to engineering or physical\nconstraints may differ from what is mathematically admissible. For example, while the\nDirac delta function is amenable to mathematical analysis in the field of generalized\nfunctions, it is physically impossible to mechanize as a control. To avoid unacceptable\nsolutions (inadmissible functions) it may be possible to reformulate the problem, for\nexample by putting bounds on the control or on its derivatives.\n\nThe Bolza problem is an ideal form for studying space trajectory optimization in\nwhich a control (such as the steering law for the thrust vector) is used to direct a launch\nvehicle into orbit using the least amount of propellant. While this text focuses on space\ntrajectory optimization, it will include other examples of optimal control, such as the\nclassical problem of Zermelo.\n\n2.6. Exercises\n\n1. Find the C space for f (x1, x2) = x1 + x\n3/2\n2 :\n\n1a. For ?? < x1 < ?, 0 ? x2 < ?\n1b. For ?? < x1 < ?, 0 < x2 < ?\n\n2. Let\n\nx?1 =\n1\nt\n\nx?2 = x1\n\nAssume 0 < t < ?. What class of functions are x1 and x2? (Answer in terms of\nP.C., C0, C1, etc.)\n\n\n\n38 Chapter 2. Optimal Control Theory\n\nReferences\n\nE.T. Bell, Men [sic] of Mathematics (Simon and Schuster, New York, 1965)\nG.A. Bliss, Lectures on the Calculus of Variations. Phoenix Science Series (The University of\n\nChicago Press, Chicago, 1968)\nO. Bolza, Lectures on the Calculus of Variations (Dover, New York, 1961)\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\nD.G. Hull, Optimal Control Theory for Applications (Springer, New York, 2003)\nW. Kaplan, Operational Methods for Linear Systems (Addison-Wesley, Reading, 1962)\nC. Lanczos, The Variational Principles of Mechanics, 4th edn. (Dover, New York, 1986)\nR.F. Stengel, Optimal Control and Estimation (Dover, New York, 1994)\nJ. Vagners, Optimization techniques, in Handbook of Applied Mathematics, ed. by C.E. Pearson, 2nd\n\nedn. (Van Nostrand Reinhold, New York, 1983), pp. 1140\u20131216\n\n\n\nChapter 3\n\nThe Euler-Lagrange Theorem\n\n3.1. The Variation\n\nThe brachistochrone problem posed by Johann Bernoulli was a new type of\nmathematical problem which required a new mathematical approach. Lagrange\ndeveloped the calculus of variations in which he considered suboptimal paths nearby\nthe optimal one. He then showed that, for arbitrary but infinitesimal variations from\nthe optimal path, the function sought must obey a differential equation now known as\nthe Euler-Lagrange equation.\n\nLet us consider a generalization of Lagrange\u2019s original technique in which x(t, ?)\nrepresents a family of curves that are near the optimal path. This one-parameter\nfamily is illustrated in Fig. 3.1 for different, infinitesimally small values of ? (e.g.,\n?1, ?2, ?3, . . .). When ? is set to zero, the curve is the optimal path. Of course we don\u2019t\nknow x(t, 0), but we assume it exists and seek conditions which will lead to its solution.\nNote that varying ? has just as significant an effect as varying time. That is, for a given\ntime, t1, the value of x(t1, ?) changes with ?. In our search for the optimal path we will\nfind that derivatives with respect to parameters (such as ?), as well as derivatives with\nrespect to time, must be taken. Figure 3.2 depicts the optimal solution, x(t, 0), and a\nnearby non-optimal solution, x(t, ?).\n\nNow, let us expand x(t, ?) in a Taylor series about ? = 0 at time t:\n\nx(t, ?) = x(t, 0) +\n?x\n??\n\n????\n?=0\n\n(? ? 0) + O(?2)\n\n? x(t, 0) + ?x\n??\n\n????\n?=0\n? (3.1)\n\nwhere we neglect terms of order ?2 (and above) as indicated by the \u201cBig O\u201d symbol,\nO(?2). The first variation of a function x(t, ?) at time t is defined as:\n\n?x(t) ? ?x(t, ?)\n??\n\n????\n?=0\n? (3.2)\n\nFigure 3.2 illustrates the first variation. Another form of the first variation originally\nused by Lagrange is:\n\n?x(t) = ??(t) (3.3)\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 3,\n\u00a9 Springer Science+Business Media New York 2014\n\n39\n\n\n\n40 Chapter 3. The Euler-Lagrange Theorem\n\nx\n\nt1 t\n\n?1\n\n?2\n\n?3\n\nFigure 3.1. One-parameter family of curves, x(t, ?). During a variation the value of x\nchanges with ? at a fixed time, t1.\n\nx(t, 0)\n\nx(t, ?) ?x(t)\n\nx\n\nt\n\nFigure 3.2. Retaining ? to first-order expansion of Eq. (3.1) about ? = 0 provides the first\n\nvariation ?x ? ?x\n??\n\n?\n?\n?\n?=0\n\n?.\n\nWe see in Eq. (3.3) the essential features of the variation. First, the amplitude is\ndetermined by ? which is always assumed to be infinitesimally small. Second, the\nfunction ?(t) is arbitrary. That is, the function ?(t) represents an arbitrarily large set of\nvirtual functions; it is not itself a particular function.\n\nOf course, we can always choose specific functions and examine their variations.\n\n\n\n3.2. Euler-Lagrange Equation and Brachistochrone Problem 41\n\nx\n\nt\n\n?2? 0 2????\n\nFigure 3.3. An example of expansion about ? = 0 from Eq. (3.4).\n\nExample 3.1 Assumed varied path.\n\nIf we let x(t, ?) = (? + ?2) sin(t), then x(t, 0) = 0 is the optimal solution and\n\n?x(t) =\n?x\n??\n\n????\n?=0\n?\n\n= [1 + 2?]|?=0 ? sin t\n= ? sin t (3.4)\n\nFigure 3.3 illustrates this particular variation. In general the variation merely creates a\nperturbation on the amplitude.\n\n3.2. The Euler-Lagrange Equation and the Brachistochrone\nProblem\n\nBefore introducing the Euler-Lagrange theorem, which provides the necessary con-\nditions for trajectory optimization (such as the problem of launching a satellite into\norbit), we derive the Euler-Lagrange equation and apply it to the brachistochrone\nproblem.\n\nThe Euler-Lagrange equation is simpler to derive than the theorem because the\nEuler-Lagrange equation only solves for a path, such as the shape of y(x) for the\nbrachistochrone problem. The Euler-Lagrange theorem applies to the more difficult\ncase (of optimal control) in which a control input is involved, such as the steering of\nthe thrust vector on a launch vehicle.\n\n\n\n42 Chapter 3. The Euler-Lagrange Theorem\n\nLet us consider the generalization of the brachistochrone problem in which a path\ny(x) between two fixed points y(x0) and y(xf) must be found to minimize\n\nJ =\n? xf\n\nx0\nF[y(x), y?(x), x] dx (3.5)\n\nwhere J is a scalar, F is known, and y?(x) = dy/dx.\nFollowing Lagrange\u2019s technique, let\n\ny(x, ?) = y(x) + ??(x) (3.6)\n\nSince the endpoints are fixed we have\n\n?(x0) = ?(xf) = 0 (3.7)\n\nWe find the minimum for J by setting the first variation of J equal to zero\n\n?J =\ndJ\nd?\n\n????\n?=0\n? = 0 (3.8)\n\nThus we must have\n\ndJ\nd?\n\n????\n?=0\n\n=\n? xf\n\nx0\n\n(\n?F\n?y\n\n?y\n??\n\n????\n?=0\n\n+\n?F\n?y?\n\n?y?\n\n??\n\n????\n?=0\n\n)\ndx\n\n=\n? xf\n\nx0\n\n[\n?F\n?y\n?(x) +\n\n?F\n?y?\n??(x)\n\n]\ndx = 0\n\n(3.9)\n\nNow, by what Lanczos [1986] called \u201can ingenious application of the method of\nintegration by parts,\u201d we write\n\n? xf\nx0\n\n?F\n?y?\n??(x)dx =\n\n[\n?F\n?y?\n?(x)\n\n]xf\nx0\n\n?\n? xf\n\nx0\n?(x)\n\nd\ndx\n\n(\n?F\n?y?\n\n)\ndx (3.10)\n\nFrom Eq. (3.7), the first term on the right side drops out. Substituting the remaining\nterm on the right hand side of Eq. (3.10) into Eq. (3.9) we obtain\n\n? xf\nx0\n\n[\n?F\n?y\n\n? d\ndx\n\n(\n?F\n?y?\n\n)]\n?(x) dx = 0 (3.11)\n\nBecause ?(x) is arbitrary (except for restriction upon continuity and the end condi-\ntions) it follows that for Eq. (3.11) to hold, a necessary condition is that the integrand\nvanishes. Thus, we have\n\n?F\n?y\n\n? d\ndx\n\n(\n?F\n?y?\n\n)\n= 0 (3.12)\n\nwhich is the Euler-Lagrange equation.\n\n\n\n3.2. Euler-Lagrange Equation and Brachistochrone Problem 43\n\nNext we re-examine the brachistochrone problem of Chap. 2. [See Fig. 2.3 and\nEq. (2.18).] The time to be minimized is\n\nt =\n? xf\n\n0\n\n?\n1 + y?2?\n\n2gx\ndx (3.13)\n\nwhere we must find the time-optimal path y = y(x). The Euler-Lagrange equation,\nEq. (3.12), must be satisfied. Since F, the integrand of Eq. (3.13), is not an explicit\nfunction of y the first term of Eq. (3.12) is zero so the term inside the parentheses must\nbe constant:\n\n?F\n?y?\n\n=\ny??\n\n2gx(1 + y?2)\n= c (3.14)\n\nEquation (3.14) can be rearranged as\n\ndy\ndx\n\n=\n\n?\n2gc2x\n\n1 ? 2gc2x (3.15)\n\nThe (not immediately obvious) trigonometric substitution\n\nx = a(1 ? cos ? ) (3.16)\n\nsolves the problem where a = 1/(4gc2). By substituting Eq. (3.16) into Eq. (3.15), we\nobtain (after simplification):\n\ny =\n?\n\na(1 ? cos ? ) d? (3.17)\n\nwhich provides\n\ny = a(? ? sin ? ) (3.18)\n\nEquations (3.16) and (3.18) are the parametric equations of a cycloid that begins\nat the origin. In this analysis, we have shown that the cycloid provides a stationary\nvalue for time, but not necessarily the minimum time. Greenwood [1997] points out\nthat a comparison of nearby trajectories confirms that the cycloid does indeed give the\nminimum-time path.\n\nExample 3.2 A simple problem in calculus of variations.\n\nAssume an optimal x?(t) exists and take an assumed varied path:\n\nx(t, ?) = x?(t) + ? sin t (3.19)\n\n\n\n44 Chapter 3. The Euler-Lagrange Theorem\n\n0\n\nJ\n\n?\n\nJ[x?(t)]\n\nFigure 3.4. Minimizing the cost functional J(?), as in the case of Eq. (3.23), means that\nJ(0) = Jmin.\n\nIn this case the first variation, ?x(t) = ? sin t, is the same as given in Eq. (3.4) and\nillustrated in Fig. 3.3. Find a necessary condition for the problem to minimize:\n\nJ =\n? ?\n\n0\nF(t, x, x?)dt (3.20)\n\nwith boundary conditions:\n\nx(0) = xo (3.21)\n\nx(?) = xf (3.22)\n\nWe can write the cost functional as J(?):\n\nJ(?) =\n? ?\n\n0\nF[t, x? + ? sin t, x?? + ? cos t]dt (3.23)\n\nsince x?(t, ?) = x?? + ? cos t. Figure 3.4 represents the behavior of J(?). Differentiating\nwith respect to ?, we have:\n\ndJ\nd?\n\n=\n? ?\n\n0\n\n(\n?F\n?x\n\nsin t +\n?F\n? x?\n\ncos t\n)\n\ndt (3.24)\n\nIntegrating the last term by parts we obtain:\n? ?\n\n0\n\n?F\n? x?\n\ncos tdt =\n(\n?F\n? x?\n\nsin t\n)????\n?\n\n0\n?\n\n? ?\n0\n\nd\ndt\n\n(\n?F\n? x?\n\n)\nsin t dt (3.25)\n\nTherefore:\n\ndJ\nd?\n\n????\n?=0\n\n=\n? ?\n\n0\n\n[\n?F\n?x\n\n? d\ndt\n\n(\n?F\n? x?\n\n)]\nsin t dt = 0 (3.26)\n\n\n\n3.3. The Euler-Lagrange Theorem 45\n\ntf (0) = t?f tf (?)\n\nx(t, ?)\n\nx?(t) = x(t, 0)\n\n?x(t?f ) x??(t?f )dtf\n\ndxf\n\ndtf\n\nt\n\nx??(t?f )\n\nx\n\nFigure 3.5. The variation at the final time is ?x?(tf ); however, the difference in the final\nstate, dxf , can be greater due to the difference in the final time, dtf .\n\nIn this simple problem, we again deduce that the Euler-Lagrange equation must hold\n(for this very specific variation):\n\n?F\n?x\n\n? d\ndt\n\n(\n?F\n? x?\n\n)\n= 0 (3.27)\n\n3.3. The Euler-Lagrange Theorem\n\nTo derive the necessary conditions of the Euler-Lagrange theorem, the change\nin J due to control variations ?u (and hence ?x) and to the differential change in\nthe terminal time tf must be found. Here we make an important distinction between\nthe brachistochrone problem, where the endpoints of the trajectory are fixed, and the\nlaunch problem, where the final endpoint is not necessarily fixed. In the latter case we\nmust allow nearby suboptimal paths to take more time to achieve orbit than the time-\noptimal path. In Fig. 3.5, we illustrate the complication that arises from the free final\nboundary condition. For simplicity, we only show one component of the state variable,\nwhere x(t, ?) represents the varied path and x?(t) = x(t, 0) is the optimal path. Here we\nadopt notation in which the optimal path and optimal final time are indicated by an\nasterisk. The final time varies with nearby suboptimal paths and is represented by tf(?).\nThus, the optimal final time is given by t?f = tf(0).\n\nWe note in Fig. 3.5 that, at the optimal final time, the variation is ?x(t?f ), but because\nthe varied path can take longer (as in the case of a suboptimal launch trajectory\nrequiring more time to achieve orbit than the optimal trajectory), the change in the\nfinal state (with respect to the optimal final state) is dxf. Thus,\n\n\n\n46 Chapter 3. The Euler-Lagrange Theorem\n\ndxf ? x[tf(?), ?] ? x[tf(0), 0]\n= x[tf(?), ?] ? x?(t?f ) (3.28)\n\nExamining Fig. 3.5 we can write:\n\ndxf ? ?x(t?f ) + x??(t?f )dtf (3.29)\n\nAlternatively, using a Taylor series expansion we obtain\n\nx[tf(?), ?] = x[tf(0), 0] +\n[\n?x\n? tf\n\ndtf\nd?\n\n]????\n?=0\n\n(? ? 0)\n\n+\n[\n?x\n??\n\n]????\n?=0\n\n(? ? 0) + O(?2) (3.30)\n\nwhere d? = (? ? 0). So to first order, dxf becomes\n\ndxf ?\n{\n?x[tf(0), 0]\n\n? tf\n\n}\ndtf +\n\n{\n?x[tf(0), 0]\n\n??\n\n}\n? (3.31)\n\n? x??(t?f )dtf + ?x(t?f )\n\nas before.\n\n3.3.1. Proof Outline of the Euler-Lagrange Theorem\n\nNow we restate the Problem of Bolza (from Chap. 2) for which we will prove (or more\nprecisely provide an outline of the proof of) the Euler-Lagrange theorem:\n\nFor a specified t0 minimize:\n\nJ = ?(tf, xf) +\n? tf\n\nto\nL(t, x, u)dt (3.32)\n\nsubject to:\n\nx? = f(t, x, u) Process Equations (3.33a)\n\nx(to) = xo Initial Conditions (I.C.s) (3.33b)\n\n?(tf, xf) = 0 Terminal Constraints (3.33c)\n\nwhere,\n\nx is an n-vector\n\nu is an m-vector\n\n? is a q-vector with 0 ? q ? n\n\n\n\n3.3. The Euler-Lagrange Theorem 47\n\nand J is the cost. The upper bound q on the dimension of \t is based on the number of\nindependent constraints that determine the final values of all n state variables. [Note:\nin the present counting scheme, Eq. (3.33b) represents n I.C.s and does not count to as\nan I.C. Later, in Sect. 3.3.3 we will include to as an I.C. to obtain n + 1 I.C.s.]\n\nAssume ?, L, f,\t ? C1 on their respective domains and that the optimal control,\nu?(t), is unconstrained. If u?(t) ? C0[to, tf] minimizes J, then the Euler-Lagrange\ntheorem states that there exist a time-varying multiplier vector ?T(t) = (?1, ?2, . . . , ?n)\nand a constant multiplier vector ?T =\n\n(\n?1, ?2, . . . , ?q\n\n)\nsuch that with the Hamiltonian\n\nH(t, x, u,???) ? L(t, x, u) + ???Tf(t, x, u) (3.34a)\n\nand a terminal function\n\n?(tf, xf) ? ?(tf, xf) + ?T?(tf, xf) (3.34b)\nthe following necessary conditions must hold:\n\n??\nT = ??H\n\n?x\n\n?\n= ?H?x (3.35a)\n\n?T(tf) =\n??\n\n?xf\n\n?\n(3.35b)\n\nH?u = 0T (3.35c)\n\nand the transversality condition:\n\n?(tf, xf, uf) ? L?f +\nd?\ndtf\n\n?\n= 0 (3.35d)\n\nwhich applies only if tf is unspecified (i.e. dtf ?= 0).\nThe Euler-Lagrange theorem [Eqs. (3.35)] assumes there exists a one-parameter\n\nfamily u(t, ?) which satisfies the constraints and u(t, 0) = u?(t). We also note that\nthere exists an associated family x(t, ?) formed by integrating x? = f[t, x, u(t, ?)] with\nx(to) = xo where x?(t) ? C1. (The state variable is usually one order higher in\ncontinuity class than the control variable due to the integration of x? = f.)\n\nProof Outline of the Euler-Lagrange theorem. Let u(t, ?) be a one-parameter family\nof admissible controls with u?(t) = u(t, 0). Augment the cost functional with the\nconstraints by some as yet undefined variables ?1(t), . . . , ?n(t) and ?1, . . . , ?q:\n\nJ(?) = ?{tf(?), x[tf(?), ?]}+?T?{tf(?), x[tf(?), ?]}\n\n+\n? tf(?)\n\nto\n\n(\nL[t, x(t, ?), u(t, ?)]+???T(t) {f[t, x(t, ?), u(t, ?)]?x?(t, ?)}\n\n)\ndt (3.36)\n\n\n\n48 Chapter 3. The Euler-Lagrange Theorem\n\nJ JJ\n\n? ? ?\n\nbo\nun\n\nde\nd\n\nFigure 3.6. Possible graphs of J. The case of dJd?\n\n?\n?\n?\n?=0\n\n> 0 can occur for bounded control\n\nproblems which are discussed in Chap. 9.\n\nEquation (3.36) provides the cost, J(?), for nearby suboptimal solutions. By def-\ninition, J(0) is the minimum cost. Following the method of Lagrange, we will show\nthat the problem of finding the control u?(t) to minimize J can be converted into the\nproblem of solving the algebraic and differential equations, Eqs. (3.35). (The meaning\nand methods of solving these equations will be discussed later.) We see in the integrand\nof Eq. (3.36) that the term ???T{f? x?} is zero on the optimal trajectory due to the process\nequations, Eq. (3.33a). Similarly, the term ?T? is zero due to Eq. (3.33c).\n\nFigure 3.6 illustrates how the cost of J(?) may vary with ?. For unbounded controls\nwe have:\n\ndJ\nd?\n\n????\n?=0\n\n= 0 (3.37)\n\ncorresponding to the two diagrams on the left in Fig. 3.6.\nFor bounded controls:\n\ndJ\nd?\n\n????\n?=0\n\n? 0 (3.38)\n\nas illustrated in the right-most diagram of Fig. 3.6. In the present proof we assume\nthe control is unconstrained so that only Eq. (3.37) holds. We consider the problem of\nconstrained (or bounded) controls later in the text.\n\nUsing the definition of the Hamiltonian, Eq. (3.34a), and the terminal function,\nEq. (3.34b), in Eq. (3.36) we obtain\n\nJ(?) = ?{tf(?), x[tf(?), ?]} +\n? tf(?)\n\nto\n\n{\nH[t, x(t, ?), u(t, ?),???(t)] ? ???T(t)x?(t, ?)\n\n}\ndt (3.39)\n\n\n\n3.3. The Euler-Lagrange Theorem 49\n\nNext we need Leibniz\u2019 rule to form dJ/d? of the functional J(?):\n\nd\nd?\n\n(? b(?)\na(?)\n\nf(x, ?)dx\n\n)\n= f[b(?), ?]db(?)\n\nd?\n?f[a(?), ?]da(?)\n\nd?\n+\n? b(?)\n\na(?)\n\n? f(x, ?)\n??\n\ndx (3.40)\n\nWe note that ? appears in the upper bound, tf(?), of the integral in Eq. (3.39)\nand that ? also appears in the Hamiltonian through x(t, ?) and u(t, ?) since H =\nH[t, x(t, ?), u(t, ?), ?(t)]. Thus, we can write\n\ndJ\nd?\n\n=\nd?\nd?\n\n+ L[tf(?)]dtf(?)d? +\n? tf(?)\n\nto\n\n(\n?H\n?x\n?x\n??\n\n+\n?H\n?u\n\n?u\n??\n\n? ???T(t)? x?\n??\n\n)\ndt (3.41)\n\nwhere ???(t) is a function of time only. Setting ? = 0 we obtain\n\ndJ\nd?\n\n????\n?=0\n\n=\nd??\n\nd?\n+ L?(t?f )\n\ndtf\nd?\n\n+\n? t?f\n\nto\n\n(\nH?x\n\n?x\n??\n\n????\n?=0\n\n+ H?u\n?u\n??\n\n????\n?=0\n\n? ???T(t) ? x?\n??\n\n????\n?=0\n\n)\ndt\n\n(3.42)\n\nWe find dJ|?=0 by multiplying dJd? |?=0 by d? = ??0 and noting that d? = ???tf dtf+ ???xf dxf:\n\ndJ|?=0 = ??\n? tf\n\n?\ndtf +\n\n??\n\n?xf\n\n?\ndxf + L?(t?f )dtf\n\n+\n? t?f\n\nto\n[H?x?x(t) + H?u?u(t) ? ?T(t)?x?(t)]dt = 0 (3.43)\n\nwhere we have made use of the definition of the variation, Eq. (3.2), so that ?u =\n?u\n??\n\n??\n?=0? and ?x? =\n\n? x?\n??\n\n??\n?=0?. The third term on the right-hand side of Eq. (3.43) is\n\nthe contribution to dJ by the integral term in Eq. (3.32), namely the product of the\nintegrand value at tf times dtf. Now let us integrate\n\n? t?f\nto ????T(t)?x?(t)dt by parts:\n\n? t?f\nto\n\n????T(t)?x?(t)dt = [????T(t)?x(t)]\n????\nt?f\n\nto\n+\n? t?f\n\nto\n????\n\nT(t)?xdt (3.44)\n\nWe recall that a similar step was made in the derivation of the Euler-Lagrange equation\nin Eq. (3.10).\n\nSubstituting Eq. (3.44) into Eq. (3.43), we obtain:\n\ndJ|?=0 = ??\n? tf\n\n?\ndtf +\n\n??\n\n?xf\n\n?\ndxf + L?(t?f )dtf ? ?T(t?f )?x(t?f )\n\n+\n? t?f\n\nto\n[H?x?x(t) + H?u?u(t) + ??T(t)?x(t)]dt = 0 (3.45)\n\n\n\n50 Chapter 3. The Euler-Lagrange Theorem\n\nx(t, ?)\n\nto\n\nx?(t)\n\nsubject\nto\n\nt?f\n\n?(tf, xf) = 0\n\ndtf\n\nx\n\nt\n\nFigure 3.7. When tf is free the terminal constraint, ?(tf , xf ) must be satisfied on the varied\npath.\n\nwhere we have used ?x(to) = 0. Keeping in mind that the final time, tf, may be free\n(as shown in Fig. 3.7), we will replace ?x(t?f ) with ?x(t\n\n?\nf ) = dxf ? x??f dtf [according to\n\nEq. (3.29)], therefore:\n\ndJ|?=0 =\n[\n??\n\n? tf\n\n?\n+ L?(t?f ) + ?\n\nT(t?f )x?\n?\nf\n\n]\ndtf +\n\n[\n??\n\n?xf\n\n?\n? ?T(t?f )\n\n]\ndx(tf)\n\n+\n? t?f\n\nto\n{[H?x + ??T]?x(t) + H?u?u(t)}dt = 0 (3.46)\n\nWe now come to the determination of the Lagrange multipliers, also known as costate\nvariables. For a stationary value of the cost J, the variation dJ in Eq. (3.46) must be\nzero. For this condition to be true for all ?x(t) [for arbitrary ?x(t)] it is necessary that\n\n????\nT(t) = ?Hx[t, x?(t), u?(t),???(t)] (3.47)\n\nSimilarly, to have dJ = 0 for all dx(tf) it is necessary that\n\n?T(t?f ) =\n??\n\n?xf\n\n?\n(3.48)\n\nNote that Eq. (3.48) provides the required boundary condition to accompany\nEq. (3.47). Next, dJ = 0 for all dtf requires its coefficient to be zero in Eq. (3.46).\nSubstituting in Eq. (3.48) this condition is\n\n? =\nd?\ndtf\n\n?\n+ L?(t?f ) = 0 (3.49)\n\nThis relation is the transversality condition that applies only if tf is unspecified (that\nis, dtf ?= 0).\n\n\n\n3.3. The Euler-Lagrange Theorem 51\n\nEquation (3.49) can be calculated as ??\n?\n\n?tf + H\n?(t?f ) = 0 although, strictly speaking,\n\nthe arguments of the function ? in Eq. (3.35d) do not include ??f (on which H\n?\nf\n\nexplicitly depends). Thus, the only term remaining in Eq. (3.46) is:\n\ndJ =\n? t?f\n\nto\nH?u?udt\n\n= 0 (3.50)\n\nso we conclude that because ?u is arbitrary, a necessary condition is\n\nH?u = 0T (3.51)\n\nwhich is valid only for unconstrained control. We note that this part of the proof is not\nrigorous, because ?u is not arbitrary if there are terminal constraints ?(tf, xf) = 0. The\nadmissible ?u are only those that generate ?x that satisfy ? = 0 (see Fig. 3.7), but a\nmore rigorous treatment in Bryson and Ho [1975] shows that Eq. (3.51) is a correct\nnecessary condition, even with terminal constraints.\n\nThis completes the proof outline of the Euler-Lagrange theorem.\nIf we retain the term ?T(to)?x(to) from Eq. (3.44) in Eq. (3.45) rather than eliminate\n\nit using ?x(to) = 0, two useful facts emerge: (i) if any component xi(to) is not specified\n[i.e. ?xi(to) ?= 0], then the condition that will determine its optimal value x?i (to) is that\nthe corresponding ?i(to) = 0; and (ii) this provides an interpretation for the Lagrange\nmultiplier ?. Each component ?i(to) is the first-order sensitivity (gradient) of the cost\nJ due to a differential change in the initial state component xi(to), ?i(to) = ?J/?xi(t0).\n\nAlong an optimal solution, any time t is the \u201cinitial time\u201d for the remainder of\nthe solution, so this interpretation of ? also applies at any time t. Because of this\ninterpretation, one can evaluate the small change in cost due to a small change in state\nat the initial time (or any other time due to a disturbance) by using the value of ?\nrather than completely re-solving the problem. This observation is especially useful if\nsolutions are determined numerically.\n\nWe also note that the function ? in Eq. (3.35d), which is the coefficient of dtf in\nEq. (3.46), has the interpretation that it is the sensitivity of the change in cost J due to a\ndifferential change in the final time tf, ? = ?J/? tf. So when the final time is specified,\nthe algebraic sign of? indicates whether a small increase or decrease in the final time\nwill lower the cost and provides a first-order estimate of the cost change.\n\nAs shown in Exercise 5, the components of the Lagrange multiplier ?, introduced in\nEq. (3.34b), have the interpretation that they relate the change in the cost due to small\nchanges in the constants in the terminal constraints. Again, this is especially useful if\nsolutions are determined numerically, because we do not have to completely re-solve\nthe problem.\n\n\n\n52 Chapter 3. The Euler-Lagrange Theorem\n\n3.3.2. Summary of the Euler-Lagrange Theorem\n\nFor a minimum of J, the following set of necessary conditions must be met:\n\nx? = f(t, x, u) = HT??? (3.52a)\n\n???? = ?HTx (3.52b)\nHTu = 0 (3.52c)\n\nwhere Eqs. (3.52a) and (3.52b) each represent n differential equations and Eq. (3.52c)\nrepresents m algebraic equations. In addition we have the end conditions:\n\nx(to) = xo (3.53a)\n\n?T(tf) =\n??\n\n?xf\n(3.53b)\n\n?(xf, tf) = 0 (3.53c)\n\nwhere Eq. (3.53a) represents n initial conditions (not including the initial time) and\nEq. (3.53c) represents q boundary conditions where q ? n. Finally we have the\ntransversality condition if dtf ?= 0:\n\n? = Lf +\nd?\ndtf\n\n= 0 (3.54)\n\nwhich can be calculated using the comment after Eq. (3.49) and in Exercise 4. The m\nalgebraic equations obtained from Eq. (3.52c) provide the optimal control, u?.\n\nThere are 2n + m + q + 1 unknown variables x, ?, u, ?, and tf; and there are a\ncorresponding number of equations to solve for them: Eq. (3.52a) with B.C.s (3.53a),\nEq. (3.52b) with B.C.s (3.53b), (3.52c), (3.53c), and (3.54).\n\nExamples of how the Euler-Lagrange theorem leads to a two-point boundary-value\nproblem are given in Chap. 4.\n\nIn the next section an alternative formulation of the necessary conditions is\ndiscussed which is similar to what has been described above, except that the terminal\nconstraints are satisfied by manually enforcing (directly solving) d? = 0, rather than\nby using the Lagrange multiplier vector, ?.\n\n3.3.3. Alternate Form of the Transversality Condition\n\nIn Sect. 3.3.1, the terminal constraints, ?(tf, xf), were adjoined to the cost functional,\nJ, through the use of the additional multiplier vector, ?, as given in Eq. (3.34b). This\nmethod has a certain elegance in its structure, and has been adopted by most modern\nauthorities following Bryson and Ho [1975]. It does provide the q components of\n? and these components provide additional information about the optimal solution,\nnamely, the change in the cost due to small changes in the terminal constraints. (See\nExercise 5).\n\n\n\n3.3. The Euler-Lagrange Theorem 53\n\nThere is an alternative approach in which the prescribed terminal constraints are not\nadjoined to the cost functional, so that the ?i never appear. In this approach, the\ntransversality condition appears in a differential form which, when combined with\nthe differentials of the terminal constraints, provides the natural boundary conditions.\n\nCitron [1969], Hestenes [1966], Kenneth and McGill [1966], and Pierre [1969]\nall use the differential form of the transversality condition. Citron demonstrates the\nequivalence of both methods of employing the transversality condition in an example\nand states, \u201cIt is up to the user to decide which method better suits his [or her] needs\nin any particular problem.\u201d\n\nWe can derive the differential form of the transversality condition by a slight\nmodification of the material in Sect. 3.3.1. We begin by dropping ? from Eq. (3.34b)\nand, of course, from Eq. (3.36) and note that the terminal B.C.s, ?(xf, tf) = 0, are\nwritten as a p-vector where 1 ? p ? n + 1. As a result, ? must provide at least one\nstopping condition and may contain all of the final states and the final time. The only\nchange in Eq. (3.39) is that ? is replaced by ?. Equation (3.43) becomes\n\ndJ|?=0 = d?? + (H? ? ???Tx??)|t?f dtf +\n? t?f\n\nto\n[H?x?x(t) + H?u?u(t) ? ???T(t)?x?(t)]dt\n\n= 0 (3.55)\n\nwhere we retain H? ? ?Tx?? in lieu of L?.\nAfter integration by parts [Eq. (3.44)], we obtain\n\ndJ|?=0 = d?? + (H? ? ???Tx??)\n????\nt?f\n\ndtf ? ???T(t?f )?x(t?f )\n\n+\n? t?f\n\nto\n[H?x?x(t) + H?u?u(t) + ????T(t)?x]dt\n\n= 0 (3.56)\n\nwhere we have used ?x(to) = 0, as before.\nAfter replacing ?x(t?f ) with ?x(t\n\n?\nf ) = dxf ? x??f dtf we have the analog to Eq. (3.46):\n\ndJ\n??\n?=0 = d?\n\n? + H?f dtf ? ???T(t?f )dxf\n\n+\n? t?f\n\nto\n[(H?x + ????T)?x + H?u?u]dt\n\n= 0 (3.57)\n\nwhich, as illustrated in Fig. 3.7, is subject to the final boundary conditions:\n\nd? = ??tf dtf + ?xfdxf = 0 (3.58)\n\n\n\n54 Chapter 3. The Euler-Lagrange Theorem\n\nWe note that in this formulation most authors assume that ? is a p-vector where\n\n1 ? p ? n + 1 (3.59)\n\nso that up to n + 1 constraints can be enforced, allowing all the final states and the final\ntime to be specified. Equations (3.58) and (3.59) are the basis of the alternate form of\nthe transversality condition. Rather than being a q-vector, where 0 ? q ? n, ? is now\na p-vector, where 1 ? p ? n + 1. Thus, there is always at least one terminal constraint.\nIf the value of the final time is specified, it becomes a component of the ? vector.\nBy contrast, in Sect. 3.3.1 a specified final time is treated as a separate constraint\nindependent of the ? vector. If the final time is unspecified, some component of the ?\nvector acts as a \u201cstopping condition\u201d that determines the value of the final time, e.g.\nfinal altitude, final velocity, etc.\n\nThe variables p and q are related in a simple manner: p = q unless the final time is\nspecified, in which case p = q + 1. Then the first component,\t1, is equal to tf ? t?f .\n\nAs in Eq. (3.47), we select\n\n??\nT(t) = ?Hx[t, x?(t), u?(t), ?(t)] (3.60)\n\nwhich eliminates the first parenthetical term in the integrand of Eq. (3.57). In order to\neliminate the non-integral terms in Eq. (3.57):\n\nH?f dtf ? ???T(t?f )dxf + d?? = 0 (3.61)\n\nsubject to the terminal constraint:\n\nd? = 0 (3.62)\n\nThe terminal cost term in Eq. (3.61) can be expanded as\n\nd? =\n(\n??\n\n?xf\n\n)\ndxf +\n\n(\n??\n\n? tf\n\n)\ndtf (3.63a)\n\nSubstituting Eq. (3.63a) into (3.61) yields\n\n(\n???\n\n?xf\n? ?T(t?f )\n\n)\ndxf +\n\n(\n???\n\n? tf\n+ H?f\n\n)\ndtf = 0 (3.63b)\n\nBecause dxf and dtf (if it is non-zero) are independent and arbitrary, choose\n\n?T(t?f ) =\n???\n\n?xf\n(3.63c)\n\n\n\n3.3. The Euler-Lagrange Theorem 55\n\nand\n\n???\n\n? tf\n+ H?f = 0 (3.63d)\n\nEquation (3.63c) provides the boundary condition for Eqs. (3.60) and (3.63d)\napplies only if dtf ?= 0 (tf unspecified). In combination with d? = 0, Eq. (3.63c) is\nequivalent to Eqs. (3.53b) and (3.63d) is equivalent to Eq. (3.54). (See Exercise 4.)\n\nThus, the only term remaining in Eq. (3.57) is:\n\ndJ =\n? t?f\n\nto\nH?u?udt\n\n= 0 (3.64)\n\nso we conclude as before that a necessary condition is\n\nH?u = 0T (3.65)\n\nwhich is valid only for unconstrained control.\nTo summarize the Euler-Lagrange theorem in which the transversality condition is\n\nexpressed in differential form, the following set of necessary conditions must be met:\n\nx? = f(t, x, u) = HT??? (3.66a)\n\n???? = ?HTx (3.66b)\nHu = 0T (3.66c)\n\nwhere Eqs. (3.66a) and (3.66b) each represent n differential equations and Eq. (3.66c)\nrepresents m algebraic equations. In addition we have the end conditions:\n\nx(to) = xo, to specified (3.67a)\n\n?(xf, tf) = 0 (3.67b)\n\nwhere Eq. (3.67a) represents n + 1 initial conditions and Eq. (3.67b) represents p\nterminal conditions where 1 ? p ? n + 1. Finally we have the differential form of\nthe transversality condition:\n\nHfdtf ? ???Tf dxf + d? = 0 (3.68)\n\nwhich provides n + 1 ? p boundary conditions. As previously mentioned, Eq. (3.68)\ncan be separated into Eqs. (3.63c) and (3.63d). [That is, in this counting scheme we\nneed 2n + 2 B.C.s to solve for 2n differential equations, Eqs. (3.66a) and (3.66b).\n\n\n\n56 Chapter 3. The Euler-Lagrange Theorem\n\nSince Eqs. (3.67a) and (3.67b) provide n+1+p B.C.s, Eq. (3.68) provides the remaining\nconditions: 2n + 2 ? (n + 1 + p) = n + 1 ? p.] Examples of how the Euler-Lagrange\ntheorem leads to a two-point boundary-value problem using Eq. (3.68) are given in\nChap. 4.\n\n3.4. Summary\n\nThe problem posed by Johann Bernoulli inspired Lagrange to develop a new\nmathematical tool, the calculus of variations, to find a function which minimizes\n(or extremizes) a functional. Lagrange\u2019s method led to the Euler-Lagrange equation,\nwhich converts the problem of minimizing the integral into a problem of solving a\ndifferential equation.\n\nIn the optimization of space trajectories a similar problem arises, but is complicated\nby a choice of controls (such as choosing the steering law for the thrust vector) and\nby the possibility of having free final boundary conditions. However, the variational\napproach of Lagrange once again yields a set of differential equations that must apply\nfor an optimal trajectory.\n\nThe Problem of Bolza is specified in Eq. (3.32) and consists of a terminal cost,\nwhich depends on the final time and final state, and a path cost, which depends on an\nintegral over the path. The Bolza problem includes a set of process equations (usually\nthe equations of motion) along with a specified set of initial and final boundary\nconditions, Eqs. (3.33).\n\nThe Euler-Lagrange theorem states that if u?(t) is the optimal control (which is\nassumed to be continuous and unconstrained) that minimizes J of the Bolza problem,\nthen a set of differential equations and algebraic equations, Eqs. (3.35), must be sat-\nisfied. Thus, along with the process (or state) equations, Eqs. (3.33a), the differential\nequations for the Lagrange multipliers (or costates), Eqs. (3.35a), must also be solved.\nThese costate equations arose from the introduction of the Lagrange multipliers into\nthe proof, and have an interesting and useful physical interpretation. A set of algebraic\nequations, Eqs. (3.35c), provides control laws for u(t). Equation (3.35d), which\nis called the transversality condition, provides the additional necessary boundary\nconditions to solve for the differential equations, Eqs. (3.33a) and (3.35a), as we will\nshow later.\n\nThe proof of the Euler-Lagrange theorem depends on the definition of the\nHamiltonian, Eq. (3.34a), and the use of the one-parameter families for the control\nand for the state, u(t, ?) and x(t, ?), respectively. The proof requires the application of\nLeibniz\u2019 rule and integration by parts. The arbitrary nature of the Lagrange multipliers\npermits selection of these functions and their final boundary conditions to simplify the\nproof. The proof consists of Eqs. (3.36) through (3.51).\n\nIt is important to note the limitations of the proof. We have assumed that the control\nis unconstrained (unbounded) and is continuous, and that the state is continuously\ndifferentiable. At this stage we have no theorem for the cases where the control is\nbounded or piecewise continuous. We will need other theorems discussed in later\nchapters for such problems.\n\n\n\n3.5. Exercises 57\n\nOne final remark will be made before moving on to applications of the\nEuler-Lagrange theorem. Are there other approaches besides the calculus of variations\nto solve the optimal control problem? With the availability of computational\ntechniques, direct methods of solving Bolza\u2019s problem now exist. By direct, we\nmean the numerical construction of a control law and trajectory path which can\nbe inserted into the integrand so that a numerical value of the cost can be calculated.\nThen a number of nearby trajectories can be submitted to calculate their costs. Another\napproach, discussed by Lanczos [1986], is to represent the path by a truncated Fourier\nseries in which the coefficients are solved. This method changes the optimal control\nproblem into a parameter optimization problem, but requires a small error to be\naccepted due to the truncation. Lanczos credits Hilbert for originating this concept\nof \u201cfunction space.\u201d Further discussion of direct methods is outside the scope of this\ntext. The goal of the present work is to provide an introduction to the classical indirect\nmethod\u2014the use of the calculus of variations\u2014to solve the Problem of Bolza.\n\n3.5. Exercises\n\n1. State and prove the Euler-Lagrange theorem using the same assumptions and\ntechniques presented in Sect. 3.3.1 except for the following differences:\n\n1a. The initial state x(to) is free and the initial time to is free,\n1b. The boundary conditions are expressed as\n\n?(to, xo, tf, xf) = 0 (3.69)\n\n(i.e., in terms of initial and final conditions), and\n1c. J = ?(to, xo, tf, xf) +\n\n? tf\nto L(t, x, u)dt.\n\nHint: you should find that the additional necessary condition is ?T(to) =\n???/?xo and ??/? to ? H(to) = 0.\n\n2. Repeat Exercise 1 using the assumptions of Sect. 3.3.3 in which the terminal costs\nare not adjoined to the cost functional.\nHint: you should find that the new transversality conditions are [Hdt ? ?Tdx]??tfto +\nd? = 0 subject to d? = 0.\n\n3. Derive Eq. (3.49) by substituting Eq. (3.48) into Eq. (3.46).\n4. Show that, as mentioned after Eq. (3.49), the variable? can be calculated as ??\n\n?\n?tf +\n\nH?(t?f ) = 0.\n5. The terminal constraint, Eq. (3.53c), can be generalized to be ?(tf, xf, c) = 0, when\n\nc is a vector of constants, such as the specified final altitude, etc. Show that the\nvector ? introduced in Eq. (3.34b), has the physical interpretation of relating a\nchange in the cost due to a small change in c, namely ?J\n\n?c = ?\nT?c. Also show\n\nthat in component form we have ?J\n?ci =\n\n?q\nj=1 ?j\n\n?\tj\n?ci .\n\nHint: ?Td? = ?T\n[\n? tfdtf + ?xfdxf + ?cdc\n\n]\n.\n\n\n\n58 Chapter 3. The Euler-Lagrange Theorem\n\n6. Zermelo\u2019s Problem\nWe wish to minimize the time for a boat to cross a river (see Fig. 2.10). As men-\ntioned earlier, Zermelo\u2019s problem has an interesting aerospace application: that of\nan aircraft flying in a crosswind.\n\nMin J =\n? tf\n\nto\ndt (3.70)\n\nsubject to\n\nx? = V cos ? + u(x, y) (3.71a)\n\ny? = V sin ? + v(x, y) (3.71b)\n\nwhere to, xo, yo, xf, yf are given and V is constant. Let u and v represent strong\ncurrents which may depend on location.\n\n6a. Make use of the fact that since the Hamiltonian is not an explicit function of\ntime, it is a constant throughout the motion (we will prove this in Sect. 4.8).\nShow that\n\n?x =\n? cos ?\n\nV + u cos ? + v sin ?\n(3.72a)\n\n?y =\n? sin ?\n\nV + u cos ? + v sin ?\n(3.72b)\n\n6b. We note that if u and v are constants, then ? is a constant and the minimum\npaths are straight lines. Show that if\n\nu = u(y) (3.73a)\n\nv = v(y) (3.73b)\n\nthen\n\ncos ?\n\nV + u(y) cos ? + v(y) sin ?\n= constant (3.74)\n\nEquation (3.74) implies that the heading angle, ? , changes with local current\nvelocities in direct analogy with Snell\u2019s law of optics.\n\n6c. Suppose\n\nu = ?Vy/h (3.75a)\nv = 0 (3.75b)\n\n\n\nReferences 59\n\nwhere h is constant. Show that\n\ncos ? =\ncos ?f[\n\n1 + yh cos ?f\n] (3.76)\n\nfor (xf, yf) = (0, 0).\n\nReferences\n\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\nS.J. Citron, Elements of Optimal Control (Holt, Rinehart, and Winston, New York, 1969)\nD.T. Greenwood, Classical Dynamics (Dover, New York, 1997)\nM.R. Hestenes, Calculus of Variations and Optimal Control Theory (Wiley, New York, 1966)\nP. Kenneth, R. McGill, Two-point boundary value problem techniques, in Advances in Control\n\nSystems: Theory and Applications, vol. 3, chap. 2, ed. by C.T. Leondes (Academic, New York,\n1966)\n\nC. Lanczos, The Variational Principles of Mechanics, 4th edn. (Dover, New York, 1986)\nD.A. Pierre, Optimization Theory with Applications (Wiley, New York, 1969)\n\n\n\nChapter 4\n\nApplication of the Euler-Lagrange Theorem\n\n4.1. Introduction\n\nIn this chapter we will look at some applications of the Euler-Lagrange theorem.\nThe theorem transforms the Problem of Bolza into a set of differential equations\nand attendant boundary conditions. In some cases, simple closed-form solutions are\navailable which completely solve the problem. In other cases, numerical methods are\nrequired to solve the \u201ctwo-point boundary-value problem.\u201d In some instances we find\nthat the Euler-Lagrange theorem does not supply enough conditions to determine the\noptimal control law. In such cases we appeal to another theorem (the Weierstrass\ncondition or Minimum Principle, discussed in Chap. 5) to solve the problem.\n\n4.2. Two-Point Boundary-Value Problem (TPBVP)\n\nBefore defining a two-point boundary-value problem (TPBVP),we review what is\nmeant by an initial-value problem. The initial-value problem is the typical problem\nstudents encounter in their first course on linear, ordinary differential equations.\nSuppose\n\nx? = f(t, x) (4.1)\n\nis an initial-value problem. Because x is an N-vector, we know that Eq. (4.1) represents\nN scalar equations. Then N+1 numbers (to, x1o, . . . , xNo) are needed to obtain a unique\nsolution. We imagine propagating the solution forward in time (by numerical methods)\nfrom the initial conditions (I.C.s). (Whether an analytical solution exists is immaterial\nto the present discussion.) Because we have the entire initial state (x1o, . . . , xNo) and\nthe initial time (to), we can determine the state at an infinitesimal time step in the\nfuture. In numerical methods we take small, finite steps in time, but in principle we\ncan combine these steps (making them as small as necessary) to create a complete,\nhighly accurate solution at a future time.\n\nExample 4.1 Split boundary conditions (B.C.s).\n\nConsider the scalar differential equation\n\nx? + x = 0 (4.2)\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 4,\n\u00a9 Springer Science+Business Media New York 2014\n\n61\n\n\n\n62 Chapter 4. Application of the Euler-Lagrange Theorem\n\n0 0.5 1 1.5 2 2.5 3 3.5 4\n?2\n\n?1.5\n\n?1\n\n?0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\nc2 = 1.5\nc2 = 1\nc2 = 0.5\n\nx\n\nt\n\nFigure 4.1. Example of split B.C.s where I.C. is given but final B.C. is not, x = c2 sin t.\n\nIn this particular case we have the analytical solution:\n\nx = c1 cos t + c2 sin t (4.3)\n\nTo be an initial value problem three numbers (N + 1) must be specified, i.e.,\n[to, x(to), x?(to)]. Now suppose that to and x(to) are given but not x?(to).\n\nIn particular, let us assume:\n\nto = 0\n\nx(to) = 0 (4.4)\n\nso that\n\nx = c2 sin t (4.5)\n\nThis is an example of split B.C.s (where not all conditions are I.C.s). In this case of\nsplit B.C.s, we require N + 2 boundary conditions. Figure 4.1 illustrates the situation.\nSuppose tf = ?2 . Then we also need x(\n\n?\n2 ). Say, for example, that x(\n\n?\n2 ) = 1. Then we\n\nhave the case of c2 = 1, as shown in Fig. 4.1. Here we note that:\n\nto = 0 (4.6a)\n\nxo = 0 (4.6b)\n\n\n\n4.3. Two Approaches to Terminal Constraints 63\n\ntf =\n?\n\n2\n(4.6c)\n\nxf = 1 (4.6d)\n\ngive the required N + 2 B.C.s for a well-defined TPBVP. This example also illustrates\nthat it is possible to have an ill-defined TPBVP: if tf = ? then we learn nothing new\nabout the solution because all curves pass through zero at this point [x(?) = 0]. Such\na case is called a conjugate point. A similar case arises when we seek the shortest path\nfrom the Earth\u2019s North Pole to the South Pole: all meridians give the same answer, so\nno proper minimum exists. Conjugate points are discussed in more detail in Sect. 6.7\nand in Bryson and Ho [1975], Citron [1969], Hull [2003], and Vagners [1983].\n\n4.3. Two Approaches to Terminal Constraints\n\nThere are two approaches for handling terminal B.C.s which appear in the literature\nand are discussed in Chap. 3. These methods are distinguished by whether the terminal\nB.C.s are multiplied by a constant multiplier vector, ?, and adjoined to the cost\nfunctional, J in Eq. (3.32), or not. We will refer to these two approaches as the adjoined\nmethod and the un-adjoined method. In both methods the number of equations to be\nsolved is the same.\n\nMost books on optimal control concentrate exclusively on one method or the other.\nBryson and Ho [1975] and subsequent works overwhelmingly favor the adjoined\nmethod which leads to the algebraic form of the transversality condition. Prior to\n1975 authors (e.g. Hestenes [1966]) most often employed the un-adjoined approach\nresulting in the differential form of the transversality condition, Eq. (3.68).\n\nCitron [1969] is one of the few authors who presents both approaches. He demon-\nstrates the equivalence of both methods by example and indicates that it is up to the\nuser to determine which method works best for a particular problem.\n\nIn the un-adjoined method the differential form of the transversality condition is\ncombined with the differentials of the terminal constraints to provide natural boundary\nconditions. This method is a concise technique that is very efficient in obtaining a\nTPBVP. Because this approach is not addressed in modern texts, we are providing\nnumerous examples in the present work.\n\nThe adjoined technique is well documented in Bryson and Ho [1975] and in many\nmodern texts that have followed it. Since there are numerous works emphasizing the\nadjoined method, we provide fewer examples than for the un-adjoined method\u2014but\ncertainly sufficient examples to make the method clear and accessible to the reader.\nWe also demonstrate in a number of examples that the two methods can be combined.\n\nThe reader, on a first reading, may elect to concentrate on only one method and in\neither case the text will provide a thorough introduction on how to setup a TPBVP for\noptimal control problems.\n\nThe main advantage of the adjoined method is due to the elegant mathematical\nstructure which is readily translated into a numerical algorithm. However, we do have\nto solve explicitly for the ? q-vector, but with this step comes a great benefit: the ?i\n\n\n\n64 Chapter 4. Application of the Euler-Lagrange Theorem\n\ncomponents provide a numerical sensitivity of the optimal cost due to small changes in\nthe terminal constraints (as discussed in Exercise 5 of Chap. 3). A similar observation\nis made in Sect. 3.3.1 about how each ?i(to) provides the gradient of the cost J due to\na differential change in xi(to).\n\nIn the un-adjoined method we have 2n differential equations (for x and for ? which\nin this counting scheme require 2n+2 B.C.s including to and possibly tf). The terminal\nB.C.s give p equations (where 1 ? p ? n + 1)\n\n?(tf, xf) = 0 (4.7)\n\nand we have n + 1 I.C.s (xo, to) so we need\n\n2n + 2 ? (n + 1) ? p = n + 1 ? p (4.8)\n\nadditional B.C.s. These n + 1 ? p B.C.s are obtained through the differential form of\nthe transversality condition, Eq. (3.68)\n\nHfdtf ? ???Tf dxf + d? = 0 (4.9)\n\nwhich has n + 1 differential terms (dxf, dtf) which, in general, are not independent.\nThere are p constraints, ?(tf, xf) = 0, which after elimination from Eq. (4.9) reduces\nthe differential form of the transversality condition to n + 1?p independent equations,\nthus providing the remaining B.C.s required for a well-defined TPBVP.\n\nThe main disadvantage of the un-adjoined method is that the differential constraints\non the transversality condition must be eliminated by hand\u2014which for simple\nproblems (the kind most often found in textbooks)\u2014is usually easy. However, it is not\nalways possible to perform the elimination, so the method is highly specific. Citron\n[1969] points out that this method does not provide an explicit set of equations with\nwhich to work until the problem of interest has been defined, which is another reason\nthat we provide more examples of the un-adjoined method than of the adjoined. On the\nother hand, Citron also recognizes that it is useful to have explicit equations for the\ngeneral case (i.e. the adjoined method).\n\nHere we note that in the adjoined method ? is a q-vector (where 0 ? q ? n) as\nin Bryson and Ho [1975]. In this counting scheme ? does not include to and tf. The\ninitial time, to, is ignored and the final time, tf if specified, is treated as a separate\nconstraint independent of ?. If the final time is unspecified, some component of ?\nacts as stopping condition as noted in Sect. 3.3.3. In this approach the 2n system of\nequations (for x? and ??) are required to have 2n B.C.s (as opposed to 2n + 2 B.C.s in\nthe un-adjoined method).\n\nIn the examples throughout the book we always make clear whether ? is a p vector\n(1 ? p ? n + 1) or a q vector (0 ? q ? n), corresponding to the un-adjoined or\nadjoined method, respectively.\n\n\n\n4.4. Transversality Condition 65\n\n4.4. Transversality Condition\n\nIn the proof of the Euler-Lagrange theorem for the un-adjoined method (in Chap. 3)\nwe chose final boundary conditions for the Lagrange multipliers to satisfy:\n\nHfdtf ? ???Tf dxf + d? = 0 (4.10)\n\nand we were given p B.C.s:\n\nd? = 0 (4.11)\n\nEq. (4.10) is called \u201cthe transversality condition.\u201d Because the ?\u2019s were originally\narbitrary functions, we were able to choose these functions and their B.C.s to simplify\nthe proof. Thus, we have a total of 2n differential equations (i.e. N differential\nequations using the notation of Sect. 4.2) plus m algebraic equations:\n\nx? = f (4.12a)\n\n???? = ?HTx (4.12b)\nHu = 0T (4.12c)\n\nwhere Hx and Hu denote the vectors that contain the derivatives of H with respect to\nthe x\u2019s and u\u2019s.\n\nIn general, we have 2n differential equations given by Eqs. (4.12a) and (4.12b).\nSolution of these equations provides x and ??? (each are n-vectors). The x is the state\nvector that usually has explicit physical meaning. The ??? is the costate vector (or the\nLagrange multiplier) that also has physical meaning, as the change in the cost due to a\nsmall change in the state vector. To solve the 2n differential equations we need 2n + 2\ninitial and final boundary conditions. We already know t0, x0, and ?, which provide a\ntotal of n + 1 + p B.C.s. Then, for the general problem we need (2n + 2) ? (n + 1 + p) =\nn + 1 ? p additional boundary conditions. We will discuss this problem in more detail\nafter first looking at some special cases.\n\n4.4.1. Case 1 Final Time Specified\n\nSuppose the final time is given:\n\n\t1 = tf ? T = 0 (4.13)\n\nso that p = 1, as illustrated in Fig. 4.2. Then\n\nd\t1 = dtf = 0 (4.14)\n\n\n\n66 Chapter 4. Application of the Euler-Lagrange Theorem\n\nT\n\nx\n\nt\n\nFigure 4.2. Fixed final time problem.\n\nIn this case for a well-defined TPBVP we need n + 1 ? p = n more B.C.s. assuming\nthe un-adjoined method. From the differential form of the transversality condition we\nhave1:\n\nHfdtf ? ???Tf dxf + ?tfdtf + ?xf dxf = 0 (4.15)\n\nsubject to\n\ndtf = 0 (4.16)\n\nwe have,\n\n(????Tf + ?xf)dxf = 0 (4.17)\n\nand\n\n?if =\n??\n\n?xif\n(i = 1, . . . , n) (4.18)\n\nThus, the 2n + 2 B.C.s are given by to, xo, tf = T, and ?1f = ???x1f , . . . , ?nf =\n??\n?xnf .\n\nNote that as mentioned near the end of Sect. 3.3.1, the dependence of the cost on a\nsmall change in the value of T is determined by ?J\n\n?T = Hf + ?tf (because ? = ? in this\nexample).\n\n1Recall that ?xf is a row vector.\n\n\n\n4.4. Transversality Condition 67\n\nx1f\n\nx\n\nt\n\nFigure 4.3. One final state specified.\n\n4.4.2. Case 2 Final State Specified\n\nSuppose one component of the final state is specified:\n\n\t1 = x1(tf) ? x1f = 0 (4.19)\n\nso that p = 1.\n\nExample 4.2 Minimum time-to-climb problem.\n\nConsider the case in which we minimize the time for an aircraft to climb to a specified\naltitude, as illustrated in Fig. 4.3. Let ? = tf. Then, from Eq. (4.19) d\t = dx1f = 0.\nFollowing the un-adjoined method, we need n more B.C.s for a well-defined TPBVP\n(i.e., n + 1 ? p = n + 1 ? 1 = n). From the transversality condition:\n\nHfdtf ? ???Tf dxf + ?tf dtf + ?Txfdxf = 0 (4.20)\n\nApplying the final boundary condition\n\ndx1f = 0 (4.21)\n\nthe transversality condition becomes:\n\n(Hf + ?tf )dtf +\nn?\n\ni=2\n(??if + ?xif)dxif = 0 (4.22)\n\n\n\n68 Chapter 4. Application of the Euler-Lagrange Theorem\n\nand we have n equations:\n\nHf + 1 = 0 (4.23)\n\n?if = ?xif = 0 (i = 2, . . . , n)\n\nRecall H = L + ???Tf, so we can get a B.C. for ?1f by substituting Eqs. (4.23) into the\nHamiltonian.\n\nNote that in the adjoined formulation of Sect. 3.3.1? = ?+?\t = tf+?\n[\nx1(tf) ? x1f\n\n]\nand ?Tf =\n\n??\n?xf . Thus ?1f = ? and ?if = ?xif = 0 for i = 2, . . . , n as shown in Eq. (4.23).\n\nAlso, ??\n?tf = 1 and\n\n??\n?tf + Hf = 0 = 1 + ?\t1f from which ? = ? 1\t1f = ? 1x?1f . From\n\nExercise 5 in Chap. 3 the scalar c = x1f and ?\t?c = ?1. So ?J?x1f = ?? = 1x?1f =\ndtf\n\ndx1f ,\nwhich makes sense because a small change dx1f in the specified final altitude results\nin the small change in the cost dtf.\n\n4.4.3. Case 3 Final Endpoint Specified\n\nSuppose we have a fixed endpoint:\n\n?(tf, xf) =\n\n?\n??????\n\ntf ? T\nx1(tf) ? x1f\n\n...\nxn(tf) ? xnf\n\n?\n??????\n\n= 0 (4.24)\n\n(where T, x1f, . . . , xnf are given) then,\n\ndtf = 0 (4.25a)\n\ndx1f = 0 (4.25b)\n\n...\n\ndxnf = 0 (4.25c)\n\nand we have p = n + 1 equations from the final boundary conditions. Since we\nalready have n + 1 equations from the I.C.s, we have the required conditions for a\nwell-defined TPBVP. In this case the transversality condition provides no additional\nboundary conditions, since n + 1 ? p = 0.\n\n4.5. General Case of Supplying Needed B.C.s\n\nWe can now summarize how the two forms of the transversality condition can be\nused to supply the needed B.C.s in the general case in which the Euler-Lagrange\ntheorem applies. (A summary of the Euler-Lagrange theorem is given in Sect. 3.3.2.)\n\n\n\n4.5. General Case of Supplying Needed B.C.s 69\n\nThe m-vector control u, is solved for through Eq. (3.52c) and the result is substituted\ninto Eqs. (3.52a) and (3.52b) which provide a system of 2n differential equations.\n\n4.5.1. Adjoined Method\n\nIn the adjoined method we recall that ? is a q-vector (where 0 ? q ? n) that provides\nthe terminal B.C.s, ? = 0, as given in Eq. (3.53c). In this method ? is multiplied\nby a constant vector ?, and adjoined to the cost functional J in Eq. (3.32). In the\ncounting scheme for the adjoined method (the same scheme used by Bryson and Ho\n[1975]), the number of B.C.s needed for the system of 2n differential equations is\n2n. Equation (3.53a) provides n I.C.s and Eq. (3.53b) provides n B.C.s (which are\ntreated as independent) where the terminal function ?(tf, xf) is given by Eq. (3.34b).\nThe q-vector, ?, which appears in the definition of ? is solved through the use of\nEq. (3.53c).\n\nIn the case where the final time is unspecified (i.e. dtf ?= 0) we have the algebraic\nform of the transversality condition, Eq. (3.54)\n\n? = Lf +\nd?\ndtf\n\n= 0 (4.26)\n\n4.5.2. Un-adjoined Method\n\nIn the un-adjoined method we write the terminal B.C.s, ? = 0 (which is now a\np-vector) as\n\nd? = ? tf dtf + ?xfdxf = 0 (4.27)\n\nto solve for p differentials in terms of the remaining n + 1 ? p differentials. That is,\nsubstitute the known final B.C.s into Eq. (4.27) to obtain p independent equations.\n\nNext we substitute for the selected p differentials into\n\nHfdtf ? ???Tf dxf + d?f = 0 (4.28)\n\nwhich originally contains n + 1 differential terms. Thus, we have an expression in\nn + 1 ? p independent differentials.\n\nFinally we set the coefficients of the remaining n + 1 ? p differentials to zero:\n\nNi(tf, xf, ?f) = 0, i = 1, . . . , n + 1 ? p (4.29)\n\nTo summarize, we have n + 1 I.C.s (t0, x0), p B.C.s \ti, and n + 1 ? p differential\nexpressions, Ni.\n\n\n\n70 Chapter 4. Application of the Euler-Lagrange Theorem\n\n4.6. Examples\n\nExample 4.3 Minimum effort, minimum control problem.\n\nConsider the following:\n\nMinimize:\n\nJ =\n1\n2\n\n? 1\n0\n\n(x2 + Pu2)dt (4.30)\n\nHere we are trying to minimize the square of the error, x2, and of the control effort,\nu2, over the time interval from 0 to 1, subject to:\n\nx? = u (4.31a)\n\nx(0) = 1 (4.31b)\n\nwhere x and u are scalars. This is the state regulator problem (see Bryson and Ho\n[1975]) where P is a weighting factor on the control effort. Note that if P = 0 there\nis no solution, as discussed in Chap. 3. On the other hand, as P ? ? the curve\nis flattened. See Fig. 4.4. In a typical application, P is a finite, non-zero value that\nspecifies the relative cost of the control effort compared to the error in maintaining the\nstate near zero.\n\nWe note that when solving an optimization problem, it is often a good practice to\nguess what the solution might be and to analyze the extreme cases.\n\nP = 0\n\nP ? ?\n\nP = 1\n\nx\n\nt\n\nFigure 4.4. Error and control effort minimization depends on the control-effort weighting\nfactor P, in Eq. (4.30).\n\n\n\n4.6. Examples 71\n\nLetting P = 1, we solve our problem in a step-by-step process:\n\n1. Form the Hamiltonian:\n\nH =\n1\n2\n\nx2 +\n1\n2\n\nu2 + ?u (4.32)\n\n2. Write the Euler-Lagrange equations ?? = ?Hx, Hu = 0:\n\n?? = ??H\n?x\n\n= ?x (4.33)\n?H\n?u\n\n= u + ? = 0 (4.34)\n\nso that\n\nu = ?? (4.35)\n\n3. For the differential form of the transversality condition we have\n\nHfdtf ? ???Tf dxf + d?f = 0 (4.36)\nsubject to:\n\nd? = 0 (4.37)\n\nIn this case ? = 0 and \t = tf ? 1 = 0, so d\t = dtf = 0 and\n?f = ?(tf) = 0 (4.38)\n\nUsing the adjoined method Eq. (4.38) results from ?f = ?(tf) = ???x(tf) = 0. Our well-\ndefined TPBVP is (for both methods):\n\nx? = ?? (4.39a)\n?? = ?x (4.39b)\nto = 0, x(0) = 1 (4.39c)\n\ntf = 1, ?f(1) = 0 (4.39d)\n\nwhere we have two first-order differential equations (2n = 2) and 2n + 2 = 2 + 2 = 4\nB.C.s.\n\nLet us put our system in state-variable form by defining:\n\nz ?\n[\n\nz1\nz2\n\n]\n?\n\n[\nx\n?\n\n]\n(4.40)\n\n\n\n72 Chapter 4. Application of the Euler-Lagrange Theorem\n\nand, therefore\n\nz? =\n\n[\nz?1\nz?2\n\n]\n=\n\n[\n?z2\n?z1\n\n]\n(4.41)\n\nz1(0) = 1 (4.42a)\n\nz2(1) = 0 (4.42b)\n\nEqs. (4.40)\u2013(4.42) are in a form suitable for numerical integration (as a TPBVP). In\nthis particular case, an analytical solution exists. We can write\n\nz?1 = ?z?2 = z1 (4.43)\n\nso that\n\nz?1 ? z1 = 0 (4.44)\n\nThe solution has the form:\n\nz1 = c1et + c2e?t (4.45a)\n\nz2 = ?z?1 = ?c1et + c2e?t (4.45b)\n\nFrom the B.C.s:\n\nz1(0) = c1 + c2 = 1 (4.46a)\n\nz2(1) = ?c1e1 + c2e?1 = 0 (4.46b)\n\nwe can solve for c1 and c2:\n\nc1 =\n1\n\n1 + e2\n(4.46c)\n\nand\n\nc2 =\ne2\n\n1 + e2\n(4.46d)\n\n\n\n4.6. Examples 73\n\nV\n\n?\n\n(1, 1)\n\ny\n\nx\n(0, 0)\n\nFigure 4.5. Zermelo\u2019s problem in which a boat crosses a river in minimum time.\n\nThus, for our optimal solution we obtain:\n\nx? = z1 =\net + e2e?t\n\n1 + e2\n(4.47a)\n\nu? = ?? = ?z2 = e\nt ? e2e?t\n1 + e2\n\n(4.47b)\n\nExample 4.4 Zermelo\u2019s problem.\n\nMinimize:\n\nJ = tf (4.48)\n\nsubject to:\n\nx? = V cos ? (4.49a)\n\ny? = V sin ? (4.49b)\n\nwhere V is a given constant and x(tf) = y(tf) = 1. See Fig. 4.5. We already know that\nfor no current the solution is the line ? = 45 deg, as we found in Chap. 2 and illustrated\nin Fig. 2.11. Let us follow our systematic procedure on this simple problem:\n\n1. Form the Hamiltonian:\n\nH = ?1V cos ? + ?2V sin ? (4.50)\n\n\n\n74 Chapter 4. Application of the Euler-Lagrange Theorem\n\n2. Write the Euler-Lagrange equations ?????? = ?Hx, Hu = 0:\n\n??1 = ??H\n?x\n\n= 0 (4.51a)\n\n??2 = ??H\n?y\n\n= 0 (4.51b)\n\nThus, ?1 and ?2 are constants. To obtain the control law for ? we have,\n\nHu = ??1V sin ? + ?2V cos ? = 0 (4.51c)\n\nand\n\ntan ? =\n?2\n\n?1\n(4.51d)\n\nso that\n\n? = constant = ?o (4.51e)\n\nSolving the state equations, Eqs. (4.49) with both V and ? constant provides\n\nx(t) = xo + (V cos ?o)t (4.52a)\n\ny(t) = yo + (V sin ?o)t (4.52b)\n\nEvaluating at tf:\n\nx(tf) = 1 = 0 + (V cos ?o)tf (4.53a)\n\ny(tf) = 1 = 0 + (V sin ?o)tf (4.53b)\n\nso\n\ntan ?o = 1 (4.53c)\n\nand\n\n??o = 45o (4.53d)\n\n\n\n4.6. Examples 75\n\nrc\n\nF\n?\n\ng\n\ny\n\nx\n\nFigure 4.6. Flat-Earth problem: launch of a satellite into circular orbit in minimum time.\n\nas before. For the optimal time we obtain:\n\nt?f =\n1\n\nV cos 45?\n=\n\n?\n2\n\nV\n(4.53e)\n\nExample 4.5 Launch into circular orbit from flat-Earth.\n\nIn Fig. 4.6 we illustrate the problem of launching a satellite into circular orbit where\nwe assume a uniform gravitational field, g = constant. Our assumptions that the\nx and y axes are rectilinear and that the gravitational acceleration is constant are\nequivalent to assuming that the Earth is flat. Although these assumptions may seem\nto be oversimplifying, it is interesting to note that the Saturn V launch vehicle (which\nlaunched men to the Moon) used a guidance system based on the control law resulting\nfrom the flat-Earth model, with frequent updates of the control parameters.\n\nWe base our model on the one introduced in Chap. 2. [See Eqs. (2.1)\u2013(2.8).] Since\nwe are trying to maximize the payload delivered into circular orbit, and since we\nassume a constant burn rate for the propellant, we note that minimizing the time to\nreach orbit is an equivalent goal.\n\nSo, the problem can be stated as:\n\nMinimize:\n\nJ = tf (4.54)\n\n\n\n76 Chapter 4. Application of the Euler-Lagrange Theorem\n\nsubject to:\n\nx? = vx (4.55a)\n\ny? = vy (4.55b)\n\nv?x =\nF\nm\n\ncos(?) (4.55c)\n\nv?y =\nF\nm\n\nsin(?) ? g (4.55d)\n\nwith I.C.s: (to, xo, yo, vxo , vyo) and where F is a constant thrust.\nThe terminal B.C.s are:\n\n? =\n\n?\n???\n\t1\n\n\t2\n\n\t3\n\n?\n??? =\n\n?\n???\n\nyf ? rc + rEarth\nvxf ? vc\nvyf ? 0\n\n?\n??? = 0 (4.56)\n\nNext, we set up the necessary conditions from the Euler-Lagrange theorem:\n\n1. Form the Hamiltonian: H = L + ???Tf\n\nH = ?1vx + ?2vy + ?3\nF\nm\n\ncos? + ?4\n(\n\nF\nm\n\nsin ? ? g\n)\n\n(4.57)\n\n2. Write the Euler-Lagrange equations: ?????? = ?Hx, Hu = 0. We have, for the costate\nequations:\n\n??1 = ??H\n?x\n\n= 0 (4.58a)\n\n??2 = ??H\n?y\n\n= 0 (4.58b)\n\nThus\n\n?1 = c1 (4.58c)\n\nand\n\n?2 = c2 (4.58d)\n\nso that\n\n??3 = ? ?H\n?vx\n\n= ??1 (4.58e)\n\n\n\n4.6. Examples 77\n\n??4 = ? ?H\n?vy\n\n= ??2 (4.58f)\n\nSince ?1 and ?2 are constant,\n\n?3 = ?c1t + c3 (4.58g)\n\nand\n\n?4 = ?c2t + c4 (4.58h)\n\nThe control equation is found from:\n\n?H\n??\n\n= ??3 Fm sin ? + ?4\nF\nm\n\ncos? = 0 (4.59)\n\nso we have\n\ntan? =\n\u00b1?4\n\u00b1?3 (4.60)\n\nThus, we have the bi-linear tangent steering law:\n\ntan? =\n?4\n\n?3\n=\n\n?c2t + c4\n?c1t + c3 (4.61)\n\nwhich is an important result for flight control.\nInspection of Eq. (4.61) reveals that it also obeys:\n\ntan? =\n?4\n\n?3\n=\n\n??4\n??3 (4.62)\n\nwhich means that the control law does not distinguish the quadrant in which ?\nresides. The values of cos? and sin ? are undetermined:\n\ncos? =\n\u00b1?3?\n?23 + ?\n\n2\n4\n\n(4.63a)\n\nsin ? =\n\u00b1?4?\n?23 + ?\n\n2\n4\n\n(4.63b)\n\nwhere we must take both plus signs or both minus signs. (We assume the positive\nsign for the square root.) This problem is solved by an additional necessary\ncondition, which will be stated and used now (and will be proven later).\n\n\n\n78 Chapter 4. Application of the Euler-Lagrange Theorem\n\nThe additional necessary condition we need is called the Minimum Principle\n(discussed in Chap. 6) which states that the Hamiltonian must be minimized with\nrespect to the control. (The precise meaning of this statement will be explained\nlater.) A more restricted version of this principle is the Weierstrass condition\n(discussed in Chap. 5) where the control must be continuous. In our particular\nproblem we assume that the control is continuous and unbounded. The additional\nnecessary condition is\n\n[\n?2H\n?u2\n\n????\n?]\n\n? 0 (4.64)\n\nThat is, the matrix, H?uu must be positive semi-definite. Since our control is scalar\nfor our flat-Earth problem, we have:\n\n?2H\n??2\n\n= ??3 Fm cos? ? ?4\nF\nm\n\nsin ? (4.65a)\n\n=\nF\nm\n\n?\n????3\n\n?\n?? \u00b1?3?\n\n?23 + ?\n2\n4\n\n?\n?? ? ?4\n\n?\n?? \u00b1?4?\n\n?23 + ?\n2\n4\n\n?\n??\n\n?\n?? ? 0 (4.65b)\n\nWe pick the minus sign to obtain:\n\n?2H\n??2\n\n=\nF\nm\n\n?\n?? ?\n\n2\n3 + ?\n\n2\n4?\n\n?23 + ?\n2\n4\n\n?\n?? ? 0 (4.66)\n\nEq. (4.66) is satisfied because F, m, and the square root are all positive.\nAlternatively, there is a more direct way to determine the correct algebraic\n\nsigns in Eq. (4.63) and in all similar problems. First, let\n\n? =\n\n[\n?3\n\n?4\n\n]\n(4.67)\n\nand\n\n? =\n\n[\ncos?\n\nsin ?\n\n]\n(4.68)\n\n\n\n4.6. Examples 79\n\nwhere ? is a unit vector. Then, Eq. (4.57) can be written as:\n\nH = ?1vx + ?2vy ? ?4g + Fm?\nT? (4.69)\n\nTo minimize H choose ? to be antiparallel to ?, so that\n\n?T? = ?? (4.70)\nfor which\n\n? =\n??\n?\n\n; ? =\n?\n?23 + ?\n\n2\n4 (4.71)\n\nand note that the vector equation Eq. (4.71) is the same as Eqs. (4.63) with the\nminus signs.\n\n3. Transversality condition for flat-Earth problem:\nApply the differential form of the transversality condition to obtain a well-defined\nTPBVP. To solve the differential equations (the state and costate equations), 2n + 2\nconditions are needed. In this case n = 4, so 10 B.C.s are required. We have five\ninitial conditions (to, xo, yo, vxo, vyo) and three final conditions (yf, vxf, vyf). We are\nmissing two terms (associated with tf, xf).\n\nSince we know:\n\ndyf = 0 (4.72a)\n\ndvxf = 0 (4.72b)\n\ndvyf = 0 (4.72c)\n\nthe transversality condition becomes:\n\nHfdtf ? ?1fdxf + ?tfdtf + ?xfdxf = 0 (4.73)\n\nBut dtf and dxf are independent differentials. We have ? = tf so:\n\n??\n\n? tf\n= 1 (4.74a)\n\n??\n\n?xf\n= 0 (4.74b)\n\nTherefore\n\nHfdtf ? ?1fdxf + dtf = 0 (4.75a)\n\nso that\n\n\n\n80 Chapter 4. Application of the Euler-Lagrange Theorem\n\n(Hf + 1)dtf ? ?1fdxf = 0 (4.75b)\n\nand\n\nHf = ?1, ?1f = 0 (4.75c)\n\nUsing the adjoined method\n\n? = ? + ?T?\n\n= tf + ?1(yf ? rc + rEarth) + ?2(vxf ? vc) + ?3(vyf) (4.76)\n\nThen, consistent with Eqs. (4.58c) and (4.75c),\n\n?1f =\n??\n\n?xf\n= 0 (4.77)\n\nand\n\n?2f = ???yf = ?1 (4.78)\n\n?3f = ???vxf = ?2 (4.79)\n\n?4f = ???vyf = ?3 (4.80)\n\nwhere the final values ?1f, ?2f, ?3f, and ?4f are the sensitivities of the cost to small\nchanges in xf, yf, vxf, and vyf. The sensitivity to a small change in xf is zero. Also,\n??\n?tf + Hf = 0, which yields Hf = ?1 as in Eq. (4.75c). In this case then (with the\nnegative signs chosen):\n\ntan ? =\nc2t ? c4\nc1t ? c3 (4.81)\n\nBut since ?1 = c1 and ?1f = 0, we have c1 = 0. Therefore, we obtain the linear\ntangent steering law\n\ntan? =\nc2t\n?c3 +\n\n?c4\n?c3 = at + b (4.82)\n\nThis law was used in the Apollo guidance system with updates for a and b each\nsecond.\n\nWe can now specify a well-defined TPBVP. For our state equations we have\n\nx? = vx (4.83a)\n\ny? = vy (4.83b)\n\n\n\n4.6. Examples 81\n\nv?x =\nF\n\nmo + m?t\n\n?\n?? ??3?\n\n?23 + ?\n2\n4\n\n?\n?? (4.83c)\n\nv?y =\nF\n\nmo + m?t\n\n?\n?? ??4?\n\n?23 + ?\n2\n4\n\n?\n?? ? g (4.83d)\n\nFor our costate equations we have\n\n??1 = 0 (4.83e)\n\n??2 = 0 (4.83f)\n\n??3 = ??1 (4.83g)\n??4 = ??2 (4.83h)\n\nthus there are eight differential equations, namely,\n\nx? = f(t, x,???)\n\n???? = f?(t, x,???)\n(4.84)\n\nNow how do we deal with the split B.C.s? We have five initial conditions and\nfive final conditions. One numerical approach that has been used is called the shooting\nmethod. While the shooting method is not necessarily the best numerical method, it has\nthe additional advantage of serving as a good \u201cthought experiment\u201d and so contributes\nto understanding the TPBVP.\n\nIn our example, the shooting method could be done in the following steps.\n\n1. Guess ?1o, ?2o, ?3o, ?4o, tf.\n2. Integrate x? = f, ???? = f? forward to t = tf.\n3. Compute the final conditions:\n\n\t1 = yf ? rc + rEarth (4.85)\n\t2 = vxf ? vc (4.86)\n\t3 = vyf (4.87)\n\n\t4 = ?1f (4.88)\n\n\t5 = Hf + 1 (4.89)\n\nwhich change as (???o, tf) are changed iteratively.\n4. Converge on \ti(???o, tf) = 0 for i = 1, . . . , 5.\n\n\n\n82 Chapter 4. Application of the Euler-Lagrange Theorem\n\n(xo, to)\n\n?\n(n)\no , t\n\n(n)\nf\n\n?\n(1)\no , t\n\n(1)\nf\n\ny\n\nx\n\nrc\n?\n\n(2)\no , t\n\n(2)\nf\n\nFigure 4.7. Shooting method for flat-Earth problem.\n\nThe technique is illustrated in Fig. 4.7. A discussion on the shooting method can be\nfound in Citron [1969].\n\n4.7. A \u201cCookbook\u201d for Optimization Problems\n\nIn the examples, we have developed a step-by-step procedure to reach a well-defined\nTPBVP based on the Euler-Lagrange theorem and the Minimum Principle. We can\nnow outline this systematic method in \u201ccookbook\u201d form. While it would not be wise\nto blindly apply such an approach to all problems, this cookbook should prove useful\nin many cases. As we shall see, however, there are a number of examples in the\nliterature of trajectory optimization which require innovative and creative thinking\nbeyond the rote application of these four steps.\n\nStep 1\nForm the Hamiltonian:\n\nH = L + ???Tf (4.90)\n\n\n\n4.7. A \u201cCookbook\u201d for Optimization Problems 83\n\nStep 2\nWrite the Euler-Lagrange equations:\n\n??i = ??H\n?xi\n\n, i = 1, . . . , n (4.91)\n\nHu = 0 (4.92)\n\nWhen possible, use Eq. (4.92) to find the control u (an m-vector). When a definitive\ncontrol is not obtained from Eq. (4.92), use step 4 (the Minimum Principle). In either\ncase substitute the resulting control into the state equation:\n\nx? = f(t, x, u) (4.93)\n\nand into Eq. (4.91)\n\nStep 3: Adjoined Method\nIf the final time is unspecified (ie. dtf ?= 0), use the algebraic form of the transversality\ncondition Eq. (3.54)\n\n? = Lf +\nd?\ndt\n\n= 0 (4.94)\n\nwhere?(tf, xf) is obtained from Eq. (3.34b):\n\n?(tf, xf) ? ?(tf, xf) + ?T?(tf, xf) (4.95)\n\nand where ? is a q-vector (0 ? q ? n) that specifies the terminal constraints\n?(tf, xf) = 0 (4.96)\n\nIf the final time is specified then Eq. (4.94) is invalid. Note that in the counting scheme\nfor the adjoined method the 2n differential equations, Eqs. (4.91) and (4.93), require\n2n B.C.s which are provided by Eqs. (3.53a) and (3.53b). Treat the components of\n?(tf) as independent. Solve for the q-vector, ? which appears in ? using Eq. (3.53c).\n\nStep 3: Un-Adjoined Method\nWrite the terminal B.C.s\n\n?(tf, xf) = 0 (4.97)\n\nas a p-vector where 1 ? p ? n + 1. In the counting scheme for the un-adjoined\nmethod, the 2n differential equations, Eqs. (4.91) and (4.93) require 2n + 2 B.C.s. The\nI.C.s (to, x) provide n + 1 conditions and Eq. (4.97) provide p conditions. The number\nof additional conditions needed are\n\n2n + 2 ? (n + 1) ? p = n + 1 ? p (4.98)\n\n\n\n84 Chapter 4. Application of the Euler-Lagrange Theorem\n\nUse the differential form of the transversality condition:\n\n1. Use d? = 0 to solve for p differentials in terms of the remaining n + 1 ? p\ndifferentials.\n\n2. Substitute these p differentials into:\n\nHfdtf ? ???Tf dxf + d? = 0 (4.99)\n\n3. Obtain an expression involving n + 1 ? p \u201cindependent\u201d differentials and equate\ntheir coefficients to zero:\n\nNi(tf, xf,???f) = 0, i = 1, . . . , n + 1 ? p (4.100)\n\nStep 4\nApply the Minimum Principle (\u201cminimize H with respect to u\u201d) to minimize J. If u?\nis an interior control (not on control boundary) then,\n\n[\n?2H\n?u2\n\n????\n?]\n\n? 0 (4.101)\n\nwhich is to say that the matrix is positive semi-definite.\nWe note that H?uu > 0 is called the convexity condition (or the strengthened\n\nLegendre-Clebsch condition), a sufficient condition for a minimum of H and part of\nthe sufficient conditions for a minimum of the cost J. These concepts are developed in\nChaps. 5 and 6. The main purpose of the Minimum Principle is to provide additional\nconditions on the control law so that a specific control law may be found and then\nused in Step 2.\n\n4.7.1. Examples of Step 4\n\nExample 4.6 Unbounded control.\n\nSuppose u is a scalar and the Hamiltonian is given by\n\nH = ?1 cos u + ?2 sin u (4.102)\n\nFollowing the procedure described after Eq. (4.66) write the Hamiltonian in\nEq. (4.102) as\n\nH = ?T? (4.103)\n\nwhere\n\n? =\n\n[\n?1\n\n?2\n\n]\n(4.104)\n\n\n\n4.7. A \u201cCookbook\u201d for Optimization Problems 85\n\nand\n\n? =\n\n[\ncos u\nsin u\n\n]\n(4.105)\n\nwhere ? is a unit vector. Then H is minimized by choosing\n\n? =\n??\n?\n\n(4.106)\n\nfor which\n\ncos u =\n??1?\n?21 + ?\n\n2\n2\n\n, (4.107)\n\nsin u =\n??2?\n?21 + ?\n\n2\n2\n\n(4.108)\n\nExample 4.7 Bounded control.\n\nSuppose u is a scalar, u is bounded such that |u| ? 1, and the Hamiltonian is:\n\nH = Ho(t, x,???) + H1(t, x,???)u (4.109)\n\nSince H is linear in u\n\n?H\n?u\n\n= H1 (4.110)\n\nIn this case we apply the Minimum Principle differently from Example 4.6 because\nnow the control is bounded. We are seeking a control law such that the Hamiltonian\ngiven in Eq. (4.109) is minimized by the value we select for u. The Minimum Principle\nsays that we should minimize H with respect to u, so we must choose the u that\nmakes the value of the Hamiltonian the smallest it can be. Our choice of u cannot\ninfluence H0(t, x,???), so we can ignore this term. If H1(t, x,???) is a positive number,\nthen to minimize H we should pick the lowest value of u, i.e., u = ?1 (which is\non the lower bound of the control). Similarly, if H1 < 0 then we pick u = 1. If\nH1 = 0 the Minimum Principle does not provide us with a specific control law. In\nsummary, the Minimum Principle gives us:\n\nu =\n\n?\n???\n???\n\n?1 if H1 > 0\nundetermined if H1 = 0\n\n1 if H1 < 0\n\n(4.111)\n\n\n\n86 Chapter 4. Application of the Euler-Lagrange Theorem\n\n0 2 4 6 8 10\n?1.5\n\n?1\n\n?0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\nH\n1\n\nt\n\n0 2 4 6 8 10\n?1.5\n\n?1\n\n?0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\nu\n\nt\n\nFigure 4.8. The switching function and the bang-bang control given by Eq. (4.111).\n\nThe coefficient H1(t, x,???) is called the switching function. Figure 4.8 shows an exam-\nple where H1 oscillates through positive and negative values (moving instantaneously\nthrough zero). In such a case, the control law switches back and forth between its\nminimum and maximum values and is called a \u201cbang-bang\u201d control.\n\nIn the case where H1(t, x, u) ? 0 on some non-zero interval, say [t1, t2] ? [to, tf],\nthen the subarc [t1, t2] is called a singular subarc. When singular subarcs appear\nwe need yet another theorem called the Generalized Legendre-Clebsch condition to\ndetermine the control law. (See Chap. 9.)\n\nExample 4.8 Bounded control problem.\n\nConsider the following:\n\nMinimize:\n\nJ =\n1\n2\n\n? 3\n0\n\nx2dt (4.112)\n\nsubject to:\n\nx? = u (4.113)\n\nwith B.C.s:\n\nx(0) = 1 (4.114)\n\nx(3) = 1 (4.115)\n\n\n\n4.7. A \u201cCookbook\u201d for Optimization Problems 87\n\nand with the control constraint:\n\n|u| ? 1 (4.116)\n\nThe solution will involve analysis of the switching function. We solve it in the\nfollowing steps.\n\n1. Form the Hamiltonian:\n\nH =\n1\n2\n\nx2 + ?u (4.117)\n\n2. Write the Euler-Lagrange equations:\n\n?? = ?Hx = ?x (4.118)\nHu = ? = H1 (4.119)\n\nThus, we have a switching function so the control law is:\n\nu =\n\n?\n???\n???\n\n?1 if H1 > 0\nundetermined if H1 = 0\n\n1 if H1 < 0\n\n(4.120)\n\n3. The differential form of the transversality condition is:\n\nHfdtf ? ???Tf dxf + d? = 0 (4.121)\nIn this case xf and tf have been specified and ? = 0, thus dtf = dxf = d? = 0 and the\ntransversality condition provides no additional information. This can be verified by\nnoting that there are 2n + 2 = 2(1) + 2 = 4 conditions already specified. They are to,\ntf, xo, and xf.\n\nHowever, using the adjoined method one can generalize the terminal constraint from\n\t = x(3) ? 1 = 0 to be \t = x(3) ? xf = 0. Then use Exercise 5 of Chap. 3 to\nobtain ?J\n\n?xf = ?? = ??(3), which provides the change in the cost due to a small\nchange in xf without explicitly recalculating the cost using Eq. (4.112). The value of ?\nis determined using the second equation in the system of equations below:\n\nx? = u (4.122)\n\n?? = ?x (4.123)\nwith B.C.s:\n\nx(0) = 1 (4.124)\n\nx(3) = 1 (4.125)\n\n\n\n88 Chapter 4. Application of the Euler-Lagrange Theorem\n\n0 0.5 1 1.5 2 2.5 3\n?2\n\n?1\n\n0\n\n1\n\n2\n\n3\n\n4\n\nx\n\nt\n\nFigure 4.9. Possible paths for constant u from Eqs. (4.126 )\u2013(4.129).\n\nWith these two boundary conditions, four possible solutions for x appear, depending\non whether u = \u00b11 at the initial and final times.\n\nFor x(0) = 1 we have:\n\nx = +t + 1 (u = +1) (4.126)\n\nx = ?t + 1 (u = ?1) (4.127)\n\nFor x(3) = 1 we have:\n\nx = +t ? 2 (u = +1) (4.128)\nx = ?t + 4 (u = ?1) (4.129)\n\nPlotting these four solutions and looking at the possible paths from the initial\ncondition to the final condition, we obtain Fig. 4.9.\n\nConsidering the functional we are trying to minimize, it is clear that the area under\nthe curve must be as small as possible. As a result, we obtain the solution shown in\nFig. 4.10, where we see that u = ?1 from t = 0 to t = 1 at which point x becomes zero\nand the control is turned off. Then at t = 2 the control is set to maximum, u = +1, to\ndrive x up to the final condition x(3) = 1. As mentioned earlier, this behavior is called\na bang-bang control.\n\n\n\n4.8. Constant Hamiltonian 89\n\n0 0.5 1 1.5 2 2.5 3\n?0.5\n\n0\n\n0.5\n\n1\nx\n\nt\n\n0 0.5 1 1.5 2 2.5 3\n?1.5\n\n?1\n\n?0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\nu\n\nt\n\nFigure 4.10. Solution for bounded control problem, example 4.8. The cost functional,\nprocess equation, and B.C.s are given by Eqs.(4.112)\u2013(4.115). The control is\nbounded by Eq. (4.116).\n\n4.8. Constant Hamiltonian\n\nConsider an optimal control problem with Hamiltonian H(t, x,???, u) and bounded,\nscalar control |u| ? 1. Then\n\ndH\ndt\n\n=\n?H\n? t\n\n(4.130)\n\nso if H does not contain time explicitly, ?H\n?t = 0 and\n\nH = constant (4.131)\n\nWe show this by considering the Hamiltonian:\n\nH = L + ???Tf (4.132)\n\nTaking the total time derivative we have:\n\ndH\ndt\n\n=\n?H\n? t\n\n+\n?H\n?x\n\nx? +\n?H\n????\n?????? +\n\n?H\n?u\n\nu? (4.133)\n\n\n\n90 Chapter 4. Application of the Euler-Lagrange Theorem\n\nUsing the Euler-Lagrange equation\n\n?H\n?xxx\n\n= ???????T (4.134)\n\nand the state equation\n\n?H\n????\n\n= x?T (4.135)\n\nin Eq. (4.133) provides\n\ndH\ndt\n\n=\n?H\n? t\n\n? ??????Tx? + x?T?????? + ?H\n?u\n\nu? =\n?H\n? t\n\n+\n?H\n?u\n\nu? (4.136)\n\nIf u is not on the bound, then it obeys the Euler-Lagrange equation\n\n?H\n?u\n\n= 0 (4.137)\n\nand if u is on the bound (i.e., u = \u00b11) for a finite interval, then\n\nu? = 0 (4.138)\n\nThus Eq. (4.136) becomes\n\ndH\ndt\n\n=\n?H\n? t\n\n(4.139)\n\nand if the Hamiltonian is not an explicit function of time then it is a constant.\nThe observation that H is constant in certain optimization problems will prove to\n\nbe important in their solution.\n\n4.9. Summary\n\nMany technical challenges arise in the application of the Euler-Lagrange theorem.\nWhile the theorem converts the Problem of Bolza into a set of differential equations\n(for the states and the costates), the boundary conditions are split. That is, we\nhave some of the conditions set as initial conditions and some as final conditions.\nMathematically the two-point boundary-value problem (TPBVP) can be well defined,\nbut the engineer may have to resort to numerical methods to solve the problem.\nIn some cases analytical solutions exist, which can provide insight into particular\ncases.\n\nA \u201ccookbook\u201d is presented to make the application of the Euler-Lagrange theorem\nas systematic as possible. However, we soon find that there are several obstacles.\nIn obtaining necessary conditions for the minimum time to launch a satellite into\n\n\n\n4.10. Exercises 91\n\norbit, we find that the Euler-Lagrange theorem fails to uniquely specify the optimal\ncontrol law (to steer the thrust). We must invoke another theorem called the Minimum\nPrinciple. A more restricted version of the Minimum Principle, the Weierstrass\ncondition, is discussed and proven in Chap. 5. (Chapter 6 states the more general\nMinimum Principle without proof.)\n\nWe also find an example where the Minimum Principle fails to provide the control\nlaw in the case of a singular subarc. Chapter 9 presents a theorem to surmount this\ndifficulty, called the Generalized Legendre-Clebsch condition.\n\nClearly the optimization of trajectories cannot be completely solved in \u201ccookbook\u201d\nform. There exist deep mathematical and numerical challenges. Each new application\nmay require new techniques or special handling.\n\n4.10. Exercises\n\n1. Solve for the optimal control, u?(t), and the optimal trajectory, x?(t):\n\nMin J =\n1\n2\n\n? 1\n0\n\n(x2 + u2)dt\n\nsubject to\n\nx? = ?x + u\nx(0) = 1, x(1) = 0\n\n2. Pose a well-defined TPBVP for the following problem. (Do not attempt to solve\nthe differential equations.)\n\nGiven a constant-thrust rocket engine, T = Thrust, operating for a given length\nof time, tf, we wish to find the thrust-direction history, ?(t), to transfer a rocket\nvehicle from a given initial circular orbit to the largest possible circular orbit,\nwhere:\n\nr = radial distance of spacecraft from attracting center,\n\nu = radial component of velocity,\n\nv = tangential component of velocity,\n\nm = mass of spacecraft,\n\nm? = fuel consumption rate (constant),\n\n? = thrust direction angle, and\n\n? = gravitational constant of attracting center.\n\nThe problem may be stated as follows (Fig. 4.11).\n\n\n\n92 Chapter 4. Application of the Euler-Lagrange Theorem\n\nr\n\nt = 0r(0)\n\nr(tf)\n\nt = tf\n\nAttracting\ncenter\n\nSpacecraft\n\nFinal orbit\n\nInitial orbit\n\nT\n\n?u\n\nv\n\nFigure 4.11. Maximum radius orbit transfer in a given time (Adapted from Bryson and Ho\n[1975]).\n\nFind ?(t) to maximize r(tf) subject to\n\nr? = u,\n\nu? =\nv2\n\nr\n? ?\n\nr2\n+\n\nT sin?\nm0 ? |m?|t ,\n\nv? = ?uv\nr\n\n+\nT cos?\n\nm0 ? |m?|t ,\n\nand\n\nr(0) = r0, u(0) = 0, v(0) =\n?\n?\n\nr0\n,\n\n?1 = u(tf) = 0, ?2 = v(tf) ?\n?\n\n?\n\nr(tf)\n= 0.\n\nNote: Explicitly state all the equations and all of the boundary conditions (i.e.,\ninitial and final) for a well-defined TPBVP.\n\n\n\n4.10. Exercises 93\n\n3. Zermelo\u2019s Problem\nA particle must travel through a region in which its instantaneous velocity\nmagnitude is given as a function of position, V(x, y).\n\nMin J =\n? tf\n\nto\ndt\n\nsubject to\n\nx? = V(x, y) cos?\n\ny? = V(x, y) sin ?\n\nwhere to, xo, yo are given and\n\nx(tf) = 0, y(tf) = 0\n\nThe control variable is ? (t).\n\n3a. Show that, along a minimum-time path, ? (t) must satisfy the differential\nequation\n\n?? =\n?V\n?x\n\nsin ? ? ?V\n?y\n\ncos ? (4.140)\n\nHints: The Hamiltonian is constant. Substitute solutions for ?x and ?y into\n??x = ?Hx and ??y = ?Hy to find an equation in ?? . Note that\n\nd\ndt\n\nV(x, y) =\n?V\n?x\n\nx? +\n?V\n?y\n\ny?.\n\nEquation (4.140) indicates that if V is constant then the minimum-time paths\nare straight lines.\n\n3b. Consider the special case where\n\nV = V(y).\n\nShow that\n\ncos ?\n\nV(y)\n= constant (4.141)\n\nEq. (4.141) is known as Snell\u2019s law.\n\n4. Solve Example 4.3, retaining P as an arbitrary constant (instead of setting P to 1).\n5. Briefly explain why HTu = 0 is not a necessary condition for a minimum of J if H is\n\na linear function of u.\n\n\n\n94 Chapter 4. Application of the Euler-Lagrange Theorem\n\nReferences\n\nA.E. Bryson, Jr., Y.C. Ho, Applied Optimal Control (Hemisphere, Washington, D.C., 1975)\nS.J. Citron, Elements of Optimal Control (Holt, Rinehart, and Winston, New York, 1969)\nD.G. Hull, Optimal Control Theory for Applications (Springer, New York, 2003)\nJ. Vagners, Optimization techniques. in Handbook of Applied Mathematics, 2nd edn., ed. by C.E.\n\nPearson (Van Nostrand Reinhold, New York, 1983) pp. 1140\u20131216\n\n\n\nChapter 5\n\nThe Weierstrass Condition\n\n5.1. Introduction\n\nIn Chap. 4 we noted that there are optimization problems that cannot be resolved by\nthe Euler-Lagrange theorem alone. Pontryagin\u2019s Minimum Principle often provides\nan additional condition that leads to a specific control law and to the solution of the\nproblem. The most general form of the Minimum Principle is stated in Chap. 6 without\nproof.\n\nIn this chapter we state and prove the Weierstrass necessary condition. At first\nglance the Weierstrass condition appears to be identical to Pontryagin\u2019s Minimum\nPrinciple. The main difference is that the former requires the control to be a\ncontinuous, unbounded function of time while the latter is far more general in allowing\nthe control to be a \u201cmeasurable function\u201d (which includes piecewise continuous,\nbounded functions of time). We are interested in applications in which the control\nmay be a piecewise continuous function (e.g., bang-bang control in which a thruster\nis turned on and off). So we will make use of the most general form of the Minimum\nPrinciple, but for the level of this text we do not have sufficient mathematical tools to\nprove Pontryagin\u2019s Minimum Principle.\n\n5.2. Statement of the Weierstrass Necessary Condition\n\nThe Weierstrass condition is as follows.\nIf x?(t) ? C1[to, tf] and u?(t) ? C 0[to, tf]\u2014i.e., if the optimal trajectory is\n\ncontinuously differentiable and the optimal control is continuous over the closed\ninterval of time from t0 to tf\u2014such that they minimize the Problem of Bolza:\n\nJ = ?(tf, xf) +\n? tf\n\nto\nL(t, x, u)dt (5.1)\n\nsubject to:\n\nx? = f (t, x, u) (5.2)\n\nx(to) = xo (5.3)\n\n?(tf, xf) = 0 (5.4)\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 5,\n\u00a9 Springer Science+Business Media New York 2014\n\n95\n\n\n\n96 Chapter 5. The Weierstrass Condition\n\nthen for all t ? [to, tf] it is necessary that:\n\nH[t, x?(t), u?(t), ?(t)] ? H[t, x?(t), u(t), ?(t)] (5.5)\n\nfor all admissible (unbounded control) u(t). [If u(t) is bounded, then the Weierstrass\ncondition no longer holds.]\n\nEquation (5.5) is the Weierstrass necessary condition. On the left-hand side of\nthe equation we have the Hamiltonian computed on the optimal trajectory, x?(t),\nwith the optimal control, u?(t). On the right-hand side we have the Hamiltonian\ncomputed on the optimal trajectory at the same time but for a non-optimal control\nu(t). For any non-optimal control, the Hamiltonian must be greater than or equal to the\nHamiltonian computed for the optimal control (again assuming the optimal trajectory\nis always used).\n\nIn 1939, E.J. McShane found a way to express Eq. (5.5) in simple English as quoted\nin Bryson and Ho [1975], \u201cThe Hamiltonian must be minimized over the set of all\nadmissible controls\u201d (which applies to the more general Minimum Principle, as well).\nThe meaning of this principle will become clear when we present applications in\nChaps. 6 and 7. We have already seen an example in Chap. 4 where, for unbounded\ncontrol, Hu = 0 and Huu ? 0 which is a special case of minimizing H with respect\nto u.\n\n5.3. Proof Outline of the Weierstrass Necessary Condition\n\nWe will use a special variation in the proof outline of this theorem. The control blip\nU(t) disturbs the state from the optimal by X(t). The opposite blip u(t, e) brings the\nstate back to x?(t) via x(t, e), as illustrated in Fig. 5.1. Let t ? (to, tf). Let e > 0 be a\nsmall parameter. Implicit in this method of proof is the assumption that it is possible\nto return to the optimal path.\n\nto t1 t1 + e t2 tf t to t1 t1 + e t2 tf t\n\nU(t)\n\nu(t, e)\n\nx(t, e)\n\nx(t)u(t)\n\nu?(t)\n\nX(t)\n\nx?(t)\n\nFigure 5.1. Control and state history. The nonoptimal control blip, U(t), disturbs the state\nfrom its optimal path. The opposite blip u(t, e), restores the optimal path at\ntime t2.\n\n\n\n5.3. Proof Outline of the Weierstrass Necessary Condition 97\n\nNote that while holding t2 fixed,\n\nlim\ne?0 x(t, e) = x\n\n?(t) (5.6)\n\nlim\ne?0 x?(t, e) = x?\n\n?(t) (5.7)\n\nlim\ne?0 u(t, e) = u\n\n?(t) (5.8)\n\nNow we define our special variation, x?, of the state variable:\n\nx?(t) ?\n\n?\n???\n???\n\nx?(t) on [to, t1] and on [t2, tf] No variations\nX(t) on [t1, t1 + e] Strong variation\nx(t, e) on [t1 + e, t2] Weak variation\n\n(5.9)\n\nA similar variation is used by Citron [1969], Ewing [1985], and Vagners [1983]. The\nterms weak and strong will be discussed in greater detail later on (in Sect. 6.4). We note\nthat in the strong case the slope of the variation is different from that of the optimal\npath. The discontinuous jump in control, U(t), can be arbitrarily large, as long as u(t, e)\ncan bring the trajectory back to x?(t). (Of course e must be infinitesimally small.) Hull\n[2003] points out that \u201cEven though the minimum control is assumed to be continuous,\ncontrols in general can be discontinuous so that the admissible comparison control can\nbe continuous or discontinuous.\u201d\n\nLet J(e) be the cost of the trajectory defined by x?(t). The basic concept of the proof\nof Eq. (5.5) is to presume:\n\nJ(e) ? J? ? 0 (5.10)\n\nas illustrated in Fig. 5.2. Expanding J about e = 0 we have:\n[\n\nJ(0) +\ndJ\nde\n\n????\ne = 0\n\ne + O(e2)\n]\n\n? J? ? 0 (5.11)\n\nIgnoring the higher order terms we obtain:\n\ndJ\nde\n\n????\ne = 0\n\n? 0 (5.12)\n\n(where we have used J(0) = J? and e = de.) It is then clear that, in the proof we are\ntrying to show, J? is indeed the optimal solution. The rest involves Leibniz\u2019 rule:\n\nd\nd?\n\n(? b(?)\na(?)\n\nf (x, ?)dx\n\n)\n= f [b(?), ?]db(?)\n\nd?\n?f [a(?), ?]da(?)\n\nd?\n+\n? b(?)\n\na(?)\n\n? f (x, ?)\n??\n\ndx (5.13)\n\n\n\n98 Chapter 5. The Weierstrass Condition\n\ne0\n\nJ\n\nJ?\n\nFigure 5.2. Basic concept of the proof of the Weierstrass condition: J(e) ? J?.\n\nLet us write the expression for the functional:\n\nJ(e) = ?(t?f , x\n?\nf ) +\n\n? t1\nto\n\n{H? ? ???Tx??(t)}dt\n\n+\n? t1+e\n\nt1\n{H[t, X(t), U(t),???(t)] ? ???TX?(t)}dt\n\n+\n? t2\n\nt1+e\n{H[t, x(t, e), u(t, e),???(t)] ? ???Tx?(t, e)}dt\n\n+\n? tf\n\nt2\n{H? ? ???Tx??(t)}dt (5.14)\n\nwhere H? = H[t, x?(t), u?(t),???(t)].\nTo guide our analysis, we note in Eq. (5.14) that:\n\n1. The first term ?(t?f , x\n?\nf ) does not contain e,\n\n2. The second and fifth terms have no terms in e,\n3. The third term depends on e outside the integrand, and\n4. The fourth term depends on e both outside and inside the integrand.\n\nTherefore, only the third and fourth terms will contribute to dJde . Applying Leibniz\u2019\nrule we obtain:\n\ndJ\nde\n\n= {H[t, X(t), U(t),???(t)] ? ???TX?(t)}|t1+e\nd(t1 + e)\n\nde\n\n? {H[t, x(t, e), u(t, e),???(t)] ? ???Tx?(t, e)}|t1+e\nd(t1 + e)\n\nde\n\n+\n? t2\n\nt1+e\n\n[\nHx(t, e)\n\n?x(t, e)\n?e\n\n+ Hu(t, e)\n?u(t, e)\n?e\n\n? ???T ? x?(t, e)\n?e\n\n]\ndt (5.15)\n\n\n\n5.3. Proof Outline of the Weierstrass Necessary Condition 99\n\nSince we require dJde\n???\ne = 0\n\n? 0 and noting that d(t1+e)de = 1, we have:\n\ndJ\nde\n\n????\ne = 0\n\n= H[t1, X(t1), U(t1),???(t1)] ? ???T(t1)X?(t1)\n\n? H[t1, x?(t1), u?(t1),???(t1)] + ???T(t1)x??(t1)\n\n+\n? t2\n\nt1\n\n[\nH?x\n\n?x(t, e)\n?e\n\n????\ne = 0\n\n+ H?u\n?u(t, e)\n?e\n\n????\ne = 0\n\n? ???T ? x?(t, e)\n?e\n\n????\ne = 0\n\n]\ndt ? 0\n\n(5.16)\n\nFor the last term (inside the integral) we apply integration by parts:\n\n? t2\nt1\n\n????T ? x?(t, e)\n?e\n\ndt =\n[\n????T ?x(t, e)\n\n?e\n\n]????\nt2\n\nt1\n+\n? t2\n\nt1\n????\n\nT ?x(t, e)\n?e\n\ndt (5.17)\n\nThus, we have:\n\ndJ\nde\n\n????\ne = 0\n\n= H[t1, X(t1), U(t1),???(t1)] ? H?(t1)\n\n? ???T(t1)X?(t1) + ???T(t1)x??(t1)\n\n? ???T(t2) ?x(t, e)\n?e\n\n????e = 0\nt=t2\n\n+ ???T(t1)\n?x(t, e)\n?e\n\n???? e = 0\nt=t1\n\n+\n? t2\n\nt1\n\n[\n(H?x + ????\n\nT)\n?x(t, e)\n?e\n\n????\ne = 0\n\n+ (H?u)\n?u(t, e)\n?e\n\n????\ne = 0\n\n]\ndt ? 0 (5.18)\n\nNow, the following term vanishes:\n\n????T(t2) ?x(t, e)\n?e\n\n???? e = 0\nt=t2\n\n= 0 (5.19)\n\nsince we are back to the optimal at t2 [i.e., x(t2, e) = x?(t2)] and\n\nH?x + ????\nT = 0 (5.20)\n\nH?u = 0 (5.21)\n\nfrom the Euler-Lagrange theorem. Figure 5.3 provides a closer look at the varied path,\nfor clarity. Thus,\n\n\n\n100 Chapter 5. The Weierstrass Condition\n\nx(t, e)\n\nt1 t1 + e\n\nX(t)\n\nx?(t)\n\nt2\nFigure 5.3. A closer look at the special variation given by Eq. (5.9).\n\nt1 + e + det1 + e t2t1\n\nX(t)\n\nX(t1 + e + de) ? X(t1 + e) x(t1 + e + de, e + de) ? x(t1 + e, e)\n\nx?(t)\n\nx(t, e)\n\nFigure 5.4. Characterization of ?x(t ,e)\n?e\n\n?\n?\n? e = 0\n\nt=t1\nwhich appears in Eq. (5.22).\n\ndJ\nde\n\n????\ne = 0\n\n= H[t1, X(t1), U(t1),???(t1)] ? H?(t1)\n\n? ???T(t1)X?(t1) + ???T(t1)x??(t1) + ???T(t1) ?x(t, e)\n?e\n\n???? e = 0\nt=t1\n\n? 0 (5.22)\n\nWe will use Fig. 5.4 in order to characterize ?x(t,e)\n?e\n\n??? e = 0\nt=t1\n\n, which is not zero.\n\nLet us compute the total derivative dxde\n???e = 0\nt=t1\n\n:\n\nd[x(t1 + e, e)]\nde\n\n=\n?x\n? t\n\nd(t1 + e)\nde\n\n+\n?x(t1 + e, e)\n\n?e\n(5.23)\n\nso that\n\ndx\nde\n\n???? e = 0\nt=t1\n\n= x??(t1) +\n?x\n?e\n\n???? e = 0\nt=t1\n\n(5.24)\n\n\n\n5.3. Proof Outline of the Weierstrass Necessary Condition 101\n\nFrom the definition of a derivative we have:\n\ndx\nde\n\n???? e = 0\nt=t1\n\n= lim\nde?0\n\n[\nx(t1 + e + de, e + de) ? x(t1 + e, e)\n\nde\n\n]????\ne = 0\n\n= lim\nde?0\n\n[\nX(t1 + e + de) ? X(t1 + e)\n\nde\n\n]????\ne = 0\n\n(5.25)\n\ntherefore:\n\ndx\nde\n\n???? e = 0\nt=t1\n\n? X?(t1) (5.26)\n\nand we obtain\n\nX?(t1) = x??(t1) +\n?x\n?e\n\n???? e = 0\nt=t1\n\n(5.27)\n\nEquivalent expressions are given by Ewing [1985] and Vagners [1983]. From\nEq. (5.27) we have:\n\n?x\n?e\n\n???? e = 0\nt=t1\n\n= X?(t1) ? x??(t1) (5.28)\n\nwhich, after substituting into Eq. (5.22), implies:\n\nH ? H? ? ???T(t1)X?(t1) + ???T(t1)x??(t1) + ???T(t1)[X?(t1) ? x??(t1)] ? 0 (5.29)\n\nThus, from Eq. (5.29) we obtain\n\nH ? H? ? 0 (5.30)\n\nor,\n\nH[t, x?(t), u?(t),???(t)] ? H[t, X(t), U(t),???(t)] (5.31)\n\nfor t = t1 ? (to, tf), where\n\nX(t1) = x?(t1) (5.32)\n\nThus, Eq. (5.31) provides the Weierstrass necessary condition. In the proof we\nassumed t = t1 ? (to, tf). Later it will be shown that H is continuous, which implies\nthat the condition must also hold at the endpoints. (By continuity H ? H? ? 0 for\nt1 ? [to, tf] ; otherwise, if H < H? at to, there is a contradiction.)\n\n\n\n102 Chapter 5. The Weierstrass Condition\n\n5.4. Summary\n\nThe Weierstrass condition, Eq. (5.5), has been proved using a special variation,\nEq. (5.9). A more general condition, the Minimum Principle, is presented in Chap. 6\nwithout proof. The Weierstrass condition applies when the control is unbounded\nand continuous, whereas the Minimum Principle applies when the control may be\npiecewise continuous and bounded (or more generally, measurable). The Minimum\nPrinciple is employed in Step 4 of our \u201cCookbook\u201d for optimization problems\npresented in Chap. 4. The meaning of this principle will become clearer in Chaps. 6\nand 7 where we give its precise statement and several examples of its application.\n\n5.5. True or False Quiz for Chaps. 1\u20135\n\nAnswer the following questions in the context of the material presented in Chaps. 1\u20135.\nCircle the correct answer.\n\n1. The problems of Bolza, Lagrange, and Mayer are interchangeable.\n\nTrue False\n\n2. The Dirac delta function, ?(t), is piecewise continuous.\n\nTrue False\n\n3. All optimization problems lead to admissible controls.\n\nTrue False\n\n4. In the proof of the Euler-Lagrange theorem we make use of the expression\n\ndxf = ?x(t?f ) + x?\n?(t?f )dtf\n\nTrue False\n\n5. In the Euler-Lagrange theorem, if x? = f(t, x, u) is an n-vector, then the number of\nboundary conditions required for a well-defined TPBVP is n + 2.\n\nTrue False\n\n6. The Minimum Principle can be stated as: \u201cH? must be minimized over the set of\nall admissible u.\u201d\n\nTrue False\n\n7. In the un-adjoined approach, the transversality condition can be ignored if all the\ninitial and terminal boundary conditions are specified.\n\nTrue False\n\n8. The step function, h(t), is piecewise continuous.\n\nTrue False\n\n\n\nReferences 103\n\n9. When (rf/r0) > 11.9, a three-impulse orbital transfer can be more economical\nthan a two-impulse transfer.\n\nTrue False\n\n10. The Minimum Principle is more general than the Weierstrass condition.\n\nTrue False\n\nSolution: 1T, 2F, 3F, 4T, 5F, 6T, 7T, 8T, 9T, 10T.\n\nReferences\n\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\nS.J. Citron, Elements of Optimal Control (Holt, Rinehart, and Winston, New York, 1969)\nG.M. Ewing, Calculus of Variations with Applications (Dover, New York, 1985)\nD.G. Hull, Optimal Control Theory for Applications (Springer, New York, 2003)\nJ. Vagners, Optimization techniques, in Handbook of Applied Mathematics, 2nd edn., ed. by C.E.\n\nPearson (Van Nostrand Reinhold, New York, 1983), pp. 1140\u20131216\n\n\n\nChapter 6\n\nThe Minimum Principle\n\n6.1. Statement of the Minimum Principle\n\nThe Weierstrass condition, which requires the Hamiltonian to be minimized over\nthe set of all admissible controls, is a powerful tool for solving a class of opti-\nmization problems that do not immediately yield to our familiar algorithm with the\nEuler-Lagrange equations and the transversality condition. However, the Weierstrass\ncondition\u2019s \u201cset of all admissible controls\u201d is limited to continuously differentiable,\nunbounded functions, which are by no means the only feasible controls in practice\nor in principle. For example, \u201cbang-bang\u201d or \u201con-off\u201d control schemes are frequently\nemployed in everyday engineering applications, but these controls do not fall within\nthe Weierstrass condition\u2019s set.\n\nThere exists a rigorous proof of a more general theorem by Pontryagin et al.\n[1962], usually stated in the literature as the Minimum Principle, which expands the\nWeierstrass condition\u2019s set of controls to include all \u201cmeasurable\u201d functions. (What\nconstitutes a measurable function is beyond the scope of this text; however, piecewise\ncontinuous functions like the bang-bang control scheme are included.) Pontryagin\u2019s\nMinimum Principle is a much stronger statement than the Weierstrass condition\nbecause it provides the most general continuity restrictions on the control and on\nthe functions of the Bolza problem. McShane (as reported in Bryson and Ho [1975])\nexpressed the principle in the wonderfully concise and clear verbal statement: \u201cH?\nmust be minimized over the set of all admissible u.\u201d\n\n6.1.1. Problem Statement\n\nFor the optimal control problem:\n\nMinimize:\n\nJ = ?o?(to, xo, tf, xf) + ?o\n? tf\n\nto\nL(t, x, u)dt (6.1)\n\nsubject to:\n\nx? = f (t, x, u) (6.2)\n\nx(to) = xo (6.3)\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 6,\n\u00a9 Springer Science+Business Media New York 2014\n\n105\n\n\n\n106 Chapter 6. The Minimum Principle\n\nwhere x is an n-vector and u is an m-vector, and where the terminal constraints are\n\n?(tf, xf) = 0 (6.4)\n\nand where\n\nu ? U (6.5)\nis the set of admissible controls.\n\nThe set U is an arbitrary set in m-dimensional Euclidean space and u(t) may be a\n\u201cmeasurable\u201d function on [to, tf] whose values lie in U. Some authors (e.g. Vagners\n[1983]) say Pontryagin\u2019s Minimum Principle is applicable to any \u201ctopological control\nspace\u201d U. Specifically, U includes the case where the control u(t) may assume a\nnumber of discrete levels u1, . . . , uk. The definitions of measurable functions and\nof topological control space are outside the scope of this text (see Ewing [1985]).\nIn applications it is usually sufficient to assume that u(t) is a bounded P.C. function on\n[to, tf] (see Berkovitz [1974]).\n\n6.1.2. Pontryagin\u2019s Minimum Principle\n\nFor the problem and assumptions stated above, suppose u?(t) ? U causes J to be\nminimized. Let us write the Hamiltonian as\n\nH(t, x, u,???) ? ?oL(t, x, u) + ???Tf (t, x, u) (6.6)\n\nAccording to the multiplier rule (see Hestenes [1966] and Ewing [1985]) there exist\ncontinuous costate functions ?i(t) on [to, tf] for i = 0, 1, . . . , n such that:\n\n??i = ?H?xi (i = 1, . . . , n) (6.7)\n\nat each t ? [to, tf] on arcs where u(t) is continuous, and ?o is a constant such that:\n\n[?o, ?1(t), . . . , ?n(t)] ?= 0. (6.8)\n\nat each t ? [to, tf]. (Nevertheless, some components may be zero. When ?o = 1 the\nproblem is \u201cnormal.\u201d Examples of normal and abnormal problems are provided in\nSect. 6.1.3.) For the conditions stated above [Eqs. (6.1)\u2013(6.8)] we have Pontryagin\u2019s\nMinimum Principle:\n\nH[t, x?(t), u?(t),???(t)] ? H[t, x?(t), u(t),???(t)] (6.9)\n\nwhere u ? U.\nPierre [1969] emphasized that Eq. (6.9) does not imply that:\n\nH[t, x(t), u?(t), ?(t)] ? H[t, x(t), u(t), ?(t)] (6.10)\n\n\n\n6.1. Statement of the Minimum Principle 107\n\nfor arbitrary (i.e., non-optimal) x(t). Proof of Pontryagin\u2019s Minimum Principle is\nnotoriously difficult. (See Pontryagin et al. [1962], Hestenes [1966], and Berkovitz\n[1974].) In his discussion of the Minimum Principle, Pierre notes that Athans and\nFalb [1966] provide a heuristic proof in forty pages of text! In his introductory text\nRoss [2009] points out that while proving Pontryagin\u2019s Minimum Principle is not\neasy, applying the principle is very easy. He then proceeds to give several important\napplications and avoids dealing with the proof entirely. In Chap. 2 on Pontryagin\u2019s\nPrinciple, Ross jokingly adds, \u201cYou want proof? You can\u2019t handle the proof!\u201d (For\nmore Curious Quotations see appendix D of the present text.) As mentioned earlier\n(in Chap. 5), we also make use of Pontryagin\u2019s Principle without proof.\n\nA problem is said to be abnormal if ?o = 0 and the conditions of the Minimum\nPrinciple are satisfied. Otherwise, ?o = +1 and the problem is normal (the usual\ncase). Of course, any positive constant for ?0 could be used in the normal case since\nits particular value does not change the optimal trajectory and optimal control\u2014the\nchoice of unity is merely a convenience.\n\n6.1.3. Examples\n\nExample 6.1 A non-optimization problem.\n\nConsider the following:\n\nMinimize:\n\nJ = ?of (x, y) (6.11)\n\nsubject to:\n\nS(x, y) = x2 + y2 = 0 (6.12)\n\nWe see immediately that Eq. (6.12) implies that\n\nx? = y? = 0 (6.13)\n\nso, this is not an optimization problem to begin with!\n\nExample 6.2 Abnormal and normal problems.\n\nConsider the following problem.\n\nMinimize:\n\nJ = ?o\n? 1\n\n0\nx2dt (6.14)\n\nsubject to:\n\nx? = u (6.15)\n\nx(0) = 1 (6.16)\n\n|u| ? 1 (6.17)\n\n\n\n108 Chapter 6. The Minimum Principle\n\nwhere x and u are scalars. The Hamiltonian is:\n\nH = ?ox2 + ?1u (6.18)\n\nLet us consider two cases:\n\n1. x(1) = 0,\n2. x(1) is free.\n\nFor both cases, let us set ?o = 0 to find out if they are abnormal cases (i.e., that we can\nignore the cost functional, J).\n\nThe costate equation becomes\n\n??1 = ?Hx = 0 (6.19)\n\nso that\n\n?1 = constant. (6.20)\n\nThe control equation is found from:\n\nHu = ?1 (6.21)\n\nwhere ?1 is the switching function:\n\n?1 > 0 ? u = ?1\n?1 = 0 ? u = undetermined\n?1 < 0 ? u = +1 (6.22)\n\nEquations (6.22) are, of course, the direct result of minimizing H with respect to u.\nThe differential form of the transversality condition (see Sect. 3.5, Exercise 2) is:\n\n[H?dt ? ?1dx]\n??tf\nto + ?od? = 0 (6.23)\n\nand since d? = 0 we have\n\nH?f dtf ? H?odto ? ?1fdxf + ?1odxo = 0, (6.24)\nwhere all the differentials vanish except\n\n?1fdxf = 0 (6.25)\n\nFor case 1 the final state is specified:\n\nx(1) = 0 (6.26)\n\n\n\n6.1. Statement of the Minimum Principle 109\n\nt\n\nx(t)\n\n1\n\n1\n\nFigure 6.1. Case 1 where the final state is specified.\n\nso\n\ndxf = 0 (6.27)\n\nThe transversality condition drops out. Thus, we have a well-defined TPBVP and\nconclude that if ?o = 0, then u = ?1 and (consequently) ?1 > 0 (i.e., the switching\nfunction must be positive) which allows us to satisfy the necessary conditions (as\nillustrated in Fig. 6.1). It is seen that (?o, ?1) = (0, ?1) ?= 0 and we have satisfied\nthe conditions of the Minimum Principle. Therefore, this is an abnormal problem.\nIn an abnormal problem we obtain a solution in which the cost functional, in this case\nEq. (6.14), is ignored\u2014so we are not really optimizing anything.\n\nFor case 2 the final state is free (as shown in Fig. 6.2) so\n\ndxf ?= 0 (6.28)\n\nThe differential form of the transversality condition is\n\n?1fdxf = 0 (6.29)\n\nso that\n\n?1(tf) = 0 (6.30)\n\nThus, we also have\n\n?1(t) = 0 (6.31)\n\n\n\n110 Chapter 6. The Minimum Principle\n\nt\n\nu = ?1\n\nu = +1\n\nReachable Set\n\nx(t)\n\n1\n\n1\n\nFigure 6.2. Case 2 where final state is free.\n\nsince ??1 = 0. Therefore (?o, ?1) = 0, which violates the first statement [Eq. (6.8)] of\nthe Minimum Principle. Thus, the necessary conditions are not satisfied.\n\nLetting ?0 = 1, we obtain:\n\nH = x2 + ?1u (6.32)\n\nx? = u (6.33)\n\nwith I.C.s x(0) = 1 and\n\n??1 = ?Hx = ?2x (6.34)\n\nso that\n\n?1(t) ?= 0 (6.35)\nThe transversality condition is:\n\n?1fdxf = 0 (6.36)\n\nso\n\n?1(tf) = 0 (6.37)\n\n\n\n6.1. Statement of the Minimum Principle 111\n\nThus, we have a well-defined TPBVP:\n\nx? = u, to = 0, x(to) = 1 (6.38)\n\n??1 = ?2x, tf = 1, ?1(tf) = 0 (6.39)\n\nFor u = 1 we obtain:\n\nx? = 1 (6.40)\n\nsince x(t0) = 1, the solution for x is\n\nx(t) = t + 1 (6.41)\n\nand thus\n\n??1 = ?2t ? 2 (6.42)\n\nThe solution for ?1, using ?(tf) = 0 is\n\n?1(t) = ?t2 ? 2t + 3 (6.43)\n\nFor u = ?1\n\nx? = ?1 (6.44)\n\nso with x(t0) = 1 we have x(t) = ?t + 1. Also,\n\n??1 = 2t ? 2 (6.45)\n\nand when we apply ?1(tf) = 0 we obtain ?1(t) = t2 ? 2t + 1.\nTo choose between these two solutions (u = 1 or u = ?1), we could evaluate J;\n\nnevertheless, by inspecting the cost functional J =\n? 1\n\n0 x\n2dt, it is clear that the u = ?1\n\nsolution provides the lowest cost:\n\nx(t) = 1 ? t (6.46)\n?1(t) = (1 ? t)2 (6.47)\nu(t) = ?1 (6.48)\n\nThat is, we see from Fig. 6.2 that when u(t) = ?1 the value of x decreases at the\nquickest possible rate to make the cost functional, Eq. (6.14), the lowest possible\nvalue.\n\n\n\n112 Chapter 6. The Minimum Principle\n\n6.2. Legendre-Clebsch Necessary Condition\n\nWe have made use of the Legendre-Clebsch necessary condition in Step 4 of our\nCookbook (in Chap. 4). We now formally state and prove this condition through use\nof the Minimum Principle.\n\nIf H is second-order differentiable in u, the optimal control at t is interior (not on\nthe control boundary), and u(t) is \u201cinfinitesimally close\u201d to u?(t), i.e., a weak variation,\nthen:\n\nH?u(t) = 0, H?uu(t) ? 0 (6.49)\n\nwhich means the matrix Huu must be positive semi-definite.\nThe proof follows from the Minimum Principle:\n\nH?[t, x?(t), u?(t),???(t)] ? H[t, x?(t), u(t),???(t)] (6.50)\n\nUsing a Taylor series to expand about u? to second-order in u we obtain:\n\nH? ? H? + H?u(u ? u?) +\n1\n2\n\n(u ? u?)TH?uu(u ? u?) + O(?u3) (6.51)\n\nbut H?u = 0, from the Euler-Lagrange theorem since we assume the optimal control\nis not on the bound. Rearranging Eq. (6.51) and ignoring O(?u3) we deduce using\nEq. (6.50)\n\nH?uu ? 0. (6.52)\n\nwhich is the Legendre-Clebsch necessary condition.\n\n6.3. Notes on Necessary and Sufficient Conditions\n\nExample 6.3 Necessary and sufficient condition problem.\n\nConsider Fig. 6.3. Suppose we have a set A with the property:\n\n{(x, y) ? A}. (6.53)\n\nA sufficient condition guarantees that (x, y) is in the set A but is usually too restrictive\nto uniquely define all (x, y) in set A. A necessary condition applies to every element in\nthe set A but is usually too loose to define all (x, y) in A uniquely.\n\nNow let us consider particular statements that pertain to the set A in Fig. 6.3. For\nexample:\n\nx =\n1\n2\n\na, y =\n1\n2\n\nb (6.54)\n\n\n\n6.3. Notes on Necessary and Sufficient Conditions 113\n\ny\n\nb\n\na x\n\nA\n\nFigure 6.3. (x, y) ? A.\n\nEquations (6.54) provide a sufficient condition since they guarantee that (x, y) ? A.\nOn the other hand:\n\n0 ? x ? a (6.55)\n\nis a necessary but not sufficient condition that (x, y) ? A. Similarly\n\n0 ? y ? b (6.56)\n\nis a necessary condition but it is not sufficient. Finally, we see that\n\n0 ? x ? a, 0 ? y ? b (6.57)\n\nis a necessary and sufficient condition.\nWe note that the combination of two necessary conditions [Eqs. (6.55) and (6.56)]\n\ngive a necessary and sufficient condition [Eq. (6.57)]. We also note that the combina-\ntion of a necessary condition [say Eq. (6.55)] and a sufficient condition [say Eq. (6.54)]\nmight not even come close to providing a necessary and sufficient condition.\n\nFollowing Hull [2003], we can generalize the concepts of necessary conditions and\nsufficient conditions. Let A and B be mathematical statements and let the symbol \u201c?\u201d\nmean \u201cimplies\u201d and the symbol \u201c?\u201d mean \u201cis implied by\u201d. We can then write\n\nA ? B means A is sufficient for B\nA ? B means that A is necessary for B\nA ? B means that A is necessary and sufficient for B\n\n\n\n114 Chapter 6. The Minimum Principle\n\nFor example\nrain ? clouds\nclouds ? rain\nSo, if it is raining then this statement is sufficient to know that it is cloudy. We can\n\nalso say that a cloudy day is necessary for rain, but not sufficient.\n\n6.4. Weak and Strong Extremals\n\nTo describe the meaning of important theorems in the literature, we need to define\nweak and strong extremals. These definitions depend, in turn, on the definition of the\nnorm:\n\n||x(t) ? x?(t)|| ? max\nt?[to ,tf]\n\n|x(t) ? x?(t)| (6.58)\n\nNext, we define N1 and N2 neighborhoods:\n\nN1(x?, u?) ? { (x, u) | ||x ? x?|| < ? }, (6.59)\nN2(x?, u?) ? { (x, u) | ||x ? x?|| < ?, ||u ? u?|| < ? } (6.60)\n\nwhere ? > 0 and ? > 0, and both are sufficiently small.\nWe can now define weak and strong extremals as follows:\n\n1. x?(t) is called a weak extremal if J(x?) ? J(x) for all (x, u) ? N2(x?, u?) which\nsatisfy the constraints.\n\n2. x?(t) is called a strong extremal if J(x?) ? J(x) for all (x, u) ? N1(x?, u?) which\nsatisfy the constraints.\n\nWe see from the definitions that the salient characteristic of a strong extremal is\nthat no change in control\u2014no matter how large\u2014can provide a lower cost.\n\nAt this point, let us consider a simple analogy to guide the subsequent discussion.\nFor the moment, let us assume that we are solving a parameter optimization problem\n(instead of an optimal control problem) and that the cost function is f(x), where x is a\nscalar. Then we can apply the method of Chap. 1 to minimize f(x). For a local minimum\n(assuming no constraints) we require fx = 0 and fxx > 0. If we find a local minimum,\nthen sufficiently small perturbations in x from x? will satisfy the conditions of a local\nminimum. This local minimum is analogous to the weak extremal of optimal control.\nNext we consider that the scalar value of x has the range: 0 ? x ? xmax. Suppose we\nsearch over the full range of x and find the global minimum. This global minimum is\nanalogous to the strong extremal of optimal control because, in the former, no value\nof f(x) is less than or equal to f(x?) and, in the latter, no value of u can produce a lower\nvalue than J(x?).\n\n\n\n6.4. Weak and Strong Extremals 115\n\nN2\n\nN1\n\nFigure 6.4. Weak and strong neighborhoods.\n\nWeak Extremals\n\nStrong\nExtremals\n\nFigure 6.5. Sets of weak and strong extremals.\n\nSeveral observations can be made about weak and strong extremals as follows.\n\n1. If x?(t) is a strong extremal, then it is also a weak extremal.\nSuppose x?(t) is a strong extremal: this implies that\n\nJ(x?) ? J(x) (6.61)\nfor all (x, u) ? N1.\n\nWe recall that the neighborhood of the strong extremal, N1, implies\n\n||x ? x?|| < ? (6.62)\n\nwhile the neighborhood, N2, implies\n\n||x ? x?|| < ?, ||u ? u?|| < ? (6.63)\n\n\n\n116 Chapter 6. The Minimum Principle\n\nfor ? > 0 and ? > 0 and both sufficiently small. Since N1 ? N2 (i.e. Neighborhood\n1 is a superset of or possibly equal to Neighborhood 2), then J(x?) ? J(x) for all\n(x, u) ? N2 implies that x? is also a weak extremal. This argument is illustrated in\nFig. 6.4. The result is consistent with our analogy from parameter optimization: a\nglobal minimum is also a local minimum.\n\n2. If a condition is necessary for a weak extremal, then it is also necessary for a strong\nextremal.\n\nSince every strong extremal is also a weak extremal, then anything necessary\nfor a weak extremal is necessary for a strong extremal, as demonstrated by the\nVenn diagram in Fig. 6.5. Using our analogy with parameter optimization, this\nobservation makes sense since a condition that is necessary for a local minimum\nwould also be necessary for a global minimum.\n\n3. If a condition is sufficient for a strong extremal, then it is sufficient for a weak\nextremal.\n\nAgain, by the Venn diagram in Fig 6.5, since a strong extremal is a weak\nextremal, anything sufficient for a strong extremal is sufficient for a weak extremal.\n(We also note that a condition necessary for a strong extremal is not always\nnecessary for a weak extremal.)\n\n6.5. An Example of a Weak but Not Strong Minimum\n\nConsider the following important example.\n\nMinimize:\n\nJ =\n? a\n\n0\nu3dt (6.64)\n\nsubject to:\n\nx? = u (6.65)\n\nwith B.C.s:\n\nx(0) = 0 (6.66)\n\nx(a) = b (6.67)\n\nwhere a > 0 and b > 0.\nWe will show in this problem that:\n\n1. The Legendre-Clebsch condition, H?uu ? 0, is satisfied.\n2. But the Weierstrass condition, H? ? H(u), is not satisfied.\n\n\n\n6.5. An Example of a Weak but Not Strong Minimum 117\n\nFrom the Euler-Lagrange theorem we have:\n\nH = u3 + ?u (6.68)\n\n?? = ?Hx = 0 (6.69)\n\nso that\n\n? = constant (6.70)\n\nHu = 3u2 + ? = 0 (6.71)\n\nso\n\nu = \u00b1\n???\n\n3\n(6.72)\n\nHuu = 6u ? 0 (6.73)\nand thus u must be positive.\n\nTherefore, we have:\n\nu = +\n???\n\n3\n. (6.74)\n\nAll of this implies:\n\nu = c1 > 0 (6.75)\n\nx? = c1 (6.76)\n\nand\n\nx(t) = c1t + c2 (6.77)\n\nwhere c1 and c2 are constants.\nThen using the B.C\u2019s:\n\nx(0) = 0, x(a) = b (6.78)\n\nwe find that\n\nc1 =\nb\na\n\n, c2 = 0 (6.79)\n\n\n\n118 Chapter 6. The Minimum Principle\n\nThus, the solution is:\n\nx? = b\na\n\nt (6.80)\n\nu? = b\na\n\n(6.81)\n\nAgain, checking the Legendre-Clebsch condition, we find\n\nH?uu = 6u = 6\nb\na\n\n? 0 (6.82)\n\nwhich is satisfied since a and b are positive constants.\nNow let us check the Weierstrass condition. Is\n\nH? ? H(x?, u) (6.83)\n\nfor all u?\nWe note that ? = ?3\n\n(\nb\na\n\n)2\nfrom u = +\n\n?\n??\n3 so that:\n\nH? = u3 + ?u =\n(\n\nb\na\n\n)3\n+ (?3)\n\n(\nb\na\n\n)2 (b\na\n\n)\n= ?2\n\n(\nb\na\n\n)3\n(6.84)\n\nIs\n\n?2\n(\n\nb\na\n\n)3\n? u3 ? 3\n\n(\nb\na\n\n)2\nu (6.85)\n\nfor all u? Clearly, it is possible to select u small enough to reverse the inequality.\nConsider:\n\nu = ?10 b\na\n\n(6.86)\n\nThen:\n\nH? = ?2\n(\n\nb\na\n\n)3\n> ?1,000\n\n(\nb\na\n\n)3\n+ 30\n\n(\nb\na\n\n)3\n= ?970\n\n(\nb\na\n\n)3\n(6.87)\n\nThus, the Weierstrass condition does not hold for all u, since we have:\n\nH? > H (6.88)\n\nwhen u = ?10\n(\n\nb\na\n\n)\n.\n\n\n\n6.5. An Example of a Weak but Not Strong Minimum 119\n\nNext we construct an example of a strong variation for this problem. We will follow\nthe concept illustrated in Fig. 5.1, in which a control blip is applied to the candidate\noptimal control which causes a variation in the state variable given in Eq. (5.9).\nWe assume that the control blip begins at time t1 and that the state is brought back\nto the candidate optimal state by time t2. In Fig. 6.6 we show the candidate optimal\nsolution expressed by Eqs. (6.80) and (6.81).\n\nIn Fig. 6.7 we show the effect that a strong variation may have on our example\nproblem. The main idea is that we use U(t) = ?b/?a as our control blip, which begins\nat t1 and ends at t1 + ?2a. Then, from time t1 + ?2a to t2 we assume a constant control,\nu(t, ?) = c, to restore the state to the candidate optimal solution. Thus, for the strong\nvariation of the control we assume the following:\n\nu(t) =\n\n?\n?????\n?????\n\nb\na t ? [0, t1]\n? b\n?a t ? [t1, t1 + ?2a]\n\nc t ? [t1 + ?2a, t2]\nb\na t ? [t2, a]\n\n(6.89)\n\nFor the corresponding strong variation of the state we have:\n\nx(t) =\n\n?\n?????\n?????\n\nb\na t t ? [0, t1]\nb\na t1 ? b?a (t ? t1) t ? [t1, t1 + ?2a]\nct + d t ? [t1 + ?2a, t2]\nb\na t t ? [t2, a]\n\n(6.90)\n\nx(t)\n\nb\na\n\nx? = ba t\n\naa t t\n\nbu\n? = b/a\n\nu(t)\n\nFigure 6.6. Candidate optimal solution from Legendre-Clebsch condition.\n\n\n\n120 Chapter 6. The Minimum Principle\n\nx(t)\n\nt\n\nu(t)\n\nt1 + ? 2a t t1 t1 + ? 2a\n\nb\n\nb\na t1\n\nt2 a t2 a\n\nb\na t2\n\n?b\n?a\n\nc\nb\na\n\nt1\n\nFigure 6.7. Effect of a strong variation on an example.\n\nwhere d is given by\n\nd =\nx(t1 + ?2a)t2 ? x(t2)(t1 + ?2a)\n\nt2 ? (t1 + ?2a) (6.91)\n\nand where the value of c in Eqs. (6.89) and (6.90) is:\n\nc =\nx(t2) ? x(t1 + ?2a)\n\nt2 ? (t1 + ?2a)\n\n=\nb\na t2 ?\n\n[\nb\na t1 ? b?a (t1 + ?2a ? t1)\n\n]\n\nt2 ? t1 ? ?2a\n\n=\nb\na (t2 ? t1 + ?a)\nt2 ? t1 ? ?2a (6.92)\n\nWe see that for small ?, the value of c is a little greater than b/a.\nWe can compute the value of the strong variation on the cost functional Jstrong, by\n\nsubstituting Eqs. (6.89) into Eq. (6.64):\n\nJstrong =\n? a\n\n0\nu3dt\n\n=\n? t1\n\n0\n\n(\nb\na\n\n)3\ndt +\n\n? t1+?2a\nt1\n\n(?b\n?a\n\n)3\ndt +\n\n? t2\nt1+?2a\n\nc3dt +\n? a\n\nt2\n\n(\nb\na\n\n)3\ndt\n\n=\n(\n\nb\na\n\n)3\nt1 ? 1\n\n?3\n\n(\nb\na\n\n)3\n(?2a) + c3(t2 ? t1 ? ?2a) +\n\n(\nb\na\n\n)3\n(a ? t2) (6.93)\n\n\n\n6.6. Second-Order Necessary and Sufficient Conditions 121\n\nSince 1/? appears in Eq. (6.93), it represents a large number when ? is small and thus\nwe retain this term but can drop terms of order ?. When ? terms are dropped, Eq. (6.92)\ngives c = b/a, so that Eq. (6.93) becomes:\n\nJstrong =\nb3\n\na2\n\n(\n1 ? 1\n\n?\n\n)\n(6.94)\n\nWe can compare the cost of the strong variation, Eq. (6.94), to the cost of the weak\nvariation, Jweak, which is [from Eqs. (6.64) and (6.81)]:\n\nJweak =\n? a\n\n0\nu3dt =\n\n? a\n0\n\n(\nb\na\n\n)3\ndt =\n\nb3\n\na2\n(6.95)\n\nOf course ? < 1 because we tacitly assumed the time order: t1 + ?2a < t2 < a as\nillustrated in Fig. 6.7. For any ? < 1, Jstrong is negative, while Jweak is always positive,\ntherefore\n\nJstrong < Jweak (6.96)\n\nThus, we have shown that the Weierstrass condition (or more generally, the Minimum\nPrinciple) is not satisfied by Eqs. (6.80) and (6.81). Furthermore, we have constructed\na control which provides a lower cost than that of the weak variation. Here we appeal\nto the more general Minimum Principle because our control is piecewise continuous.\nThere is no true minimum in this case because the cost approaches an infinitely\nnegative value as ? approaches zero.\n\n6.6. Second-Order Necessary and Sufficient Conditions\n\nUp to now we have determined first-order conditions that are necessary for u(t) to be\noptimal. In this section, we briefly state a second-order necessary condition and some\nknown conditions that are sufficient.\n\nThe second-order necessary condition is the Jacobi (conjugate point) condition\n[i.e., no points are conjugate on the open interval (to, tf)]. This condition is usually not\napplied because of the difficulty in doing so. However, a recent simplified procedure\nhas been developed for the case of a continuous control by Prussing and Sandrik\n[2005]. The Jacobi condition is necessary because if an extremal solution contains\na conjugate point, there exists a neighboring solution of lower cost.\n\nOne can argue that a necessary condition is more informative than a sufficient\ncondition. If a sufficient condition is not satisfied, the result is inconclusive (see\nExercise 2 of Chap. 1). However, if a necessary condition is not satisfied, the result\nis fatal and the solution is not optimal.\n\nIf only one solution satisfies the first necessary conditions (Euler-Lagrange plus\ntransversality), then:\n\n1. It is the optimal solution, or\n2. The optimal solution lies outside the class of functions being considered.\n\n\n\n122 Chapter 6. The Minimum Principle\n\nIf many solutions satisfy the necessary conditions, then further criteria must be\ndeveloped.\n\nLeitmann [1981] provides sufficient conditions for a proper, weak, relative\nminimum, as follows.\n\nLet x?(t) ? C2[to, tf], u?(t) ? C1[to, tf].\nIf:\n\n1. The Euler-Lagrange equations and the transversality condition are satisfied,\n2. The Strengthened Legendre-Clebsch Condition is satisfied (i.e., H?uu is positive\n\ndefinite: H?uu > 0), and\n3. The Strengthened Jacobi (or conjugate point) condition is satisfied (i.e., no points\n\nare conjugate on the closed interval [to, tf]),\nthen: x?(t) is a proper, weak, relative minimum. By proper we mean unique in\nneighborhood N2.\n\n6.7. Examples Illustrating the Concept of a Conjugate Point\n\nIn Chap. 4 (in our discussion of Example 4.1) we mentioned the problem of a\nconjugate point. If, for example, we consider the shortest path on the surface of the\nEarth from the North Pole to the South Pole, it is clear that there are infinitely many\npaths (called meridians) that are equally short. Since these solutions are not unique,\nnone of them are considered to be a proper minimum. From a practical point of view,\nwe wish to identify such problems to avoid attempting their numerical solution (a\nprocess unlikely to reach any resolution).\n\nWe illustrate the problem of conjugate points with the following classic examples.\n\nExample 6.4 Shortest path to a great circle on a sphere.\n\nN\n\n?\n\n?\n\n? = ?1\n\nMeridian\n\nFigure 6.8. A point and a great circle on a sphere.\n\n\n\n6.7. Examples Illustrating the Concept of a Conjugate Point 123\n\nConsider the shortest path between a point and a great circle on a sphere, as illustrated\nin Fig 6.8. The element of distance on a sphere is given by:\n\nds =\n?\n\nr2(d? )2 + r2(cos ? )2(d?)2 (6.97)\n\nWithout loss of generality, we assume that r = 1, that we begin at the origin of Fig. 6.8,\nand that we wish to find the shortest path to the meridian, ?1, without regard for the\nfinal value of latitude. We state our problem as follows (see Bryson and Ho [1975]).\n\nFind u(?) to minimize J:\n\nJ =\n? ?1\n\n0\n\n?\nu2 + (cos ? )2d? (6.98)\n\nwhere\n\nd?\nd?\n\n= u, ? (0) = 0 (6.99)\n\nLet us first approach this problem by using the four steps of the cookbook in Chap. 4.\n\n1. Form the Hamiltonian:\n\nH =\n?\n\nu2 + (cos ? )2 + ?u (6.100)\n\n2. Write Euler-Lagrange equations:\n\nd?\nd?\n\n= ??H\n??\n\n=\ncos ? sin ??\nu2 + (cos ? )2\n\n(6.101)\n\n?H\n?u\n\n=\nu?\n\nu2 + (cos ? )2\n+ ? = 0 (6.102)\n\nso that\n\n? = ? u?\nu2 + (cos ? )2\n\n(6.103)\n\n3. Use the differential form of the transversality condition:\n\nH?f dtf ? ?fdxf = H?f d?f ? ?fd?f = 0 (6.104)\nd?f = 0 (6.105)\n\nso that\n\n?f = 0 (6.106)\n\n\n\n124 Chapter 6. The Minimum Principle\n\nWe note that ? = u = ? = 0 satisfies the above conditions, which corresponds to a\npath along the equator in Fig. 6.8.\n\n4. Checking the Legendre-Clebsch condition we obtain:\n\nHuu = (u2 + cos2 ? )?\n1\n2 ? u\n\n2\n(u2 + cos2 ? )?\n\n3\n2 2u\n\n= (u2 + cos2 ? )?\n1\n2 [1 ? u2(u2 + cos2 ? )?1]\n\n= 1 > 0 (6.107)\n\nIn the general case, to determine whether a conjugate point exists requires the\ncalculation described in Prussing and Sandrik [2005]. But for this simple example,\nwe can examine the second variation ?2J analytically.\n\nExpanding the cost function to include the second variation yields\n\nJ = J? + ?J + ?2J\n\nBecause ?J = 0 on the solution that satisfies the first-order necessary conditions,\n?2J > 0 on neighboring solutions implies that J > J?, i.e., the cost J? is a local\nminimum. The classical approach to this analysis is called the accessory minimum\nproblem, in which the second variations are minimized to see if that minimum value\nis positive.\n\nConsider neighboring paths (to u = 0, ? = 0). By expanding the index of\nperformance to form the second variation ?2J :\n\nJ =\n? ?1\n\n0\n\n[\nu2 +\n\n(\n1 ? ?\n\n2\n\n2! + \u00b7 \u00b7 \u00b7\n)2] 12\n\nd? (6.108)\n\nand by ignoring the higher order terms and using a binomial expansion we obtain:\n\nJ =\n? ?1\n\n0\n\n[\n1 + u2 ? ?2\n\n] 1\n2 d?\n\n?\n? ?1\n\n0\n\n[\n1 +\n\n1\n2\n\n(u2 ? ?2)\n]\n\nd?\n\n= ?1 +\n1\n2\n\n? ?1\n0\n\n(u2 ? ?2)d? (6.109)\n\nThus we have the accessory minimum problem:\n\nMinimize:\n\n?2J = J ? ?1 = 12\n? ?1\n\n0\n(u2 ? ?2)d? (6.110)\n\nThe Hamiltonian is:\n\nH =\n1\n2\n\n(u2 ? ?2) + ?u (6.111)\n\n\n\n6.7. Examples Illustrating the Concept of a Conjugate Point 125\n\nand the Euler-Lagrange equations provide:\n\nd?\nd?\n\n= ?H? = ? (6.112)\n\nHu = u + ? = 0 (6.113)\n\nu = ?? (6.114)\n\nFrom the transversality condition we obtain\n\nH?f d?f ? ?fd?f = 0 (6.115)\n\nand since\n\nd?f = 0 (6.116)\n\nwe have\n\n?f = ?(?1) = 0 (6.117)\n\nNow from the process equation we have:\n\nd?\nd?\n\n= u = ?? (6.118)\n\nDifferentiating and using the costate equation we obtain\n\nd2?\nd?2\n\n=\n?d?\nd?\n\n= ?? (6.119)\n\nThus, we have the simple harmonic oscillator equation:\n\nd2?\nd?2\n\n+ ? = 0 (6.120)\n\nwith B.C.s:\n\n? (0) = 0 (6.121)\n\n??(?1) = d?d?\n????\n?1\n\n= 0 (6.122)\n\nThe neighboring solution for ? (0) = 0 is:\n\n? = ? sin ?, |?| ? 1 (6.123)\n\n\n\n126 Chapter 6. The Minimum Principle\n\nThe final B.C. is then:\n\nd?\nd?\n\n(?1) = ? cos?1 = 0 (6.124)\n\nFrom the accessory problem we can make the following observations. Analytical\nsolutions are available for the state and costate equations. The final boundary condition\nis satisfied only by ? = 0 if ?1 < ?2 , but it is satisfied by any ? if ?1 =\n\n?\n2 . Point O (the\n\norigin of Fig. 6.8) is said to be a conjugate point to ?1 = ?2 . At this point, the second\nvariation vanishes and an infinite number of solutions provide the same minimum\ndistance. No proper minimum exists.\n\nFor ?2 < ?1 < ? the value of ?\n2J is negative (see Exercise 3) and the extremal\n\nsolution ? = u = 0 is not a local minimum because the neighboring solution ? = ? sin ?\nhas a lower cost than the extremal solution. Furthermore, this lower cost neighboring\nsolution does not even satisfy the necessary condition, Eq. (6.124).\n\nExample 6.5 Shortest path between two points on a sphere.\n\nConsider the shortest path between two points on a sphere, as illustrated in Fig. 6.9.\nThis is a classical problem of the literature. Here we provide well-known results (as\nreported by Bryson and Ho [1975], Fox [1987], and Hull [2003]). This problem is\nsimilar to Example 6.4 except that ?f = ? (?1) = 0 replaces ?f = 0 of Eq. (6.106).\nA conjugate point exists for ?1 = ? . The second variation is the same as Eq. (6.110)\nand a neighboring solution to ? = u = 0 that satisfies the B.C.s is ? = ? sin? ?\n\n?1\nwith\n\n|?| ? 1. For the neighboring solution the second variation is equal to ? ?24?1 (?21 ??2),\nwhich is\n\n(i) Greater than zero for ?1 < ? ,\n(ii) Equal to zero for ?1 = ? , and\n\n(iii) Less than zero for ?1 > ? .\n\nAs in Example 6.3 if the extremal path ? = u = 0 (which satisfies the first-\norder necessary conditions) contains a conjugate point (if ?1 > ?), it is not a\nminimizing solution because a neighboring path (that bypasses the conjugate point)\nhas a lower cost.\n\nO O\u2019\nCr r\n\n?\n\nP\n\nFigure 6.9. Shortest path between two points on a sphere.\n\n\n\n6.9. Exercises 127\n\n6.8. Summary\n\nThere are a variety of statements of the Minimum Principle. In words, McShane has\ngiven the most succinct, \u201cthe Hamiltonian must be minimized over the set of all\nadmissible controls.\u201d The Legendre-Clebsch condition states that Huu must be positive\nsemi-definite; it applies only to interior controls and only to weak variations. The\nWeierstrass condition applies to strong variations (meaning the control can have large\nchanges from the optimal while the state can only have small changes) and where the\noptimal control must be continuous. Pontryagin provides the most general statement\nof the Minimum Principle where the control can be piecewise continuous (or more\nprecisely \u201cmeasurable\u201d).\n\nIn any case we must bear in mind that the calculus of variations can only provide\nlocal optimal solutions because variations of the state must remain infinitesimally\nsmall. However, variations of the control may be large. When only small variations of\nthe control are considered, we refer to the variations as weak variations. As we have\nseen in an example, strong variations can sometimes lead to a lower cost.\n\nIn two examples we have illustrated the existence of a conjugate point and\ndemonstrated, by calculating the second variation, that an extremal that contains a\nconjugate point is not a minimum.\n\n6.9. Exercises\n\n1. An astronaut in space must transfer in minimum time from point A to point B,\na distance L. Assume that the astronaut has a thruster which produces a variable\nthrust F, with a maximum of Fmax. Also, for simplicity, assume that the total mass\nof the astronaut, propellant, and thruster remains constant during the maneuver. The\ninitial velocity and final velocity of the astronaut is zero with respect to an inertial\nframe. There are no other forces acting on the astronaut.\n\n1a. Set up the minimization problem statement as a Lagrange problem, with u = F.\n(Note: F can be P. C.)\n\n1b. Show that the switching function is a linear function of time, i.e., ?2 = c1t + c2.\n(Don\u2019t evaluate constants c1 and c2.)\n\n1c. Make sketches of the switching function, the thrust profile, and the velocity as\nfunctions of time. (Hint: Use engineering judgement to deduce the shapes of\nthese plots. Give correct shape and sign.)\n\n2. A bead can move along a line where its position is given by x. Assume that the\nbead is initially located at x = 0 and that its final position is x = L. Assume that the\ncontrol of the bead is the velocity, V (Fig. 6.10).\nSet up the optimal control problem as a Lagrange problem and work out the\nfollowing steps.\n\n\n\n128 Chapter 6. The Minimum Principle\n\nx x = L\n\nFigure 6.10. Lagrange problem: Bead on a wire.\n\n2a. Assume that we wish to minimize the following:\n\nMin J =\n? tf\n\nt0\n(V2 + 1)dt\n\nwhere V is the control. Write the state equation and the initial and final\nconditions for the state. Assume that t0 = 0 and tf is free.\n\n2b. Write the Hamiltonian.\n2c. Write the costate equation, and give the form of its solution.\n2d. Assuming unbounded control, state the control law (for V) in terms of the\n\ncostate.\n2e. Show that your control satisfies the Legendre-Clebsch necessary condition.\n\nNote: you are not required to solve for the constants that may appear in Exercises 2c\nand 2d.\n\n3. Show that in Example 6.4 the second variation in Eq. (6.110) for the neighboring\nsolution ? = ? sin? is\n\n(i) > 0 for ?1 < ?2 ,\n(ii) = 0 for ?1 = ?2 , and\n\n(iii) < 0 for ?2 < ?1 < ? .\n\n4. In Example 6.5 verify that our second variation of Eq. (6.110) for the neighboring\npath ? = ? sin? ?\n\n?1\nis equal to ? ?24?1 (?21 ? ?2).\n\nReferences\n\nM. Athans, P.L. Falb, in Optimal Control: An Introduction to the Theory and Its Applications (Dover,\nNew York, 1966)\n\nL.D. Berkovitz, Optimal Control Theory (Springer, New York, 1974)\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\nG.M. Ewing, Calculus of Variations with Applications (Dover, New York, 1985)\nC. Fox, An Introduction to the Calculus of Variations (Dover, New York, 1987)\nM.R. Hestenes, Calculus of Variations and Optimal Control Theory (Wiley, New York, 1966)\nD.G. Hull, Optimal Control Theory for Applications (Springer, New York, 2003)\nG. Leitmann, The Calculus of Variations and Optimal Control (Plenum, New York 1981)\nD.A. Pierre, Optimization Theory with Applications (Wiley, New York, 1969)\n\n\n\nReferences 129\n\nL.S. Pontryagin, V.G. Boltyanskii, R.V. Gamkrelidze, E.F. Mishchenko, The Mathematical Theory of\nOptimal Processes (Wiley, New York, 1962)\n\nJ.E. Prussing, S.L. Sandrik, Second-order necessary conditions and sufficient conditions applied to\ncontinuous-thrust trajectories. J. Guid Control Dyn. 28(4), 812\u2013816 (2005). Engineering Note\n\nI.M. Ross, A Primer on Pontryagin\u2019s Principle in Optimal Control (Collegiate Publishers, Carmel,\n2009)\n\nJ. Vagners, Optimization techniques, in Handbook of Applied Mathematics, 2nd edn., ed. by C.E.\nPearson (Van Nostrand Reinhold, New York, 1983), pp. 1140\u20131216\n\n\n\nChapter 7\n\nSome Applications\n\n7.1. Aircraft Performance Optimization\n\nWhy discuss aircraft performance in a text chiefly about optimization of spacecraft\ntrajectories? Because aerospace engineers sometimes wish to capture the best of both\nworlds\u2014as in the examples of Pegasus and SpaceShipOne which use aircraft as first\nstages and rockets as second stages to send vehicles into space.\n\nTypical flight envelopes for subsonic and supersonic aircraft are shown in Figs. 7.1\nand 7.2. When test pilots talk about \u201cpushing the envelope\u201d (as quoted famously in\nthe movie The Right Stuff) they are referring to the empirical determination of these\nflight envelopes. In Figs. 7.1 and 7.2 we have altitude, h, plotted on the vertical axis\nand speed in Mach number, V, plotted on the horizontal axis. At low speed, aircraft are\nunable to fly, so the flight envelope starts at V > 0 for h = 0. As speed increases, the\naltitude (that the aircraft can reach) increases. Subsonic flight envelopes usually have\na simple inverted parabolic shape where the greatest speed occurs at zero altitude,\nwhich can be achieved by diving from high altitude (as shown in Fig. 7.1). Supersonic\nflight envelopes are more complicated (as illustrated in Fig. 7.2) because, in addition\nto constraints of insufficient lift and insufficient thrust, there may be insufficient\nstructure. That is, at low altitude and high Mach number, the supersonic aircraft may\nhave to throttle back to avoid tearing the wings off in the denser atmosphere.\n\nA classical optimization question is: what is the minimum-time trajectory from\nP1 to P2 (or P2 to P3) in Fig. 7.2? This typical aircraft performance question will be\naddressed in the following analysis.\n\nThe free-body diagram for this problem is given in Fig. 7.3 where L and D are\nthe lift and drag vectors and T and W are the thrust and weight vectors, respectively.\nThe inertial velocity vector, V, is oriented at flight-path angle, ? , with respect to the\nlocal horizontal plane. The angle of attack, ?, is the angle between V and the zero-lift\naxis. By definition, when ? = 0 the aircraft produces no lift; the zero-lift orientation\ntypically occurs when the nose of the aircraft is pointed slightly downward (relative\nto V). The angle between the zero-lift axis and T is denoted by ?.\n\nNow we will derive the aircraft equations of motion for translation in the vertical\nplane (the h-x plane of Fig. 7.3). First, we note that lift is perpendicular to velocity. Let\nus define a frame of reference (fixed at the center of mass of the aircraft) so:\n\nV? = cos ? x? + sin ? h? (7.1a)\n\nL? = ? sin ? x? + cos ? h? (7.1b)\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 7,\n\u00a9 Springer Science+Business Media New York 2014\n\n131\n\n\n\n132 Chapter 7. Some Applications\n\nh\n\nV (Mach)0 1\n\nFigure 7.1. Typical flight envelope for subsonic aircraft (V < 1).\n\nh\n\n0 21\nP3\n\nP2\n\nP1\n\nV (Mach)\n\nStructure\nInsufficient\n\nInsufficient\nThrust\n\nInsufficient\nLift\n\nFigure 7.2. Typical flight envelope for supersonic aircraft (V > 1).\n\n\n\n7.1. Aircraft Performance Optimization 133\n\nL T\n\nV\n\nW\n\nD\n\nzero lift axis\n\nlocal horizontal\n?\n\n??\n\nx\n\nh\n\nC\n\nO\n\nFigure 7.3. Aircraft free-body diagram (Adapted from Vinh [1993]).\n\nwhere V? and L? are unit vectors along the velocity and lift vectors and where x? and h?\nare unit vectors along the x and h axes, respectively. We define z? as out of the page:\n\nx? \u00d7 h? = V? \u00d7 L? = z? (7.2)\n\nThe scalar velocity components are:\n\nx? = V cos ? (7.3a)\n\nh? = V sin ? (7.3b)\n\nWe derive the equations of motion in the V?-L? frame by applying Newton\u2019s law\nF = ma. The inertial acceleration of the center of mass of the aircraft, C, with respect\nto the origin, O, of the h-x frame is:\n\niaOC = V?V? + ?? z? \u00d7 VV?\n= V?V? + V?? L? (7.4)\n\n\n\n134 Chapter 7. Some Applications\n\nwhere the superscript i indicates the inertial frame. The total force is given by\n\nF = [T cos(? + ?) ? D ? mg sin ? ]V?\n+ [T sin(? + ?) + L ? mg cos ? ]L? (7.5)\n\nWriting F = ma and using Eqs. (7.4) and (7.5) we find that the scalar equations in the\nvertical plane provide:\n\nmV? = T cos(? + ?) ? D ? mg sin ? (7.6a)\nmV?? = T sin(? + ?) + L ? mg cos ? (7.6b)\n\nwhere Eq. (7.6a) provides the components along V? and Eq. (7.6b) provides the\ncomponents along L?.\n\nIn addition, since the mass is a time-varying quantity we have\n\nm? = f(h, V) (7.7)\n\nThus there are five differential equations in six variables: h, x, V, ? , m, ?which implies\nthat one variable can be chosen as a control variable, leaving five state variables.\nWe assume in this model that D = D(h, V, ?) and L = L(h, V, ?); drag and lift are\nknown functions of altitude, speed, and angle of attack. We also assume that T =\nT(h, V) and m? = f(h, V); thrust and mass rates of change are known functions of altitude\nand velocity for a given throttle setting.\n\nNext we consider some simplifying assumptions. If we assume the mass is constant\nand if we drop range considerations (see Miele [1962] for maximum range problem),\nthen we have:\n\nh? = V sin ? (7.8a)\n\nmV? = T cos(? + ?) ? D ? mg sin ? (7.8b)\nmV?? = T sin(? + ?) + L ? mg cos ? (7.8c)\n\nIn addition, since mV?? is usually small (i.e., the acceleration perpendicular to the\nvelocity is negligible):\n\nT(h, V) sin(? + ?) + L(h, V, ?) ? W cos ? = 0 (7.9)\n\nEquation (7.9) gives the angle of attack, that is,\n\n? = ?(h, V, ? ) (7.10)\n\nand thus one equation is eliminated.\nBefore analyzing the problem of unsteady climb, we briefly remark that for steady\n\nclimb we assume that V? = 0 and usually assume that ? + ? = 0. For steady cruise\nwe also set ? = 0 which implies L = W and T = D, resulting in a trivial equilibrium\nproblem.\n\n\n\n7.1. Aircraft Performance Optimization 135\n\nFor unsteady climb analysis, we have two equations, Eqs. (7.8a) and (7.8b), in three\nvariables (h, V, ? ). Multiplying Eq. (7.8b) by V/(mg) and adding it to Eq. (7.8a) yields:\n\nh? +\nVV?\ng\n\n=\nTV cos(? + ?) ? DV\n\nmg\n(7.11)\n\nThus, we have eliminated one equation and one variable, ? . Although not necessary,\nwe will gain more insight by assuming cos(?+?) = 1, since ? and ? are typically small\nangles, so we have:\n\nh? +\nVV?\ng\n\n=\n(T ? D)V\n\nW\n(7.12)\n\nwhere the left hand side is the derivative of the total mechanical energy divided by the\nweight ddt [(mgh + 12 mV2)/W].\n\nWe now introduce excess power, P, and energy height, hc, which are defined as\nfollows\n\nP(h, V) ? [T(h, V) ? D(h, V)]V\nW\n\n(7.13)\n\nhc ? h + 12\nV2\n\ng\n(7.14)\n\nThese definitions are widely used in the energy method of evaluating accelerated\nclimbs (i.e., unsteady climbs).\n\nFrom these definitions and Eq. (7.12) we have:\n\nh?c = P(h, V)\n\n=\n[T(h, V) ? D(h, V)]V\n\nW\n\n=\n{T[h(hc, V), V] ? D[h(hc, V), V]}V\n\nW\n(7.15)\n\nThe rate of change of energy height equals the excess power. We see from Eq. (7.15)\nthat excess power allows us to change the energy height of the aircraft. We view hc as\nthe state variable, V as the control variable and Eq. (7.15) as the process equation.\n\nIn Fig. 7.4 we illustrate a typical altitude-Mach number plot of constant energy\nheight. These curves are universal (i.e., they do not depend on the specific aircraft).\nAn aircraft at A can dive to point B or zoom climb to C in a short time span. For\nexample, an aircraft at 20,000 ft and zero airspeed can dive to zero altitude and pick\nup a velocity of Mach 1. Similarly, an aircraft at zero altitude traveling at Mach 1 can\nquickly ascend (zoom climb) to an altitude of 20,000 ft where it loses all its airspeed.\n(In this simplified analysis we ignore the effect of drag). Thus, when we use energy\nheight as the state variable for unsteady climb analysis, we are viewing the aircraft as\na falling body problem which obeys conservation of total energy. A particle dropped\n\n\n\n136 Chapter 7. Some Applications\n\nh\n\nV Mach1 2\n\nC\n\nB\n\nA\n\nD\n\nFigure 7.4. Typical altitude-Mach number plot of constant energy height where energy\nheight, hc, is defined by Eq. (7.14). Points A, B, and C have the same hc; point\nD has a higher value.\n\nfrom an altitude of 20,000 ft will (again ignoring drag) strike the ground in 125 s.\nA particle on the ground with an initial vertical speed of Mach 1 will rise to an\naltitude of 20,000 ft in 125 s. On the other hand, getting from A to D takes power\nand time. Airline passengers are used to the slow climb to cruise altitude (typically\nabout 30,000 ft) which takes many minutes\u2014the airliner starts at zero altitude and zero\nspeed and must build up the energy height through the excess power of the engines.\nAs long as the engines can provide more thrust than the drag, the aircraft can continue\nits accelerated climb according to Eq. (7.15).\n\nExample 7.1 Minimum time to climb.\n\nMinimize the time to climb from (ho, Vo) to (hf, Vf) in Fig. 7.5. Note that there is a\nground constraint h ? 0, that we should not attempt to violate!\n\nMinimize:\n\nJ = tf (7.16)\n\nsubject to:\n\nh?c = P(hc, V) (7.17)\n\nwith boundary conditions hc(0) and hc(tf).\n\n\n\n7.1. Aircraft Performance Optimization 137\n\nh\n\nV Mach1 2\n\n(ho, Vo)\n\n(hf, Vf)\n\nFigure 7.5. Minimum time-to-climb problem. Aircraft can dive or zoom climb at constant hc\nin a matter of seconds but require several minutes to change hc significantly.\n\nOnce the aircraft achieves the desired energy height (hc), it can zoom climb (or\ndive) in virtually no time to get to the desired altitude. We set up the necessary\nconditions as follows.\n\n1. Form the Hamiltonian:\n\nH = ?P(hc, V) (7.18)\n\n2. From the Euler-Lagrange theorem and the Legendre-Clebsch condition we find:\n\nHV = 0 (7.19)\n\nso\n\n?PV = 0 (7.20)\n\nand\n\nHVV ? 0 (7.21)\nso that\n\n?PVV ? 0 (7.22)\n\n3. The differential form of the transversality condition provides:\n\nHfdtf ? ?fdhc(tf) + dtf = 0 (7.23)\n\n\n\n138 Chapter 7. Some Applications\n\nThus\n\n(Hf + 1)dtf = 0 (7.24)\n\nso we obtain\n\nHf = ?1 (7.25)\n\nIn Sect. 4.8 we showed that if the Hamiltonian is not an explicit function of time,\nthen it is a constant. We see from Eq. (7.18) that time does not appear explicitly; thus\nH = ?P = ?1 for the entire trajectory.\n\nFor climb\n\nT ? D (7.26)\n\nso\n\nP ? 0 (7.27)\n\nTherefore\n\n? ? 0 (7.28)\n\nClearly ? ?= 0, since ?P = ?1. Thus, from ?PV = 0, ?PVV ? 0 and ? < 0 we have:\n\nPV = 0\n\nPVV ? 0 (7.29)\n\nwhich means that to minimize the time to climb at a given energy height, hc, pick the\nvelocity, V, to maximize excess power.\n\nBefore we examine this optimal control strategy graphically, let us briefly consider\nan alternate derivation.\n\nFrom the process equation:\n\nh?c = P(V, hc) =\ndhc\ndt\n\n(7.30)\n\nor\n\ndt =\ndhc\n\nP(V, hc)\n(7.31)\n\n\n\n7.1. Aircraft Performance Optimization 139\n\nIntegrating, we obtain\n\n? tf\nto\n\ndt = tf ? to =\n? hcf\n\nhco\n\n1\nP(V, hc)\n\ndhc (7.32)\n\nWe see from Eq. (7.32) that to ensure the time is a minimum, the excess power which\nappears in the denominator of the integrand must be a maximum. Again: to minimize\nthe time to climb at a given height hc, pick V to maximize excess power.\n\nBut how does the pilot pick V? We return to our earlier discussion of dives and\nzoom climbs. At any given energy height, the pilot can choose from of a range of\nvelocities that he or she can obtain very quickly by diving (to increase V) or by zoom\nclimbing (to decrease V). We assume that the time required for this change of velocity\nis small (e.g., measured in seconds) compared to the time required to significantly\nchange the energy height by the use of engine excess power (e.g., measured in\nminutes). In practice the results obtained by ignoring the time for diving and zoom\nclimbing provide very good first-order optimal guesses. Refined optimal solutions for\nminimum time-to-climb problems can be found using the higher fidelity equations of\nmotion developed earlier in this chapter.\n\nLet us consider Fig. 7.6. For each hc curve there is a point where P is maximum.\nIn fact, at these points the P curve is tangent to the hc curve. We observe that there\nare two local extremals: the arcs A\u2013D and D?\u2013I. To get from the starting point of low\nenergy height and low velocity (ho, Vo) to the final point of high energy height and\nhigh velocity (hf, Vf) in minimum time, we use the following strategy:\n\n1. Start with low altitude flight to maximize P, 0\u20130?. During take off, an aircraft\naccelerates along the runway and maintains low altitude until maximum excess\npower is reached. The ground constraint (h ? 0) precludes any option of diving at\nthis time.\n\n2. Fly along the extremal A\u2013D (tangent points between P and hc contours) where\nexcess power is maximum.\n\n3. Dive through Mach 1 to get to the second extremal D?\u2013I. (Diving takes virtually no\ntime.) Follow the second extremal to E.\n\n4. To reach the final goal of (hf, Vf), zoom climb on the hcf contour which requires\nvirtually no time.\n\nWe note in this supersonic example that two extremal arcs exist, due to two local\nmaxima for P: one at low speed and one at high speed. The excess power contours are,\nof course, specific to the aircraft. These power contours are typically displayed in the\ncockpits of high performance aircraft. The energy state approximation not only serves\nas an initial guess for computation of the true optimum, but also provides valuable\ninsight into the nature of the optimal solution.\n\nThe counterintuitive answer that a supersonic aircraft must dive first in order to\nclimb to a given altitude in minimum time was first discovered by Walter Denham and\nArt Bryson, Jr. See Ho and Speyer [1990] for historical details.\n\n\n\n140 Chapter 7. Some Applications\n\nMachV\n\nG\nH\n\nI\n\nF\n\n1.0 2.00\u20190\n\nD\nB\n\nD\u2019\n\nC\n\nA\n\nhf, Vf 200 ft/s\n100 ft/s\n\nP = 0 ft/s\n\n300 ft/s\n\nh\n\n10 k ft\n\n40 k ft\n\n60 k ft\n\n80 k ft\n\n20 k ft\n\nE\n\nFigure 7.6. Maximizing excess power (Adapted from Anderson [1999] and Vinh [1993]). In\nthis example the aircraft starts at zero altitude and zero velocity and reaches a\ndesired final altitude and final velocity in minimum time. The power contours\nrange from 500 ft/s (near A) to 0 ft/s (near I).\n\n7.2. Maximization of the Range of a Rocket\n\nLet us consider the problem of maximizing the range of a rocket, as illustrated in\nFig. 7.7. Here we assume a uniform gravity field (with acceleration g) and ignore the\neffect of drag. We also assume that the thrust acceleration, f(t), is a given positive\nfunction of time and that burnout occurs at t = T. Thus, our problem is to find\nthe control function ? (t) to maximize the range, R. That is,\nMaximize:\n\nJ = R (7.33)\n\nsubject to:\n\nx? = Vx (7.34a)\n\ny? = Vy (7.34b)\n\nV?x = f cos ? (7.34c)\n\nV?y = f sin ? ? g (7.34d)\n\n\n\n7.2. Maximization of the Range of a Rocket 141\n\nx\n\ny\n\ng?\n\nf\n\nFigure 7.7. Maximization of the range of a rocket.\n\nwhere\n\nf(t) = ?m?Ispm/m (7.35)\n\nis a predetermined function of time and Ispm is specific impulse based on mass flow\nrate, i.e. effective exhaust velocity.\n\nFor the I.C.s we assume:\n\nx(0) = y(0) = 0, Vx(0) = Vy(0) = 0 (7.36)\n\nIn the analysis of this problem we follow the approach of Lawden [1963].\nIf (x1, y1, Vx1, Vy1) is the state at burnout (t = T), then the range is found as follows.\n\nTo determine the duration of the coasting arc, tc, we write the familiar equation for\nthe falling body:\n\nd = ? 1\n2\n\ngt2c + Vy1tc + y1 (7.37)\n\nwhere d is the altitude of the body above the ground. Setting d = 0 for the time of\nimpact we have\n\n? 1\n2\n\ngt2c + Vy1tc + y1 = 0 (7.38)\n\n\n\n142 Chapter 7. Some Applications\n\nso that (choosing the larger root)\n\ntc =\n(\n\nVy1 +\n?\n\nV2y1 + 2gy1\n)\n/g (7.39)\n\nTherefore, the range is:\n\nR = x1 + Vx1tc = x1 +\nVx1\ng\n\n(\nVy1 +\n\n?\nV2y1 + 2gy1\n\n)\n(7.40)\n\nNow our cost function is in terms of the state variables at burnout which, in turn,\ncan be manipulated by using the control ? (t). Of course we don\u2019t yet know the state at\nburnout, nor do we know the duration of the coasting arc. Let us apply the necessary\nconditions as follows.\n\n1. The Hamiltonian is\n\nH = ?xVx + ?yVy + ?Vx f cos ? + ?Vy (f sin ? ? g) (7.41)\n\n2. The Euler-Lagrange equations are\n\n??x = ?Hx = 0, ??y = ?Hy = 0 (7.42a)\n\nso that\n\n?x = c1, ?y = c2 (7.42b)\n\nand\n\n??Vx = ?HVx = ??x, ??Vy = ?HVy = ??y (7.42c)\n\nso\n\n?Vx = ?c1t + c3, ?Vy = ?c2t + c4 (7.42d)\n\nwhere c1, c2, c3, and c4 are constants.\nFollowing the procedure described after Eq. (4.66) we write the Hamiltonian in\n\nEq. (7.41) as\n\nH = ?xVx + ?yVy ? ?Vy g + f?T? (7.43)\n\n\n\n7.2. Maximization of the Range of a Rocket 143\n\nwhere\n\n? =\n\n[\n?Vx\n\n?Vy\n\n]\n(7.44)\n\nand\n\n? =\n\n[\ncos ?\n\nsin ?\n\n]\n(7.45)\n\nwhere ? is a unit vector. Because we want to maximize J (the range) we choose the\ncontrol to maximize H; so ?T? = ? and\n\n? =\n?\n\n?\n(7.46)\n\nfor which\n\ncos ? =\n?Vx?\n\n?2Vx + ?\n2\nVy\n\n(7.47)\n\nsin ? =\n?Vy?\n\n?2Vx + ?\n2\nVy\n\n(7.48)\n\n3. From the differential form of the transversality condition we have\n\nHfdtf ? ???Tf dxf + d? = 0 (7.49)\n\nFollowing Lawden [1963], we evaluate the transversality condition at t1 = T:\n\nH1dt1 ? ???T1dx1 + d?(x1) = 0 (7.50)\n\nWe note that since t1 = T we have dt1 = 0; we also note that x1 is free. Recalling\nthat:\n\n?(x1) = x1 + Vx1tc = x1 +\nVx1\ng\n\n(\nVy1 +\n\n?\nV2y1 + 2gy1\n\n)\n(7.51)\n\nwe have:\n\nd?(x1) =\n??\n\n?x1\ndx1 +\n\n??\n\n?y1\ndy1 +\n\n??\n\n?Vx1\ndVx1 +\n\n??\n\n?Vy1\ndVy1 (7.52)\n\n\n\n144 Chapter 7. Some Applications\n\nThus from transversality we obtain:\n(??x1dx1 ? ?y1dy1 ? ?Vx1 dVx1 ? ?Vy1 dVy1\n\n)\n\n+\n{\n\ndx1 + Vx1\n(\n\nV2y1 + 2gy1\n)?1/2\n\ndy1 +\n1\ng\n\n(\nVy1 +\n\n?\nV2y1 + 2gy1\n\n)\ndVx1\n\n+\nVx1\ng\n\n[\n1 + Vy1\n\n(\nV2y1 + 2gy1\n\n)?1/2]\ndVy1\n\n}\n= 0 (7.53)\n\nSetting the coefficients to zero:\n\n?x1 = 1 (7.54a)\n\n?y1 =\nVx1\nr\n\n(7.54b)\n\n?Vx1 =\nVy1 + r\n\ng\n(7.54c)\n\n?Vy1 =\nVx1\ngr\n\n(\nr + Vy1\n\n)\n(7.54d)\n\nwhere we use\n\nr ?\n?\n\nV2y1 + 2gy1 (7.54e)\n\nto simplify the expressions.\n\nThus, for the control law we have:\n\ntan ? =\n+?Vy\n+?Vx\n\n=\n?c2t + c4\n?c1t + c3 (7.55)\n\nwhere\n\nc1 = ?x1 = 1 (7.56a)\n\nc2 = ?y1 =\nVx1\nr\n\n(7.56b)\n\nc3 = ?Vx1 + c1T =\nVy1 + r\n\ng\n+ T (7.56c)\n\nc4 = ?Vy1 + c2T =\nVx1\ngr\n\n(r + Vy1) +\nVx1\nr\n\nT (7.56d)\n\n\n\n7.2. Maximization of the Range of a Rocket 145\n\nso that\n\ntan ? =\n?c2t + c4\n?c1t + c3 =\n\n?Vx1\nr t +\n\nVx1\nr\n\n(\nr+Vy1\n\ng + T\n)\n\n?t + Vy1+rg + T\n(7.57)\n\nwhich reduces to the simple form:\n\ntan ? =\nVx1\nr\n\n(7.58)\n\nRecalling that r is a constant that depends on Vy1 and y1, we see that the maximum\nrange is achieved by ? = constant which means that the thrust must be kept at a\nconstant angle to the horizontal, even though f = f(t).\n\n7.2.1. Integration of Equations of Motion When f Is Constant\n\nLet us consider the special case of constant acceleration. When f is constant,\nintegration of the equations of motion, Eqs. (7.34a)\u2013(7.34d), provides:\n\nVx1 = f T cos ? (7.59a)\n\nVy1 = (f sin ? ? g)T (7.59b)\n\nx1 =\n1\n2\n\nf T 2 cos ? (7.59c)\n\ny1 =\n1\n2\n\n(f sin ? ? g)T 2 (7.59d)\n\nfor the state at t = T. Substituting the solution into the control law, Eq. (7.58), gives:\n\ntan ? =\nf T cos ??\n\n(f sin ? ? g)2T2 + 2g 12 (f sin ? ? g)T2\n\n=\nf T cos ??\n\nT2f 2(sin2 ? ? gf sin ? )\n\n=\ncos ??\n\nsin2 ? ? gf sin ?\n(7.60)\n\nEquation (7.60) implies that:\n\nsin ?\n?\n\nsin2 ? ? g\nf\n\nsin ? = cos2 ?\n\n= 1 ? sin2 ? (7.61)\n\n\n\n146 Chapter 7. Some Applications\n\nSquaring both sides of Eq. (7.61) provides:\n\nsin2 ? (sin2 ? ? g\nf\n\nsin ? ) = 1 ? 2 sin2 ? + sin4 ? (7.62)\n\nor\n\ng\nf\n\nsin3 ? ? 2 sin2 ? + 1 = 0 (7.63)\n\nEquation (7.63) is a transcendental equation which we can solve numerically to\ndetermine ? . Lawden [1963] summarizes the solutions for ? as follows.\n\n1. If f > g, then there are four roots for 0 < ? < 2? (one in each quadrant), but only\nthe positive acute solution ? < ?/2 is meaningful.\n\n2. If f < g, then there is insufficient thrust. The solutions for ? are in the third\nand fourth quadrants, corresponding to non-physical cases of falling below ground\nlevel.\n\n7.2.2. The Optimal Trajectory\n\nOnce ? has been calculated, we solve for the state at T(x1, y1, Vx1, Vy1) from the\nintegrated equations of motion, Eqs. (7.59a)\u2013(7.59d). Thus, the optimal trajectory is\ngiven (parametrically) as:\n\nx =\n1\n2\n\nf t2 cos ?\n\ny =\n1\n2\n\n(f sin ? ? g)t2 (7.64)\n\nfor 0 ? t ? T. Equations (7.64) indicate that the rocket travels along a straight line\nduring thrusting, given by the flight path angle ? (see Fig. 7.8).\n\ntan ? =\ny\nx\n\n= tan ? ? g\nf\n\nsec ? (7.65)\n\nSince\n\nx? = f cos ? (7.66a)\n\ny? = f sin ? ? g (7.66b)\n\nthe line is traversed at a constant acceleration:\n\na2 = x?2 + y?2\n\n= f 2 ? 2gf sin ? + g2 (7.67)\n\n\n\n7.2. Maximization of the Range of a Rocket 147\n\nxRmax\n\ny\n\ng?\n?\n\nf\nV\n\nFigure 7.8. Solution for maximum rocket range.\n\n7.2.3. Maximum Range Equation\n\nThe maximum range of the rocket is found from Eq. (7.40):\n\nR = x1 +\nVx1\ng\n\n(\nVy1 + r\n\n)\n(7.68)\n\nwhere r is given in Eq. (7.54e). Using Eq. (7.58) to eliminate r from Eq. (7.68) we\nobtain\n\nR = x1 +\nVx1\ng\n\n(\nVy1 +\n\nVx1\ntan ?\n\n)\n(7.69)\n\nSubstituting the solutions for x1, Vx1 and Vy1 from Eqs. (7.59) gives:\n\nR =\n1\n2\n\nf T2 cos ? +\n1\ng\n\nf T cos ?\n(\n\nfT sin ? ? gT + cos ?\ntan ?\n\nf T\n)\n\n= ?1\n2\n\nf T2 cos ? +\nf 2T2\n\ng\ncos ?\n\n(\nsin2 ? + cos2 ?\n\nsin ?\n\n)\n(7.70)\n\n\n\n148 Chapter 7. Some Applications\n\nTable 7.1. Maximum range for various nondimensional thrust acceleration levels\n(continuous thrust, uniform gravity)\n\nThrust Thrust Flight path Nondimensional\n\nacceleration angle angle range\n\nf/g ? (deg) ? (deg) gRmax/f2T 2\n\n1.000 90.0 0.0 0.0\n\n1.001 87.4 0.00526 0.0224\n\n1.1 68.6 3.45 0.226\n\n1.5 56.3 16.6 0.482\n\n2.0 52.1 25.2 0.625\n\n3.0 49.2 32.9 0.756\n\n10.0 46.1 41.8 0.929\n\n20.0 45.5 43.4 0.965\n\n\u2013 \u2013 \u2013 \u2013\n\n? 45.0 45.0 1.0\n\nThus, the maximum range of the rocket is\n\nRmax = fT2\n(\n\nf\ng\n\ncot ? ? 1\n2\n\ncos ?\n\n)\n(7.71)\n\nwhere f is the constant acceleration from the thrust, f > g, and ? is the constant thrust\nangle given by Eq. (7.63).\n\nTable 7.1 shows the result for various nondimensional thrust acceleration levels,\nf/g, increasing from 1 to ?. The infinite value represents an impulsive thrust and the\ntrajectory is the ballistic projectile path studied in elementary mechanics, for which the\nmaximum range is achieved by the launch angle, ? , of 45 deg. In the limit as f ? ?,\nT ? 0 and the product fT approaches the launch velocity (the impulsive?V).\n\nIn Table 7.1 the thrust angle ? is greater than the flight path angle ? for finite\nduration thrusts in order to counteract gravity acting downward. The nondimensional\nrange shown is the actual Rmax divided by the range of the ballistic path. The fact that\nthis nondimensional range is less than one for finite duration thrust is due to gravity\nloss.\n\n7.3. Time Optimal Launching of a Satellite\n\nWe now return to one of the fundamental examples of the text: the time-optimal\nlaunching of a satellite into orbit, illustrated in Fig. 7.9. We continue with the same\nassumptions of Example 4.5, Launch into circular orbit from flat-Earth.\n\n\n\n7.3. Time Optimal Launching of a Satellite 149\n\ny\n\nx\n\n?\n\nvc\nh\n\nf\ng (uniform)\n\nFigure 7.9. Time-optimal launching of a satellite into a circular orbit at velocity vc and\naltitude h. In the flat-Earth assumption the gravity field is uniform.\n\nSpecifically, our problem is as follows.\nMinimize:\n\nJ = tf (7.72)\n\nsubject to:\n\nx? = Vx (7.73a)\n\ny? = Vy (7.73b)\n\nV?x = f cos ? (7.73c)\n\nV?y = f sin ? ? g (7.73d)\n\nwhere\n\nf(t) = ?m?Ispm/m (7.74)\n\nis the thrust acceleration, a predetermined function of time. The initial conditions are\n\nto = xo = yo = Vxo = Vyo = 0 (7.75)\n\n\n\n150 Chapter 7. Some Applications\n\nand the terminal boundary conditions are:\n\nyf = h (7.76a)\n\nVxf = Vc (7.76b)\n\nVyf = 0 (7.76c)\n\nWe note that tf and xf are free variables. The Hamiltonian is\n\nH = ?xVx + ?yVy + ?vxf cos ? + ?vy(f sin ? ? g) (7.77)\n\nIn Chap. 4 we showed that the necessary conditions provide:\n\nHf = ?1 (7.78a)\n?xf = 0 (7.78b)\n\nAlso:\n\n?x = c1 = 0 (7.79)\n\n?y = c2 (7.80)\n\n?vx = ?c1t + c3 = c3 (7.81)\n?vy = ?c2t + c4 (7.82)\n\nand\n\ntan ? =\n??vy\n??vx\n\n=\nc2t ? c4\nc1t ? c3\n\n=\n?c2\nc3\n\nt +\nc4\nc3\n\n= at + b (7.83)\n\nwhich is called the linear tangent steering law. This law was provided earlier, in\nEq. (4.82).\n\n7.3.1. Integration of the EOMs\n\nIf f is a constant, the equations of motion, Eqs. (7.73a)\u2013(7.73d), can be integrated as\nfollows.\n\nDifferentiate the steering law [Eq. (7.83)] with respect to time:\n\nd\ndt\n\n(tan ? ) =\nd\ndt\n\n(at + b) (7.84)\n\n\n\n7.3. Time Optimal Launching of a Satellite 151\n\nso that\n\n(sec2 ? )\nd?\ndt\n\n= a (7.85)\n\nWe can now change the independent variable from t to ? by the chain rule:\n\ndx\ndt\n\n=\ndx\nd?\n\nd?\ndt\n\n=\na\n\nsec2 ?\n\ndx\nd?\n\n(7.86)\n\nThus, the equations of motion become the following:\n\ndx\nd?\n\n=\nVx\na\n\nsec2 ? (7.87a)\n\ndy\nd?\n\n=\nVy\na\n\nsec2 ? (7.87b)\n\ndVx\nd?\n\n=\nf\na\n\ncos ? sec2 ?\n\n=\nf\na\n\nsec ? (7.87c)\n\ndVy\nd?\n\n=\nf\na\n\nsec2 ? sin ? ? g\na\n\nsec2 ?\n\n=\nf\na\n\nsec ? tan ? ? g\na\n\nsec2 ? (7.87d)\n\nIntegrating the Vx equation, Eq. (7.87c), we have:\n\nVx(? ) =\nf\na\n\n? ?\n?o\n\nsec ?d?\n\n=\nf\na\n[ln(tan ? + sec ? )]|??o\n\n=\nf\na\n\nln\n\n[\ntan ? + sec ?\n\ntan ?o + sec ?o\n\n]\n(7.88)\n\nFor Vy we have, by integrating Eq. (7.87d):\n\nVy(? ) =\nf\na\n\n? ?\n?o\n\nsec ? tan ?d? ? g\na\n\n? ?\n?o\n\nsec2 ?d?\n\n=\nf\na\n\n(sec ? ? sec ?o) ? ga (tan ? ? tan ?o) (7.89)\n\n\n\n152 Chapter 7. Some Applications\n\nTo find x(? ) we integrate Eq. (7.87a):\n\nx(? ) =\n1\na\n\n? ?\n?o\n\nVx(? ) sec2 ?d?\n\n=\nf\n\na2\n\n? ?\n?o\n\nln\n\n(\ntan ? + sec ?\n\ntan ?o + sec ?o\n\n)\nsec2 ?d?\n\n=\nf\n\na2\n\n? ?\n?o\n\n[ln(tan ? + sec ? ) ? ln(tan ?o + sec ?o)] sec2 ?d? (7.90)\n\nUsing integration by parts provides:\n\n? ?\n?o\n\n[ln(tan ? + sec ? )] sec2 ?d?\n\n= [ln(tan ? + sec ? )] tan ? ? [ln(tan ?o + sec ?o)] tan ?o ?\n? ?\n?o\n\ntan ? sec ?d?\n\n= [ln(tan ? + sec ? )] tan ? ? [ln(tan ?o + sec ?o)] tan ?o ? (sec ? ? sec ?o) (7.91)\n\nAlso we note that,\n\n? ?\n?o\n\n? ln(tan ?o + sec ?o) sec2 ?d? = ?[ln(tan ?o + sec ?o)](tan ? ? tan ?o) (7.92)\n\nThus, using Eqs. (7.91) and (7.92) in Eq. (7.90), we obtain:\n\nx(? ) =\nf\n\na2\n\n[\nln\n\n(\ntan ? + sec ?\n\ntan ?o + sec ?o\n\n)\ntan ? + sec ?o ? sec ?\n\n]\n(7.93)\n\nNow, to find y(? ) from Eqs. (7.87b) and (7.89), we write:\n\ny(? ) =\n1\na\n\n? ?\n?o\n\nVy sec2 ?d?\n\n=\n1\na\n\n? ?\n?o\n\n[\nf\na\n\n(sec ? ? sec ?o) ? ga (tan ? ? tan ?o)\n]\n\nsec2 ?d? (7.94)\n\nWe evaluate\n? ?\n?o\n\nsec3 ?d? =\n1\n2\n\ntan ? sec ? ? 1\n2\n\ntan ?o sec ?o +\n1\n2\n\n? ?\n?o\n\nsec ?d?\n\n=\n1\n2\n\ntan ? sec ? ? 1\n2\n\ntan ?o sec ?o +\n1\n2\n\nln\n\n(\ntan ? + sec ?\n\ntan ?o + sec ?o\n\n)\n(7.95)\n\n\n\n7.3. Time Optimal Launching of a Satellite 153\n\nand\n\n? ?\n?o\n\ntan ? sec2 ?d? =\n1\n2\n\ntan2 ? ? 1\n2\n\ntan2 ?o (7.96)\n\nto obtain\n\ny(? ) =\nf\n\na2\n\n[\n1\n2\n\ntan ? sec ? ? 1\n2\n\ntan ?o sec ?o +\n1\n2\n\nln\n\n(\ntan ? + sec ?\n\ntan ?o + sec ?o\n\n)]\n\n? f\na2\n\n(tan ? ? tan ?o) sec ?o ? ga2\n(\n\n1\n2\n\ntan2 ? ? 1\n2\n\ntan2 ?o\n\n)\n\n+\ng\na2\n\n(tan ? ? tan ?o) tan ?o (7.97)\n\nThe last two terms on the right hand side of Eq. (7.97) can be combined to form a\nperfect square so we have\n\ny(? ) =\nf\n\n2a2\n\n[\n(tan ?o ? tan ? ) sec ?o ? (sec ?o ? sec ? ) tan ? + ln\n\n(\ntan ? + sec ?\n\ntan ?o + sec ?o\n\n)]\n\n? g\n2a2\n\n[tan ? ? tan ?o]2 (7.98)\n\nLet us now consider how to solve the problem. First of all, we have four unknowns:\n?o, ?f, tf, and a. Second, we have four equations. Three equations are provided by our\nanalytical solutions that make use of the three specified final boundary conditions:\nyf = h, Vxf = Vc, and Vyf = 0 (three knowns) obtained from Eqs. (7.98), (7.88), and\n(7.89), respectively. Our fourth equation is\n\na =\ntan ?f ? tan ?o\n\ntf\n(7.99)\n\nwhich comes from evaluating the steering law, Eq. (7.83), at to = 0 and at tf.\nBy setting Vy(?f) = 0 in Eq. (7.89) we obtain:\n\nf\ng\n\n=\ntan ?f ? tan ?o\nsec ?f ? sec ?o (7.100)\n\nFrom Eq. (7.98) we write a2y(?f) = a2h which gives\n\na2h =\nf\n2\n\n[\n(To ? Tf)So ? (So ? Sf)Tf + ln\n\n(\nSf + Tf\nSo + To\n\n)]\n? g\n\n2\n(Tf ? To)2 (7.101)\n\nwhere we use \u201cT\u201d to represent tangent and \u201cS\u201d to represent secant and subscripts \u201co\u201d\nand \u201cf\u201d to indicate initial and final values, respectively.\n\n\n\n154 Chapter 7. Some Applications\n\nUsing Vx(?f) = Vc in Eq. (7.88) provides\n\na2 =\nf2\n\nV2c\nln2\n\n(\nTf + Sf\nTo + So\n\n)\n(7.102)\n\nSubstituting Eq. (7.102) into Eq. (7.101), dividing both sides by ln2(), and multiplying\nby 2f we obtain:\n\n2hf\nV2c\n\n=\n\n[\n(To ? Tf)So ? (So ? Sf)Tf + ln\n\n(\nSf+Tf\nSo+To\n\n)]\n? gf (Tf ? To)2\n\nln2\n(\n\nSf+Tf\nSo+To\n\n) (7.103)\n\nAfter substituting for gf , using Eq. (7.100), the numerator becomes:\n\nToSo ? TfSo ? SoTf + SfTf + ln\n(\n\nSf + Tf\nSo + To\n\n)\n? SfTf + SfTo + SoTf ? SoTo\n\n= ?SoTf + ln\n(\n\nSf + Tf\nSo + To\n\n)\n+ SfTo (7.104)\n\nSubstituting Eq. (7.104) into Eq. (7.103) gives:\n\n2hf\nV2c\n\n=\ntan ?o sec ?f ? tan ?f sec ?o + ln\n\n(\nsec ?f+tan ?f\nsec ?o+tan ?o\n\n)\n\nln2\n(\n\nsec ?f+tan ?f\nsec ?o+tan ?o\n\n) (7.105)\n\nThe expressions for fg and\n2hf\nV2c\n\n, Eqs. (7.100) and (7.105), are functions of two\nunknowns, ?o and ?f, so we have two equations to solve for the two unknowns. After\nsolving for ?o and ?f we can use Vx(?f) = Vc, Eq. (7.88), to solve for a:\n\na =\nf\n\nVc\nln\n\n(\nsec ?f + tan ?f\nsec ?o + tan ?o\n\n)\n(7.106)\n\nFinally, tf can be obtained from the steering law itself, Eq. (7.99):\n\ntf =\ntan ?f ? tan ?o\n\na\n(7.107)\n\nWe note that Eqs. (7.100) and (7.105) are implicit relations for the unknowns, ?o\nand ?f. They cannot be solved analytically, so we must resort to numerical methods.\nOne approach is as follows.\n\n1. Guess a value for ?o and use Eq. (7.100) to find ?f.\n2. Substitute ?o and ?f into Eq. (7.105) and compare to 2hfV2c .\n\n\n\n7.3. Time Optimal Launching of a Satellite 155\n\ny\n\nx\n\n?f = 11 deg\n\n?f = ?52 deg\n\n?0 = 27 deg\n\n?0 = 71 deg\n\nFigure 7.10. Schematic of lunar takeoff (Adapted from Bryson and Ho [1975]), with updated\nvalues that satisfy Eqs. (7.100) and (7.105). The assumptions include constant\nthrust, constant mass, no drag, and uniform flat-Moon gravity. The upper\ntrajectory represents a time-optimal launch into a 100 n.mi. circular orbit; the\nlower into a 50,000 ft \u00d7 100 n.mi. elliptical orbit.\n\n3. Adjust ?o. Note that increasing ?o increases 2hfV2c , which in turn increases height.\n\nAlternatively, MATLAB provides a convenient subroutine (fsolve) for such problems.\n\nExample 7.2 Lunar takeoff.\n\nBryson and Ho [1975] provide numerical results for a launch from the lunar surface.\nThey give the values in the units historically used as follows.\n\nLet fg = 3; g = 5.32 ft/s\n2 (lunar gravity), r = 938 nautical miles (lunar radius).\n\nWe note that 1 nautical mile = 6,080 ft.\nConsider two trajectories (illustrated in Fig. 7.10):\n\n1. Launch to 100 n.mi. circular orbit.\n2. Launch to periapsis of an elliptical orbit of 50,000 ft \u00d7 100 n.mi. (then inject into\n\n100 n.mi. circular orbit using a ?V of 464 ft/s).\n\nThe characteristic velocity for launch at constant acceleration, f, is computed from\n\n?Vchar = ftf (7.108)\n\nwhere tf is the thrust duration.\n\n\n\n156 Chapter 7. Some Applications\n\nFor the 100 n.mi. case we obtain from Eqs. (7.100) and (7.105): ?0 = 70.6 deg\nand ?f = ?52.3 deg; using Eqs. (7.107) and (7.108) we have: tf = 478 s, ?Vchar =\n7,624 ft/s. Comparing this result to a Hohmann transfer to 100 n.mi. orbit we have:\n?Vchar = 5,782 ft/s (5,648 ft/s at surface plus 134 ft/s at apoapsis).\n\nFor the 50,000 ft \u00d7 100 n.mi. case we obtain (for constant f): ?0 = 27.4 deg, ?f =\n11.1 deg, tf = 375 s, and ?Vchar = 5,976 ft/s. (These values are a little different from\nthose reported by Bryson and Ho, but they may have modified their results to include\na parabolic representation of the lunar surface.) We note that the time-optimal solution\nfor a lunar landing is found by running the launch solution backwards in time.\n\n7.3.2. TPBVP\n\nLet us assume that the thrust acceleration, f(t), is not necessarily a constant, so we\ndo not have the analytical solution presented in Sect. 7.3.1. Then we must consider\nsolving the problem numerically by setting up the TPBVP.\n\nReferring to Eqs. (4.83), we find that the state and costate equations for the flat\nMoon (or for the flat-Earth assuming no drag) are the following eight differential\nequations:\n\nx? = Vx (7.109a)\n\ny? = Vy (7.109b)\n\nV?x = f(t)\n\n?\n?? ??3?\n\n?23 + ?\n2\n4\n\n?\n?? (7.109c)\n\nV?y = f(t)\n\n?\n?? ??4?\n\n?23 + ?\n2\n4\n\n?\n?? ? g (7.109d)\n\n??1 = 0 (7.109e)\n\n??2 = 0 (7.109f)\n\n??3 = ??1 (7.109g)\n??4 = ??2 (7.109h)\n\nwith ten B.C.s:\n\nt0 = 0, x(0) = y(0) = 0, Vx(0) = Vy(0) = 0 (7.110a)\n\ny(tf) = h, Vx(tf) = Vc, Vy(tf) = 0, ?1(tf) = 0, H(tf) = ?1 (7.110b)\n\nwhere ?1f and Hf are found from the transversality condition. Since ?1 = 0, we can\ndrop it from further consideration, so now we have three costate equations\n\n\n\n7.3. Time Optimal Launching of a Satellite 157\n\n?\n\nD\ng\n\nF\n\nx (Downrange)\n\ny\n(A\n\nlti\ntu\n\nde\n)\n\n?\n\nFigure 7.11. Launch vehicle subject to drag.\n\n??2 = 0 (7.111a)\n\n??3 = 0 (7.111b)\n\n??4 = ??2 (7.111c)\n\nfor a total of seven differential equations with nine boundary conditions, which\nprovides a well-defined TPBVP. Appendix A provides a numerical solution for the\nlaunch from the Moon using the TPBVP in MATLAB, bvp4c.\n\n7.3.3. Flat-Earth Launch Including Atmospheric Drag\n\nNow let\u2019s consider the case of launch into circular orbit in which we have atmospheric\ndrag acting on the vehicle. See Fig. 7.11. Retaining the flat-Earth model, we have:\n\nx? = Vx (7.112a)\n\ny? = Vy (7.112b)\n\nV?x =\nF\nm\n\ncos ? ? D\nm\n\ncos ? (7.112c)\n\nV?y =\nF\nm\n\nsin ? ? D\nm\n\nsin ? ? g (7.112d)\n\nwhere the thrust, F, and the mass, m, are in general prescribed functions of time and\nthe drag, D, is given by\n\n\n\n158 Chapter 7. Some Applications\n\nD =\n1\n2\n?CDA(V2x + V\n\n2\ny) (7.113)\n\nwhere CD is the drag coefficient (assumed constant), A is the cross sectional area, and\n? is the flight path angle.\n\nFor simplicity, we will assume an exponential atmosphere where the density, ?, is\ngiven by\n\n? = ?ref exp(?y/hscale) (7.114)\n\nwhere ?ref is the reference density (usually corresponding to the value at the launch\nsite) and hscale is the scale height. We see from Eq. (7.114) that when y = hscale, the\ndensity, ?, drops by a factor 1/e compared to ?ref.\n\nForming the Hamiltonian, we have\n\nH = ?1Vx + ?2Vy + ?3\n(\n\nF\nm\n\ncos ? ? D\nm\n\ncos ?\n\n)\n+ ?4\n\n(\nF\nm\n\nsin ? ? D\nm\n\nsin ? ? g\n)\n\n(7.115)\n\nWe obtain the control law from the procedure described after Eq. (4.66). The\nHamiltonian in Eq. (7.115) can be written as:\n\nH = ?1Vx + ?2Vy ? ?3\n(\n\nD\nm\n\ncos ?\n\n)\n? ?4\n\n(\nD\nm\n\nsin ? ? g\n)\n\n+\nF\nm\n\n?T? (7.116)\n\nthen\n\ncos ? =\n??3?\n?23 + ?\n\n2\n4\n\n(7.117a)\n\nsin ? =\n??4?\n?23 + ?\n\n2\n4\n\n(7.117b)\n\nFrom Eqs. (7.112) to (7.115), the Hamiltonian is\n\nH = ?1Vx + ?2Vy + ?3\n\n?\n??Fm\n\n?\n?? ??3?\n\n?23 + ?\n2\n4\n\n?\n?? ? Dm\n\nVx?\nV2x + V2y\n\n?\n??\n\n+ ?4\n\n?\n??Fm\n\n?\n?? ??4?\n\n?23 + ?\n2\n4\n\n?\n?? ? Dm\n\nVy?\nV2x + V2y\n\n? g\n?\n?? (7.118)\n\nor\n\nH = ?1Vx + ?2Vy ? Fm\n?\n?23 + ?\n\n2\n4 ?\n\n[\n?refCDA\n\n2m\nexp\n\n( ?y\nhscale\n\n)?\nV2x + V2y\n\n(\n?3Vx + ?4Vy\n\n)] ? ?4g\n\n(7.119)\n\n\n\n7.3. Time Optimal Launching of a Satellite 159\n\nLet us assume that the final conditions are\n\ny(tf) = h, Vx(tf) = Vc, Vy(tf) = 0 (7.120)\n\nThe differential form of the transversality condition requires that\n\nHfdtf ? ???Tf dxf + d? = 0 (7.121)\n\nSince the final time, tf, and the horizontal position, xf, are free, but the other final states\nare specified [by Eqs. (7.120)], the transversality condition provides:\n\nHfdtf ? ?1fdxf + dtf = 0 (7.122)\n\nFrom Eq. (7.122) we obtain\n\nHf = ?1 (7.123a)\n?1f = 0 (7.123b)\n\nWe note from the first of the Euler-Lagrange equations that\n\n??1 = 0 (7.124)\n\nso that\n\n?1 = 0 (7.125)\n\nand we can drop ?1 from further consideration.\nFor convenience let us define\n\nK1 =\n?refCDA\n\n2m\n(7.126)\n\nThe remaining costate equations are:\n\n??2 = ??H\n?y\n\n= (?3Vx + ?4Vy) exp\n( ?y\n\nhscale\n\n)(?K1 |V|\nhscale\n\n)\n(7.127a)\n\n??3 = ? ?H\n?Vx\n\n= ??1 + K1 exp\n( ?y\n\nhscale\n\n)[\n?3\n\n(\nV2x\n|V| + |V|\n\n)\n+ ?4\n\nVxVy\n|V|\n\n]\n(7.127b)\n\n??4 = ? ?H\n?Vy\n\n= ??2 + K1 exp\n( ?y\n\nhscale\n\n)[\n?4\n\n(\nV2y\n|V| + |V|\n\n)\n+ ?3\n\nVxVy\n|V|\n\n]\n(7.127c)\n\n\n\n160 Chapter 7. Some Applications\n\nwhere we have used |V| to represent the magnitude of the velocity, (V2x +V2y)1/2. We can\nspecify the TPBVP by substituting the control law, Eqs. (7.117), into the equations of\nmotion, Eqs. (7.112)\u2013(7.114), and by using\n\n?3 cos ? + ?4 sin ? = ?\n?\n?23 + ?\n\n2\n4 (7.128)\n\nin the costate equations, Eqs. (7.127), using ?1 = 0:\n\nx? = Vx (7.129a)\n\ny? = Vy (7.129b)\n\nV?x =\nF\nm\n\n??3?\n?23 + ?\n\n2\n4\n\n? K1 exp\n( ?y\n\nhscale\n\n)\nVx\n\n?\nV2x + V2y (7.129c)\n\nV?y =\nF\nm\n\n??4?\n?23 + ?\n\n2\n4\n\n? K1 exp\n( ?y\n\nhscale\n\n)\nVy\n\n?\nV2x + V2y ? g (7.129d)\n\n??2 = (?3Vx + ?4Vy) exp\n( ?y\n\nhscale\n\n)\n?\n??\n\n?K1\n?\n\nV2x + V2y\nhscale\n\n?\n?? (7.129e)\n\n??3 = K1 exp\n( ?y\n\nhscale\n\n)\n?\n???3\n\n?\n?? V\n\n2\nx?\n\nV2x + V2y\n+\n?\n\nV2x + V2y\n\n?\n?? + ?4 VxVy?\n\nV2x + V2y\n\n?\n?? (7.129f)\n\n??4 = ??2+K1 exp\n( ?y\n\nhscale\n\n)????4\n\n?\n??\n\nV2y?\nV2x+V2y\n\n+\n?\n\nV2x+V2y\n\n?\n??+?3 VxVy?\n\nV2x+V2y\n\n?\n?? (7.129g)\n\nwith B.C.s\n\nt0 = 0, x(0) = y(0) = 0, Vx(0) = Vy(0) = 0 (7.130a)\n\ny(tf) = h, Vx(tf) = Vc, Vy(tf) = 0 (7.130b)\n\nHf = ?1 (7.130c)\n\nLet us examine the constraint on the final Hamiltonian, Eq. (7.130c), in detail:\n\nHf=?1fVxf+?2fVyf? Ffmf\n?\n?23f+?\n\n2\n4f? exp\n\n(?yf\nhscale\n\n)[\n?refCDA\n\n2m\n\n?\nV2xf+V\n\n2\nyf\n(\n?3fVxf+?4fVyf\n\n)]\n\n(7.131)\n\n\n\n7.3. Time Optimal Launching of a Satellite 161\n\nSince ?1f = 0, Vyf = 0, yf = h, and Vxf = Vc, Eq. (7.131) becomes:\n\nHf = ? Ffmf\n?\n?23f + ?\n\n2\n4f ? ?ref exp(?h/hscale)\n\nCDA\n2mf\n\nV2c?3f ? ?4fg = ?1 (7.132)\n\nWe recall that the thrust, F(t), and the mass, m(t), are prescribed functions of time.\nThe seven differential equations, Eqs. (7.129), along with the nine B.C.s, Eqs. (7.130)\nand Eq. (7.132) provide a well-defined TPBVP.\n\nExample 7.3 Time-optimal flat-Earth launch of a Titan II rocket including the effects\nof atmospheric drag and time-varying mass.\n\nLet us consider the case of launching a Titan II, subject to atmospheric drag, into\na circular LEO in minimum time, including the effect of time-varying mass (with\nconstant thrust).\n\nAssume the following numerical values:\n\nF = 2.10 \u00d7 106 N (7.133a)\nmo = 1.1702 \u00d7 105 kg (7.133b)\n\nA = 7.069 m2 (7.133c)\n\nCD = 0.5 (7.133d)\n\n?ref = 1.225 kg/m3 (7.133e)\n\nhscale = 8.44 \u00d7 103 m (7.133f)\ng = 9.80665 m/s2 (7.133g)\n\nWe use Eqs. (7.112) for our equations of motion along with Eq. (7.113) for the drag\nmodel and an exponential atmosphere for the density, given in Eq. (7.114). The thrust\nof the launch vehicle is constant as given above in Eq. (7.133a) and the acceleration\nof gravity is the standard free-fall constant given in Eq. (7.133g).\n\nEquations (7.129), (7.130), and (7.132) provide the TPBVP.\nFor the final altitude and velocity we use\n\nh = 1.80 \u00d7 105 m (7.134a)\nVc = 7.796 \u00d7 103 m/s (7.134b)\n\nTo include the effect of time-varying mass we use a constant mass-flow rate of:\n\nm? = ?(1.1702 \u00d7 105 kg ? 4.76 \u00d7 103 kg)/139 s = ?807.6 kg/s (7.135)\n\n\n\n162 Chapter 7. Some Applications\n\n0 50 100 150 200 250\n?50\n\n0\n\n50\n\n100\n\nTime [sec]\n\n? \n [d\n\neg\n]\n\nFigure 7.12. Steering angle for the time-optimal launch of a Titan II rocket into a 180 km\ncircular orbit. Assumptions include constant thrust, time-varying mass, drag\nfrom exponential atmosphere, and uniform flat-Earth gravity.\n\nWe note that we are only considering the first stage of the Titan II, which is capable\nof getting into orbit (i.e. we are not including the second stage in this problem). In the\nreal case, the initial mass of the first stage is 117,020 kg (fully fueled), the final mass\nis 4,760 kg (empty), and the burn time is 139 s. (Note that, because of our simplified\nmodel, we do not expect to obtain precisely these values in our TPBVP solver.) We\nnote that the burn time we are using here (of 139 s) is merely an approximation and\nis not the optimal time we are seeking; it allows us to calculate a mass-flow rate. The\nTPBVP solver will provide the minimum time.\n\nFigures 7.12 and 7.13 show results from the numerical solution of the TPBVP. (See\nAppendix B for more details on how to solve this problem in MATLAB.) In Fig. 7.12\nwe see that the initial steering angle is near 90 deg, in contrast to the lunar takeoff\nproblem, Example 7.2, where the initial steering angle can be quite small. The reasons\nfor the high steering angle in the Earth-launch case are two-fold. The first reason is\nthat the vehicle must climb to higher altitude to reduce the effect of drag losses. The\nsecond is that the initial acceleration, F/m, is very low, about 1.8 g\u2019s, so any steering\nangle less than about 57 deg is too low to counter the gravitational acceleration. Near\nthe end of the trajectory the steering angle is about ?50 deg, which cancels the vertical\nvelocity in a similar manner to that of the lunar takeoff problem. Figure 7.13 shows\nthe trajectory profile of the altitude vs. the downrange distance.\n\n\n\n7.5. Exercises 163\n\n0 20 40 60 80 100 120\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\nx [km]\n\ny \n[k\n\nm\n]\n\nFigure 7.13. Altitude vs. range for time-optimal launch of Titan II.\n\n7.4. Summary\n\nWe have considered three classical problems (aircraft minimum time to climb, max-\nimum range of a rocket, and the optimal launch of a satellite), in which approximate\nanalytical solutions are available. These solutions give special insight into some of\nthe most important applications in trajectory optimization. It is particularly interesting\nto note that before optimal control theory was applied to the aircraft minimum time-\nto-climb problem, pilots were not aware of the strategy of diving through the sound\nbarrier. Knowledge of the optimal solution ushered in many new time-to-climb records\nfor existing aircraft.\n\n7.5. Exercises\n\n1. Solve the problem of maximizing the altitude of a rocket that is launched vertically\nusing the following assumptions. The process equations are\n\nx? = v\n\nv? = f ? g\nm? = ??f\n\nwhere we assume uniform gravity, g, and no drag (Fig. 7.14). The initial conditions\nare\n\nt0 = 0, x(t0) = 0, v(t0) = 0, m(t0) = m0\n\n\n\n164 Chapter 7. Some Applications\n\nx\n\ng\n\nFigure 7.14. Maximizing the altitude of a rocket launched vertically.\n\nwhere x is the altitude, v is the velocity, and m is the mass of the rocket which has\na final value:\n\nm(tb) = mb\n\nwhere tb is the burnout time. Note that the burnout time is not prescribed, but\ndepends on the acceleration f. The acceleration is the only control and is bounded\nas follows:\n\n0 ? f ? fmax\nAssume that f can be a time-varying function in general and that ?, in the third\nprocess equation, is a positive constant.\n\nSet up the optimal control problem as a Mayer problem and solve according to\nthe following steps.\n\n1a. Show that Max J = xf can be written as Max J = xb + 12 v\n2\nb/g where xb and vb\n\nare the altitude and velocity at burnout and xf is the maximum altitude reached.\n1b. Write the Hamiltonian using ?x, ?v, and ?m as the costates, respectively.\n1c. Indicate why we know that the Hamiltonian is a constant in this case.\n1d. Give the costate differential equations and the form of their solutions.\n1e. Give an expression for the switching function in terms of ?v and ?m.\n1f. Write the transversality condition and give explicit solutions for ?x(t) and\n\n?v(t). Also state the value of H(t). Deduce that ?m = vb/(g?). (Hint: write\nthe transversality condition at t = tb.)\n\n1g. Give your final expression for the switching function in terms of t and tb and\ngive the control law, based on the switching function.\n\n2. Use MATLAB\u2019s bvp4c to solve the two cases of the lunar takeoff problem\ndescribed in Example 7.2. (See Appendix A.)\n\n\n\n7.5. Exercises 165\n\n2a. For the first case use the following numerical values:\n\ngMoon = 1.62 m/s2\n\nyf = 185.2 km\n\nF/m = 3gMoon\n\nVc = 1.627 km/s\n\n2b. Determine the maximum ranges for initial guesses for tf, ?2(0), and ?4(0) in\norder to converge on the optimal solution. (Note: to simplify this analysis you\nmay hold two values fixed while varying the third.)\n\n2c. Propagate the EOMs (using I.C.s and the steering law found in solving the\nTPBVP) to see if the satellite achieves the desired orbit. Investigate the effect\nof small errors in the propagated solution. (For example, consider inserting\nsmall errors in the I.C.s or in the steering law.) Comment on the behavior and\naccuracy of your propagated solution.\n\n2d. Compare the results obtained in Exercise 2a with the initial and final values for\nthe steering values given by Eqs. (7.100) and (7.105).\n\n2e. For the second case repeat parts Exercises 2a through 2d using the same\nvalues for gMoon and F/m, but use the values for yf and Vf (in metric units)\nthat correspond to a launch to an elliptical orbit of 50,000 ft \u00d7 100 n.mi.\n\n3. Use bvp4c to solve the Titan launch problem described in Example 7.3. (See\nAppendix B.)\n\n3a. Make plots for the zero-drag, constant-mass case.\n3b. Make plots for the drag plus variable-mass case.\n3c. Discuss the differences between the results for Exercise 3a and for Exercise 3b.\n\n4. Consider the following projects.\n\n4a. Compare the flat-Moon TPBVP solution to the complete analytical solution\ngiven in Sect. 7.3.1.\n\n4b. Create a more historically accurate version of the lunar takeoff problem by\nmodeling the variable mass of the Lunar Module in your TPBVP.\n\n4c. Compute time-optimal launches from Titan, Venus, or Mars.\n4d. Investigate the advantages of air launch (from balloons or aircraft).\n4e. Study the effect of improved thrust efficiency as a function of altitude in a\n\ntime-optimal approach.\n4f. Examine the effect of ballistic coefficient, BC = m/(CDA), which tends to be\n\nlarge for large launch vehicles and small for small launch vehicles (i.e. it is\nproportional to scale length of the vehicle).\n\n4g. Solve the launch problem assuming predetermined staging.\n\n5. Answer the following questions based on the material presented in Chap. 7.\n\n\n\n166 Chapter 7. Some Applications\n\n5a. In the aircraft performance analysis it was shown that to minimize the time\nto climb the following rule applies: at a given energy height pick the velocity\nwhich maximizes the excess power.\n\nTrue False\n\n5b. Sometimes a supersonic aircraft may need to dive in order to achieve the\nminimum time to climb to a particular altitude. (Assume the aircraft trajectory\nbegins at zero altitude with zero velocity.)\n\nTrue False\n\n5c. In our simplified analysis of the aircraft minimum time to climb problem we\nassumed that the time required for zoom climbs and dives is negligible.\n\nTrue False\n\n5d. The optimal trajectory for launch from the flat moon using f/g = 3 requires\nmore propellant than a Hohmann transfer.\n\nTrue False\n\n5e. In the maximization of the range of a rocket (for no drag and for uniform\ngravity), it was found that the steering control law is tan ? = at + b where\n? is the thrust angle with respect to the horizontal and a and b are nonzero\nconstants.\n\nTrue False\n\nSolution: aT, bT, cT, dT, eF.\n\nReferences\n\nJ.D. Anderson Jr., Introduction to Flight, 4th edn. (McGraw Hill, New York, 1999)\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\nY.C. Ho, J.L. Speyer, In appreciation of Arthur E. Bryson, Jr. J. Guid. Control Dyn. 13(5), 770\u2013774\n\n(1990)\nD.F. Lawden, Optimal Trajectories for Space Navigation (Butterworths, London, 1963)\nA. Miele, Flight Mechanics: Theory of Flight Paths, vol. 1 (Addison-Wesley, Reading, 1962)\nN.X. Vinh, Flight Mechanics of High-Performance Aircraft (Cambridge University Press, New York,\n\n1993)\n\n\n\nChapter 8\n\nWeierstrass-Erdmann Corner Conditions\n\n8.1. Statement of the Weierstrass-Erdmann Corner Conditions\n\nSo far, we have discussed four sets of necessary conditions which must be met by x?(t)\nand u?(t), over the class of admissible functions:\n\nNecessary Condition I:\nEuler-Lagrange equations: ???? = ?Hx, Hu = 0\nalong with the transversality condition.\n\nNecessary Condition II:\nLegendre-Clebsch condition: Huu ? 0.\nNecessary Condition III:\nWeierstrass condition: H(t, x?,???, u?) ? H(t, x?,???, u).\nNecessary Condition IV:\nJacobi condition: requires the non-existence of a conjugate point on (to, tf).\n\nThese four conditions are also treated in the classical texts (e.g., Bliss [1968], Bolza\n[1961], Bryson et al. [1975], and Lawden [1963]). Now, let us consider the conditions\nthat must be met at a corner of x?(t), where x??(t1) is discontinuous.\n\nSuppose u is a scalar with |u| ? 1 for the standard Bolza problem. If [x?(t), u?(t)]\nminimizes J with u?(t) ? P.C.[to, tf], then:\n1. ???? = ?Hx on each sub-arc between corners (i.e. points where the control is\n\ndiscontinuous).\n2. ???(t) and H(t) are continuous on the entire trajectory and, in particular, across corners\n\n(the Weierstrass-Erdmann corner conditions).\n3. Also:\n\nH?u(t)\n\n?\n???\n???\n\n? 0 if u?(t) = +1\n= 0 if ?1 < u?(t) < +1\n? 0 if u?(t) = ?1\n\n(8.1)\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 8,\n\u00a9 Springer Science+Business Media New York 2014\n\n167\n\n\n\n168 Chapter 8. Weierstrass-Erdmann Corner Conditions\n\n8.2. Proof Outline of Weierstrass-Erdmann Corner Conditions\n\nIn this section we prove statements 1\u20133 of Sect. 8.1 including statement 2, the\nWeierstrass-Erdmann corner conditions. (For a similar treatment see Hull [2003] and\nVagners [1983]). Without loss of generality, we assume:\n\nu?(t)\n{\n\ninterior on [to, t1)\n+1 on (t1, t?f ]\n\n(8.2)\n\nwhere t1 (the time when the corner occurs) and tf are not known beforehand. Figure 8.1\nillustrates a one-sided variation of the control for t ? (t1, tf] : ?u ? 0.\n\nVarying the control can alter the time required to reach the final state. Now, as in\nthe proof of the Euler-Lagrange theorem (in Chap. 3), we make use of a one-parameter\nfamily, u(t, ?), where u?(t) = u(t, 0) and ? ? 0. In this analysis it is convenient to use\nthe un-adjoined approach. Let us form dJd?\n\n???\n?=0\n\n? 0 as follows:\n\nt1\n\nt\n\ntf t\n\nu?(t)\n\nx?(t)\n\n?u ? 0\none-sided variation\n\nt1 tf\n\n+1\n\nFigure 8.1. Two-sided and one-sided variations considered for proof of corner conditions.\n\n\n\n8.2. Proof Outline of Weierstrass-Erdmann Corner Conditions 169\n\nJ = ?{tf(?), x[tf(?), ?]} +\n? t?1 (?)\n\nto\n\n{\nH[t, x(t, ?),???(t), u(t, ?)] ? ???T(t)x?(t, ?)\n\n}\ndt\n\n+\n? tf(?)\n\nt+1 (?)\n\n{\nH[t, x(t, ?),???(t), u(t, ?)] ? ???T(t)x?(t, ?)\n\n}\ndt (8.3)\n\nwhere t?1 (?) represents the limit of t1(?) approached from the left side and t+1(?)\nrepresents the limit of t1(?) approached from the right. Applying Leibniz\u2019 rule,\nEq. (3.40), to Eq. (8.3) we obtain\n\ndJ\nd?\n\n=\nd?\nd?\n\n+\ndt?1 (?)\n\nd?\n\n(\nH ? ???Tx?\n\n)???\nt?1\n\n? dt\n+\n1(?)\nd?\n\n(\nH ? ???Tx?\n\n)???\nt+1\n\n+\ndtf(?)\n\nd?\n\n(\nH ? ???Tx?\n\n)???\ntf\n\n+\n? t?1 (?)\n\nto\n\n(\nHx\n?x\n??\n\n+ Hu\n?u\n??\n\n? ???T ? x?\n??\n\n)\ndt +\n\n? tf\nt+1 (?)\n\n(\nHx\n?x\n??\n\n+ Hu\n?u\n??\n\n? ???T ? x?\n??\n\n)\ndt\n\n(8.4)\n\nThen, the differential change in J is:\n\ndJ =\ndJ\nd?\n\n????\n?=0\n\nd? = d??+\n(\n\nH????Tx?\n)???\n\nt??1\ndt?1 ?\n\n(\nH????Tx?\n\n)???\nt+?1\n\ndt+1+\n(\n\nH????Tx?\n)???\n\nt?f\ndtf\n\n+\n? t??1\n\nto\n\n(\nH?x?x+H?u?u????T?x?\n\n)\ndt+\n\n? t?f\nt+?1\n\n(\nH?x?x+H?u?u????T?x?\n\n)\ndt ? 0\n\n(8.5)\n\nUsing integration by parts we have the following:\n\n? t??1\nto\n\n????T?x?dt = (????T?x)\n????\nt??1\n\nt0\n+\n? t??1\n\nto\n????\n\nT\n?xdt (8.6)\n\n? t?f\nt+?1\n\n????T?x?dt = (????T?x)\n????\nt?f\n\nt+?1\n+\n? t?f\n\nt+?1\n????\n\nT\n?xdt (8.7)\n\nBy choosing ???(t) on each sub-arc to cause\n\n????\nT = ?H?x (8.8)\n\non [to, t??1 ] and [t+?1 , t?f ], we eliminate the ?x terms in the integrands of Eq. (8.5). Next\nwe consider how to evaluate ?x(t?1 ), ?x(t+1), dx(t\n\n?\n1 ), dx(t\n\n+\n1), dt\n\n?\n1 , and dt\n\n+\n1 arising in\n\nEqs. (8.5)\u2013(8.7). In Fig. 8.2 we see that at the corner:\n\ndt?1 = t\n?\n1 |varied path ? t?1 |optimal path (8.9)\n\ndt+1 = t\n+\n1 |varied path ? t+1 |optimal path (8.10)\n\n\n\n170 Chapter 8. Weierstrass-Erdmann Corner Conditions\n\nx(t)\n\ntt?1 t1\n\ndx(t1)\nx(t)\n\nx?(t) dt1\n\nFigure 8.2. Variations near a corner at t?1 .\n\nThus,\n\ndt+1 = dt\n?\n1 ? dt1 (8.11)\n\nAlso, we have:\n\ndx(t?1 ) = x(t\n?\n1 ) ? x?(t??1 ) ? dx(t1) (8.12)\n\ndx(t+1) = x(t\n+\n1) ? x?(t+?1 ) ? dx(t1) (8.13)\n\nbecause x is continuous across the corner.\nIn Fig. 8.3 we consider each sub-arc separately, to conclude that\n\ndx(t?1 ) = ?x(t\n??\n1 ) + x?\n\n?(t??1 )dt1 (8.14)\n\ndx(t+1) = ?x(t\n+?\n1 ) + x?\n\n?(t+?1 )dt1 (8.15)\n\nFigure 8.4 shows a combined picture of the sub-arcs illustrated in Fig. 8.3 to\nemphasize the difference between ?x(t??1 ) and ?x(t+?1 ).\n\nRearranging Eqs. (8.14) and (8.15) and generalizing Eq. (3.29) to the case of a\nvector (as we did in the proof of the Euler-Lagrange theorem), we can substitute the\nrelations:\n\n?x(t??1 ) = dx1 ? x??(t??1 )dt1 (8.16)\n?x(t+?1 ) = dx1 ? x??(t+?1 )dt1 (8.17)\n?x(t?f ) = dxf ? x??(t?f )dtf (8.18)\n\n\n\n8.2. Proof Outline of Weierstrass-Erdmann Corner Conditions 171\n\nx(t)\n\nt\n\nx(t)\n\ntt+1t\n?\n1\n\ndx(t?1 ) dx(t+1)\n?x(t??1 ) ?x(t+?1 )\n\nt??1 t+?1\n\nFigure 8.3. Sub-arcs to the left and right of a corner in which dx(t?1 ) = dx(t\n+\n1 ).\n\nx(t)\n\ntt?1 t1\n\ndx(t1)\nx(t)\n\nx?(t)\n\ndt?1\n\ndt+1\n\ndt1\n\n?x(t??1 )\n\n?x(t+?1 )\n\nFigure 8.4. Combined picture of sub-arcs on either side of a corner from Figs. 8.2 and 8.3.\n\ninto the expression for dJ, Eqs. (8.5)\u2013(8.8), to obtain:\n\ndJ = d?? + (H ? ???Tx?)|t??1 dt\n?\n1 ? (H ? ???Tx?)|t+?1 dt\n\n+\n1 + (H ? ???Tx?)|t?f dtf\n\n? ???T(t??1 )\n[\ndx1 ? x??(t??1 )dt1\n\n]\n+ ???T(t+?1 )\n\n[\ndx1 ? x??(t+?1 )dt1\n\n]\n\n? ???T(t?f )\n[\ndxf ? x??(t?f )dtf\n\n]\n+\n? t??1\n\nto\nHu??u dt +\n\n? t?f\nt+?1\n\nHu??u dt ? 0 (8.19)\n\nNow, if we choose ???f so that\n\nd?? + H?f dtf ? ???Tf dxf = 0 (8.20)\n\n\n\n172 Chapter 8. Weierstrass-Erdmann Corner Conditions\n\nsubject to d? = 0 (the final boundary conditions), we can simplify to obtain:\n\ndJ =\n[\nH(t??1 ) ? H(t+?1 )\n\n]\ndt1 +\n\n[\n???T(t+?1 ) ? ???T(t??1 )\n\n]\ndx1\n\n+\n? t??1\n\nto\nHu??udt +\n\n? t?f\nt+?1\n\nHu??udt ? 0 (8.21)\n\nEquation (8.20) is, of course, the differential form of the transversality condition as\nit appeared in Eq. (3.68). We use Eq. (8.21) to show that:\n\nH(t+?1 ) = H(t\n??\n1 ) (8.22a)\n\n???T(t+?1 ) = ???T(t\n??\n1 ) (8.22b)\n\nwhich are the Weierstrass-Erdmann corner conditions. We get these conditions by the\nfollowing special variations, i.e. let us assume\n\nH(t+?1 ) ?= H(t??1 ) (8.23)\n\nand let us specify that ?u(t) = 0, dx(t1) = 0, and that\n\ndt1 = ?[H(t??1 ) ? H(t+?1 )] (8.24)\n\nWhen we use the special variation for dt1 in Eq. (8.24) in conjunction with the\nhypothesis of Eq. (8.23) we find that dJ < 0, which is a contradiction; hence Eq. (8.23)\nis not true.\n\nTherefore, for dJ, we conclude [since H(t+?1 ) = H(t\n??\n1 )] that:\n\ndJ =\n? t??1\n\nto\nHu??udt +\n\n? t?f\nt+?1\n\nHu??udt ? 0 (8.25)\n\nNext let us assume ?u(t) = 0 on (t1, tf) and let us choose ?u(t) to be a nonzero\nvariation on (t0, t1), as shown in Fig. 8.5. Since any variation (?u) on this interval\ncould be reversed in sign (??u), it is necessary that H?u = 0 on (to, t1). Suppose H?u ?= 0\nat some t ? (to, t1). Without loss of generality assume H?u > 0. Because of continuity,\nH?u > 0 on some interval (t ? ?, t + ?) where ? > 0. Let us choose:\n\n?u =\n\n{\n0 on (to, t ? ?) ? (t + ?, t1)\n\n?H?u(t) on (t ? ?, t + ?)\n(8.26)\n\nwhich implies that\n\ndJ =\n? t+?\n\nt??\n?H?2u (s)ds < 0 (8.27)\n\n\n\n8.3. Summary 173\n\ntt1\n\n1\n\n-1\n\nu\n\nto\n\n?u\n\n??u\n\nFigure 8.5. Positive and negative variations on (t0, t1).\n\nwhich is a contradiction; hence H?u must be zero on (t0, t1). Next, we consider the time\ninterval (t+1, tf). Our remaining expression for the cost variation is\n\ndJ =\n? tf\n\nt+1\nHu??udt ? 0 (8.28)\n\nRecall our one-sided variation illustrated in Fig. 8.1, where ?u ? 0. If ?u could be a\ntwo-sided variation then we would have Hu(t) = 0, as we just demonstrated for the\ninterval (t0, t1). Thus, we see that when u?(t) = +1, ?u ? 0, so we must have Hu ? 0\nto satisfy Eq (8.28). On the other hand, when u?(t) = ?1, ?u ? 0, and we must have\nHu ? 0. So, in conclusion:\n\nH?u(t)\n\n????\n???\n\n? 0 if u?(t) = +1\n= 0 if ?1 < u?(t) < +1\n? 0 if u?(t) = ?1\n\n(8.29)\n\n8.3. Summary\n\nFor the standard Bolza problem, the Hamiltonian and the costates are continuous\nacross discontinuous jumps in the control that result in a corner (discontinuity at x??).\nThe costate equation, ?????? = ?Hx, holds on either side of the corner. Also, Hu ? 0 means\n\n\n\n174 Chapter 8. Weierstrass-Erdmann Corner Conditions\n\nthat the control is not on a bound. The Weierstrass-Erdmann corner conditions have\nimportant applications in the general theory of optimal rocket trajectories as we will\nsee in Chap. 10 where we develop Lawden\u2019s primer vector theory.\n\nReferences\n\nG.A. Bliss, Lectures on the Calculus of Variations. Phoenix Science Series (The University of\nChicago Press, Chicago, 1968)\n\nO. Bolza, Lectures on the Calculus of Variations (Dover, New York, 1961)\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\nD.G. Hull, Optimal Control Theory for Applications (Springer, New York, 2003)\nD.F. Lawden, Optimal Trajectories for Space Navigation (Butterworths, London, 1963)\nJ. Vagners, Optimization techniques, in Handbook of Applied Mathematics, 2nd edn., ed. by C.E.\n\nPearson (Van Nostrand Reinhold, New York, 1983), pp. 1140\u20131216\n\n\n\nChapter 9\n\nBounded Control Problems\n\n9.1. Optimal Control Problems with Constraints\n\nWe recall that the general form of the minimization problem can be stated as\n\nMinimize:\n\nJ = ?(to, xo, tf, xf) +\n? tf\n\nto\nL(t, x, u)dt (9.1)\n\nsubject to:\n\nx? = f (t, x, u) (9.2)\n\nx(to) = xo (9.3)\n\nu ? U (9.4)\n?(to, xo, tf, xf) = 0 (9.5)\n\nSo far we have discussed optimization problems where endpoint constraints may\nappear. In this chapter we discuss the problem of bounded control where u is a scalar.\nThe form of the constraint can be written as\n\nG(u) ? 0 (9.6)\n\ne.g., G = u2 ? 1 ? 0 or |u| ? 1. In this case, the Minimum Principle applies without\nmodification.\n\nBefore addressing the bounded control problem, we briefly mention that other\nconstraints often appear (in the literature and in applications) involving not only the\ncontrol but the state as well. There may be equality constraints of the form\n\nC(x, u, t) = 0 (9.7)\n\nand inequality constraints of the form\n\nC(x, u, t) ? 0 (9.8)\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 9,\n\u00a9 Springer Science+Business Media New York 2014\n\n175\n\n\n\n176 Chapter 9. Bounded Control Problems\n\nh\n\nv\n\nFigure 9.1. Aircraft state inequality constraint example: S(h) = ?h ? 0.\n\nWhen the control does not appear in Eq. (9.8) we have the state variable inequality\nconstraint:\n\nS(x, t) ? 0 (9.9)\n\nAn example of Eq. (9.9) occurs in the aircraft performance problem (Fig. 9.1) where\nthe aircraft may not fly below the ground level (?h ? 0).\n\nIn addition there is the isoperimetric (or integral) constraint:\n\nG(tf) =\n? tf\n\nt0\n? (x, u, t) dt = 0 (9.10)\n\nwhich applies to the ancient problem presented to Carthaginian Princess Dido: find the\nlargest land area enclosed between a shoreline and a closed curve made from a bull\u2019s\nhide.\n\nThese problems involving constraints on the state (while important and fascinating\nin their own right) require special techniques beyond the scope of this introductory\ntext. We refer the reader to the treatment of state constraints in Bryson and Ho [1975],\nin Vagners [1983], and in Hull [2003].\n\n9.2. Examples of Bounded Control Problems\n\nExample 9.1 Single-axis spacecraft attitude control problem.\n\nLet us assume that a spacecraft (illustrated in Fig. 9.2) has a principal moment of\ninertia given by I. Our problem is to find the minimum-time control law to achieve the\n\n\n\n9.2. Examples of Bounded Control Problems 177\n\n\u00b1M\n? (t)\n\nI\n\nF\n\nF\n\nF\n\nF\n\nFigure 9.2. Single-axis spacecraft attitude control problem in which the initial state is\ndriven to a final state, ? (tf ) = ?? (tf ) = 0.\n\nfinal state ? (tf) = ?? (tf) = 0, starting from the initial state, ? (0) and ?? (0), where ? (t) is\nthe orientation angle measured from an inertial reference direction.\n\nWe assume that the thrusters on the spacecraft can produce a variable moment,\nM(t), with a maximum magnitude:\n\n|M(t)| ? Mmax (9.11)\n\nFrom Euler\u2019s equations of motion we have:\n\n?? =\nM(t)\n\nI\n(9.12)\n\nfor this single degree-of-freedom problem.\nMore formally, we can state our bounded control problem as follows:\n\nMinimize:\n\nJ = tf (9.13)\n\nsubject to:\n\nx?1 = x2 (9.14a)\n\nx?2 = u (9.14b)\n\n|u| ? 1 (9.14c)\n\n\n\n178 Chapter 9. Bounded Control Problems\n\nwith x1o and x2o given, x1f = x2f = 0, and where we have made the variable changes:\n\nx1 ? ? , x2 ? I??Mmax , u ?\nM(t)\nMmax\n\n(9.15)\n\nThe Hamiltonian is:\n\nH = ?1x2 + ?2u (9.16)\n\nThe Euler-Lagrange equations are:\n\n??1 = ?Hx1 = 0 (9.17)\n\nso\n\n?1 = c1 (9.18)\n\nand\n\n??2 = ?Hx2 = ??1 = ?c1 (9.19)\n\nso that\n\n?2 = ?c1t + c2 (9.20)\n\nwhere c1 and c2 are constants.\nHere we note that we cannot set Hu = 0, which is only good for interior arcs.\n\nWe wish to minimize H with respect to u, but Hu is not necessarily equal to zero.\nIn fact, we see that Hu = ?2 provides the switching function, ?2, which we introduced\nin Chap. 4 (Example 4.7). Thus, to minimize H with respect to u:\n\nu =\n\n{\n+1 if ?2 < 0\n?1 if ?2 > 0\n\n(9.21)\n\nIt turns out that \u201csingular arcs\u201d are non-optimal in this problem, i.e., ?2 ?? 0 on a\nnon-zero time interval. We will define and discuss singular arcs later in this chapter.\nFor the present, we merely wish to show that it is not possible in this problem to have\n?2 identically equal to zero for a nonzero time interval.\n\nAssume the contrary that ?2 ? 0. Then:\n\nc1 = 0, c2 = 0, ?1 = 0 (9.22)\n\n\n\n9.2. Examples of Bounded Control Problems 179\n\nFrom the differential form of the transversality condition\n\nHfdtf ? ???Tf dxf + d? = 0 (9.23)\n\nand since ??? ? 0\n\nHfdtf + dtf = 0 (9.24)\n\nso that\n\nHf = ?1 (9.25)\n\nBut evaluating the Hamiltonian from Eq. (9.16) at tf and using ?1 = ?2 = 0, we find\nthat:\n\nHf = 0 (9.26)\n\nEquations (9.25) and (9.26) contradict each other. Therefore, it is impossible to\nhave ?2 ? 0 in the optimal solution. Thus, according to Eq. (9.21) the control u must\nalways be either +1 or ?1 depending on the sign of ?2; u never takes on intermediate\nvalues (?1 < u < 1) since ?2 is never identically zero.\n\nThe next question to be answered is: How many switches are possible? This\nquestion can be answered by plotting the switching function, ?2, as shown in Fig. 9.3.\nRecalling that ?2 = ?c1t + c2, we have the following possibilities:\n1. If ?c1 > 0, c2 > 0, then ?2 is always positive and there is no switch.\n2. If ?c1 < 0, c2 > 0, then ?2 is positive initially and may become negative so that\n\none switch is possible.\n3. If ?c1 > 0, c2 < 0, then ?2 is negative initially and may become positive so that\n\none switch is possible.\n4. If ?c1 < 0, c2 < 0, then ?2 is always negative and there is no switch.\n\nSince this problem is two dimensional, a phase plane analysis can be applied (in\nwhich we plot x2 as a function of x1). We have a bang-bang controller where:\n\nu = \u00b11 = k (9.27)\n\nThe term \u201cbang-bang\u201d is used throughout the literature for controls that suddenly\nchange from one extreme to the other. (In early lab experiments with servomech-\nanisms, loud banging noises were heard when the servos switched control direction.\nSimilarly, Shuttle astronauts have noted the banging of their attitude control thrusters.)\n\nUsing Eq. (9.27) in the equations of motion, Eqs. (9.14a) and (9.14b), we have\n\nx?1 = x2 (9.28)\n\nx?2 = k (9.29)\n\n\n\n180 Chapter 9. Bounded Control Problems\n\n?2(t)\n\nc2\n\nc2\n\n?c1 > 0, c2 < 0\n\n?c1 < 0, c2 < 0\n\nt\n?c1 < 0, c2 > 0\n\n?c1 > 0, c2 > 0\n\nFigure 9.3. Switches for the attitude control problem occur when ?2 in Eq. (9.20) changes\nsign.\n\nDividing Eq. (9.28) by Eq. (9.29) we have x?1/x?2 = dx1/dx2 to obtain:\n\ndx1 =\n1\nk\n\nx2dx2 (9.30)\n\nIntegrating Eq. (9.30) we get\n\nx1 ? x1o = 12k (x\n2\n2 ? x22o) (9.31)\n\nwhich is the equation of a parabola. In Fig. 9.4 we show two contours corresponding\nto a parabola opening to the right (where u = +1) and to a parabola opening to the left\n(where u = ?1). By its very nature, the trajectory flow in this phase plane plot is to the\nright when x2 > 0 (since this implies that x?1 is positive and therefore x1 is increasing)\nand to the left when x2 < 0 (when x?1 is negative).\n\nIn Fig. 9.5, we show several examples of these parabolas for u = \u00b11, including the\nspecial case where two parabolas (one with u = +1 and one with u = ?1) intersect at\nthe origin.\n\nThis special case is called the switching curve. We note that any point on the\nswitching curve will be driven to the origin and requires no switches in the direction\nof the control. (Of course, once the trajectory reaches the origin, the control is turned\noff\u2014but this is not considered to be a switch.)\n\nIn Fig. 9.6, we show the switching curve and consider the initial state to begin at\npoint a. If we start at a with u = ?1, then only one switch is required at b (i.e. to\nu = +1) to get to the origin in minimum time. If we start at a with u = +1, then at\n\n\n\n9.2. Examples of Bounded Control Problems 181\n\nx1\n\nx2\n\ntrajectory flow\n\ntrajectory flow\n\nu = +1\n\nu = ?1\n\nFigure 9.4. Trajectory flow: when x2 > 0 the flow is from left to right; when x2 < 0 the flow\nis from right to left.\n\nx1\n\nu = +1u = ?1\nx2\n\nFigure 9.5. Sample trajectories for the spacecraft attitude control problem consist of\nparabolas that open to the right for u = +1 and to the left for u = ?1. A special\ncase occurs when both parabolas meet at the origin.\n\n\n\n182 Chapter 9. Bounded Control Problems\n\nx1\n\nx2 c\nu =\n\n+1\n\nu = +1\n\nd\n\nb\n\na\n\n1\n\n2\n\nu = +1\n\nu =\n?1\n\nu = ?1 switching curve\n\nFigure 9.6. The switching curve. I.C.s that lie on the switching curve (for either u = +1 or\nu = ?1) are driven to the origin without changing the sign of u. I.C.s that are\nnot initially on the switching curve must be driven to the switching curve first,\nat which point the sign of u is changed.\n\nleast two switches are required, for example one at c and one at d to get to the origin.\nThis trajectory cannot be time optimal because, according to the Minimum Principle\n(as illustrated in Fig. 9.3), the optimal trajectory can have, at most, only one switch.\nTo get off the switching curve and still return to the origin, we need three switches (one\nto get off and two to get back on, as shown via points 1 and 2 in Fig. 9.6)\u2014clearly not\nan optimal path.\n\nWe summarize the results for the single-axis spacecraft attitude control problem as\nfollows. If the trajectory is on the switching curve, then no switching is required to\ndrive the final state, ? (tf), ??(tf), to the origin. In general (i.e. when the initial trajectory\nis not necessarily on the switching curve), at most one switch is required to get to the\norigin. (Note: to keep ? single valued we can assume ?180 deg< ? ? 180 deg.)\n\nExample 9.2 Oscillator with bounded control.\n\nLet us consider the following problem:\n\nMinimize:\n\nJ = tf (9.32)\n\n\n\n9.2. Examples of Bounded Control Problems 183\n\nsubject to:\n\nx?1 = ?x2 (9.33a)\n\nx?2 = ??x1 + u (9.33b)\n|u| ? 1 (9.33c)\n\nwith initial conditions x1(0) = x2(0) = 1 and final conditions x1(tf) = x2(tf) = 0.\nFor this problem we will show the following:\n\n1. The singular arc is non-optimal,\n2. The control must switch at least every ?\n\n?\ntime units,\n\n3. A sketch of the optimal trajectory in the phase plane, and\n4. The solution in the sketch (3) satisfies the Minimum Principle in terms of the\n\nswitching time.\n\nThe Hamiltonian is:\n\nH = ?1?x2 ? ?2?x1 + ?2u (9.34)\n\nand the Euler-Lagrange equations are:\n\n??1 = ?Hx1 = ?2? (9.35a)\n??2 = ?Hx2 = ??1? (9.35b)\n\nDifferentiating the expression for ??1 in Eq. (9.35a), we obtain\n\n??1 = ???2 (9.36)\n\nSubstituting Eq. (9.35b) into Eq. (9.36) provides\n\n??1 + ?2?1 = 0 (9.37)\n\nThe solutions for ?1 and ?2 can be written as\n\n?1 = A cos(?t) + B sin(?t) (9.38a)\n\n?2 =\n??1\n\n?\n= ?A sin(?t) + B cos(?t) (9.38b)\n\nSince H is a linear function of u, the switching function is:\n\nHu = ?2 (9.39)\n\n\n\n184 Chapter 9. Bounded Control Problems\n\nt\n\n?2(t)\n\nT = ?/?\n\nFigure 9.7. Switches occur every half period for the oscillator with bounded control.\n\n1. We can show that a singular arc is non-optimal, that is, ?2 ?? 0 on a nonzero time\ninterval. Assuming the contrary, ?2 ? 0 implies that A = B = 0 and that ?1 ? 0.\nThen from the transversality condition\n\nHfdtf ? ???Tf dxf + d? = 0 (9.40)\n\nwe obtain\n\nHf = ?1 (9.41)\n\nOn the other hand, evaluating the Hamiltonian using Eq. (9.34) at tf, with\n?1 = ?2 = 0, gives Hf = 0. Thus, we get a contradiction and ?2 cannot be identically\nzero for an optimal solution.\n\n2. We now show that the control must switch at least every ?/? time units. From the\nswitching function:\n\nu =\n\n{\n+1 if ?2 < 0\n?1 if ?2 > 0\n\n(9.42)\n\nSince\n\n?2 = ?A sin(?t) + B cos(?t) = C cos(?t + ?) (9.43)\n\nthe half period is ?/?, when a sign change will occur in ?2, as illustrated in Fig. 9.7.\n\n\n\n9.2. Examples of Bounded Control Problems 185\n\n3. The equations of motion can be integrated for phase plane analysis. Thus, dividing\nEq. (9.33a) by Eq. (9.33b), where u is a constant (+1 or ?1) we have\n\ndx1\ndx2\n\n=\n?x2\n\n??x1 + u (9.44)\n\nwhich implies that\n\n(??x1 + u)dx1 = (?x2)dx2 (9.45)\n\nIntegrating Eq. (9.45) with initial conditions x1(0) = x2(0) = 1 provides\n\n?1\n2\n?x21 +\n\n1\n2\n? + ux1 ? u = 12?x\n\n2\n2 ?\n\n1\n2\n? (9.46)\n\nRearranging Eq. (9.46) in perfect squares we obtain\n\n(\nx1 ? u\n\n?\n\n)2\n+ x22 =\n\n( u\n?\n\n? 1\n)2\n\n+ 1 (9.47)\n\nwhere we note that the key parameter is u/?. Thus, the trajectory is a circle with\ncenter at (u/?, 0) and radius\n\nr =\n?( u\n\n?\n? 1\n\n)2\n+ 1 (9.48)\n\nWithout loss of generality, let us consider the two cases: u/? = 1 and u/? = ?1.\nWe have two circles: one with center at (1, 0) and radius of 1 and the other with\ncenter at (?1, 0) and radius of ?5, as shown in Fig. 9.8. In the figure we see that\nthere are two paths that drive the state to the origin. The first path remains on the\nsmall circle (of radius 1), starts from the coordinates (1, 1) and ends at (0, 0) with\nu = +1. Clearly this first path uses the fixed value of u/? = +1 for more than a\nhalf revolution, so we expect it is not optimal (since for this example the Minimum\nPrinciple requires a switch to occur every half period, ?/?). The second path starts\nat (1, 1) with u/? = ?1 and travels along the large circle (of radius ?5) until it\nreaches the point (1, ?1). At that point the control switches to u/? = +1 and the\ntrajectory continues on the small circle until it reaches the origin (0, 0). The second\npath is our candidate for the time-optimal trajectory because the control switches\nbefore a half revolution is completed.\n\n4. We can show that the solution in (3) satisfies the Minimum Principle in terms of the\nswitching time. Solving the equations of motion for u/? = ?1, x1(0) = x2(0) = 1,\nand ? = 1 provides\n\nx1(t) = 2 cos(t) + sin(t) ? 1 (9.49a)\nx2(t) = ?2 sin(t) + cos(t) (9.49b)\n\n\n\n186 Chapter 9. Bounded Control Problems\n\nx1-1 1\n\n(1, 1)\n\nu\n?\n\n= ?1\n\nu\n?\n\n= +1\n\nr =\n?\n\n5\n\nx2\n\nr = 1\n\n(1, ?1)\n\nFigure 9.8. Phase plane analysis for the oscillator problem. The I.C. is (1,1) when u/? = ?1\ndrives the state on the large radius circle (r =\n\n?\n5) to intersect (1, ?1) at which\n\npoint u/? = +1 and the system follows the switching curve to the origin.\n\nNow, with x1(t) = 1 and x2(t) = ?1, we see that the time required on this path is\n\nt = cos?1\n(\n\n3\n5\n\n)\n= 0.927 ? ? seconds (9.50)\n\nThe time is less than the half period, ? , as required by the Minimum Principle.\nThus we have found the time-optimal solution that drives the initial state to the\norigin.\n\n9.3. Singular Arcs\n\nIn some optimization problems, extremal arcs, Hu = 0, occur on which the matrix\nHuu is singular. Such arcs are called singular arcs (as discussed in Bryson and Ho\n[1975]). In the singular problem, neither the Minimum Principle nor classical calculus\nof variations provides adequate tests for optimality. We will consider cases in which\nH is linear in a control variable.\n\n\n\n9.3. Singular Arcs 187\n\nAssume that the Hamiltonian has the form\n\nH = Ho(t, x,???) + H1(t, x,???)u (9.51)\n\nwhere |u| ? 1 and u is a scalar. From the Minimum Principle we have\n\nu =\n\n{\n+1 if H1(t, x,???) < 0\n?1 if H1(t, x,???) > 0\n\n(9.52)\n\nWe now introduce the Generalized Legendre-Clebsch condition which may be\nregarded as an extension and generalization of the work of Contensou [1962] and\nKelley [1964].\n\nIf u?(t) is a scalar singular optimal control, then the Generalized Legendre-Clebsch\ncondition states that\n\n(?1)q ?\n?u\n\n(\nd2qH?u\ndt2q\n\n)\n? 0 (9.53)\n\nwhere the 2q-th derivative is the first even derivative of Hu that contains u explicitly.\n(See Kelley et al. [1967].)\n\nTo determine candidate singular controls, we differentiate Hu = 0 with respect to\ntime. For example:\n\nd\ndt\n\n(Hu) = 0 =\n?Hu\n? t\n\n+\n?Hu\n?x\n\nx? +\n?Hu\n??\n\n?? +\n?Hu\n?u\n\nu? (9.54)\n\nwhere the last term vanishes. Next we substitute x? = f(t, x, u) and ?? = ?Hx(t, x, ?, u)\ninto Eq. (9.54). We then form d\n\n2\n\ndt2 Hu ? 0, and if u appears explicitly we apply\nEq. (9.53). If u does not appear we continue taking even time derivatives until\nEq. (9.53) can be applied.\n\nEquation (9.53) is referred to as the Kelley-Contensou condition (Marec 1979).\nWhen q = 0, Eq. (9.53) reduces to the Legendre-Clebsch condition, Huu ? 0.\n\nSeveral investigators have contributed to the generalization of the Legendre-\nClebsch condition and its application to different types of problems. These investiga-\ntors include Miele [1958], Tait [1965], Kopp and Moyer [1965], Goh [1966], Robbins\n[1967], and Bryson and Ho [1975]. Goh [1966] provides a necessary condition that\napplies to systems with multiple controls.\n\nExample 9.3 Application of the Generalized Legendre-Clebsch condition.\n\nConsider the case of a boat moving at constant speed, V, traveling from the origin to\n(xf, yf) in minimum time, as illustrated in Fig. 9.9. We assume that the control is the\nturn rate, u = ??, which is bounded so that |u| ? k. Also, we assume that the turn angle,\n?, is initially zero. We state our problem formally as follows.\n\nMinimize:\n\nJ = tf (9.55)\n\n\n\n188 Chapter 9. Bounded Control Problems\n\ny\n\nx?(0) = 0\n\n(xf, yf)\n\n(0, 0)\n\n?\n\nV\n\nFigure 9.9. Example of a boat crossing a river requiring the Generalized Legendre-Clebsch\ncondition. In this example the maximum turn rate is bounded.\n\nsubject to:\n\nx? = V cos? (9.56a)\n\ny? = V sin? (9.56b)\n\n?? = u (9.56c)\n\n|u| ? k (9.56d)\n\nwhere V is a constant and we have I.C.s: ?(0) = x(0) = y(0) = 0.\nIntuitively, we expect that the boat should turn at the maximum rate until the turn\n\nangle aligns with the terminal point (xf, yf) and that the turn angle would remain\nconstant for the remainder of the trajectory, as shown in Fig. 9.10.\n\nFor the Hamiltonian we have\n\nH = ?1V cos? + ?2V sin? + ?3u (9.57)\n\nso that from the Minimum Principle we have\n\nu =\n\n{\n+k if ?3 < 0\n?k if ?3 > 0\n\n(9.58)\n\nWe expect the switching function, ?3, to behave as illustrated in Fig. 9.11 where ?3\nbecomes zero for the interval (t1, tf). We now apply the Generalized Legendre-Clebsch\ncondition over the interval (t1, tf).\n\n\n\n9.3. Singular Arcs 189\n\nk\nt1\n\nu = 0\n\ny u\n\nu = +k\n\ntf\n\nx t1 tf t\n\nFigure 9.10. Expected solution for the river crossing problem. The maximum turn rate is\nused until the boat is pointed at the destination at which point the turn rate,\n?? = k, is switched to zero. This solution is verified by the Minimum Principle\nand the Generalized Legendre-Clebsch condition.\n\nt\n\n?3(t)\n\nt1 tf\n\nFigure 9.11. Switching function ?3 for the river crossing problem.\n\nThe first derivative of Hu with respect to time is given by\n\nd\ndt\n\n(Hu) = ??3 = ?H? = ?1V sin ? ? ?2V cos? = 0 (9.59)\n\nwhere we have made use of the Euler-Lagrange equation, ??3 = ?H?. We observe that,\non the singular arc\n\ntan? =\n?2\n\n?1\n=\n\n??2\n??1 (9.60)\n\n\n\n190 Chapter 9. Bounded Control Problems\n\nEquation (9.60) implies (as in Example 4.5) that\n\ncos? =\n\u00b1?1?\n?21 + ?\n\n2\n2\n\n(9.61a)\n\nsin ? =\n\u00b1?2?\n?21 + ?\n\n2\n2\n\n(9.61b)\n\nwhere we must pick both positive or both negative signs. Taking the second derivative,\nwe obtain\n\nd2\n\ndt2\n(Hu) = (?1V cos?)?? + (?2V sin?)?? = 0\n\n= (?1V cos? + ?2V sin?)u = 0 (9.62)\n\nFrom Eq. (9.62) we see that q = 1 and thus u = 0 is the singular control. Therefore,\nusing Eq. (9.53) we have\n\n(?1) ?\n?u\n\n(\nd2Hu\ndt2\n\n)\n= ?(?1V cos? + ?2V sin?) ? 0 (9.63)\n\nAs a result, we pick the minus signs for Eqs. (9.61a) and (9.61b), which corresponds\nto the H?uu ? 0 condition when ?? is unconstrained, where\n\nH? = ?1V cos? + ?2V sin? (9.64)\n\nThe Hamiltonian in Eq. (9.64) appeared in Example 4.4 in our analysis of Zermelo\u2019s\nproblem.\n\n9.4. Summary\n\nIn this chapter we have addressed the problem of bounded control where the control is\nscalar. In some cases the Minimum Principle provides the control law, so the problem\ncan be solved. There are, however, cases in which the matrix, Huu, is singular on\nthe extremal arc (where Hu = 0) so that the Minimum Principle does not provide an\nadequate test for optimality. In these singular arc problems an additional condition,\nthe Generalized Legendre-Clebsch condition, can provide the control law.\n\n9.5. Exercises\n\n1. Consider the following bounded control problem:\n\nMin J = tf\n\n\n\nReferences 191\n\nsubject to\n\nx?1 = x2\n\nx?2 = ?x1 + u\nx1(0) = 4.5, x1(tf) = 0\n\nx2(0) = 0, x2(tf) = 0\n\n|u| ? 1\n\n1a. Show that the control must switch at least every ? time units.\n1b. Sketch the optimal trajectory in the phase plane. (Include a sketch of the time\n\noptimal switching curve.)\n\n2. It\u2019s raining outside. An aerospace engineering student must run from point A to\npoint B a distance L. Assume that the fastest the student can run is Vmax, and that the\ncontrol is the student\u2019s velocity, V. The rain is falling straight down at a velocity,\nVrain, and the density of the rain is ?rain. The student\u2019s goal is to run at a velocity that\nresults in minimum wetness. Make appropriate assumptions and state the problem\nas an optimization problem. Determine the student\u2019s velocity to achieve minimum\nwetness.\n\nReferences\n\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\nP. Contensou, Etude the?orique des trajectoires optimales dans un champ de gravitation. Application\n\nau cas d\u2019un centre d\u2019attraction unique. Astronaut. Acta 8, 134\u2013150 (1962)\nB.S. Goh, Necessary conditions for singular extremals involving multiple control variables. SIAM\n\nJ. Control 4(4), 716\u2013731 (1966)\nD.G. Hull, Optimal Control Theory for Applications (Springer, New York, 2003)\nH.J. Kelley, A second variation test for singular extremals. AIAA J. 2, 1380\u20131382 (1964)\nH.J. Kelley, R.E. Kopp, A.G. Moyer, Singular extremals, Chapter 3, in Topics in Optimization, ed. by\n\nG. Leitmann (Academic, New York, 1967), p. 63\nR.E. Kopp, A.G. Moyer, Necessary conditions for singular extremals. AIAA J. 3, 1439\u20131444 (1965)\nJ.P. Marec, Optimal Space Trajectories (Elsevier Scientific, New York, 1979)\nA. Miele, Flight mechanics and variational problems of a linear type. J. Aerosp. Sci. 25(9), 581\u2013590\n\n(1958)\nH.M. Robbins, A generalized Legendre-Clebsch condition for the singular cases of optimal control.\n\nIBM J. Res. Dev. 11(4), 361\u2013372 (1967)\nK.S. Tait, Singular problems in optimal control. PhD thesis, Harvard University, Cambridge (1965)\nJ. Vagners, Optimization techniques, in Handbook of Applied Mathematics, 2nd edn., ed. by C.E.\n\nPearson (Van Nostrand Reinhold, New York, 1983), pp. 1140\u20131216\n\n\n\nChapter 10\n\nGeneral Theory of Optimal Rocket Trajectories\n\n10.1. Introduction\n\nIn this chapter we develop a general theory of optimal spacecraft trajectories based\non two pioneering works: Breakwell [1959] and Lawden [1963]. Lawden introduced\nthe concept of the primer vector, which plays a dominant role in minimum-propellant\ntrajectories and also in other types of optimal trajectories. A more complete discussion\nof the topics in this chapter, including several example trajectories, is in Prussing\n[2010].\n\n10.2. Equations of Motion\n\nThe equation of motion of a spacecraft which is thrusting in a gravitational field can\nbe expressed in terms of the orbital radius vector r as:\n\nr?(t) = g(r) + \n(t), \n(t) = ?(t)u(t) (10.1)\n\nThe variable \n is the thrust acceleration vector, whose magnitude ? is defined\nas the thrust (force), T, divided by the mass of the vehicle, m. The variable u is a\nunit vector in the thrust direction, and g(r) is the gravitational acceleration vector.\nA careful derivation of Eq. (10.1) requires deriving the rocket equation by equating the\nnet external force (such as gravity) to the time rate of change of the linear momentum\nof the vehicle/exhaust particle system (see Sects. 6.1\u20136.4 of Prussing and Conway\n[2013]).\n\nAn additional equation expresses the change in mass of the spacecraft due to the\ngeneration of thrust:\n\nm? = ?b, b ? 0 (10.2)\n\nIn Eq. (10.2) b is the (nonnegative) mass flow rate. The thrust magnitude, T, is given by\nT = bc, where c is the effective exhaust velocity of the engine. The word \u201ceffective\u201d\napplies to high-thrust chemical engines where the exhaust gases may not be fully\nexpanded at the nozzle exit. In this case there exists an additional contribution to the\nthrust which is incorporated into the effective exhaust velocity by defining\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0 10,\n\u00a9 Springer Science+Business Media New York 2014\n\n193\n\n\n\n194 Chapter 10. General Theory of Optimal Rocket Trajectories\n\nc ? ca + (pe ? p?)Aeb (10.3)\n\nIn Eq. (10.3) the subscript \u201ce\u201d refers to the pressure and area at the nozzle exit, ca is\nthe actual exhaust velocity at the exit, and p? is the ambient pressure. If the gases are\nexhausted into the vacuum of space, p? = 0.\n\nAn alternative to specifying the effective exhaust velocity is to describe the engine\nin terms of its specific impulse, defined to be:\n\nIsp ? (bc)?t(b?t)go =\nc\ngo\n\n(10.4)\n\nwhere go is the standard acceleration of free fall on Earth, equal to 9.80665 m/s2.\nAs shown in Eq. (10.4) the specific impulse is obtained by dividing the mechan-\nical impulse delivered to the vehicle by the weight of propellant consumed. The\nmechanical impulse provided by the thrust force over a time ?t is simply (bc)?t\nand, in the absence of other forces acting on the vehicle, is equal to the change\nin its linear momentum. The weight (on Earth) of propellant consumed during that\nsame time interval is (b?t)go. We note that if instead one divides by the mass of the\npropellant (which, of course, is the fundamental measure of the amount of substance),\nthe specific impulse would be identical to the exhaust velocity. However, the definition\nin Eq. (10.4) is in standard use with the value typically expressed in units of seconds.\n\n10.3. High and Low-Thrust Engines\n\nWe can distinguish between high- and low-thrust engines based on the value of the\nnondimensional ratio ?max/go. For high-thrust devices this ratio is greater than unity\nand thus these engines can be used to launch vehicles from the surface of the Earth.\nThis ratio may extend to as high as 100. The corresponding range of specific impulse\nvalues is between 200 and approximately 850 s, with the lower values corresponding\nto chemical rockets, both solid and liquid, and the higher values corresponding to\nnuclear thermal rockets.\n\nFor low-thrust devices the ratio?max/go is quite small, ranging from approximately\n10?2 down to 10?5. These values are typical of electric rocket engines such as\nmagnetohydrodynamic (MHD), plasma arc, and ion engines, and also for solar sails.\nThe ratio for solar sails is of the order of 10?5. An electric engine requires a separate\npower generator such as a radioisotope thermoelectric generator (RTG) or solar cells.\n\nOther engine designs such as the magnetoplasmadynamic (MPD) thrusters and the\nvariable specific impulse magnetoplasma rocket (VASIMR) seek to achieve higher\nlevels of thrust while maintaining the high specific impulse typical of low-thrust\nengines.\n\n\n\n10.4. Cost Functionals for Rocket Engines 195\n\n10.4. Cost Functionals for Rocket Engines\n\nTwo basic types of rocket engines exist: constant specific impulse (CSI) and variable\nspecific impulse (VSI), also called power limited (PL) engines. The CSI category\nincludes both high- and low-thrust devices. The mass flow rate b in some cases can be\ncontinuously varied, but is limited by a maximum value bmax. For this reason a CSI\nengine is also described as a thrust-limited engine, with 0 ? ? ? ?max.\n\nThe VSI category includes those low-thrust engines, such as electric engines, which\nneed a separate power source to run the engine. For these engines, the power is\nlimited by a maximum value Pmax, but the specific impulse can be varied over a\nrange of values. The propellant expenditure for the CSI and VSI categories is handled\nseparately.\n\nThe equation of motion, Eq. (10.1), can be expressed as:\n\nv? =\ncb\nm\n\nu + g(r),\ncb\nm\n\n? ? (10.5)\n\nFor the CSI case we solve Eq. (10.5) using the fact that c is constant as follows:\n\ndv =\ncb\nm\n\nudt + g(r)dt (10.6)\n\nUsing Eq. (10.2),\n\ndv = ?cudm\nm\n\n+ g(r)dt (10.7)\n\nwhich can be integrated (assuming constant u) to yield:\n\n?v = v(tf) ? v(to) = ?cu\n(\nln mf ? ln mo\n\n)\n+\n? tf\n\nto\ng(r)dt (10.8)\n\nor\n\n?v = cu ln\n(\n\nmo\nmf\n\n)\n+\n? tf\n\nto\ng(r)dt (10.9)\n\nwhich correctly indicates that, in the absence of gravity, the velocity change would\nbe in the thrust direction u. The actual velocity change achieved also depends on\nthe gravitational acceleration g(r) which is acting during the thrust period. The term\nin Eq. (10.9) involving the gravitational acceleration g(r) is called the gravity loss.\nWe note that there is no gravity loss due to an (instantaneous) impulsive thrust,\ndescribed in Sect. 10.5.2.\n\nIf we ignore the gravity loss term for the time being, a cost functional representing\npropellant consumed can be formulated. As will be seen, minimizing this cost\n\n\n\n196 Chapter 10. General Theory of Optimal Rocket Trajectories\n\nfunctional is equivalent to maximizing the final mass of the vehicle. Since the thrust is\nequal to the product of the mass flow rate b and the exhaust velocity c, we can write:\n\nm? = ?b = ?m?\nc\n\n(10.10)\n\ndm\nm\n\n= ??\nc\n\ndt (10.11)\n\nFor the CSI case the exhaust velocity, c, is constant and Eq. (10.11) can be\nintegrated to yield\n\nln\n\n(\nmf\nmo\n\n)\n= ?1\n\nc\n\n? tf\nto\n?dt (10.12)\n\nor\n\nc ln\n(\n\nmo\nmf\n\n)\n=\n? tf\n\nto\n?dt ? JCSI (10.13)\n\nJCSI is referred to as the characteristic velocity of the maneuver or the?V (pronounced\n\u201cdelta vee\u201d) and it is clear from Eq. (10.13) that minimizing JCSI is equivalent to\nmaximizing the final mass mf. This form for JCSI is also derived in Marec [1979].\n\nIn the impulsive thrust approximation for the unbounded thrust case (?max ? ?)\nthe vector thrust acceleration is represented by\n\n\n(t) =\nn?\n\nk=1\n\n?vk?(t ? tk) (10.14)\n\nwith to ? t1 < t2 . . . < tn ? tf representing the times of the n thrust impulses.\n(See Sects. 6.1\u20136.3 of Prussing and Conway [2013].) Using the definition of a unit\nimpulse,\n\n? t+k\nt?k\n?(t ? tk) dt = 1 (10.15)\n\nwhere t\u00b1k ? lim??0(tk \u00b1 ?), ? > 0.\nUsing Eq. (10.14) in Eq. (10.13) we obtain:\n\nJCSI =\n? tf\n\nto\n? dt =\n\nn?\nk=1\n\n?vk (10.16)\n\nand the total propellant cost is given by the sum of the magnitudes of the velocity\nchanges.\n\n\n\n10.4. Cost Functionals for Rocket Engines 197\n\nThe corresponding cost functional for the VSI case is obtained differently. The\nexhaust power (stream or beam power) is half of the product of the thrust and the\nexhaust velocity:\n\nP =\n1\n2\n\nTc =\n1\n2\n\nm?c =\n1\n2\n\nbc2 (10.17)\n\nUsing Eq. (10.17) along with\n\nb\nm2\n\n=\n?m?\nm2\n\n=\nd\ndt\n\n(\n1\nm\n\n)\n(10.18)\n\nresults in\n\nd\ndt\n\n(\n1\nm\n\n)\n=\n?2\n\n2P\n(10.19)\n\nwhich integrates to\n\n1\nmf\n\n? 1\nmo\n\n=\n1\n2\n\n? tf\nto\n\n?2\n\nP\ndt (10.20)\n\nMaximizing mf for a given value of mo regardless of whether it is optimal or not\nis obtained by running the engine at maximum power P = Pmax. This conclusion is\nnot as obvious as it looks in Eq. (10.20), because the value of ? might be different for\ndifferent values of P. To see that the engine should be run at maximum power we note\nthat for a specified trajectory, r(t), the required vector thrust acceleration is given by\nEq. (10.1) as\n\n\n(t) = r?(t) ? g[r(t)] (10.21)\n\nThus, for a given trajectory r(t) (optimal or not), the final mass in Eq. (10.20) is\nmaximized by running the engine at maximum power.\n\nFor this reason the VSI cost functional can be taken to be\n\nJVSI =\n1\n2\n\n? tf\nto\n?2dt (10.22)\n\nThis form for JVSI is also derived in Marec [1979].\nTo summarize, the cost functionals representing minimum-propellant expenditure\n\nare given by\n\nJCSI =\n? tf\n\nto\n?dt (10.23)\n\n\n\n198 Chapter 10. General Theory of Optimal Rocket Trajectories\n\nand\n\nJVSI =\n1\n2\n\n? tf\nto\n?2dt (10.24)\n\nWe see from Eqs. (10.23) and (10.24) that the minimum-propellant cost can be\nwritten in terms of the control magnitude ?(t) rather than introducing the mass as an\nadditional state variable whose final value is to be maximized.\n\n10.5. First-Order Necessary Conditions\n\n10.5.1. Optimal Constant Specific Impulse Trajectory\n\nFor a constant specific impulse (CSI) engine the thrust is bounded by 0 ? T ? Tmax\n(where Tmax is a constant), corresponding to bounds on the mass flow rate: 0 ? b ?\nbmax (where bmax is a constant). Note that we can also prescribe bounds on the thrust\nacceleration (thrust per unit mass) ? ? T/m as 0 ? ? ? ?max, where ?max is achieved\nby running the engine at Tmax. However, ?max is not constant, but increases due to the\ndecreasing mass. One must keep track of the changing mass in order to compute ? for\na given thrust level, but this is easy to do, especially if the thrust is held constant, e.g.,\nat its maximum value. However, if the propellant mass required is a small fraction of\nthe total mass, a constant ?max approximation can be made.\n\nThe cost functional representing minimum-propellant consumption for the CSI\ncase is given in Eq. (10.13) as\n\nJ =\n? tf\n\nto\n?(t)dt (10.25)\n\nThe state vector is defined as\n\nx(t) =\n\n[\nr(t)\nv(t)\n\n]\n(10.26)\n\nwhere r(t) is the spacecraft position vector and v(t) is its velocity vector. The mass m\ncan be kept track of without defining it to be a state variable by noting that\n\nm(t) = moe? F(t)/c (10.27)\n\nwhere\n\nF(t) =\n? t\n\nto\n?(? )d? (10.28)\n\n\n\n10.5. First-Order Necessary Conditions 199\n\nWe note from Eq. (10.28) that F(tf) is equal to the cost JCSI. In the constant thrust case\n? varies according to ?? = 1c?\n\n2, which is consistent with the mass decreasing linearly\nwith time. (See Exercise 1.)\n\nThe equation of motion is\n\nx? =\n\n[\nr?\nv?\n\n]\n=\n\n[\nv\n\ng(r) + ?u\n\n]\n(10.29)\n\nwith the initial state x(to) specified.\nThe first-order necessary conditions for an optimal CSI trajectory were first derived\n\nby Lawden [1963] using classical calculus of variations. In the derivation that follows,\nan optimal control theory formulation is used, but the derivations and examples are\nanalogous to those of Lawden and Breakwell. One significant difference is that the\nmass is not considered a state variable, but is kept track of separately which simplifies\nthe state equations and the adjoint equations by having fewer variables.\n\nIn order to minimize the cost in Eq. (10.25) we form the Hamiltonian using\nEq. (10.29) as\n\nH = ? + ???Tr v + ???\nT\nv[g(r) + ?u] (10.30)\n\nThe adjoint (costate) equations are then\n\n????\nT\nr = ?\n\n?H\n?r\n\n= ? ???TvG(r) (10.31)\n\n????\nT\nv = ?\n\n?H\n?v\n\n= ? ???Tr (10.32)\n\nwhere\n\nG(r) ? ?g(r)\n?r\n\n(10.33)\n\nis the symmetric 3 \u00d7 3 gravity gradient matrix. (See Exercise 2.)\n\nExample 10.1 Derivatives of the gravity gradient matrix.\n\nFor the inverse-square gravitational field: g(r) = ? (?/r2)r/r = ? (?/r3)r, show that\nthe gravity gradient matrix G(r) of Eq. (10.33) is equal to G(r) = ?r5 (3rr\n\nT ? r2I3),\nwhere I3 is the 3 \u00d7 3 identity matrix.\n\nFor g = ??rr3 we have:\n\nG =\n?g\n?r\n\n=\n[\n\nr3(???r\n?r\n\n) + ?r(3r2\n?r\n?r\n\n)\n]\n/r6 (10.34)\n\n\n\n200 Chapter 10. General Theory of Optimal Rocket Trajectories\n\nUsing ?r/?r = I3 and differentiating r2 = rTr yields 2r(?r/?r) = 2rT, so ?r/?r = rT/r\nand we obtain:\n\nG =\n3?r2rrT/r ? ?r3I3\n\nr6\n=\n?\n\nr5\n(\n\n3rrT ? r2I3\n)\n\n(10.35)\n\nFollowing the notation of Sect. 3.3.1 the terminal constraints for optimal rocket\ntrajectories are of the form\n\n?[tf, r(tf), v(tf)] = 0 (10.36)\n\nwhich may describe an orbital intercept, rendezvous, etc. The boundary conditions on\nEqs. (10.31) and (10.32) are given in terms of\n\n? ? ???T?[r(tf), v(tf), tf] (10.37)\n\nas\n\n???Tr (tf) =\n??\n\n?r(tf)\n= ???T\n\n??\n\n?r(tf)\n(10.38)\n\n???Tv(tf) =\n??\n\n?v(tf)\n= ???T\n\n??\n\n?v(tf)\n(10.39)\n\nwhere ??? is a constant Lagrange multiplier vector.\nThere are two control variables, the thrust direction u and the thrust acceleration\n\nmagnitude ?, that must be chosen to satisfy the Minimum Principle, i.e., to minimize\nthe instantaneous value of the Hamiltonian H, as discussed in Chap. 6. By inspection,\nthe Hamiltonian of Eq. (10.30) is minimized over the choice of thrust direction by\naligning the unit vector u(t) opposite to the adjoint vector ???v(t). Because of the\nsignificance of the vector ? ???v(t) Lawden [1963] termed it the primer vector p(t):\n\np(t) ? ????v(t) (10.40)\nThe optimal thrust unit vector is then in the direction of the primer vector, specifically:\n\nu(t) =\np(t)\np(t)\n\n(10.41)\n\nand\n\n???Tvu = ? ?v = ? p (10.42)\nin the Hamiltonian of Eq. (10.30).\n\nFrom Eqs. (10.32) and (10.38) we see that\n\np?(t) = ???r(t) (10.43)\n\n\n\n10.5. First-Order Necessary Conditions 201\n\nEquations (10.31), (10.32), (10.38), and (10.41) combine to yield the primer vector\nequation\n\np? = G(r)p (10.44)\n\nThe boundary conditions on the solution to Eq. (10.42) are obtained from Eqs. (10.36)\nand (10.37):\n\npT(tf) = ? ???T ??\n?v(tf)\n\n(10.45)\n\np?T(tf) = ???T\n??\n\n?r(tf)\n(10.46)\n\nWe note that in Eq. (10.43) the final value of the primer vector for an optimal intercept\n(only final position specified) is the zero vector, because the terminal constraint ?\ndoes not depend on the final velocity v(tf).\n\nUsing Eqs. (10.38) and (10.41) the Hamiltonian of Eq. (10.30) can be rewritten as\n\nH = ? (p ? 1) ? + p?Tv ? pTg (10.47)\n\nTo minimize the Hamiltonian over the choice of the thrust acceleration magnitude,\n?, we note that the Hamiltonian is a linear function of ?, and thus the minimizing\nvalue for 0 ? ? ? ?max will depend on the algebraic sign of the coefficient of ? in\nEq. (10.45). It is convenient to define the switching function\n\nS(t) ? p(t) ? 1 (10.48)\n\nThe choice of the thrust acceleration magnitude, ?, that minimizes H is then given\nby the bang-bang control law:\n\n? =\n\n{\n?max for S > 0 (p > 1)\n\n0 for S < 0 (p < 1)\n(10.49)\n\nThat is, the thrust magnitude switches between its limiting values of 0 (an NT, null-\nthrust, arc) and Tmax (an MT, maximum-thrust, arc) each time S(t) passes through 0\n[i.e. p(t) passes through 1] according to Eq. (10.47). Figure 10.1 shows an example\nswitching function for a three-burn sequence.\n\nThe possibility also exists that S(t) ? 0 [p(t) ? 1] on an interval of finite duration.\nFrom Eq. (10.45) it is evident that in this case the thrust acceleration magnitude is not\ndetermined by the Minimum Principle and may take on intermediate values between\n0 and ?max. This IT (intermediate thrust arc) in Lawden [1963] is called a singular arc\nin optimal control.\n\n\n\n202 Chapter 10. General Theory of Optimal Rocket Trajectories\n\n0\ntNT NT\n\nS(t)\n\n?max\n\nMT MT MT\n\nFigure 10.1. Three-burn CSI switching function and thrust profile.\n\nFrom the Weierstrass-Erdmann corner conditions of Chap. 8, we know that, at a\ncorner separating thrust arcs of different types, ???r and ???v, and hence p and p?, are\ncontinuous. Equation (10.46) then indicates that the switching function S(t) is also\ncontinuous.\n\nLawden explained to co-author Prussing the origin of the term primer vector in a\npersonal letter in 1990: \u201cIn regard to the term \u2018primer vector\u2019 you are quite correct in\nyour supposition. I served in the artillery during the war [World War II] and became\nfamiliar with the initiation of the burning of cordite by means of a primer charge.\nThus, p = 1 is the signal for the rocket motor to be ignited.\u201d\n\nIt follows then from Eq. (10.27) that, if T = Tmax and the engine is on for a total of\n?t time units,\n\n?max(t) = eF(t)/c Tmax/mo = Tmax/ (mo ? bmax?t) (10.50)\n\nEven though the gravitational field is time-invariant, the Hamiltonian in this formula-\ntion does not provide a first integral (constant of the motion) on an MT arc, because\n?max is an explicit function of time as shown in Eq. (10.48). On NT and IT arcs,\nhowever, the Hamiltonian is constant. (See Example 10.2.) From the corner conditions\nwe note that the Hamiltonian is continuous at a corner between arcs of different types,\nwhich is also evident from Eq. (10.45) because S = 0 (i.e. p = 1) at those instants when\n? is discontinuous.\n\n10.5.2. Optimal Impulsive Trajectory\n\nFor a high-thrust CSI engine the thrust durations are very small compared with the\ntimes between thrusts. Because of these short durations we can approximate each MT\narc as an impulse (a Dirac delta function) having unbounded magnitude (?max ?\n?) and zero duration. The primer vector then determines both the optimal times and\ndirections of the thrust impulses with p ? 1 corresponding to S ? 0. The impulses\ncan occur only at those instants at which S = 0 (p = 1). These impulses are separated\n\n\n\n10.5. First-Order Necessary Conditions 203\n\nt\n\nNT NT\n\nt1\n\nS(t)\n\nFigure 10.2. Switching function for an impulsive thrust.\n\nt\n\nt1\n\nNT NT\n\nS(t)\n\nFigure 10.3. Hypothetical cusp for which S? \t= 0 when S = 0.\n\nby NT arcs along which S < 0 (p < 1). At the impulse times, the primer vector is a\nunit vector in the optimal thrust direction. Figure 10.2 shows a switching function for\nan impulsive thrust at time t1.\n\nThe primer vector p is defined at an impulse time and r is continuous at an impulse\n(recall that it is r? = v that is discontinuous). Combined with the primer vector\nEq. (10.42) it follows that p, p?, and p? are continuous at an impulse.\n\nFigure 10.3 shows a hypothetical cusp for which S? ?= 0 when S = 0. However,\nas we will show, a cusp is not possible. From the Hamiltonian of Eq. (10.45) and the\nWeierstrass-Erdmann corner condition\n\nH+ ? H? = 0 = p?T(v+ ? v?) = p?T?v = ?vp?Tp (10.51)\n\nbecause p, p?, and g are continuous, S = 0 (p = 1), and ?v = ?vp. Thus p?Tp = p? = 0\n(see Exercise 7), which implies that S? = 0. So the hypothetical case shown in Fig. 10.3\ndoes not exist and there can be no cusp. This argument does not apply at the terminals\nof the trajectory because the corner conditions do not apply at the terminals. So in\ngeneral p? ?= 0 at the terminals.\n\n\n\n204 Chapter 10. General Theory of Optimal Rocket Trajectories\n\nIn Lion and Handelsman [1968] a procedure is developed to iteratively improve\na nonoptimal trajectory (that violates one or more of the necessary conditions\nsummarized below) to converge to an optimal trajectory. As discussed in Prussing\n[2010], when adding a midcourse impulse lowers the cost, the cost gradients with\nrespect to the midcourse impulse position and time (which are used to iterate on\nthese variables) depend on the discontinuities in p? and H at the midcourse impulse.\nAs the midcourse impulse position and time approach their optimal values, these\ndiscontinuities tend to zero.\n\nThe necessary conditions (NC) for an optimal impulsive trajectory, first derived by\nLawden [1963], are as follows\n\n1. The primer vector and its first derivative are continuous everywhere.\n2. The magnitude of the primer vector satisfies p(t) ? 1 with the impulses occurring\n\nat those instants at which p = 1.\n3. At the impulse times the primer vector is a unit vector in the optimal thrust\n\ndirection.\n4. As a consequence of the above conditions, dp/dt = p? = p?Tp = 0 at an intermediate\n\nimpulse (not at the initial or final time). (See Exercise 7.)\n\nFor a linear system, Prussing [1995] shows that these NC are also sufficient\nconditions (SC) for an optimal trajectory. Prussing also derives an upper bound on\nthe number of impulses required for an optimal solution. However, for a nonlinear\nsystem no upper bound exists.\n\nWe note also that for a thrust impulse at time tk\n\n?(t) = ?vk?(t ? tk) (10.52)\n\nand, from Eq. (10.28), the ?vk can be expressed as\n\n?vk =\n? t+k\n\nt?k\n?(t) dt = F(t+k ) ? F(t?k ) (10.53)\n\nwhere t+k and t\n?\nk are times immediately after and before the impulse time, respectively.\n\nEquation (10.27) then becomes the familiar solution to the rocket equation, Eq. (10.9),\nwith the interval term equal to zero.\n\nm(t+k ) = m(t\n?\nk ) e\n\n??vk/c (10.54)\n\nFigure 10.4 illustrates the primer vector magnitude for a three-impulse trajectory.\n\n10.5.3. Optimal Variable Specific Impulse Trajectory\n\nA variable specific impulse (VSI) engine is also known as a power-limited (PL)\nengine, because the power source is separate from the engine itself, e.g., solar panels,\nradioisotope thermoelectric generator, etc. The power delivered to the engine is\nbounded between 0 and a maximum value Pmax, with the optimal value being constant\n\n\n\n10.5. First-Order Necessary Conditions 205\n\n1\n\np(t)\n\nt\n\nFigure 10.4. Sample primer vector history for a three-impulse trajectory. The magnitude\nof the primer vector satisfies p(t) ? 1 with the impulses occurring at those\ninstants at which p = 1.\n\nand equal to the maximum, as discussed after Eq. (10.20). The cost functional repre-\nsenting minimum-propellant consumption for the VSI case is given by Eq. (10.22) as\n\nJ =\n1\n2\n\n? tf\nto\n?2(t) dt (10.55)\n\nWriting ?2 as \nT\n we obtain the corresponding Hamiltonian function:\n\nH =\n1\n2\n\nT\n + ???Tr v + ???\n\nT\nv[g(r) + \n] (10.56)\n\nFor the VSI case there is no need to consider the thrust acceleration magnitude and\ndirection separately, so the vector \n is used in place of the term ?u that appears in\nEq. (10.30).\nBecause H is a nonlinear function of \n, the Minimum Principle is applied by setting\n\n?H\n?\n\n= \nT + ???Tv = 0\nT (10.57)\n\nor\n\n\n(t) = ? ???v(t) = p(t) (10.58)\n\nusing the definition of the primer vector in Eq. (10.38). Thus for a VSI engine the\noptimal thrust acceleration vector is equal to the primer vector: \n(t) = p(t). Now\nEq. (10.1) r? = g(r) + \n, can be combined with Eq. (10.42) to yield a fourth-order\ndifferential equation in r:\n\nriv ? G?r? + G(g ? 2r?) = 0 (10.59)\n\n\n\n206 Chapter 10. General Theory of Optimal Rocket Trajectories\n\nEvery solution to Eq. (10.57) is an optimal VSI trajectory through the gravity field\ng(r). However, desired boundary conditions, such as specified position and velocity\nvectors at the initial and final times must be satisfied.\n\nWe also note that from Eq. (10.55):\n\n?2H\n?\n2\n\n=\n?\n\n?\n\n(\n?H\n?\n\n)T\n= I3 (10.60)\n\nwhere I3 is the 3\u00d73 identity matrix. Equation (10.58) shows that the (Hessian) matrix\nof second partial derivatives is positive definite, verifying that H is minimized.\n\nBecause the optimal VSI thrust acceleration is continuous, the procedure in\nPrussing and Sandrik [2005] to test whether second-order NC and SC are satisfied\ncan be applied. Equation (10.57) shows that an NC for minimum cost (Hessian\nmatrix positive semidefinite) and part of the SC (Hessian matrix positive definite) are\nsatisfied. The other condition that is both an NC and SC is the Jacobi no-conjugate-\npoint condition discussed in Sect. 6.6. Prussing and Sandrik [2005] provide the details\nof the no-conjugate-point test.\n\nExample 10.2 The Hamiltonian for optimal rocket trajectories.\n\n1. For an optimal CSI trajectory show that the Hamiltonian in Eq. (10.45) is constant\non IT and NT arcs for a static gravitational field. Hint: calculate H?.\n\n2. For an optimal VSI trajectory show that the Hamiltonian in Eq. (10.54) is constant.\n\nSolution:\n\n1. On an IT arc we have p = 1 and on an NT arc ? = 0, so the first term in Eq. (10.45)\nis zero in both cases. Then H? = p?Tv + p?Tv? ? p?Tg ? pTg?. Using p? = Gp, v? = g + \nand g? = Gv (see Exercise 3), H? = pTGv + p?T(g + \n) ? p?Tg ? pTGv = p?T\n. On an\nNT arc \n = 0 and on IT arc p = 1, \n = ?p, and p?Tp = p? = 0.\n\n2. Substituting \n = p, ?r = p?, and ?v = ?p into the expression for H? we have\nH? = pTp? + p?Tv + p?T(g + p) ? p?T(g + p) ? pT(Gv + p?). Using solution (a) and the fact\nthat G is symmetric we find that the Hamiltonian is constant.\n\n10.6. Optimal Trajectories in a Uniform Field\n\nFor a uniform gravitational field, we have g = constant which implies from\nEqs. (10.33) and (10.44) that p? = 0. Thus, the general solution for the primer vector is\n\np = at + b (10.61)\n\nwhere a and b are constant vectors. Equation (10.61) is, obviously, the equation of\na straight line. In the special case where a = 0, the thrust direction never varies\nthroughout the maneuver. In the general case, the thrust direction may vary in a plane,\ndetermined by the vectors a and b, as illustrated in Fig. 10.5. Components of the primer\nvector (in general) are of the form:\n\n\n\n10.6. Optimal Trajectories in a Uniform Field 207\n\n?\n\np?\n\na?t\n\nb?\n\np2\n\np1\n\nFigure 10.5. In a uniform gravity field the primer vector is restricted to a plane which means\nthat the thrust direction may only vary in a plane.\n\np1 = a1t + b1 (10.62a)\n\np2 = a2t + b2 (10.62b)\n\np3 = 0 (10.62c)\n\nwhere we have chosen a convenient set of coordinates so that p is in the xy plane.\nThe angle made by the primer vector (which provides us with the thrust direction)\n\nis given by\n\ntan ? =\np2\np1\n\n=\na2t + b2\na1t + b1\n\n(10.63)\n\nwhich we recognize as the bilinear tangent steering law encountered in Chap. 4. [See\nEq. (4.61)].\n\nThe optimal trajectory in a uniform field can include an IT arc only in special\ncircumstances.\n\nLawden [1963] shows (for CSI) that for an IT arc a = 0 and p = b. Thus the thrust\ndirection is constant throughout the maneuver. Under these conditions the equations of\nmotion can be integrated, leading to highly constrained end conditions which rule out\nmost trajectories, in which case no IT arcs are optimal. On the other hand, if these end\nconditions are satisfied, it is possible to have a number of IT arcs. In the case where the\nend conditions rule out an IT arc, the optimal trajectory will consist of no more than\nthree NT and MT subarcs (as shown by Leitmann [1959]). In Fig. 10.6 we illustrate\npossible behavior of the primer vector. In the figure we note that p is the distance from\nthe origin. In the general case, we can have three phases:\n\n1. The magnitude of the primer vector, p, starts out at some initial value,\n2. p decreases to a minimum (or to zero), then\n3. p increases to the final value.\n\n\n\n208 Chapter 10. General Theory of Optimal Rocket Trajectories\n\na?t\n\np?\n\nb?\n\np2\n\np1\n\nFigure 10.6. The primer vector in a uniform field may decrease in magnitude initially, reach\na minimum, and then increase.\n\ntNT\nMT MT\n\nS(t)\n\nFigure 10.7. At most only three subarcs can exist MT, NT, MT according to the switching\nfunction for the primer vector in a uniform field.\n\nFor cost functional, JCSI, if the initial value of p is greater than unity, the minimum\nless than unity, and the final greater than unity, then from Eq. (10.46) the switching\nfunction will have values of S > 1, S < 1, and S > 1, respectively corresponding to\nEq. (10.47) and Fig. 10.7. We conclude that we can have at most three subarcs: MT,\nNT, MT in that order. We also note that for impulsive thrusts there are at most two\nimpulses. These simple examples demonstrate the power of Lawden\u2019s primer vector\ntheory.\n\n10.7. Summary\n\nFor optimal rocket trajectories in space, we assume that the only forces acting on the\nspacecraft are due to gravity and rocket thrust. The thrusters can be pointed in arbitrary\ndirections and the magnitude of the thrust may be limited. The cost to be minimized,\n\n\n\n10.8. Exercises 209\n\nJ, is the very important one of minimum-propellant consumption (which is equivalent\nto maximizing final mass). For a space mission, every kilogram of propellant saved\nby optimization provides an additional kilogram of payload at the final destination.\n\nFor this problem, Lawden found, using the calculus of variations, that the adjoint\n(costate) vector corresponding to the velocity vector provides the optimal thrust\ndirection. Analysis of this vector, the primer vector, indicates when null thrust (NT),\nmaximum thrust (MT), or intermediate thrust (IT) arcs are optimal for a constant\nspecific impulse (CSI) engine. For a variable specific impulse (VSI) engine the\nmagnitude of the optimal thrust acceleration is equal to the magnitude of the primer\nvector.\n\nIf the thrust magnitude in the CSI case is unbounded, we have the impulsive thrust\ncase and the change in velocity is instantaneous. In reality, impulsive thrust does not\nexist, but the short duration of deep space thrust maneuvers compared with the time\nbetween maneuvers can be modeled as impulsive.\n\nLawden neatly summarizes the necessary conditions for optimal impulsive thrust\ntrajectories in four statements involving the primer vector. These conditions also\nform the basis for primer vector theory, in which the primer vector evaluated on a\nnonoptimal impulsive trajectory can be used to determine an optimal trajectory for the\nsame terminal conditions.\n\nWhen Lawden\u2019s primer vector is applied to the problem of optimal trajectories in\na uniform gravitational field with bounded thrust, we rediscover the bilinear tangent\nsteering law from our launch from flat-Earth problem.\n\n10.8. Exercises\n\n1. Show that for a constant thrust, ?? = 1c?\n2 corresponds to a constant mass flow rate\n\nb. Hint: m(t) = mo ? bt.\n2. Show that the gravity gradient matrix in Eq. (10.33) is symmetric for a conservative\n\ngravitational field. Hint: write gi = ? ?V?ri , where V is a (scalar) gravitational\npotential function, then calculate Gij = ?gi?rj .\n\n3. Assuming a static gravitational field where g(r) is not an explicit function of time,\ndetermine under what circumstances g? ? dgdt is nonzero.\n\n4. Consider the gravity gradient matrix for the case of a central gravitational field:\n\n4a. Determine the gravity gradient matrix G(r) for the general central gravitational\nfield: g(r) = g(r)r. Hint: the answer depends on the variables r, g(r), and\ng?(r) ? dg/dr.\n\n4b. Verify that your answer specializes to the result in Example 10.1 for g(r) =\n? ?r3 .\n\n5. Consider the vector A = p \u00d7 v ? p? \u00d7 r referenced by Marec [1979]:\n5a. Determine whether A is constant on an optimal continuous-thrust trajectory in\n\nthe general central gravitational field of Exercise 4a. Discuss both the CSI and\nVSI cases, including the discontinuous thrust in the CSI case.\n\n5b. Determine whether the vector A is continuous at an optimal impulsive thrust.\n\n\n\n210 Chapter 10. General Theory of Optimal Rocket Trajectories\n\n6. Consider an optimal impulsive trajectory in an inverse-square gravitational field:\n\n6a. Show that the scalar a defined by Lion and Handelsman [1968] is constant on\nan NT arc between impulses, where a = 2p?Tr + pTv ? 3Ht.\n\n6b. Demonstrate that the discontinuity in the variable a at an optimal impulse is\nequal to the magnitude of the velocity change?v.\n\n6c. Using the result of Exercise 6b determine a new quantity a? that is both constant\nbetween impulses and continuous at an optimal impulse. Hint: form a? by\nadding a term to a that depends on the mass.\n\n7. Show that when p = 1, p? = p?Tp, where p? ? dp/dt ?= |p?| in general. Hint:\ndifferentiate p2 = pTp.\n\n8. Consider the optimal VSI trajectory equation:\n\n8a. Derive Eq. (10.59).\n8b. Specialize your result for a uniform gravitational field, where g(r) is a constant\n\nvector.\n8c. Write the general solution r(t) to the equation obtained in Exercise 8b.\n8d. Based on Exercise 8c write an expression for the optimal thrust acceleration\n\n\n(t).\n\n9. Consider the problem of optimal intercept:\n\n9a. Based on the sentence following Eq. (10.46), specialize the form of the primer\nvector in Eq. (10.59) for an optimal intercept.\n\n9b. Qualitatively describe the behavior of the thrust direction.\n9c. Describe the possible subarc sequences involving MT, NT, and IT arcs.\n9d. For impulsive thrusts, what is the maximum number of impulses?\n\n10.9. True or False Quiz for Chaps. 6\u201310\n\nAnswer the following questions in the context of the material presented in\nChaps. 6\u201310.\n\n1. According to the general theory of optimal rocket trajectories (and assuming p ?=\n0) whenever the thruster is operating, the thrust must act in the direction of the\nprimer vector, p.\n\nTrue False\n\n2. In the theory of optimal rocket trajectories, when impulsive thrusts are considered,\nthen the switching function, S = p ? 1, is never greater than zero.\n\nTrue False\n\n3. Derivation of the rules for the primer vector is based mainly on the Minimum\nPrinciple and the Weierstrass-Erdmann corner conditions.\n\nTrue False\n\n\n\n10.9. True or False Quiz for Chaps. 6\u201310 211\n\n4. In the derivation of the Weierstrass-Erdmann corner conditions, it is shown that\n?(t) and H(t) are continuous at corners.\n\nTrue False\n\n5. The Generalized Legendre-Clebsch condition was shown to be directly derivable\nfrom the Minimum Principle.\n\nTrue False\n\n6. If Tmax ? ? then all optimal maneuvers must be impulsive.\nTrue False\n\n7. In primer theory we always have p = v and p? = g.\n\nTrue False\n\n8. No modifications of the Minimum Principle are required for the State Variable\nInequality Constraint (SVIC) Problem.\n\nTrue False\n\n9. If x?(t) is a weak extremal, then it may be possible to find a control which provides\na lower cost.\n\nTrue False\n\n10. For a uniform gravity field, if the end conditions rule out an IT arc, then the optimal\ntrajectory will consist of not more than three NT and MT subarcs.\n\nTrue False\n\n11. The Minimum Principle always tells us everything we need to know to find\noptimal trajectories.\n\nTrue False\n\n12. The main difference between the Pontryagin Minimum Principle and the Weier-\nstrass condition is the class of functions of the admissible controls.\n\nTrue False\n\n13. In general, the Legendre-Clebsch condition applies to a broader class of controls\nthan does the Pontryagin Minimum Principle.\n\nTrue False\n\n14. If x?(t) is a weak extremal, then it is also a strong extremal.\n\nTrue False\n\n15. On a corner x(t?c ) ?= x(t+c ).\nTrue False\n\nSolution: 1T, 2T, 3T, 4T, 5F, 6F, 7F, 8F, 9T, 10T, 11F, 12T, 13F, 14F, 15F.\n\n\n\n212 Chapter 10. General Theory of Optimal Rocket Trajectories\n\nReferences\n\nJ.V. Breakwell, The optimization of trajectories. J. Soc. Ind. Appl. Math. 7(2), 215\u2013247 (1959)\nD.F. Lawden, Optimal Trajectories for Space Navigation (Butterworths, London, 1963)\nG. Leitmann, On a class of variational problems in rocket flight. J. Aerosp. Sci. 26(9), 586\u2013591 (1959)\nP.M. Lion, M. Handelsman, Primer vector on fixed-time impulsive trajectories. AIAA J. 6(1),\n\n127\u2013132 (1968)\nJ.P. Marec, Optimal Space Trajectories (Elsevier Scientific, New York, 1979)\nJ.E. Prussing, Optimal impulsive linear systems: sufficient conditions and maximum number of\n\nimpulses. J. Astronaut. Sci. 43(2), 195\u2013206 (1995)\nJ.E. Prussing, Chapter 2: primer vector theory and applications, in Spacecraft Trajectory Optimiza-\n\ntion, ed. by B.A. Conway (Cambridge University Press, New York, 2010)\nJ.E. Prussing, B.A. Conway, Orbital Mechanics, 2nd edn. (Oxford University Press, New York, 2013)\nJ.E. Prussing, S.L. Sandrik, Second-order necessary conditions and sufficient conditions applied to\n\ncontinuous-thrust trajectories. J. Guid. Control Dyn. (Engineering Note) 28(4), 812\u2013816 (2005)\n\n\n\nAppendices\n\n\n\nA. Time-Optimal Lunar Ascent 215\n\nA. Time-Optimal Lunar Ascent\n\nContributor: George Pollock\n\nThis appendix includes a brief introduction to MATLAB\u2019s two-point boundary-value\nsolver and its application to the lunar takeoff problem. For the equations of motion\nand the derivation of the associated TPBVP, see Example 4.5 and Sect. 7.3.2.\n\nA.1. MATLAB\u2019s Two-Point Boundary-Value Solver\n\nMATLAB now includes a two-point boundary-value problem (TPBVP) solver, known\nas bvp4c, in its regular package (not in a separate toolbox). This feature allows the user\nto quickly setup and numerically solve TPBVPs. Here we introduce the basic use of\nbvp4c (for more detailed information, refer to the MATLAB help file for bvp4c).\n\nThe function bvp4c is a finite difference code that implements the three-stage\nLobatto IIIa formula. This method uses a collocation formula and the collocation\npolynomial provides a C1-continuous solution that is fourth-order accurate uniformly\nin [to, tf]. Mesh selection and error control are based on the residual of the continuous\nsolution.\n\nThe function integrates a system of ordinary differential equations of the form\n\ny? = f (t, y) (A1)\n\non the known interval [to, tf] subject to the two-point boundary value conditions,\n\n\t[y(to), y(tf)] = 0 (A2)\n\nwhere in the context of trajectory optimization y is a vector that includes the state,\ncostate (adjoint), and control variables, i.e.,\n\ny(t) =\n\n?\n???\n\nx(t)\n?(t)\nu(t)\n\n?\n??? (A3)\n\nThe function bvp4c can also handle unknown parameters in the differential equations.\nFor example, suppose that p is a vector of unknown parameters. The problem becomes\n\ny? = f(t, y, p) (A4a)\n\n\t[y(to), y(tf), p] = 0 (A4b)\n\nIn trajectory optimization, a classic example of having an unknown parameter is when\nthe final time is unknown. We will use this feature of bvp4c in solving the optimal\nlaunch from the flat-Moon problem.\n\n\n\n216 A. Time-Optimal Lunar Ascent\n\nA.2. Solution Method\n\nFollow the example code given to use MATLAB\u2019s boundary-value problem solver,\nbvp4c, to numerically solve the flat-Moon problem. Users can write their own versions\nof the script file (OptimalAscent.m) and the two function files (ascent odes tf.m and\nascent bcs tf.m) that follow. For this problem, use the following initial guesses:\n\n?\n????????\n\nxo\nyo\nvyo\n??2\n\n??4\n\n?\n????????\n\n= 0 (A5)\n\nNote that we must provide an initial guess for the final time, even though it is a free\nvariable (recall that we seek to minimize tf).\n\nIn many boundary-value problems, finding a suitable initial guess is a major\ndifficulty. No general procedure exists to develop initial guesses, and in many\ncases the engineer must attain some insight into the problem through numerical\nexperimentation. Approximate solutions or expansions may also provide a suitable\nstarting point for the numerical TPBVP solver.\n\nTo solve this problem (with a free final time) with bvp4c we must introduce\nthe final time as an unknown parameter and remove explicit dependencies on the\nfinal time from the state and costate equations. We will accomplish this goal by\nnondimensionalizing the time according to the relation\n\n? =\nt\ntf\n\n(A6a)\n\n? d? = dt\ntf\n\n(A6b)\n\nand then\n\nd\nd?\n\n= tf\nd\ndt\n\n(A7a)\n\nwith ? ? [0, 1]. This parameterization of the time allows bvp4c to solve the problem\nwith assumed initial and final nondimensional times (?o = 0 and ?f = 1) and to treat the\nactual final time, tf, as an unknown parameter to be found in the optimization routine.\nSee the following code and plots.\n\n\n\nA. Time-Optimal Lunar Ascent 217\n\nA.3. MATLAB Code\n% Optimal Ascent Problem with MATLAB\u2019s bvp4c\n\n%\n\n% by Jose J. Guzman and George E. Pollock\n\n%\n\n% This script uses MATLAB\u2019s bvp4c to solve the problem of finding the\n\n% optimal ascent trajectory for launch from a flat Moon to a 100 nautical\n\n% mile circular orbit. In addition to this script, we use two functions:\n\n% one to provide the differential equations and another that gives the\n\n% boundary conditions:\n\n%\n\n% This file: OptimalAscent.m\n\n% State and Costate Equations: ascent_odes_tf.m\n\n% Boundary Conditions: ascent_bcs_tf.m\n\n%\n\nclose all; clear all; clc;\n\n% Define parameters of the problem\n\nglobal g_accel Thrust2Weight % pass these parameters to the DE function\n\nh = 185.2e3; % meters, final altitude (100 nmi circular orbit)\n\nVc = 1.627e3; % m/s, Circular speed at 100 nmi\n\ng_accel = 1.62; % m/s\u02c62, gravitational acceleration of Moon\n\nThrust2Weight = 3; % Thrust to Weight ratio for Ascent Vehicle, in lunar G\u2019s\n\nrad2deg = 180/pi;\n\n%----------------------------------------------------------------------------\n\n%% Boundary Conditions\n\n%----------------------------------------------------------------------------\n\nglobal x0 y0 Vx0 Vy0 yf Vxf Vyf % pass these BCs to the BC function\n\n% Initial conditions\n\n% Launch from zero altitude with zero initial velocity\n\nx0 = 0; % meters, initial x-position\n\ny0 = 0; % meters, initial y-position\n\nVx0 = 0; % m/s, initial downrange velocity\n\nVy0 = 0; % m/s, initial vertical velocity\n\n% Final conditions\n\nyf = h; % meters, final altitude\n\nVxf = Vc; % m/s, final downrange velocity\n\nVyf = 0; % m/s, final vertical velocity\n\n%----------------------------------------------------------------------------\n\n%% Initial Guesses\n\n%----------------------------------------------------------------------------\n\n% initial time\n\nt0 = 0;\n\n% list initial conditions in yinit, use zero if unknown\n\nyinit = [x0 y0 Vx0 Vy0 0 0]; % guess for initial state and costate variables\n\ntf_guess = 700; % sec, initial guess for final time\n\n\n\n218 A. Time-Optimal Lunar Ascent\n\n% Because the final time is free, we must parameterize the problem by\n\n% the unknown final time, tf. Create a nondimensional time vector,\n\n% tau, with Nt linearly spaced elements. (tau = time/tf) We will pass the\n\n% unknown final time to bvp4c as an unknown parameter and the code will\n\n% attempt to solve for the actual final time as it solves our TPBVP.\n\nNt = 41;\n\ntau = linspace(0,1,Nt)\u2019; % nondimensional time vector\n\n% Create an initial guess of the solution using the MATLAB function\n\n% bvpinit, which requires as inputs the (nondimensional) time vector,\n\n% initial states (or guesses, as applicable), and the guess for the final\n\n% time. The initial guess of the solution is stored in the structure\n\n% solinit.\n\nsolinit = bvpinit(tau,yinit,tf_guess);\n\n%----------------------------------------------------------------------------\n\n%% Solution\n\n%----------------------------------------------------------------------------\n\n% Call bvp4c to solve the TPBVP. Point the solver to the functions\n\n% containing the differential equations and the boundary conditions and\n\n% provide it with the initial guess of the solution.\n\nsol = bvp4c(@ascent_odes_tf, @ascent_bcs_tf, solinit);\n\n% Extract the final time from the solution:\n\ntf = sol.parameters(1);\n\n% Evaluate the solution at all times in the nondimensional time vector tau\n\n% and store the state variables in the matrix Z.\n\nZ = deval(sol,tau);\n\n% Convert back to dimensional time for plotting\n\ntime = t0 + tau.*(tf-t0);\n\n% Extract the solution for each state variable from the matrix Z:\n\nx_sol = Z(1,:);\n\ny_sol = Z(2,:);\n\nvx_sol = Z(3,:);\n\nvy_sol = Z(4,:);\n\nlambda2_bar_sol = Z(5,:);\n\nlambda4_bar_sol = Z(6,:);\n\n%% Plots\n\nfigure;\n\nsubplot(3,2,1);plot(time,x_sol/1000);\n\nylabel(\u2019x, km\u2019,\u2019fontsize\u2019,14);\n\nxlabel(\u2019Time, sec\u2019,\u2019fontsize\u2019,14);\n\nhold on; grid on;\n\ntitle(\u2019Optimal Ascent from Flat Moon\u2019)\n\nsubplot(3,2,2);plot(time,y_sol/1000);\n\nylabel(\u2019y, km\u2019,\u2019fontsize\u2019,14);\n\nxlabel(\u2019Time, sec\u2019,\u2019fontsize\u2019,14); hold on; grid on;\n\n\n\nA. Time-Optimal Lunar Ascent 219\n\nsubplot(3,2,3);plot(time,vx_sol/1000);\n\nylabel(\u2019V_x, km/s\u2019,\u2019fontsize\u2019,14);\n\nxlabel(\u2019Time, sec\u2019,\u2019fontsize\u2019,14);\n\nhold on; grid on;\n\nsubplot(3,2,4);plot(time,vy_sol/1000);\n\nylabel(\u2019V_y, km/s\u2019,\u2019fontsize\u2019,14);\n\nxlabel(\u2019Time, sec\u2019,\u2019fontsize\u2019,14);\n\nhold on; grid on;\n\nsubplot(3,2,5);plot(time,rad2deg*atan(lambda4_bar_sol));\n\nylabel(\u2019\\alpha, deg\u2019,\u2019fontsize\u2019,14); xlabel(\u2019Time,\n\nsec\u2019,\u2019fontsize\u2019,14); grid on; hold on;\n\nsubplot(3,2,6);plot(time,lambda4_bar_sol);\n\nylabel(\u2019\\lambda_4\u2019,\u2019fontsize\u2019,14);\n\nxlabel(\u2019Time, sec\u2019,\u2019fontsize\u2019,14);\n\ngrid on; hold on;\n\n% Plot of ascent trajectory in y versus x coordinates [km]\n\nfigure;\n\nplot(x_sol/1000, y_sol/1000); grid on; axis equal\n\nxlabel(\u2019Downrange Position, x, km\u2019,\u2019fontsize\u2019,14)\n\nylabel(\u2019Altitude, y, km\u2019,\u2019fontsize\u2019,14)\n\nThe boundary conditions are given in the function file, ascent bcs tf.m:.\n\nfunction PSI = ascent_bcs_tf(Y0,Yf,tf)\n\n%\n\n% Boundary Condition Function for the Flat-Moon Optimal Ascent Problem\n\n%\n\n%\n\n% pass in values of boundary conditions as global variables\n\nglobal x0 y0 Vx0 Vy0 yf Vxf Vyf\n\n% Create a column vector with the 7 boundary conditions on the state &\n\n% costate variables (the 8th boundary condition, t0 = 0, is not used).\n\nPSI = [ Y0(1) - x0 % Initial Condition\n\nY0(2) - y0 % Initial Condition\n\nY0(3) - Vx0 % Initial Condition\n\nY0(4) - Vy0 % Initial Condition\n\nYf(2) - yf % Final Condition\n\nYf(3) - Vxf % Final Condition\n\nYf(4) - Vyf % Final Condition\n\n];\n\nreturn\n\n\n\n220 A. Time-Optimal Lunar Ascent\n\nThe state and costate differential equations are in the function file,\nascent odes tf.m:\nfunction dX_dtau = ascent_odes_tf(tau,X,tf)\n\n%\n\n% State and Costate Differential Equation Function for the Flat-Moon\n\n% Optimal Ascent Problem\n\n%\n\n%\n\n% The independent variable here is the nondimensional time, tau, the state\n\n% vector is X, and the final time, tf, is an unknown parameter that must\n\n% also be passed to the DE function.\n\n% Note that the state vector X has components\n\n% X(1) = x, horizontal component of position\n\n% X(2) = y, vertical component of position\n\n% X(3) = Vx, horizontal component of velocity\n\n% X(4) = Vy, vertical component of velocity\n\n% X(5) = lambda2_bar\n\n% X(6) = lambda4_bar\n\nglobal g_accel Thrust2Weight\n\n% Acceleration (F/m) of the Ascent Vehicle, m/s\u02c62\n\nAcc = Thrust2Weight*g_accel;\n\n% State and Costate differential equations in terms of d/dt:\n\nxdot = X(3);\n\nydot = X(4);\n\nVxdot = Acc*(1/sqrt(1+X(6)\u02c62));\n\nVydot = Acc*(X(6)/sqrt(1+X(6)\u02c62)) - g_accel;\n\nlambda2_bar_dot = 0;\n\nlambda4_bar_dot = -X(5);\n\n% Nondimensionalize time (with tau = t/tf and d/dtau = tf*d/dt). We must\n\n% multiply each differential equation by tf to convert our derivatives from\n\n% d/dt to d/dtau.\n\ndX_dtau = tf*[xdot; ydot; Vxdot; Vydot; lambda2_bar_dot; lambda4_bar_dot];\n\nreturn\n\n\n\nA. Time-Optimal Lunar Ascent 221\n\n0 100 200 300 400 500\n\nTime [sec]\n\n?60\n\n?40\n\n?20\n\n0\n\n20\n\n40\n\n60\n\n80\n\n? \n [d\n\neg\n]\n\nSteering angle.\n\n0 50 100 150 200 250 300 350\n\nx [km]\nAltitude vs range.\n\n0\n\n50\n\n100\n\n150\n\n200\n\n250\n\n300\n\n350\n\nx \n[k\n\nm\n]\n\nTime [sec]\nDownrange vs time.\n\n0 100 200 300 400 500 0 100 200 300 400 500\n\nTime [sec]\nAltitude vs time.\n\n0 100 200 300 400 500\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\nTime [sec]\nDownrange velocity vs time.\n\n0 100 200 300 400 500\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n200\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n200\n\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\ny \n[k\n\nm\n]\n\ny \n[k\n\nm\n]\n\nV\ny \n\n[k\nm\n\n/s\n]\n\nV\nx \n\n[k\nm\n\n/s\n]\n\nTime [sec]\nVertical velocity vs time.\n\na b\n\nc d\n\ne f\n\nFigure A1. Plots for the time-optimal launch from flat Moon. Assumptions include constant\nthrust, constant mass, no drag, and uniform flat-Moon gravity\n\n\n\n222 B. Time-Optimal Launch of a Titan II\n\nB. Time-Optimal Launch of a Titan II\n\nContributors: Peter Edelman, Rob Falck, and George Pollock\n\nIn this problem we consider the case of launching a Titan II, subject to atmospheric\ndrag, into a circular LEO (Low Earth Orbit) in minimum time. We include the effects\nof a linearly time-varying mass with constant thrust and an exponential atmospheric\ndensity that varies with height. In this analysis, we assume the following numerical\nvalues:\n\nThrust: F = 2.10 \u00d7 106 N\nInitial Mass: mo = 1.1702 \u00d7 105 kg\n\nCross Sectional Area: A = 7.069 m2\n\nDrag Coefficient: CD = 0.5\n\nReference Atmospheric Density: ?ref = 1.225 kg/m3\n\nScale Height: hscale = 8.44 \u00d7 103 m\nStandard Free Fall Acceleration: g = 9.80665 m/s2\n\nMass Flow Rate: m? = ?807.5 kg/s\n\nFor the final circular LEO we use the orbital altitude:\n\nFinal Altitude : yf = 1.80 \u00d7 105 m\nFinal Velocity : Vc = 7.796 \u00d7 103 m/s\n\nNote that we are only considering the first stage of the Titan II, which is capable of\ngetting into orbit (i.e. we are not including the second stage in this problem.) In the\nreal case the initial mass of the first stage is 117,000 kg (fully fueled), the final mass\nis 4,760 kg (empty), and the burn time is 139 s. (Note that, because of our simplified\nmodel, we do not expect to obtain precisely these values in our TPBVP solver.)\n\nFor the equations of motion and the derivation of the associated TPBVP, refer to\nSect. 7.3.3. We repeat some of the text of Sect. 7.3.3 for the reader\u2019s convenience.\n\nB.1. Scaling the TPBVP\n\nWe scale the state variables to remain close to unity to aid in computational\nconvergence. Using the final orbit altitude and velocity as reference values, and\nnormalizing the time by the (unknown) final time, we define new state variables:\n\nx? =\nx\nh\n\n, y? =\ny\nh\n\n, V?x =\nVx\nh\n\n, V?y =\nVy\nh\n\n(B1)\n\n\n\nB. Time-Optimal Launch of a Titan II 223\n\nApplying the chain rule to change variables results in the following nondimensional\nEOMs:\nFor x?:\n\ndx?\nd?\n\n=\nd(x/h)\n\ndt\ndt\nd?\n\n=\ndx\ndt\n\ntf\nh\n\n= Vx\ntf\nh\n\n(B2)\n\nor,\n\ndx?\nd?\n\n= V?x\nVctf\n\nh\n(B3)\n\nFor y?:\n\ndy?\nd?\n\n=\nd(y/h)\n\ndt\ndt\nd?\n\n=\ndy\ndt\n\ntf\nh\n\n= Vy\ntf\nh\n\n(B4)\n\nor,\n\ndy?\nd?\n\n= V?x\nVctf\n\nh\n(B5)\n\nFor V?x\n\ndV?x\nd?\n\n=\nd(Vx/Vc)\n\ndt\ndt\nd?\n\n=\ndVx\ndt\n\ntf\nVc\n\n=\n[\n\nF cos ? ? K1 exp\n( ?y\n\nhscale\n\n)\nVx\n\n?\nV2x + V2y\n\n]\ntf\n\nVc(mo ? |m?|t) (B6)\n\nor,\n\ndV?x\nd?\n\n=\n[\n\nF\nVc\n\ncos ? ? K1 exp\n(?y?h\n\nhscale\n\n)\nV?x\n\n?\nV?2x + V?2y Vc\n\n]\ntf\n\nmo ? |m?|? tf (B7)\n\nFor V?y\n\ndV?y\nd?\n\n=\nd(Vy/Vc)\n\ndt\ndt\nd?\n\n=\ndVy\ndt\n\ntf\nVc\n\n=\n[\n\nF sin ? ? K1 exp\n( ?y\n\nhscale\n\n)\nVy\n\n?\nV2x + V2y\n\n]\ntf\n\nVc(mo ? |m?|t) ?\ngtf\nVc\n\n(B8)\n\nor,\n\ndV?y\nd?\n\n=\n[\n\nF\nVc\n\nsin ? ? K1 exp\n(?y?h\n\nhscale\n\n)\nV?y\n\n?\nV?2x + V?2y Vc\n\n]\ntf\n\nmo ? |m?|? tf ?\ngtf\nVc\n\n(B9)\n\n\n\n224 B. Time-Optimal Launch of a Titan II\n\nThe Hamiltonian for our problem is:\n\nH = ?1(V?x?) + ?2(V?y?) + ?3\n\n{[\nF\nVc\n\ncos ? ? K1 exp (?y??) V?x\n?\n\nV?2x + V?2y Vc\n] tf\n\nmo ? |m?|? tf\n\n}\n\n+?4\n\n{[\nF\nVc\n\nsin ? ? K1 exp (?y??) V?y\n?\n\nV?2x + V?2y Vc\n] tf\n\nmo ? |m?|? tf ? g?\n}\n\n(B10)\n\nwhere K1 is defined in Sect. 7.3.3 and where the following substitutions have been\nmade for certain constants:\n\n? =\nVctf\n\nh\n(B11a)\n\n? =\nh\n\nhscale\n(B11b)\n\ng? = g\ntf\nVc\n\n(B11c)\n\nApplying the Euler-Lagrange Equations to Eq. (B10) exactly as performed in\nSect. 7.3.3 gives:\n\nd?1\nd?\n\n= ??H\n? x?\n\n= 0 (B12a)\n\nd?2\nd?\n\n= ??H\n? y?\n\n= ? (?3V?x + ?4V?y\n)\n\nK1? exp (?y??)V?c\n?\n\nV?2x + V?2y Vc\ntf\n\nmo ? |m?|? tf\n(B12b)\n\nd?3\nd?\n\n= ? ?H\n?V?x\n\n= ??1? + K1 exp (?y??)Vc\n\n?\n???3(2V?\n\n2\nx + V?2x) + ?4V?xV?y)?\n\nV?2x + V?2y\n\n?\n?? tfmo ? |m?|? tf\n\n(B12c)\n\nd?4\nd?\n\n= ? ?H\n?V?y\n\n= ??2? + K1 exp (?y??)Vc\n\n?\n??\n?3V?xV?y + ?4(V?2x + 2V?2y)?\n\nV?2x + V?2y\n\n?\n?? tfmo ? |m?|? tf\n\n(B12d)\n\nwith the same control law as in Sect. 7.3.3 derived from the Minimum Principle:\n\ncos ? =\n??3?\n?23 + ?\n\n2\n4\n\n(B13a)\n\n\n\nB. Time-Optimal Launch of a Titan II 225\n\nsin ? =\n??4?\n?23 + ?\n\n2\n4\n\n(B13b)\n\nAll boundary conditions are the same as presented in Sect. 7.3.3, we only need to scale\nthem to the appropriate value. Upon doing so, we obtain:\n\n?o = 0, x?(0) = y?(0) = 0, V?x(0) = V?y(0) = 0 (B14a)\n\ny?(?f) = 1, V?x(?f) = 1, V?y(?f) = 0 H(?f) = ?1, ?1(?f) = 0 (B14b)\n\nWe immediately see that the last boundary condition in Eq. (B14b) along with\nEq. (B12a) implies that ?1 = 0 for the entire trajectory, meaning we can omit ?1\nfrom the problem entirely. After substituting Eqs. (B13a) and (B13b) into Eqs. (B7)\nand (B9) respectively and reiterating all pertinent differential equations and boundary\nconditions gives the newly scaled well-defined TPBVP:\n\ndx?\nd?\n\n= V?x? (B15a)\n\ndy?\nd?\n\n= V?y? (B15b)\n\ndV?x\nd?\n\n=\n\n?\n?? FVc\n\n?\n?? ??3?\n\n?23 + ?\n2\n4\n\n?\n?? ? K1 exp (?y??) V?x\n\n?\nV?2x + V?2y Vc\n\n?\n?? tfmo ? |m?|? tf (B15c)\n\ndV?y\nd?\n\n=\n\n?\n?? FVc\n\n?\n?? ??4?\n\n?23 + ?\n2\n4\n\n?\n?? ? K1 exp (?y??) V?y\n\n?\nV?2x + V?2y Vc\n\n?\n?? tfmo ? |m?|? tf ? g?\n\n(B15d)\n\nd?2\nd?\n\n= ? (?3V?x + ?4V?y\n)\n\nK1? exp (?y??)\n?\n\nV?2x + V?2y Vc\ntf\n\nmo ? |m?|? tf (B15e)\n\nd?3\nd?\n\n= K1 exp (?y??)Vc\n\n?\n??\n?3(2V?2x + V?2y) + ?4V?xV?y)?\n\nV?2x + V?2y\n\n?\n?? tfmo ? |m?|? tf (B15f)\n\nd?4\nd?\n\n= ??2? + K1 exp (?y??)Vc\n\n?\n??\n?3V?xV?y + ?4(V?2x + 2V?2y)?\n\nV?2x + V?2y\n\n?\n?? tfmo ? |m?|? tf (B15g)\n\nwith boundary conditions:\n\n?o = 0, x?(0) = y?(0) = 0, V?x(0) = V?y(0) = 0 (B16a)\n\ny?(?f) = 1, V?x(?f) = 1, V?y(?f) = 0 H(?f) = ?1 (B16b)\n\n\n\n226 B. Time-Optimal Launch of a Titan II\n\nB.2. Solution Method\n\nFirst we solve the optimal ascent problem using no drag and constant mass. The\nconstant mass used is the average between the wet and dry mass of the Titan II rocket\nand provides us with a good initial guess for when we add time-varying mass and drag.\nNext the time-varying mass case is solved using the constant mass case as the initial\nguess, however since the acceleration will be higher near the end of the trajectory, the\ntime to orbit will be shorter. Thus we also subtract some time from the guess for the\nfinal time achieved, tf, obtained from the no drag and constant mass solution, otherwise\nthe solution will not converge. Lastly, the effects of drag are added and the TPBVP is\nsolved, using the varying mass, no drag solution as the initial guess.\n\nB.3. Results\n\nFor a discussion of the results, see Sect. 7.3.3 (Fig. B1).\n\n\n\nB. Time-Optimal Launch of a Titan II 227\n\n0 50 100 150 200 250\n\nTime [sec]\n\n? \n[d\n\neg\n]\n\nSteering angle.\n\n0 20 40 60 80 100 120\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\nx [km]\n\ny \n[k\n\nm\n]\n\nAltitude vs range.\n\nx \n[k\n\nm\n]\n\nDownrange vs time.\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\n160\n\n180\n\n0 50 100 150 200 250\n\nTime [sec]\n\n0 50 100 150 200 250\n\nTime [sec]\n\ny \n[k\n\nm\n]\n\nAltitude vs time.\n\n?50\n\n0\n\n50\n\n100\n\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nV\nx \n\n[k\nm\n\n/s\n]\n\nV\ny \n\n[k\nm\n\n/s\n]\n\n0 50 100 150 200 250\nTime [sec]\n\nDownrange velocity vs time.\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\n0 50 100 150 200 250\nTime [sec]\n\nVertical velocity vs time.\n\na b\n\nc d\n\ne f\n\nFigure B1. Plots for the time-optimal launch of a Titan II rocket into a 180-km circular\norbit. Assumptions include constant thrust, time-varying mass, drag from an\nexponential atmospheric model, and uniform flat-Earth gravity\n\n\n\n228 B. Time-Optimal Launch of a Titan II\n\nB.4. MATLAB Code\n% Optimal Ascent Problem with MATLAB\u2019s bvp4c\n%\n% by Jose J. Guzman, George E. Pollock and Peter J. Edelman\n%\n% This script uses MATLAB\u2019s bvp4c to solve the problem of finding the\n% optimal ascent trajectory for launch from a flat Earth to a 180 kilometer\n% circular orbit with the inclusion of the effects from atmospheric drag\n% and linearly time-varying mass.\n% In addition to this script, we use two functions:\n% one to provide the differential equations and another that gives the\n% boundary conditions:\n%\n% This file: OptimalAscent.m\n% State and Costate Equations: ascent_odes_tf.m\n% Boundary Conditions: ascent_bcs_tf.m\n%\n% Clear figure, command and workspace histories\nclose all; clear all; clc;\n\n% Define parameters of the problem\n% pass these parameters to the DE and BC functions\nglobal g_accel Vc h eta beta f m0 mdot\nh = 180000; % meters, final altitude (180 km circular orbit)\nVc = sqrt(3.9860044e5/(6378.14+h/1000))*1000; % m/s, Circular speed at 180 km\ng_accel = 9.80665; % m/s\u02c62, gravitational acceleration of Earth\nf = 2.1e6; % N, thrust of the first stage of Titan II Rocket\nh_scale = 8440; % m, atmospheric scale-height\nbeta = h/h_scale; %[Nondim], constant used to reduce EOM equations\nrhoref = 1.225; % kg/m\u02c63, reference density\nA = 7.069; % m\u02c62, aerodynamic reference area (cross-sectional area)\n\n%---------------------------------------------------------------------------\n%% Boundary Conditions\n%---------------------------------------------------------------------------\n% pass these BCs to the BC function\nglobal xbar0 ybar0 Vxbar0 Vybar0 ybarf Vxbarf Vybarf\n\n% Initial conditions\n% Launch from zero altitude with zero initial velocity\n% All Boundary Conditions are nondimensional\nxbar0 = 0; % initial x-position\nybar0 = 0; % initial y-position\nVxbar0 = 0; % initial downrange velocity\nVybar0 = 0; % initial vertical velocity\n\n% Final conditions\nybarf = h/h; % final altitude\nVxbarf = Vc/Vc; % final downrange velocity\nVybarf = 0; % final vertical velocity\n\n%% Parameters for the NO DRAG and CONSTANT MASS case\n% Solve TPBVP without drag (C_D = 0) and constant mass (mdot = 0)\nm0 = 60880; % kg, average mass of a Titan II Rocket\nCD = 0; % Drag coefficient set to zero for no drag cases\nmdot = 0; % kg/s, mass flow rate for the constant mass case\n% eta - a constant composed of the reference density, coefficient\n\n\n\nB. Time-Optimal Launch of a Titan II 229\n\n% of drag and the aerodynamic reference area. It is only used to simplify\n% the drag expressions in the EOMs.\neta = rhoref*CD*A/2;\n\n%---------------------------------------------------------------------------\n%% Initial Guesses\n%---------------------------------------------------------------------------\n\n% initial time\nt0 = 0;\n% list initial conditions in yinit, use zero if unknown\n% guess for initial state and costate variables\nyinit = [xbar0 ybar0 Vxbar0 Vybar0 0 -1 0];\ntf_guess = 700; % sec, initial guess for final time\n% Because the final time is free, we must parameterize the problem by\n% the unknown final time, tf. Create a nondimensional time vector,\n% tau, with Nt linearly spaced elements. (tau = time/tf) We will pass the\n% unknown final time to bvp4c as an unknown parameter and the code will\n% attempt to solve for the actual final time as it solves our TPBVP.\n% Nt is the number of points that the TPBVP will be discretized into. The\n% larger Nt is, the more accurate your solution. However be aware that\n% if Nt is too large, the solver may not be able to compute a solution\n% using its algorithm.\nNt = 80;\ntau = linspace(0,1,Nt)\u2019; % nondimensional time vector\n% Create an initial guess of the solution using the MATLAB function\n% bvpinit, which requires as inputs the (nondimensional) time vector,\n% initial states (or guesses, as applicable), and the guess for the final\n% time. The initial guess of the solution is stored in the structure\n% solinit.\nsolinit = bvpinit(tau,yinit,tf_guess);\n\n%---------------------------------------------------------------------------\n%% Solution for the NO DRAG and CONSTANT MASS case\n%---------------------------------------------------------------------------\n\n% Call bvp4c to solve the TPBVP. Point the solver to the functions\n% containing the differential equations and the boundary conditions and\n% provide it with the initial guess of the solution.\nsol = bvp4c(@ascent_odes_tf, @ascent_bcs_tf, solinit);\n\n% Extract the final time from the solution:\ntf = sol.parameters(1);\n\n% Evaluate the solution at all times in the nondimensional time vector tau\n% and store the state variables in the matrix Z.\nZ = deval(sol,tau);\n\n% Convert back to dimensional time for plotting\ntime = t0 + tau.*(tf-t0);\n\n% Extract the solution for each state variable from the matrix Z and\n% convert them back into dimensional units by multiplying each by their\n% respective scaling constants.\nx_sol = Z(1,:)*h/1000;\ny_sol = Z(2,:)*h/1000;\nvx_sol = Z(3,:)*Vc/1000;\n\n\n\n230 B. Time-Optimal Launch of a Titan II\n\nvy_sol = Z(4,:)*Vc/1000;\nlambda2_bar_sol = Z(5,:);\nlambda3_bar_sol = Z(6,:);\nlambda4_bar_sol = Z(7,:);\n\n%% Parameters for VARYING MASS and NO DRAG case\nm0 = 117020; % Initial mass of Titan II rocket (kg)\nmdot = (117020-4760)/139; % Mass flow rate (kg/s)\ndelta_tf = 115; % Amount subtracted from final time of constant mass\n\n% case\n\n%---------------------------------------------------------------------------\n%% Solution for the VARYING MASS and NO DRAG case\n%---------------------------------------------------------------------------\n\n% Copy initial guess for the drag solution into a new structure named\n% solinit_mass\nsolinit_mass = solinit;\n% Save the time histories of the 7 state and costate variables from the NO\n% DRAG, CONSTANT MASS solution in the structure of the initial guess for\n% the VARYING MASS, NO DRAG case\nsolinit_mass.y = Z;\n% Save the final time of the NO DRAG, CONSTANT MASS solution and use it as\n% the guess for the final time for the VARYING MASS, NO DRAG case. Also\n% subtract delta_tf from this guess as described before\nsolinit_mass.parameters(1) = tf-delta_tf;\n% Run bvp4c for the VARYING MASS, NO DRAG\nsol_mass = bvp4c(@ascent_odes_tf,@ascent_bcs_tf,solinit_mass);\n% Evaluate the solution at all times in the nondimensional time vector tau\n% and store the state variables in the matrix Z_mass.\nZ_mass = deval(sol_mass,tau);\n% Extract the final time from the solution with VARYING MASS, NO DRAG:\ntf_mass = sol_mass.parameters(1);\n% Convert back to dimensional time for plotting\ntime_mass = t0+tau*(tf_mass-t0);\n% Extract the solution for each state variable from the matrix Z_mass and\n% convert them back into dimensional units by multiplying each by their\n% respective scaling constants.\nx_sol_mass = Z_mass(1,:)*h/1000;\ny_sol_mass = Z_mass(2,:)*h/1000;\nvx_sol_mass = Z_mass(3,:)*Vc/1000;\nvy_sol_mass = Z_mass(4,:)*Vc/1000;\nlambda2_bar_sol_mass = Z_mass(5,:);\nlambda3_bar_sol_mass = Z_mass(6,:);\nlambda4_bar_sol_mass = Z_mass(7,:);\n\n%% Parameters for the VARYING MASS AND DRAG case\nCD = .5; % Drag coefficient\neta = rhoref*CD*A/2; % Update eta, since CD is now nonzero\n\n%---------------------------------------------------------------------------\n%% Solution for the VARYING MASS AND DRAG case\n%---------------------------------------------------------------------------\n\n% Copy initial guess for the VARYING MASS AND DRAG solution into a new\n% structure named solinit_mass_drag\nsolinit_mass_drag = solinit_mass;\n\n\n\nB. Time-Optimal Launch of a Titan II 231\n\n% Save the time histories of the 7 state and costate variables from the\n% VARYING MASS, NO DRAG solution in the structure of the initial guess for\n% the VARYING MASS AND DRAG case\nsolinit_mass_drag.y = Z_mass;\n% Save the final time of the VARYING MASS, NO DRAG solution and use it as\n% the guess for the final time for the VARYING MASS AND DRAG case\nsolinit_mass_drag.parameters(1) = tf_mass;\n% Run bvp4c for the drag case\nsol_mass_drag = bvp4c(@ascent_odes_tf,@ascent_bcs_tf,solinit_mass_drag);\n% Evaluate the solution at all times in the nondimensional time vector tau\n% and store the state variables in the matrix Z_mass_drag.\nZ_mass_drag = deval(sol_mass_drag,tau);\n% Extract the final time from the solution:\ntf_mass_drag = sol_mass_drag.parameters(1);\n% Convert back to dimensional time for plotting\ntime_mass_drag = t0+tau*(tf_mass_drag-t0);\n% Extract the solution for each state variable from the matrix Z_mass_drag\n% and convert them back into dimensional units by multiplying each by their\n% respective scaling constants.\nx_sol_mass_drag = Z_mass_drag(1,:)*h/1000;\ny_sol_mass_drag = Z_mass_drag(2,:)*h/1000;\nvx_sol_mass_drag = Z_mass_drag(3,:)*Vc/1000;\nvy_sol_mass_drag = Z_mass_drag(4,:)*Vc/1000;\nlambda2_bar_sol_mass_drag = Z_mass_drag(5,:);\nlambda3_bar_sol_mass_drag = Z_mass_drag(6,:);\nlambda4_bar_sol_mass_drag = Z_mass_drag(7,:);\n\n%% Plot the solutions\nfigure(1)\nsubplot(221)\nplot(time_mass_drag,x_sol_mass_drag,\u2019k\u2019)\nxlabel(\u2019Time [s]\u2019,\u2019fontsize\u2019,14)\nylabel(\u2019x [km]\u2019,\u2019fontsize\u2019,14)\nxlim([t0 tf_mass_drag])\n\nsubplot(222)\nplot(time_mass_drag,y_sol_mass_drag,\u2019k\u2019)\nxlabel(\u2019Time [s]\u2019,\u2019fontsize\u2019,14)\nylabel(\u2019y [km]\u2019,\u2019fontsize\u2019,14)\nxlim([t0 tf_mass_drag])\n\nsubplot(223)\nplot(time_mass_drag,vx_sol_mass_drag,\u2019k\u2019)\nxlabel(\u2019Time [s]\u2019,\u2019fontsize\u2019,14)\nylabel(\u2019V_x [km/s]\u2019,\u2019fontsize\u2019,14)\nxlim([t0 tf_mass_drag])\n\nsubplot(224)\nplot(time_mass_drag,vy_sol_mass_drag,\u2019k\u2019)\nxlabel(\u2019Time [s]\u2019,\u2019fontsize\u2019,14)\nylabel(\u2019V_y [km/s]\u2019,\u2019fontsize\u2019,14)\nxlim([t0 tf_mass_drag])\n\nfigure(2)\nplot(time_mass_drag,...\natand(lambda4_bar_sol_mass_drag./lambda3_bar_sol_mass_drag),\u2019k\u2019)\nxlabel(\u2019Time [s]\u2019,\u2019fontsize\u2019,14) ylabel(\u2019\\theta\n\n\n\n232 B. Time-Optimal Launch of a Titan II\n\n[deg]\u2019,\u2019fontsize\u2019,14) xlim([t0 tf_mass_drag])\n\nfigure(3)\nplot(x_sol_mass_drag,y_sol_mass_drag,\u2019k\u2019)\nxlabel(\u2019Downrange Position, x [km]\u2019,\u2019fontsize\u2019,14)\nylabel(\u2019Altitude, y [km]\u2019,\u2019fontsize\u2019,14)\nxlim([x_sol_mass_drag(1) x_sol_mass_drag(end)])\nylim([0 200])\n\nfunction dX_dtau = ascent_odes_tf(tau,X,tf)\n%\n% State and Costate Differential Equation Function for the Flat-Earth\n% Optimal Ascent Problem with Atmospheric Drag and linearly time-varying\n% mass\n%\n%\n% The independent variable here is the nondimensional time, tau, the state\n% vector is X, and the final time, tf, is an unknown parameter that must\n% also be passed to the DE function.\n\n% Note that the state vector X has components\n% X(1) = xbar, horizontal component of position\n% X(2) = ybar, vertical component of position\n% X(3) = Vxbar, horizontal component of velocity\n% X(4) = Vybar, vertical component of velocity\n% X(5) = lambda_2_bar, first costate\n% X(6) = lambda_3_bar, second costate\n% X(7) = lambda_4_bar, third costate\n\n% pass in values of relevant constants as global variables\nglobal g_accel Vc h eta beta f m0 mdot\n\nm = m0-abs(mdot)*tau*tf;\n\n% State and Costate differential equations in terms of d/dt:\nxbardot = X(3)*Vc/h; ybardot = X(4)*Vc/h; Vxbardot =\n(f/Vc*(-X(6)/sqrt(X(6)\u02c62+X(7)\u02c62)) ...\n-eta*exp(-X(2)*beta)*X(3)*sqrt(X(3)\u02c62+X(4)\u02c62)*Vc)/m;\nVybardot = (f/Vc*(-X(7)/sqrt(X(6)\u02c62+X(7)\u02c62)) ...\n-eta*exp(-X(2)*beta)*X(4)*sqrt(X(3)\u02c62+X(4)\u02c62)*Vc)/m-g_accel/Vc;\nif sqrt(X(3)\u02c62+X(4)\u02c62) == 0\n\nlambda_2_bar = 0;\nlambda_3_bar = 0;\nlambda_4_bar = -X(5)*Vc/h;\n\nelse\nlambda_2_bar = ...\n\n-(X(6)*X(3)+X(7)*X(4))*eta*beta*exp(-X(2)*beta)*sqrt(X(3)\u02c62+X(4)\u02c62)*Vc/m;\nlambda_3_bar = eta*exp(-X(2)*beta)*Vc*(X(6)*(2*X(3)\u02c62+X(4)\u02c62) ...\n\n+ X(7)*X(3)*X(4))/sqrt(X(3)\u02c62+X(4)\u02c62)/m;\nlambda_4_bar = -X(5)*Vc/h+eta*exp(-X(2)*beta)*Vc*(X(7)*(X(3)\u02c62 ...\n\n+2*X(4)\u02c62) ...\n+X(6)*X(3)*X(4))/sqrt(X(3)\u02c62+X(4)\u02c62)/m;\n\nend\n\n% Nondimensionalize time (with tau = t/tf and d/dtau = tf*d/dt). We must\n% multiply each differential equation by tf to convert our derivatives from\n% d/dt to d/dtau.\n\n\n\nB. Time-Optimal Launch of a Titan II 233\n\ndX_dtau = ...\ntf*[xbardot; ybardot; Vxbardot; Vybardot; ...\n\nlambda_2_bar; lambda_3_bar; lambda_4_bar];\nreturn\n\nfunction PSI = ascent_bcs_tf(Y0,Yf,tf)\n%\n% Boundary Condition Function for the Flat-Earth Optimal Ascent Problem\n% with Atmospheric Drag and linearly varying mass\n%\n\n% pass in values of boundary conditions and other constants as\n% global variables\nglobal xbar0 ybar0 Vxbar0 Vybar0 ybarf Vxbarf Vybarf Vc f\nglobal eta beta g_accel m0 mdot\n\n% the final mass is the same as the initial mass since it was assumed\n% constant\nmf = m0-abs(mdot)*tf;\n\n% Create a column vector with the 7 boundary conditions on the state &\n% costate variables (the 8th boundary condition, t0 = 0, is not used).\nPSI = [Y0(1) - xbar0; % Initial Condition\n\nY0(2) - ybar0; % Initial Condition\nY0(3) - Vxbar0; % Initial Condition\nY0(4) - Vybar0; % Initial Condition\nYf(2) - ybarf; % Final Condition\nYf(3) - Vxbarf; % Final Condition\nYf(4) - Vybarf; % Final Condition\n% Final Value of Hamiltonian:\n(-sqrt(Yf(6)\u02c62+Yf(7)\u02c62)*f/mf/Vc ...\n\n-(Yf(6)*Yf(3))*eta*exp(-beta)*sqrt(Yf(3)\u02c62)*Vc/mf-Yf(7)*g_accel/Vc)*tf ...\n+1];\nreturn\n\n\n\n234 C. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\nC. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\nContributors: Peter J. Edelman and Kshitij Mall\n\nWe want to find the optimal transfer trajectory to get from a 300 km altitude, low-\nEarth orbit (LEO) to a 35,786 km altitude, geosynchronous-Earth orbit (GEO). In\nthis problem we assume a planar transfer with a spherical, non-rotating Earth, and\nneglect other external forces due to the Moon, the Sun, and solar radiation pressure,\netc. Additionally we assume a constant thrust magnitude and a constant mass flow\nrate. An illustration of the defined variables is shown in Fig. C1.\n\nC.1. Optimization Problem\n\nFollowing Bryson and Ho [1975], the optimization problem is posed as follows:\nMaximize:\n\nJ = r(tf) (C1)\n\nsubject to:\n\nr? = u (C2a)\n\nu? =\nv2\n\nr\n? ?\n\nr2\n+\n\nT sin ?\nmo ? |m?|t (C2b)\n\nFigure C1. Schematic of a low-thrust orbit transfer from LEO to a maximum radius circular\norbit in given time, tf\n\n\n\nC. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer 235\n\nv? = ?uv\nr\n\n+\nT cos?\n\nmo ? |m?|t (C2c)\n\n?? =\nv\nr\n\n(C2d)\n\nwhere the variables and constants are defined as:\n\nr = Radius, km\nu = Radial component of velocity, km/s\nv = Tangential component of velocity, km/s\n? = Longitudinal angle, rad\n? = Thrust angle, rad\nT = Thrust magnitude, N\nmo = Initial vehicle mass, kg\nm? = Mass flow rate, kg/s\n? = Gravitational parameter, km3/s2\n\nNote: The optimization problem is posed as a maximum radius transfer rather than\na minimum time transfer with known initial and final orbit radii (due to numerical\ndifficulties associated with the latter). We obtain the time of flight for the LEO to GEO\ntransfer via iteration, by checking to see if the final orbit radius achieved matches the\nradius at GEO at the end of each iteration.\n\nC.2. Scaling the Equations of Motion\n\nWe scale the state variables to remain close to unity to improve numerical con-\nvergence. Using the initial orbit radius and initial velocity as reference values, and\nnormalizing the time by the final time, we define the new state variables as:\n\nr? =\nr\nro\n\n, u? =\nu\nvo\n\n, v? =\nv\nvo\n\n, ? =\nt\ntf\n\n(C3)\n\nApplying the chain rule to change variables results in the following new\nnondimensional equations of motion:\n\nFor r?:\n\ndr?\nd?\n\n=\nd(r/ro)\n\ndt\ndt\nd?\n\n=\ndr\ndt\n\ntf\nro\n\n= u\ntf\nro\n\n(C4)\n\nor,\n\ndr?\nd?\n\n= u?? (C5)\n\nwhere\n\n\n\n236 C. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\n? =\nvotf\nro\n\n(C6)\n\nFor u?:\n\ndu?\nd?\n\n=\nd(u/vo)\n\ndt\ndt\nd?\n\n=\ndu\ndt\n\ntf\nvo\n\n=\n(\n\nv2\n\nr\n? ?\n\nr2\n+\n\nT sin?\nmo ? |m?|t\n\n)\ntf\nvo\n\n(C7)\n\nor,\n\ndu?\nd?\n\n=\n(\n\nv?2\n\nr?\n? 1\n\nr?2\n\n)\n? +\n\nT? sin ?\nmo ? |m?|? tf (C8)\n\nwhere\n\nT? =\nTtf\nvo\n\n(C9)\n\nFor v?:\n\ndv?\nd?\n\n=\nd(v/vo)\n\ndt\ndt\nd?\n\n=\ndv\ndt\n\ntf\nvo\n\n=\n(\n\n?uv\nr\n\n+\nT cos?\n\nmo ? |m?|t\n)\n\ntf\nvo\n\n(C10)\n\nor,\n\ndv?\nd?\n\n= ? u?v?\nr?\n? +\n\nT? cos?\nmo ? |m?|? tf (C11)\n\nFor ? :\n\nd?\nd?\n\n=\nd?\ndt\n\ndt\nd?\n\n=\nd?\ndt\n\ntf =\nv\nr\n\ntf (C12)\n\nor,\n\nd?\nd?\n\n=\nv?\nr?\n? (C13)\n\nIn summary, our newly scaled equations of motion are:\n\ndr?\nd?\n\n= u?? (C14a)\n\ndu?\nd?\n\n=\n(\n\nv?2\n\nr?\n? 1\n\nr?2\n\n)\n? +\n\nT? sin ?\nmo ? |m?|? tf (C14b)\n\ndv?\nd?\n\n= ? u?v?\nr?\n? +\n\nT? cos?\nmo ? |m?|? tf (C14c)\n\n\n\nC. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer 237\n\nd?\nd?\n\n=\nv?\nr?\n? (C14d)\n\nAll of Eqs. (C14) are used to form the TPBVP from the Euler-Lagrange theorem\nand are used in the numerical simulation.\n\nC.3. Applying the Euler-Lagrange Theorem\n\nThe Hamiltonian for our problem is:\n\nH = ?r(u??) + ?u?\n[(\n\nv?2\n\nr?\n? 1\n\nr?2\n\n)\n? +\n\nT? sin ?\nmo ? |m?|? tf\n\n]\n+ ?v?\n\n[\n? u?v?\n\nr?\n? +\n\nT? cos?\nmo ? |m?|? tf\n\n]\n\n+ ??\n(\n\nv?\nr?\n?\n\n)\n(C15)\n\nwhere the ?s are the costates. The Euler-Lagrange equations yield:\n\nd?r?\nd?\n\n= ??H\n? r?\n\n= ?u?\n(\n\nv?2\n\nr?2\n? 2\n\nr?3\n\n)\n? ? ?v? u?v?r?2 ? + ??\n\n(\nv?\nr?2\n\n)\n? (C16a)\n\nd?u?\nd?\n\n= ??H\n? u?\n\n= ??r?? + ?v? v?r? (C16b)\nd?v?\nd?\n\n= ??H\n? v?\n\n= ??u? 2v?r? ? + ?v?\nu?\nr?\n? ? ?? 1r? ? (C16c)\n\nd??\nd?\n\n= ??H\n??\n\n= 0 (C16d)\n\nWe immediately note that Eq. (C16d) implies that ?? is constant throughout the\ntrajectory.\n\nThe control variable, ?, is an angle allowed to have the full range [0, 2?], thus we\nassume that it is unbounded.\n\nThe optimal control law is then found using the procedure discussed after Eq. (4.66)\nby writing the thrust terms in the Hamiltonian of Eq. (C15) as T??T?/(mo ? |m?|? tf)\nwhere\n\n? =\n\n[\n?u?\n\n?v?\n\n]\n(C17)\n\nand\n\n? =\n\n[\nsin ?\n\ncos?\n\n]\n(C18)\n\nwhere ? is a unit vector. Then H is maximized by choosing\n\n? =\n?\n\n?\n(C19)\n\n\n\n238 C. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\nwhich yields\n\nsin ? =\n?u??\n?u? + ?v?\n\n(C20a)\n\ncos? =\n?v??\n?u? + ?v?\n\n(C20b)\n\nC.4. Boundary Conditions and the TPBVP\n\nWe require 2n + 2 boundary conditions, where n is the number of process equations,\nfor a well-defined TPBVP. For our problem, we require 2(4) + 2 = 10, and currently\nknow 8. The known boundary conditions are:\nInitial Conditions:\n\nto = 0 s, ro = 6,678 km, uo = 0 km/s, vo =\n?\n?/ro = 7.726 km/s, ?o = 0 rad\n\n(C21a)\n\nFinal Conditions:\n\ntf = known, uf = 0 km/s, \t1 = vf ?\n?\n?/rf = 0\n\nwhere we have used ? = 3.986 \u00d7 105 km3/s2. We apply the transversality condition\nto pose a well-defined TPBVP:\n\n[\nHdt ? ?Tdx\n\n]???\ntf\n\n+ d? = 0 (C22)\n\nsubject to d? = 0. Expanding the nonzero terms in Eq. (C22) while noting that we\nhave a Mayer form for our optimization problem, where ? = rf:\n\n(1 ? ?rf)drf ? ?vfdvvf ? ??f d?f = 0 (C23)\n\nwith\n\nd\t1 = dvf +\n1\n2\n\n?\n?\n\nr3f\ndrf = 0 (C24)\n\nor,\n\ndvf = ?12\n?\n?\n\nr3f\ndrf (C25)\n\nSince the differentials of the final values of the states are nonzero, the coefficients are\nchosen such that Eq. (C23) is satisfied. Upon substituting Eq. (C25) into Eq. (C23), we\nget the following new boundary conditions:\n\n\n\nC. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer 239\n\n1 ? ?rf +\n1\n2\n?vf\n\n?\n?\n\nr3f\n= 0 (C26a)\n\n??f = 0 (C27)\n\nWe now have enough boundary conditions for a well-defined TPBVP. First we\nscale all the boundary conditions so they are consistent with the differential equations.\nUpon doing so we obtain:\n\n?o = 0, r?o = 1, u?o = 0, v?o = 1, ?o = 0 (C27a)\n\n?f = 1, u?f = 0, v?f =\n\n?\n1\nr?f\n\n, 1 ? ?r?f +\n1\n2\n?v?f\n\n?\n1\nr?3f\n\n= 0, ??f = 0 (C27b)\n\nWe note that the last boundary condition in Eq. (C27b) along with Eq. (C16d)\nreadily implies that ??f = 0 for the entire trajectory, thus we can remove it from the\nproblem entirely. Substituting Eqs. (C20a) and (C20b) into Eqs. (C16) and reiterating\nall differential equations and boundary conditions gives the well-defined TPBVP:\n\ndr?\nd?\n\n= u?? (C28a)\n\ndu?\nd?\n\n=\n(\n\nv?2\n\nr?\n? 1\n\nr?2\n\n)\n? +\n\nT?\nmo ? |m?|? tf\n\n?\n?? ?u??\n\n?2u? + ?\n2\nv?\n\n?\n?? (C28b)\n\ndv?\nd?\n\n= ? u?v?\nr?\n? +\n\nT?\nmo ? |m?|? tf\n\n?\n?? ?v??\n\n?2u? + ?\n2\nv?\n\n?\n?? (C28c)\n\nd?\nd?\n\n=\nv?\nr?\n? (C28d)\n\nd?r?\nd?\n\n= ?u?\n(\n\nv?2\n\nr?2\n? 2\n\nr?3\n\n)\n? ? ?v? u?v?r?2 ? + ??\n\n(\nv?\nr?2\n\n)\n? (C28e)\n\nd?u?\nd?\n\n= ??r?? + ?v? v?r? (C28f)\nd?v?\nd?\n\n= ??u? 2v?r? ? + ?v?\nu?\nr?\n? ? ?? 1r? ? (C28g)\n\n?o = 0, r?o = 1, u?o = 0, v?o = 1, ?o = 0 (C29a)\n\n?f = 1, u?f = 0, v?f =\n\n?\n1\nr?f\n\n, 1 ? ?r?f +\n1\n2\n?v?f\n\n?\n1\nr?3f\n\n= 0, ??f = 0 (C29b)\n\n\n\n240 C. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\nC.5. Results\n\n?4 ?3 ?2 ?1 0 1 2 3\nx 104\n\n?2\n\n?1\n\n0\n\n1\n\n2\n\n3\n\nx 104\n\nx [km]\n\ny \n[k\n\nm\n]\n\nFigure C2. Low-thrust LEO to GEO spiral\n\n0 0.5 1 1.5 2 2.5 3 3.5\n?40\n\n?30\n\n?20\n\n?10\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\nTime [days]\n\n?\n(t\n\n) \n[d\n\neg\n]\n\nFigure C3. Control history of the thrust angle plotted as a function of time\n\n\n\nC. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer 241\n\nDiscussion of Results\n\nThe trajectory resembles that of a spiral with increasing width between each revolu-\ntion. The increase in width can be attributed to the fact that as the vehicle gets farther\nfrom the central body, there exists a weaker gravitational force, enabling velocity\nchanges in the radial direction to cost less propellant. The TOF from LEO to GEO\nwith a constant thrust of 20 Newtons is approximately 4.0 days. Current technology\nallows low-thrust capabilities much smaller than what we used here, meaning there\nwould be many more revolutions as well as a highly increased TOF. We performed\nthis simulation with unrealistic parameters in order to decrease computational time as\nwell as to give a better visualization of the trajectory.\n\nThe thrust angle (the control) oscillates about the zero position with an increasing\namplitude envelope. One period of the control history corresponds to one revolution\naround the Earth, and the period gets larger as the vehicle gets farther away.\nThis envelope would theoretically have an upper limit, which is when the vehicle\napproaches escape speed.\n\n\n\n242 C. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\nC.6. MATLAB Code\n\nExecutable File\n% LEO to GEO Circular Orbit Radius Transfer Problem with MATLAB\u2019s bvp4c\n%\n% by Peter J. Edelman and Kshitij Mall\n%\n% This script uses MATLAB\u2019s bvp4c to solve the problem of finding the\n% optimal transfer trajectory for launch from a 300 kilometer altitude LEO\n% to a 35,786 kilometer altitude GEO orbit.\n% A linearly time-varying mass is assumed.\n% In addition to this script, we use two functions:\n% one to provide the differential equations and another that gives the\n% boundary conditions:\n%\n% This file: Max_Xfer.m\n% State and Costate Equations: transfer_odes.m\n% Boundary Conditions: transfer_bcs.m\n%\n% Clear figure, command and workspace histories\nclear all; close all; clc;\n\n% Define parameters of the problem\n\n% pass these parameters to the DE and BC functions\nglobal eta mdot Tbar tf m0\nh0 = 300; % Initial altitude [km]\nrearth = 6378; % Mean radius of the Earth [km]\nmu = 3.986004418e5; % Gravitational parameter of Earth [km\u02c63/s\u02c62]\nT = 20; % Thrust of spacecraft [N]\nIsp = 6000; % Specific Impulse [sec]\nmdot = T/Isp/9.80665; % Mass flow rate [kg/s]\nm0 = 1500; % Initial spacecraft mass [kg]\n\n%---------------------------------------------------------------------------\n%% Boundary Conditions\n%---------------------------------------------------------------------------\n\nglobal r0bar u0bar v0bar theta0 ufbar % pass these BCs to the BC function\n\n% Initial conditions\n% Start from 300 km altitude circular orbit\n% All Boundary Conditions are nondimensional\nr0 = rearth+h0; % Initial circular orbit radius [km]\nu0 = 0; % Initial radial component of velocity [km/s]\nv0 = sqrt(mu/r0); % Initial circular orbit speed [km/s]\ntheta0 = 0; % Initial longitude [rad]\nt0 = 0; % Initial time [sec]\n\n% Final conditions\nuf = 0; % Final radial component of velocity [km/s]\ndays = .1; % Initial amount of days to thrust. (0.1 days)\ntf = 24*3600*days; % Days in seconds\n\n%---------------------------------------------------------------------------\n%% Nondimensionalize Boundary Conditions and Important Parameters\n%---------------------------------------------------------------------------\n\n\n\nC. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer 243\n\n% Scaling constant eta\neta = v0*tf/r0;\n\n% Scaled thrust Tbar\nTbar = T*tf/(v0*1000);\n\n% Scaled Initial Conditions\nr0bar = r0/r0;\nu0bar = u0/v0;\nv0bar = v0/v0;\n\n% Scaled Final Conditions\nufbar = uf/v0;\n\n%---------------------------------------------------------------------------\n%% Solve the TPBVP\n%---------------------------------------------------------------------------\n\n% Nt is the number of points that the TPBVP will be discretized into. First\n% 1000 mesh points will be used at each iteration to reduce computational\n% time. After the very last iteration, the solution will be spline\n% interpolated to 5000 mesh points and solved again, so as to ensure smooth\n% plots.\nNt = 1000;\ntau = linspace(0,1,Nt); % nondimensional time vector\n% list initial conditions in yinit\nyinit = [r0bar u0bar v0bar 0 0 -1 0];\n% Create an initial guess of the solution using the MATLAB function\n% bvpinit, which requires as inputs the (nondimensional) time vector,\n% initial states (or guesses, as applicable).\n% The initial guess of the solution is stored in the structure solinit.\nsolinit = bvpinit(tau,yinit);\n% Call bvp4c to solve the TPBVP. Point the solver to the functions\n% containing the differential equations and the boundary conditions and\n% provide it with the initial guess of the solution.\nsol = bvp4c(@transfer_odes,@transfer_bcs,solinit);\n% Evaluate the solution at all times in the nondimensional time vector tau\n% and store the state variables in the matrix Z.\nZ = deval(sol,tau);\n% Implement for-loop to increment final time by 0.1 days each iteration\nfor days = .2:.1:2\n\n% update final time\ntf = 24*3600*days;\n% update Tbar and eta, which are functions of tf\nTbar = T*tf/(v0*1000);\neta = v0*tf/r0;\n% store the previous solution as the guess for the next iteration\nsolinit.y = Z;\nsolinit.x = tau;\n% solve the TPBVP\nsol = bvp4c(@transfer_odes,@transfer_bcs,solinit);\n% store the newly found solution in a matrix \u2019Z\u2019\nZ = deval(sol,tau);\n\nend\n% for-loop to increment final time by 0.05 days each iteration for days 2 -\n% 3.95. Due to numerical sensitivity, the step size had to be reduced.\nfor days = 2.05:.05:3.95\n\n\n\n244 C. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\n% update final time\ntf = 24*3600*days;\n% update Tbar and eta, which are functions of tf\nTbar = T*tf/(v0*1000);\neta = v0*tf/r0;\n% store the previous solution as the guess for the next iteration\nsolinit.y = Z;\nsolinit.x = tau;\n% solve the TPBVP\nsol = bvp4c(@transfer_odes,@transfer_bcs,solinit);\n% store the newly found solution in a matrix \u2019Z\u2019\nZ = deval(sol,tau);\n\nend\n% Final iteration to get to GEO (still 1000 mesh points)\ndays = 3.97152;\n% update final time\ntf = 24*3600*days;\n% update Tbar and eta, which are functions of tf\nTbar = T*tf/(v0*1000);\neta = v0*tf/r0;\n% store the previous solution as the guess for the next iteration\nsolinit.y = Z;\nsolinit.x = tau;\n% solve the TPBVP\nsol = bvp4c(@transfer_odes,@transfer_bcs,solinit);\n% store the newly found solution in a matrix \u2019Z\u2019\nZ = deval(sol,tau);\n\n%% Interpolate with spline to get 5000 mesh points\n% Create 5000 point time vector\ntau2 = linspace(0,1,5*Nt);\n% Interpolate solution with spline using the new time vector\nfor q = 1:7\n\nZ2(q,:) = spline(tau,Z(q,:),tau2);\nend\n% Store the new solution in tau and Z\ntau = tau2;\nZ = Z2;\n\n%% Solve TPBVP again with the 5000 mesh points for \"smooth\" answer\nsolinit.y = Z;\nsolinit.x = tau;\nsol = bvp4c(@transfer_odes,@transfer_bcs,solinit);\n% store the newly found solution in a matrix \u2019Z\u2019\nZ = deval(sol,tau);\n\n% Convert back to dimensional time for plotting\ntime = t0+tau*(tf-t0);\n\n% Extract the solution for each state variable from the matrix Z and\n% convert them back into dimensional units by multiplying each by their\n% respective scaling constants.\nr_sol = Z(1,:)*r0; % Radius [km]\nu_sol = Z(2,:)*v0; % Radial component of velocity [km/s]\nv_sol = Z(3,:)*v0; % Tangential component of velocity [km/s]\ntheta_sol = Z(4,:); % Angle between x-axis and radius vector [rad]\nlambda_rbar_sol = Z(5,:); % 1st costate\n\n\n\nC. Optimal Low-Thrust LEO to GEO Circular Orbit Transfer 245\n\nlambda_ubar_sol = Z(6,:); % 2nd costate\nlambda_vbar_sol = Z(7,:); % 3rd costate\n\n% Displays final value of orbit radius\nfinal_radius = r_sol(end)\n\n%---------------------------------------------------------------------------\n%% Plots\n%---------------------------------------------------------------------------\nfigure(1)\nplot(r_sol.*cos(theta_sol), r_sol.*sin(theta_sol),\u2019k\u2019)\nxlabel(\u2019x-direction [km]\u2019)\nylabel(\u2019y-direction [km]\u2019)\naxis equal\n\n% Plot the steering angle as a function of time\nfigure(2)\nplot(time/(3600*24), atand(lambda_ubar_sol./lambda_vbar_sol),\u2019k\u2019)\nxlabel(\u2019Time [days]\u2019)\nylabel(\u2019\\theta(t) [deg]\u2019)\nxlim([time(1) time(end)]/(3600*24))\n\nfunction dX_dtau = transfer_odes(tau,x)\n%\n% State and Costate Differential Equation Function for the Maximal Radius\n% Low-Thrust Orbit Transfer\n%\n%\n% The independent variable here is the nondimensional time, tau, and the\n% state vector is X\n\n% Note that the state vector X has components\n% x(1) = rbar, nondimensional radius from center of Earth\n% x(2) = ubar, nondimensional radial component of velocity\n% x(3) = vbar, nondimensional tangential component of velocity\n% x(4) = theta, angle between inertial x-axis and radius vector\n% x(5) = lambda_r_bar, first costate\n% x(6) = lambda_u_bar, second costate\n% x(7) = lambda_v_bar, third costate\n\n% pass in values of relevant constants as global variables\nglobal eta mdot Tbar tf m0\n\nm = m0-abs(mdot)*tau*tf;\n\ndrbar_dtau = x(2)*eta;\ndubar_dtau = x(3)\u02c62/x(1)*eta-eta/x(1)\u02c62 ...\n-Tbar/m*(x(6)/sqrt(x(6)\u02c62+x(7)\u02c62));\ndvbar_dtau = -x(2)*x(3)/x(1)*eta-Tbar/m*(x(7)/sqrt(x(6)\u02c62+x(7)\u02c62));\ndtheta_dtau = x(3)/x(1)*eta;\ndlambda_r_bar_dtau = x(6)*(x(3)\u02c62/x(1)\u02c62*eta-2*eta/x(1)\u02c63) ...\n-x(7)*x(2)*x(3)/x(1)\u02c62*eta;\ndlambda_u_bar_dtau = -x(5)*eta+x(7)*x(3)/x(1)*eta;\ndlambda_v_bar_dtau = -x(6)*2*x(3)/x(1)*eta+x(7)*x(2)/x(1)*eta;\n\ndX_dtau = [drbar_dtau; dubar_dtau; dvbar_dtau; dtheta_dtau; ...\ndlambda_r_bar_dtau; dlambda_u_bar_dtau; dlambda_v_bar_dtau];\nreturn\n\n\n\n246 Reference\n\nfunction PSI = transfer_bcs(Y0,Yf)\n%\n% Boundary Condition Function for the Maximal Radius Low-Thrust Orbit\n% Transfer\n%\n\n% pass in values of boundary conditions and other constants as global variables\nglobal r0bar u0bar v0bar ufbar theta0\n\n% Create a column vector with the 7 boundary conditions on the state &\n% costate variables\nPSI = [Y0(1)-r0bar % Initial Condition\n\nY0(2)-u0bar % Initial Condition\nY0(3)-v0bar % Initial Condition\nY0(4)-theta0 % Initial Condition\nYf(2)-ufbar % Final Condition\nYf(3)-sqrt(1/Yf(1)) % Final Condition\n\n-Yf(5)+1/2*Yf(7)/Yf(1)\u02c6(3/2)-1];% Final Condition\nreturn\n\nReference\n\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C., 1975)\n\n\n\nD. Curious Quotations 247\n\nD. Curious Quotations\n\nIn case you don\u2019t find the concepts of the calculus of variations incipiently clear, or\nif after much study you now have doubts about your ideas, your intelligence, or your\nsanity, perhaps the following quotes from great minds and renowned authors will\nassuage your concerns\u2014or at least put you in a better mood!\n\n\u201cA reader meeting the calculus of variations for the first time is likely to feel at\nthis stage that a great many things are not completely clear. This is normal. We are\njust getting started. To feel otherwise is either a mark of genius or indication of real\ntrouble.\u201d\n\nGeorge M. Ewing\n\n\u201cMany of the treatises of today are formulated in a half-mystical language, as though\nto impress the reader that he is in the permanent presence of a superman. The present\nbook is conceived in a humble spirit and is written for humble people.\u201d\n\nCornelius Lanczos\n\n\u201cAt the age of 12\u201316 . . . I had the good fortune of hitting on books which were\nnot too particular in their logical rigour, but which made up for this by permitting the\nmain thoughts to stand out clearly and synoptically.\u201d\n\nAlbert Einstein\n\n\u201c. . . the application of this condition to the problems with which we shall be concerned\nis difficult to carry through and has, as yet (1962), received very little attention. The\nconsequences of this additional necessary condition (first considered by Jacobi) will\nnot therefore be explored in this book.\u201d\n\nD.F. Lawden\n\n\u201cThe vague, mechanical \u2018? method\u2019 is avoided throughout. Thus, while no advantage\nis taken of a sometimes convenient shorthand tactic, there is eliminated a source of\nconfusion which often grips the careful student when confronted with its use.\u201d\n\nRobert Weinstock\n\n\u201c. . .a theory allowing for a larger class of admissible functions\u2014namely, Lebesgue\nmeasurable ones\u2014has been devised. Such a theory is beyond the scope of this book,\nwhich is devoted to what is sometimes dubbed the \u2018naive\u2019 theory.\u201d\n\nGeorge Leitmann\n\n\u201cThus the main novelty arising from the discontinuities in f(t, x) is that while the\nusual formulas of differential and integral calculus are valid, there is an occasional\nwarning that certain equalities may hold only \u2018almost everywhere.\u2019 The reader who is\nwilling to grant the correctness of this extension of the calculus can proceed with the\nmotto,\u2018Damn the null sets, full differentiability ahead.\u2019 \u201d\n\nE. B. Lee and L. Markus\n\n\n\n248 D. Curious Quotations\n\n\u201cThis is a minor revision of the original 1969 publication. Some false statements\nhave been changed.\u201d\n\nGeorge M. Ewing\n\n\u201cNo attempt is made to treat problems of sufficiency or existence; no consideration\nis taken of the \u2018second variation\u2019 or of the conditions of Legendre, Jacobi, and\nWeierstrass. Besides being outside the scope of this book, these matters are excellently\ntreated in the volumes of Bolza and Bliss . . .\u201d\n\nRobert Weinstock\n\n\u201cYou want proof? You can\u2019t handle the proof!\u201d\nI. Michael Ross\n\n\u201cThere is no discipline in which more correct results can be obtained by incorrect\nmeans than in the calculus of variations.\u201d\n\nAttributed to Magnus R. Hestenes by George Leitmann\n\n\n\nBibliography (Books)\n\nN.I. Akhiezer, The Calculus of Variations (Trans. by A. H. Fink) (Blaisdell Publishing, New York,\n1962)\n\nJ.D. Anderson Jr., Introduction to Flight, 4th edn. (McGraw Hill, New York, 1999)\nM. Athans, P.L. Falb, Optimal Control: An Introduction to the Theory and Its Applications (Dover,\n\nNew York, 1966)\nR. Barrie?re, Optimal Control Theory: A Course in Automatic Control Theory (W. B. Saunders,\n\nPhiladelphia, 1967). Stresses mathematical facts and theory\nR.H. Battin, An Introduction to the Mathematics and Methods of Astrodynamics. Rev. edn. (American\n\nInstitute of Aeronautics and Astronautics, Reston, 1999). A significant work in astrodynamics.\nThe historical notes are a delight\n\nE.T. Bell, Men of Mathematics (Simon and Schuster, New York, 1965). Don\u2019t let the dated title turn\nyou off from this inspiring and entertaining book on the lives of mathematicians from Zeno to\nPoincare?. A few women are mentioned including Weierstrass\u2019s favorite pupil, Sonja Kowalewski\nwho won fame for her work on rigid body motion, and Emmy Noether who was much admired\nby Einstein for her theorem on symmetry and conservation laws\n\nD.J. Bell, D.H. Jacobson, Singular Optimal Control Problems (Academic, New York, 1975)\nR. Bellman, Dynamic Programming (Princeton University Press, Princeton, 1957)\nR. Bellman, Adaptive Control Processes: A Guided Tour (Princeton University Press, Princeton,\n\n1961)\nR. Bellman, S.E. Dreyfus, Applied Dynamic Programming (Princeton University Press, Princeton,\n\n1962)\nR. Bellman (ed.), Mathematical Optimization Techniques (University of California Press, Los\n\nAngeles, 1963)\nR. Bellman, Introduction to the Mathematical Theory of Control Processes, Volume I, Linear and\n\nQuadratic Criteria (Academic, New York, 1967)\nR. Bellman, Introduction to the Mathematical Theory of Control Processes, Volume II, Nonlinear\n\nProcesses (Academic, New York, 1971)\nJ.Z. Ben-Asher, Optimal Control Theory with Aerospace Applications (American Institute of\n\nAeronautics and Astronautics, Reston, 2010)\nL.D. Berkovitz, Optimal Control Theory (Springer, New York, 1974). Written for mathematicians\n\nrather than engineers; provides a mathematically precise statement and proof of the Minimum\nPrinciple\n\nJ.T. Betts, Practical Methods for Optimal Control Using Nonlinear Programming. SIAM Advances\nin Design and Control (Society for Industrial and Applied Mathematics, Philadelphia, 2001)\n\nG.A. Bliss, Calculus of Variations (Open Court Publishing, Chicago, 1925)\nG.A. Bliss, Lectures on the Calculus of Variations. Phoenix Science Series (The University of\n\nChicago Press, Chicago, 1968). One of the classic references, the other being Bolza [1961]. These\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0,\n\u00a9 Springer Science+Business Media New York 2014\n\n249\n\n\n\n250 Bibliography (Books)\n\nreferences are written by mathematicians, for mathematicians and are not easy reading for the\npracticing engineer or the engineering student who is learning the material for the first time\n\nV.G. Boltyanskii, Mathematical Methods of Optimal Control (Trans. from the Russian by K.N.\nTrirogoff and I. Tarnove) (Holt, Rinehart and Winston, New York, 1971)\n\nO. Bolza, Lectures on the Calculus of Variations (Dover, New York, 1961). See comment on Bliss\nabove\n\nC.D. Brown, Spacecraft Mission Design, 2nd edn. (American Institute of Aeronautics and Astronau-\ntics, Reston, 1998)\n\nA.E. Bryson Jr., Dynamic Optimization (Addison Wesley Longman, Menlo Park, 1999). The\ncompanion to Bryson and Ho [1975]. Contains many numerical solutions using MATLAB\n\nA.E. Bryson Jr., Y.C. Ho, Applied Optimal Control (Hemisphere Publishing, Washington, D.C.,\n1975). The most popular and most referenced book by aerospace engineers. A must have. A\nbit difficult for beginners, which is why the book you are reading now was written\n\nR. Bulirsch, A. Miele, J. Stoer, K.H. Well (eds.), Optimal Control: Calculus of Variations, Optimal\nControl Theory and Numerical Methods. International Series of Numerical Mathematics, ISNM,\nvol. 111 (Birkhauser, Basel, 1993)\n\nC. Carathe?odory, Calculus of Variations and Partial Differential Equations of the First Order, Part\nI: Partial Differential Equations of the First Order (Trans. by R.B. Dean and J.J. Brandstatter)\n(Holden-Day, San Francisco, 1965)\n\nC. Carathe?odory, Calculus of Variations and Partial Differential Equations of the First Order, Part II:\nCalculus of Variations (Trans. by R.B. Dean and J.J. Brandstatter) (Holden-Day, San Francisco,\n1967)\n\nP. Cicala, An Engineering Approach to the Calculus of Variations (Levrotto & Bella, Torino, 1957)\nS.J. Citron, Elements of Optimal Control (Holt, Rinehart and Winston, New York, 1969). A nice,\n\npractical book for engineers. Emphasizes understanding from a heuristic point of view over\nmathematical rigor\n\nJ.C. Clegg, Calculus of Variations (Interscience Publishers, New York, 1968)\nD.J. Clements, B.D.O. Anderson, Singular Optimal Control: The Linear-Quadratic Problem\n\n(Springer, New York, 1978)\nB.A. Conway (ed.), Spacecraft Trajectory Optimization (Cambridge University Press, New York,\n\n2010). An excellent follow up to the present text, drawing from the currently most active\nresearchers in optimization of space trajectories\n\n\u2022 Chapter 1, The problem of spacecraft trajectory optimization. B.A. Conway.\n\u2022 Chapter 2, Primer vector theory and applications. J.E. Prussing.\n\u2022 Chapter 3, Spacecraft trajectory optimization using direct transcription. B.A. Conway\n\nand S.W. Paris.\n\u2022 Chapter 4, Elements of a software system for spacecraft trajectory optimization. C.\n\nOcampo.\n\u2022 Chapter 5, Low thrust trajectory optimization using orbital averaging and control\n\nparametrization. C.A. Kluever.\n\u2022 Chapter 6, Analytic representation of optimal low-thrust transfer in circular orbit. J.A.\n\nKe?chichian.\n\u2022 Chapter 7, Global optimization and space pruning for spacecraft trajectory design. D.\n\nIzzo.\n\u2022 Chapter 8, Incremental techniques for global space trajectory design. M. Vasile and M.\n\nCeriotti.\n\u2022 Chapter 9, Optimal low-thrust trajectories using stable manifolds. C. Martin and B.A.\n\nConway.\n\u2022 Chapter 10, Swarming theory applied to space trajectory optimization. M. Pontani and\n\nB.A. Conway.\n\nR. Courant, Calculus of Variations and Supplementary Notes and Exercises (New York University,\nNew York, 1957)\n\n\n\nBibliography (Books) 251\n\nH.W. Curtis, Orbital Mechanics for Engineering Students (Elsevier, Boston, 2007). A well written\nintroductory text for undergraduates\n\nJ.M.A. Danby, Fundamentals of Celestial Mechanics, 2nd edn. (Willmann-Bell, Richmond, 1988). A\nmust have, classic book on celestial mechanics\n\nM.M. Denn, Optimization by Variational Methods (McGraw-Hill, New York, 1969)\nS.E. Dreyfus, Dynamic Programming and the Calculus of Variations (Academic, New York, 1966)\nA. Einstein, The Meaning of Relativity (Princeton University Press, Princeton, 1972)\nL.E. Elsgolc, Calculus of Variations (Trans. from the Russian) (Addison-Wesley, Reading, 1962).\n\nThis accessible text provides engineers with a basic understanding of calculus of variations\nG.M. Ewing, Calculus of Variations with Applications (Dover, New York, 1985). A fundamental\n\nwork requiring some \u201cmathematical maturity.\u201d A must have reference for advanced study\nC. Fox, An Introduction to the Calculus of Variations (Dover, New York, 1987). One of the classic\n\nintroductions\nI.M. Gelfand, S.V. Fomin, Calculus of Variations (Trans. from the Russian by R.A. Silverman)\n\n(Prentice-Hall, Englewood Cliffs, 1963). A nice balance between mathematics and applications\nwith a bibliography that has similarly accessible books for the engineer\n\nM.C. Gemignani, Elementary Topology, 2nd edn. (Dover, New York, 1990)\nP.E. Gill, W. Murray, M.H. Wright, Practical Optimization (Academic, New York, 1981)\nH.H. Goldstine, A History of the Calculus of Variations from the 17th Through the 19th Century\n\n(Springer, New York, 1980)\nD.T. Greenwood, Classical Dynamics (Dover, New York, 1997). Very well written and highly\n\naccessible text on the variational principles of mechanics. Makes an excellent companion with\nthe work by Lanczos\n\nM.D. Griffin, J.R. French, Space Vehicle Design, 2nd edn. (American Institute of Aeronautics and\nAstronautics, Reston, 2003). An AIAA bestseller and must have for spacecraft designers\n\nT. Hawkins, Lebesgue\u2019s Theory of Integration: Its Origins and Development (The University of\nWisconsin Press, Madison, 1970)\n\nM.R. Hestenes, Calculus of Variations and Optimal Control Theory (Wiley, New York, 1966). An\nimportant mathematical treatment of optimal control theory by one of Bliss\u2019s research assistants.\nNot easy reading for engineers\n\nD.G. Hull, Optimal Control Theory for Applications (Springer, New York, 2003). An excellent\nreference for the practicing engineer and for senior and graduate students. Well written and\naccessible; uses uniform, modern notation\n\nJ.L. Junkins, J.D. Turner, Optimal Spacecraft Rotational Maneuvers (Elsevier Scientific, New York,\n1986)\n\nR.E. Kalman, The theory of optimal control and the calculus of variations, Chapter 16, in Mathe-\nmatical Optimization Techniques, ed. by R. Bellman (University of California Press, Berkeley,\n1963)\n\nH.J. Kelley, R.E. Kopp, A.G. Moyer, Singular extremals, Chapter 3, in Topics in Optimization, ed. by\nG. Leitmann (Academic, New York, 1967)\n\nP. Kenneth, R. McGill, Two-point boundary value problem techniques, Chapter 2, in Advances in\nControl Systems: Theory and Applications, vol. 3, ed. by C.T. Leondes (Academic, New York,\n1966)\n\nD.E. Kirk, Optimal Control Theory: An Introduction (Prentice Hall, Englewood Cliffs, 1970).\nExplains basic concepts that are often glossed over with good use of illustrations. Accessible\nto engineers and well written\n\nG. Knowles, An Introduction to Applied Optimal Control (Academic, New York, 1981). Instead of\nproving the Minimum Principle, this readable text takes the practical approach of demonstrating\nthe Minimum Principle on problems of interest to mathematics, engineering, and business students\n\nA.V. Labunsky, O.V. Papkov, K.G. Sukhanov, Multiple Gravity-Assist Interplanetary Trajectories\n(Gordon and Breach Science, Amsterdam, 1998)\n\nC. Lanczos, The Variational Principles of Mechanics, 4th edn. (Dover, New York, 1986). An\nenthusiastic treatment woven with historical anecdotes and philosophical insights. A must have\nbook\n\n\n\n252 Bibliography (Books)\n\nD.F. Lawden, Optimal Trajectories for Space Navigation (Butterworths, London, 1963). This is the\nclassic treatment of optimal space trajectories\n\nD.F. Lawden, Analytical Methods of Optimization (Hafner, New York, 1975)\nE.B. Lee, L. Markus, Foundations of Optimal Control Theory (Wiley, New York, 1967)\nG. Leitmann, The Calculus of Variations and Optimal Control (Plenum, New York, 1981). A well\n\nwritten graduate-level text with care placed on mathematical details. A bit challenging for the\nnovice\n\nF.L. Lewis, V.L. Syrmos, Optimal Control, 2nd edn. (Wiley, New York, 1995). A readable book\nwritten by engineers for engineers. Focuses on practice over theory\n\nL.A. Lyusternik, Shortest Paths Variational Problems (Trans. and adapted from the Russian by P.\nCollins and R.B. Brown) (The Macmillan, New York, 1964). An entertaining introduction to\nvariational problems using elementary mathematics\n\nC.R. MacCluer, Calculus of Variations: Mechanics, Control, and Other Applications (Pearson\nPrentice Hall, Upper Saddle River, 2005). An accessible book for students armed with only\ncalculus, that includes a simple introduction to optimal control and Pontryagin\u2019s Minimum\nPrinciple. Difficulty ramps up after chapter 7 to cover advanced topics\n\nJ.P. Marec, Optimal Space Trajectories (Elsevier Scientific, New York, 1979)\nM. Mesterton-Gibbons, A Primer on the Calculus of Variations and Optimal Control (American\n\nMathematical Society, Providence, 2009)\nA. Miele, Flight Mechanics: Theory of Flight Paths, vol. 1 (Addison-Wesley, Reading, 1962)\nA. Miele (ed.), Theory of Optimum Shapes: Extremal Problems in the Aerodynamics of Supersonic,\n\nHypersonic, and Free-Molecular Flows (Academic, New York, 1965)\nM. Morse, The Calculus of Variations in the Large (American Mathematical Society, Providence,\n\n1934)\nR. Oldenburger, Optimal Control (Holt, Rinehart and Winston, New York, 1966)\nL.A. Pars, An Introduction to the Calculus of Variations (Wiley, New York, 1962)\nI.P. Petrov, Variational Methods in Optimum Control Theory (Academic, New York, 1968). This\n\nlittle book is a gem. Directed toward electrical engineers, it starts with fundamental concepts and\nbuilds gradually to elucidate the variational methods underlying optimum control. It includes an\ninteresting historical survey and a glossary in the appendices. Very well written\n\nD.A. Pierre, Optimization Theory with Applications (Wiley, New York, 1969)\nL.S. Pontryagin, V.G. Boltyanskii, R.V. Gamkrelidze, E.F. Mishchenko, The Mathematical Theory of\n\nOptimal Processes (Wiley, New York, 1962). The ultimate authorities on the Minimum Principle.\nWhile the mathematical proofs are somewhat recondite, the text is clear and even conversational,\nthe meaning of each theorem is clearly interpreted, and the examples are derived from practical\nproblems\n\nJ.E. Prussing, B.A. Conway, Orbital Mechanics, 2nd edn. (Oxford University Press, New York,\n2013). Fills a vacuum by supplying an excellent text for the first course on orbital mechanics\n\nS.S. Rao, Engineering Optimization: Theory and Practice, 3rd edn. (Wiley-Interscience, New York,\n1996)\n\nI.M. Ross, A Primer on Pontryagin\u2019s Principle in Optimal Control (Collegiate, Carmel, 2009). This\nwell written, humorous approach is a refreshing read. It drops any pretense of proving Pontrya-\ngin\u2019s Principle: \u201cYou want proof? You can\u2019t handle the proof!\u201d and proceeds to demonstrate that\nthe application of the Minimum Principle is easy!\n\nH. Sagan, Introduction to the Calculus of Variations (McGraw-Hill, New York, 1969)\nH. Schaub, J. Junkins, Analytical Mechanics of Space Systems, 2nd edn. (American Institute of\n\nAeronautics and Astronautics, Reston, 2009)\nD.J. Scheeres, Orbital Motion in Strongly Perturbed Environments: Applications to Asteroid, Comet\n\nand Planetary Satellite Orbiters (Springer, New York, 2013)\nP.A. Schilpp, Albert Einstein: Philosopher-Scientist. The Library of Living Philosophers, vol. VII,\n\n3rd edn. (Cambridge University Press, London, 1969)\nR.F. Stengel, Optimal Control and Estimation (Dover, New York, 1994). A very useful and readable\n\nreference for practicing engineers\n\n\n\nBibliography (Books) 253\n\nW.T. Thomson, Introduction to Space Dynamics (Dover, New York, 1986). A useful and friendly\nreference for astrodynamicists that has remained popular for half a century\n\nP. Ulivi, D.M. Harland, Robotic Exploration of the Solar System (Springer, New York, 2007)\nJ. Vagners, Optimization techniques, in Handbook of Applied Mathematics, 2nd edn., ed. by C.E.\n\nPearson (Van Nostrand Reinhold, New York, 1983), pp. 1140\u20131216. A wonderful summary\nof the fundamental elements of optimization theory. After the author admits that the literature\nis staggering and \u201cunfortunately scattered throughout the various publications by engineers,\nmathematicians, and systems analysts,\u201d he endeavors to present sufficiently complete references\nand sources to guide the reader. The book is well worth purchasing just for this chapter\n\nN.X. Vinh, A. Busemann, R.D. Culp, Hypersonic and Planetary Flight Mechanics (The University\nof Michigan Press, Ann Arbor, 1980)\n\nN.X. Vinh, Optimal Trajectories in Atmospheric Flight (Elsevier Scientific, New York, 1981)\nN.X. Vinh, Flight Mechanics of High-Performance Aircraft (Cambridge University Press, New York,\n\n1993). A masterly treatment of aircraft performance that is accessible to advanced undergraduates\nR. Weinstock, Calculus of Variations, with Applications to Physics and Engineering (Dover, New\n\nYork, 1974)\nJ.R. Wertz, W.J. Larson (eds.), Space Mission Analysis and Design, 3rd edn. (Microcosm, El Segundo,\n\n2008)\nJ.R. Wertz, with contributions by H.F. Meissinger, L.K. Newman, G.N. Smit, Mission Geometry:\n\nOrbit and Constellation Design and Management (Microcosm, El Segundo, 2001)\nJ.R. Wertz, D.F. Everett, J.J. Puschell (eds.), Space Mission Engineering: The New SMAD (Micro-\n\ncosm, Hawthorne, 2011). A must have for the practicing space mission designer\nB. Wie, Space Vehicle Dynamics and Control (American Institute of Aeronautics and Astronautics,\n\nReston, 1998)\nL.C. Young, Lectures on the Calculus of Variations and Optimal Control Theory (W.B. Saunders,\n\nPhiladelphia, 1969)\n\n\n\nBibliography (Aerospace Applications Papers\nand Reports)\n\nB. Acikmese, S.R. Ploen, Convex programming approach to powered descent guidance for mars\nlanding. J. Guid. Control Dyn. 30(5), 1353\u20131366 (2007)\n\nA.R. Archenti, N.X. Vinh, Intermediate-thrust arcs and their optimality in a central, time-invariant\nforce field. J. Optim. Theory Appl. 11(3), 293\u2013304 (1973)\n\nD.M. Azimov, R.H. Bishop, Extremal rocket motion with maximum thrust on a linear central field. J.\nSpacecr. Rockets 38(5), 765\u2013776 (2001)\n\nX. Bai, J.L. Junkins, New results for time-optimal three-axis reorientation of a rigid spacecraft. J.\nGuid. Control Dyn. 32(4), 1071\u20131076 (2009)\n\nD.R. Bartz, J.L. Horsewood, Characteristics, capabilities, and costs of solar electric spacecraft for\nplanetary missions. J. Spacecr. Rockets 7(12), 1379\u20131390 (1970)\n\nR.J. Battin, R.M. Vaughan, An elegant Lambert algorithm. J. Guid. Control Dyn. 7, 662\u2013670 (1984)\nR.A. Beck, J.M. Longuski, Annihilation of transverse velocity bias during spinning-up maneuvers.\n\nJ. Guid. Control Dyn. 20(3), 416\u2013421 (1997)\nM. Bello?-Mora, J. Rodr??guez-Canabal, On the 3-d configurations of the cluster mission, in ESA\n\nSymposium on Space Flight Dynamics, Darmstadt, Dec 1991. SP-326 (European Space Agency,\n1991), pp. 471\u2013479\n\nJ.T. Betts, Survey of numerical methods for trajectory optimization. J. Guid. Control Dyn. 21(2),\n193\u2013207 (1998)\n\nJ.T. Betts, Practical Methods for Optimal Control Using Nonlinear Programming. SIAM Advances\nin Design and Control (Society for Industrial and Applied Mathematics, Philadelphia, 2001)\n\nK.D. Bilimoria, B. Wie, Time-optimal three-axis reorientation of a rigid spacecraft. J. Guid. Control\nDyn. 16(3), 446\u2013452 (1993)\n\nR.H. Bishop, D.M. Azimov, Analytical space trajectories for extremal motion with low-thrust\nexhaust-modulated propulsion. J. Spacecr. Rockets 38(6), 897\u2013903 (2001)\n\nJ.V. Breakwell, The optimization of trajectories. J. Soc. Ind. Appl. Math. 7(2), 215\u2013247 (1959)\nJ.V. Breakwell, H.E. Rauch, Optimal guidance for a low thrust interplanetary vehicle. AIAA J. 4(4),\n\n693\u2013704 (1966)\nJ.V. Breakwell, H. Shoee, Minimum fuel flight paths for a given range, in AIAA/AAS Astrodynamics\n\nConference, Danvers, 11\u201313 Aug 1980. AIAA Paper No. 80\u20131660\nR.A. Broucke, A.F.B.A. Prado, Orbital planar maneuvers using two and three-four (through infinity)\n\nimpulses. J. Guid. Control Dyn. 19(2), 274\u2013282 (1996)\nR.G. Brusch, Constrained impulsive trajectory optimization for orbit-to-orbit transfer. J. Guid.\n\nControl 2(3), 204\u2013212 (1979)\nR.M. Byers, Improved estimation of time-optimal control switching, in AIAA/AAS Astrodynamics\n\nConference, Hilton Head Island, 10\u201312 Aug 1992. AIAA Paper No. 92-4590\nR.M. Byers, S.R. Vadali, Quasi-closed-form solution to the time-optimal rigid spacecraft reorientation\n\nproblem. J. Guid. Control Dyn. 16(3), 453\u2013461 (1993)\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0,\n\u00a9 Springer Science+Business Media New York 2014\n\n255\n\n\n\n256 Bibliography (Aerospace Applications Papers and Reports)\n\nD.V. Byrnes, J.M. Longuski, B. Aldrin, Cycler orbit between Earth and Mars. J. Spacecr. Rockets\n30(3), 334\u2013336 (1993)\n\nS. Campagnola, R.P. Russell, Endgame problem part 1: V?-leveraging technique and the leveraging\ngraph. J. Guid. Control Dyn. 33(2), 463\u2013475 (2010a)\n\nS. Campagnola, R.P. Russell, Endgame problem part 2: multibody technique and the Tisserand-\nPoincare? graph. J. Guid. Control Dyn. 33(2), 476\u2013486 (2010b)\n\nC.K. Carrington, J.L. Junkins, Optimal nonlinear feedback control for spacecraft attitude maneuvers.\nJ. Guid. Control Dyn. 9(1), 99\u2013107 (1986)\n\nT.E. Carter, Necessary and sufficient conditions for optimal impulsive Rendezvous with linear\nequations of motion. Dyn. Control 10(3), 219\u2013227 (2000)\n\nL. Casalino, Singular arcs during aerocruise. J. Guid. Control Dyn. 23(1), 118\u2013123 (2000)\nL. Casalino, G. Colasurdo, Optimization of variable-specific-impulse interplanetary trajectories.\n\nJ. Guid. Control Dyn. 27(4), 678\u2013684 (2004)\nL. Casalino, G. Colasurdo, Improved Edelbaum\u2019s approach to optimize low Earth geostationary orbits\n\nlow-thrust transfers. J. Guid. Control Dyn. 30(5), 1504\u20131510 (2007)\nL. Casalino, G. Colasurdo, D. Pastrone, Optimization procedure for preliminary design of opposition-\n\nclass Mars missions. J. Guid. Control Dyn. 21(1), 134\u2013140 (1998a)\nL. Casalino, G. Colasurdo, D. Pastrone, Optimization of?V Earth-gravity-assist trajectories. J. Guid.\n\nControl Dyn. 21(6), 991\u2013995 (1998b)\nL. Casalino, G. Colasurdo, D. Pastrone, Optimal low-thrust escape trajectories using gravity assist. J.\n\nGuid. Control Dyn. 22(5), 637\u2013642 (1999)\nM. Ceriotti, C.R. McInnes, Generation of optimal trajectories for Earth hybrid pole sitters. J. Guid.\n\nControl Dyn. 34(3), 991\u2013995 (2011)\nM. Ceriotti, M. Vasile, Automated multigravity assist trajectory planning with a modified ant colony\n\nalgorithm. J. Aerosp. Comput. Inf. Commun. 7, 261\u2013293 (2010)\nK.J. Chen, T.T. McConaghy, D.F. Landau, J.M. Longuski, B. Aldrin, Powered Earth-Mars cycler with\n\nthree-synodic-period repeat time. J. Spacecr. Rockets 42(5), 921\u2013927 (2005)\nD.F. Chichka, U.J. Shankar, E.M. Cliff, H.J. Kelley, Cruise-dash-climb analysis of an airbreathing\n\nmissile. J. Guid. Control Dyn. 11(4), 293\u2013299 (1988)\nC.T. Chomel, R.H. Bishop, Analytical lunar descent guidance algorithm. J. Guid. Control Dyn. 32(3),\n\n915\u2013926 (2009)\nR.S. Chowdhry, E.M. Cliff, F.H. Lutze, Optimal rigid-body motions. J. Guid. Control Dyn. 14(2),\n\n383\u2013390 (1991)\nT. Cichan, R.G. Melton, D.B. Spencer, Control laws for minimum orbital change\u2013the satellite\n\nretrieval problem. J. Guid. Control Dyn. 24(6), 1231\u20131233 (2001)\nV.C. Clarke Jr., Design of lunar and interplanetary ascent trajectories. AIAA J. 1(7), 1559\u20131567\n\n(1963)\nE.M. Cliff, In Memoriam\u2014Henry J. Kelley. J. Guid. Control Dyn. 11(4), 289\u2013290 (1988)\nG. Colasurdo, D. Pastrone, Indirect optimization method for impulsive transfers. in AIAA/AAS\n\nAstrodynamics Conference, Scottsdale, Aug 1994. AIAA Paper No. 94\u20133762\nB.A. Conway, Optimal low-thrust interception of Earth-crossing asteroids. J. Guid. Control Dyn.\n\n20(5), 995\u20131002 (1997)\nB.A. Conway, K.M. Larson, Collocation versus differential inclusion in direct optimization. J. Guid.\n\nControl Dyn. 21(5), 780\u2013785 (1998)\nV. Coverstone-Carroll, J.E. Prussing, Optimal cooperative power-limited rendezvous between neigh-\n\nboring circular orbits. J. Guid. Control Dyn. 16(6), 1045\u20131054 (1993)\nB. Dachwald, B. Wie, Solar sail kinetic energy impactor trajectory optimization for an asteroid-\n\ndeflection mission. J. Spacecr. Rockets 44(4), 755\u2013764 (2007)\nR. Dai, J.E. Cochran Jr., Three-dimensional trajectory optimization in constrained airspace. J. Aircr.\n\n46(2), 627\u2013634 (2009)\nL.A. D\u2019Amario, T.N. Edelbaum, Minimum impulse three-body trajectories. AIAA J. 12(4), 455\u2013462\n\n(1974)\nL.A. D\u2019Amario, D.V. Byrnes, R.H. Stanford, A new method for optimizing multiple-flyby trajecto-\n\nries. J. Guid. Control Dyn. 4(6), 591\u2013596 (1981)\n\n\n\nBibliography (Aerospace Applications Papers and Reports) 257\n\nL.A. D\u2019Amario, D.V. Byrnes, R.H. Stanford, Interplanetary trajectory optimization with application\nto Galileo. J. Guid. Control Dyn. 5(5), 465\u2013471 (1982)\n\nT.J. Debban, T.T. McConaghy, J.M. Longuski, Design and optimization of low-thrust gravity-assist\ntrajectories to selected planets, in AIAA/AAS Astrodynamics Conference, Monterey, 5\u20138 Aug\n2002. AIAA Paper No. 2002-4729\n\nP. De Pascale, M. Vasile, Preliminary design of low-thrust multiple gravity-assist trajectories. J.\nSpacecr. Rockets 43(5), 1065\u20131076 (2006)\n\nP.N. Desai, B.A. Conway, Six-degree-of-freedom trajectory optimization using a two-timescale\ncollocation architecture. J. Guid. Control Dyn. 31(5), 1308\u20131315 (2008)\n\nC.N. D\u2019Souza, An optimal guidance law for planetary landing, in AIAA Guidance, Navigation, and\nControl Conference, New Orleans, 11\u201313 Aug 1997. AIAA Paper No. 97-3709\n\nD. Dunham, S. Davis, Optimization of a multiple lunar-swingby trajectory sequence, in AIAA/AAS\nAstrodynamics Conference, Seattle, 20\u201322 Aug 1984. AIAA Paper No. 84-1978\n\nT.N. Edelbaum, How many impulses? Aeronaut. Astronaut. (now named Aerosp. Am.) 5, 64\u201369\n(1967)\n\nT.N. Edelbaum, L.L. Sackett, H.L. Malchow, Optimal low thrust geocentric transfer, in AIAA 10th\nElectric Propulsion Conference, Lake Tahoe, 31 Oct\u20132 Nov 1973. AIAA Paper No. 73-1074\n\nT. Elices, Maximum ?V in the aerogravity assist maneuver. J. Spacecr. Rockets 32(5), 921\u2013922\n(1995)\n\nP.J. Enright, B.A. Conway, Optimal finite-thrust spacecraft trajectories using collocation and nonlin-\near programming. J. Guid. Control Dyn. 14(5), 981\u2013985 (1991)\n\nP.J. Enright, B.A. Conway, Discrete approximations to optimal trajectories using direct transcription\nand nonlinear programming. J. Guid. Control Dyn. 15(4), 994\u20131002 (1992)\n\nR.W. Farquhar, Lunar communications with libration-point satellites. J. Spacecr. Rockets 4(10),\n1383\u20131384 (1967)\n\nR.W. Farquhar, Comments on optimal controls for out-of-plane motion about the translunar libration\npoint. J. Spacecr. Rockets 8(7), 815\u2013816 (1971)\n\nR.W. Farquhar, The flight of ISEE3/ICE: origins, mission history, and a legacy. J. Astronaut. Sci.\n49(1), 23\u201373 (2001)\n\nT.S. Feeley, J.L. Speyer, Techniques for developing approximate optimal advanced launch system\nguidance. J. Guid. Control Dyn. 17(5), 889\u2013896 (1994)\n\nA. Fleming, I.M. Ross, Optimal control of spinning axisymmetric spacecraft: a pseudospectral\napproach, in AIAA Guidance, Navigation, and Control Conference, Honolulu, 18\u201321 Aug 2008.\nAIAA Paper No. 2008-7164\n\nE.G. Gilbert, R.M. Howe, P. Lu, N.X. Vinh, Optimal aeroassisted intercept trajectories at hyperbolic\nspeeds. J. Guid. Control Dyn. 14(1), 123\u2013131 (1991)\n\nB.S. Goh, Necessary conditions for singular extremals involving multiple control variables. SIAM J.\nControl 4(4), 716\u2013722 (1966)\n\nB.S. Goh, Compact forms of the generalized Legendre-Clebsch conditions and the computation of\nsingular control trajectories, in Proceedings of the American Control Conference, Seattle, June\n1995, pp. 3410\u20133413. Paper No. FA19-10:35\n\nB.S. Goh, Optimal singular rocket and aircraft trajectories, in Chinese Control and Decision\nConference, Yantai, 24 July 2008\n\nE.D. Gustafson, D.J. Scheeres, Optimal timing of control-law updates for unstable systems with\ncontinuous control. J. Guid. Control Dyn. 32(3), 878\u2013887 (2009)\n\nJ.J. Guzma?n, J.L. Horsewood, Mission options for rendezvous with wild 2 in 2016 using electric\npropulsion, in AIAA/AAS Astrodynamics Conference, Keystone, 21\u201324 Aug 2006. AIAA Paper\nNo. 06-6175\n\nJ.J. Guzma?n, L.M. Mailhe, C. Schiff, S.P. Hughes, D.C. Folta, Primer vector optimization: survey\nof theory, new analysis and applications, in 53rd International Astronautical Congress, Houston,\nOct 2002. Paper No. IAC-02-A.6.09\n\nC.M. Haissig, K.D. Mease, N.X. Vinh, Canonical transformations for space trajectory optimization,\nin AIAA/AAS Astrodynamics Conference, Hilton Head Island, 10\u201312 Aug 1992. AIAA Paper\nNo.1992-4509\n\n\n\n258 Bibliography (Aerospace Applications Papers and Reports)\n\nC.D. Hall, V. Collazo-Perez, Minimum-time orbital phasing maneuvers. J. Guid. Control Dyn. 26(6),\n934\u2013941 (2003)\n\nM. Handelsman, Optimal free-space fixed-thrust trajectories using impulsive trajectories as starting\niteratives. AIAA J. 4(6), 1077\u20131082 (1966)\n\nC.R. Hargraves, S.W. Paris, Direct optimization using nonlinear programming and collocation. J.\nGuid. Control Dyn. 10(4), 338\u2013342 (1987)\n\nC. Hargraves, F. Johnson, S. Paris, I. Rettie, Numerical computation of optimal atmospheric\ntrajectories. J. Guid. Control Dyn. 4(4), 406\u2013414 (1981)\n\nG.A. Henning, J.M. Longuski, Optimization of aerogravity-assist trajectories for waveriders, in\nAAS/AIAA Astrodynamics Conference, Mackinac Island, 19\u201323 Aug 2007. AAS Paper No. 07-325\n\nT.A. Heppenheimer, Optimal controls for out-of-plane motion about the translunar libration point.\nJ. Spacecr. Rockets 7(9), 1088\u20131092 (1970)\n\nA.L. Herman, B.A. Conway, Direct optimization using collocation based on high-order Gauss-\nLobatto quadrature rules. J. Guid. Control Dyn. 19(3), 592\u2013599 (1996)\n\nA.L. Herman, B.A. Conway, Optimal, low-thrust, Earth-Moon transfer. J. Guid. Control Dyn. 21(1),\n141\u2013147 (1998)\n\nA.L. Herman, D.B. Spencer, Optimal, low-thrust Earth-orbit transfers using higher-order collocation\nmethods. J. Guid. Control Dyn. 25(1), 40\u201347 (2002)\n\nL.A. Hiday, K.C. Howell, Impulsive time-free transfers between halo orbits, in AIAA/AAS Astrody-\nnamics Conference, Hilton Head Island, 10\u201312 Aug 1992. AIAA Paper No. 92-4580\n\nL.A. Hiday, Optimal transfers between libration-point orbits in the elliptic restricted three-body\nproblem. PhD thesis, Purdue University, West Lafayette, Aug 1992\n\nY.C. Ho, J.L. Speyer, In appreciation of arthur E. Bryson, Jr. J. Guid. Control Dyn. 13(5), 770\u2013774\n(1990)\n\nD. Hocken, J. Schoenmaekers, Optimization of cluster constellation manoeuvres, in 16th Interna-\ntional Symposium on Space Flight Dynamics, Pasadena, Dec 2001\n\nJ.L. Horsewood, The optimization of low thrust interplanetary swingby trajectories, in AAS/AIAA\nAstrodynamics Conference, Santa Barbara, 19\u201321 Aug 1970. AIAA Paper No. 70-1041\n\nJ.L. Horsewood, F.I. Mann, Optimization of low-thrust heliocentric trajectories with large launch\nasymptote declinations. AIAA J. 13(10), 1304\u20131310 (1975)\n\nJ.L. Horsewood, M.A. Suskin, The effect of multi-periapse burns on planetary escape and capture, in\nAIAA/NASA/OAI Conference on Advanced SEI Technologies, Cleveland, 4\u20136 Sept 1991. AIAA\nPaper No. 91-3405\n\nJ.L. Horsewood, J.D. Vickery, Mission window definition for Jupiter swingbys to the outer planets.\nJ. Spacecr. Rockets 6(5), 525\u2013531 (1969)\n\nK.C. Howell, L.A. Hiday-Johnston, Transfers between libration points in the elliptic restricted three\nbody problem. Celest. Mech. Dyn. Astron. 58(4), 317\u2013337 (1994)\n\nK.C. Howell, B.T. Barden, M.W. Lo, Application of dynamical systems theory to trajectory design\nfor a libration point mission. J. Astronaut. Sci. 45(2), 161\u2013178 (1997)\n\nF.-K. Hsu, T.-S. Kuo, J.-S. Chern, C.-C. Lin, Optimal aeroassisted orbital plane change with heating\nrate constraint, in AIAA 26th Aerospace Sciences Meeting, Reno, 11\u201314 Jan 1988. AIAA Paper\nNo. 88-0301\n\nS.P. Hughes, L.M. Mailhe, J.J. Guzma?n, A comparison of trajectory optimization methods for\nthe impulsive minimum fuel rendezvous problem, in 26th Annual AAS Guidance and Control\nConference, Breckenridge, 5\u20139 Feb 2003. AAS Paper No. 03-006\n\nD. Izzo, Optimization of interplanetary trajectories for impulsive and continuous asteroid deflection.\nJ. Guid. Control Dyn. 30(2), 401\u2013408 (2007)\n\nD. Izzo, V.M. Becerra, D.R. Myatt, S.J. Nasuto, J.M. Bishop, Search space pruning and global\noptimisation of multiple gravity assist spacecraft trajectories. J. Glob. Optim. 38, 283\u2013296 (2007)\n\nK. Jackson, V.L. Coverstone, Optimal lunar launch trajectories to the Sun-Earth L1 vicinity. J. Guid.\nControl Dyn. 31(3), 712\u2013719 (2008)\n\nS. Jain, P. Tsiotras, Trajectory optimization using multiresolution techniques. J. Guid. Control Dyn.\n31(5), 1424\u20131436 (2008)\n\n\n\nBibliography (Aerospace Applications Papers and Reports) 259\n\nB.R. Jamison, V. Coverstone, Analytical study of the primer vector and orbit transfer switching\nfunction. J. Guid. Control Dyn. 33(1), 235\u2013245 (2010)\n\nM. Jesick, C. Ocampo, Optimal lunar orbit insertion from a variable free return with analytical\ngradients, in AIAA/AAS Astrodynamics Conference, Toronto, 2\u20135 Aug 2010. AIAA Paper No.\n2010-8388\n\nM. Jesick, C. Ocampo, Automated generation of symmetric lunar free-return trajectories. J. Guid.\nControl Dyn. 34(1), 98\u2013106 (2011)\n\nD.J. Jezewski, Primer vector theory and applications. Technical report, NASA TR R-454. NASA\nJohnson Space Center, Houston, Nov 1975\n\nD.J. Jezewski, N.L. Faust, Inequality constraints in primer-optimal, N-impulse solutions. AIAA J.\n9(4), 760\u2013763 (1971)\n\nD.J. Jezewski, H.L. Rozendaal, An efficient method for calculating optimal free-space N-impulse\ntrajectories. AIAA J. 6(11), 2160\u20132165 (1968)\n\nD.J. Jezewski, J.P. Brazzel, E.E. Prust, B.G. Brown, T.A. Mulder, D.B. Wissinger, A survey of\nrendezvous trajectory planning, in AAS/AIAA Astrodynamics Conference, Durango, Aug 1991.\nAAS Paper No. 91-505\n\nJ.-W. Jo, J.E. Prussing, Procedure for applying second-order conditions in optimal control problems.\nJ. Guid. Control Dyn. 23(2), 241\u2013250 (2000)\n\nJ.R. Johannesen, N.X. Vinh, K.D. Mease, Effect of maximum lift to drag ratio on optimal aeroassisted\nplane change, in Atmospheric Flight Mechanics Conference, Snowmass, 19\u201321 Aug 1985. AIAA\nPaper No. 85-1817\n\nW.R. Johnson, J.M. Longuski, Design of aerogravity-assist trajectories. J. Spacecr. Rockets 39(1),\n23\u201330 (2002)\n\nW.R. Johnson, J.M. Longuski, D.T. Lyons, Nondimensional analysis of reaction-wheel control for\naerobraking. J. Guid. Control Dyn. 26(6), 861\u2013868 (2003)\n\nM.D. Jokic, J.M. Longuski, Design of tether sling for human transportation systems between Earth\nand Mars. J. Spacecr. Rockets 41(6), 1010\u20131015 (2004)\n\nM.D. Jokic, J.M. Longuski, Artificial gravity and abort scenarios via tethers for human missions to\nMars. J. Spacecr. Rockets 42(5), 883\u2013889 (2005)\n\nJ.B. Jones, A solution of the variational equations for elliptic orbits in rotating coordinates, in\nAIAA/AAS Astrodynamics Conference, Danvers, 11\u201313 Aug 1980. AIAA Paper No. 80-1690\n\nJ.L. Junkins, R.C. Thompson, An asymptotic perturbation method for nonlinear optimal control\nproblems. J. Guid. Control Dyn. 9(5), 391\u2013396 (1986)\n\nJ.L. Junkins, J.D. Turner, Optimal continuous torque attitude maneuvers. J. Guid. Control Dyn. 3(3),\n210\u2013217 (1980)\n\nJ.L. Junkins, Z.H. Rahman, H. Bang, Near-minimum-time control of distributed parameter systems:\nanalytical and experimental results. J. Guid. Control Dyn. 14(2), 406\u2013415 (1991)\n\nJ.A. Kechichian, Optimal steering for North-South stationkeeping of geostationary spacecraft. J.\nGuid. Control Dyn. 20(3), 435\u2013444 (1997a)\n\nJ.A. Kechichian, Optimal low-Earth-orbit\u2013geostationary-Earth-orbit intermediate acceleration orbit\ntransfer. J. Guid. Control Dyn. 20(4), 803\u2013811 (1997b)\n\nJ.A. Kechichian, Trajectory optimization using eccentric longitude formulation. J. Spacecr. Rockets\n35(3), 317\u2013326 (1998)\n\nJ.A. Kechichian, Minimum-time low-thrust rendezvous and transfer using epoch mean longitude\nformulation. J. Guid. Control Dyn. 22(3), 421\u2013432 (1999)\n\nJ.A. Kechichian, Low-thrust trajectory optimization based on epoch eccentric longitude formulation.\nJ. Spacecr. Rockets 36(4), 543\u2013553 (1999)\n\nJ.A. Kechichian, Minimum-time constant acceleration orbit transfer with first-order oblateness effect.\nJ. Guid. Control Dyn. 23(4), 595\u2013603 (2000)\n\nJ.A. Kechichian, M.I. Cruz, E.A. Rinderle, N.X. Vinh, Optimization and closed-loop guidance of\ndrag-modulated aeroassisted orbital transfer, in AIAA Atmospheric Flight Mechanics Conference,\nGatlinburg, 15\u201317 Aug 1983. AIAA Paper No. 83-2093\n\nH.J. Kelley, A second variation test for singular extremals. AIAA J. 2, 1380\u20131382 (1964)\n\n\n\n260 Bibliography (Aerospace Applications Papers and Reports)\n\nH.J. Kelley, E.M. Cliff, F.H. Lutze, Boost-glide range-optimal guidance, in AIAA Guidance and\nControl Conference, Albuquerque, 19\u201321 Aug 1981. AIAA Paper No. 81-1781\n\nE.A. Kern, D.T. Greenwood, Minimum-fuel thrust-limited transfer trajectories between coplanar\nelliptic orbits. AIAA J. 8(10), 1772\u20131779 (1970)\n\nM. Kim, C.D. Hall, Symmetries in optimal control of solar sail spacecraft. Celest. Mech. Dyn. Astron.\n92, 273\u2013293 (2005)\n\nY.H. Kim, D.B. Spencer, Optimal spacecraft rendezvous using genetic algorithms. J. Spacecr. Rockets\n39(6), 859\u2013865 (2002)\n\nC.A. Kluever, Optimal Earth-Moon trajectories using combined chemical-electric propulsion. J.\nGuid. Control Dyn. 20(2), 253\u2013258 (1997)\n\nC.A. Kluever, K-R. Chang, Electric-propulsion spacecraft optimization for lunar missions. J. Spacecr.\nRockets 33(2), 235\u2013245 (1996)\n\nC.A. Kluever, B.L. Pierson, Optimal low-thrust three-dimensional Earth-Moon trajectories. J. Guid.\nControl Dyn. 18(4), 830\u2013837 (1995)\n\nC.A. Kluever, B.L. Pierson, Optimal Earth-Moon trajectories using nuclear propulsion. J. Guid.\nControl Dyn. 20(2), 239\u2013245 (1997)\n\nR.E. Kopp, A.G. Moyer, Necessary conditions for singular extremals. AIAA J. 3(8), 1439\u20131444\n(1965)\n\nJ.-P. Kremer, K.D. Mease, Near-optimal control of altitude and path angle during aerospace plane\nascent. J. Guid. Control Dyn. 20(4), 789\u2013796 (1997)\n\nR. Kumar, H.J. Kelley, Singular optimal atmospheric rocket trajectories. J. Guid. Control Dyn. 11(4),\n305\u2013312 (1988)\n\nD.F. Landau, J.M. Longuski, Trajectories for human missions to Mars, part 1: impulsive transfers.\nJ. Spacecr. Rockets 43(5), 1035\u20131042 (2006a)\n\nD.F. Landau, J.M. Longuski, Trajectories for human missions to Mars, part 2: low-thrust transfers.\nJ. Spacecr. Rockets 43(5), 1043\u20131047 (2006b)\n\nD.F. Landau, T. Lam, N. Strange, Broad search and optimization of solar electric propulsion\ntrajectories to Uranus and Neptune, in AAS/AIAA Astrodynamics Conference, Pittsburgh, 9\u201313\nAug 2009. AAS Paper No. 09-428\n\nD.F. Lawden, Impulsive transfer between elliptic orbits, in Optimization Techniques, ed. by G.\nLeitmann (Academy, New York, 1962), pp. 323\u2013351\n\nD.F. Lawden, Rocket trajectory optimization: 1950\u20131963. J. Guid. Control Dyn. 14(4), 705\u2013711\n(1991). Lawden gives a brief history of key technologies and some personal reflections\n\nM.A. LeCompte, T.R. Meyer, J.L. Horsewood, C.P. McKay, D.D. Durda, Early, short-duration, near-\nEarth asteroid rendezvous missions, J. Spacecr. Rockets 49(4), 731\u2013741 (2012)\n\nD. Lee, J.E. Cochran Jr., J.H. Jo, Solutions to the variational equations for relative motion of satellites.\nJ. Guid. Control Dyn. 30(3), 669\u2013678 (2007)\n\nG. Leitmann, On a class of variational problems in rocket flight. J. Aerosp. Sci. 26(9), 586\u2013591 (1959)\nC.L. Leonard, W.M. Hollister, E.V. Bergmann, Orbital formationkeeping with differential drag.\n\nJ. Guid. Control Dyn. 12(1), 108\u2013113 (1989)\nJ.M. Lewallen, B.D. Tapley, S.D. Williams, Iteration procedures for indirect trajectory optimization\n\nmethods. J. Spacecr. Rockets 5(3), 321\u2013327 (1968)\nJ.M. Lewallen, O.A. Schwausch, B.D. Tapley, Coordinate system influence on the regularized\n\ntrajectory optimization problem. J. Spacecr. Rockets 8(1), 15\u201320 (1971)\nF. Li, P.M. Bainum, Numerical approach for solving rigid spacecraft minimum time attitude\n\nmaneuvers. J. Guid. Control Dyn. 13(1), 38\u201345 (1990)\nF. Li, P.M. Bainum, Analytic time-optimal control synthesis of fourth-order system and maneuvers\n\nof flexible structures. J. Guid. Control Dyn. 17(6), 1171\u20131178 (1994)\nP.M. Lion, M. Handelsman, Primer vector on fixed-time impulsive trajectories. AIAA J. 6(1),\n\n127\u2013132 (1968)\nM.W. Lo, M.-K.J. Chung, Lunar sample return via the interplanetary superhighway, in AIAA/AAS\n\nAstrodynamics Conference, Monterey, 5\u20138 Aug 2002. AIAA Paper No. 2002-4718\n\n\n\nBibliography (Aerospace Applications Papers and Reports) 261\n\nM.W. Lo, B.G. Williams, W.E. Bollman, D. Han, Y. Hahn, J.L. Bell, E. A. Hirst, R.A. Corwin, P.E.\nHong, K.C. Howell, B. Barden, R. Wilson, Genesis mission design. J. Astronaut. Sci. 49(1), 169\u2013\n184 (2001)\n\nF.A. Lohar, A.K. Misra, D. Mateescu, Optimal atmospheric trajectory for aerogravity assist with heat\nconstraint. J. Guid. Control Dyn. 18(4), 723\u2013730 (1995)\n\nF.A. Lohar, A.K. Sherwani, A.K. Misra, Optimal transfer between coplanar elliptical orbits using\naerocruise, in AIAA/AAS Astrodynamics Conference, San Diego, 29\u201331 July 1996. AIAA Paper\nNo. 96-3594\n\nP. Lu, B. Pan, Highly constrained optimal launch ascent guidance. J. Guid. Control Dyn. 33(2), 404\u2013\n411 (2010)\n\nP. Lu, B.L. Pierson, Optimal aircraft terrain-following analysis and trajectory generation. J. Guid.\nControl Dyn. 18(3), 555\u2013560 (1995)\n\nP. Lu, N.X. Vinh, Optimal control problems with maximum functional. J. Guid. Control Dyn. 14(6),\n1215\u20131223 (1991)\n\nP. Lu, B.J. Griffin, G.A. Dukeman, F.R. Chavez, Rapid optimal multiburn ascent planning and\nguidance. J. Guid. Control Dyn. 31(6), 1656\u20131664 (2008)\n\nD.T. Lyons, E. Sklyanskiy, J. Casoliva, A.A. Wolf, Parametric optimization and guidance for an aero-\ngravity assisted atmospheric sample return from Mars and Venus, in AIAA/AAS Astrodynamics\nConference, Honolulu, 18\u201321 Aug 2008. AIAA Paper No. 2008\u20137353\n\nM. Mangad, M.D. Schwartz, Guidance, flight mechanics and trajectory optimization. Volume IV:\nthe calculus of variations and modern applications. NASA contractor report, NASA CR-1003,\nWashington, D.C., Jan 1968\n\nJ.E. Marsden, S.D. Ross, New methods in celestial mechanics and mission design. Bull. Am. Math.\nSoc. 43, 43\u201373 (2005)\n\nJ.V. McAdams, J.L. Horsewood, C.L. Yen, Discovery-class Mercury orbiter trajectory design for the\n2005 launch opportunity, in Astrodynamics Conference, Boston, 10\u201312 Aug 1998. AIAA Paper\nNo. 98-4283\n\nJ.V. McAdams, D.W. Dunham, R.W. Farquhar, A.H. Taylor, B.G. Williams, Trajectory design and\nmaneuver strategy for the MESSENGER mission to Mercury. J. Spacecr. Rockets 43(5), 1054\u2013\n1064 (2006)\n\nT.T. McConaghy, J.M. Longuski, Parameterization effects on convergence when optimizing a low-\nthrust trajectory with gravity assists, in AIAA/AAS Astrodynamics Conference, Providence, 16\u201319\nAug 2004. AIAA Paper No. 2004-5403\n\nT.T. McConaghy, T.J. Debban, A.E. Petropoulos, J.M. Longuski, Design and optimization of low-\nthrust trajectories with gravity assists. J. Spacecr. Rockets 40(3), 380\u2013387 (2003)\n\nT.T. McConaghy, J.M. Longuski, D.V. Byrnes, Analysis of a class of Earth-Mars cycler trajectories.\nJ. Spacecr. Rockets 41(4), 622\u2013628 (2004)\n\nJ.P. McDanell, W.F. Powers, Necessary conditions for joining optimal singular and nonsingular\nsubarcs. SIAM J. Control 9(2), 161\u2013173 (1971)\n\nJ.E. McIntyre, Guidance, flight mechanics and trajectory optimization. Volume VII: the Pontryagin\nmaximum principle. NASA contractor report, NASA CR-1006, Washington, D.C., Mar 1968\n\nE.J. McShane, On multipliers for lagrange problems. Am. J. Math. 61(4), 809\u2013819 (1939)\nK.D. Mease, N.X. Vinh, Minimum-fuel aeroassisted coplanar orbit transfer using lift modulation. J.\n\nGuid. Control Dyn. 8(1), 134\u2013141 (1985)\nK.D. Mease, N.X. Vinh, S.H. Kuo, Optimal plane change during constant altitude hypersonic flight.\n\nJ. Guid. Control Dyn. 14(4), 797\u2013806 (1991)\nS. Medepalli, N.X. Vinh, A Lie bracket solution of the optimal thrust magnitude on a singular arc in\n\natmospheric flight, in AIAA Atmospheric Flight Mechanics Conference, Hilton, 10\u201312 Aug 1992.\nAIAA Paper No. 1992-4345\n\nW.G. Melbourne, C.G. Sauer Jr., Optimum interplanetary rendezvous with power-limited vehicles.\nAIAA J. 1(1), 54\u201360 (1963)\n\nW.G. Melbourne, C.G. Sauer Jr., Constant-attitude thrust program optimization. AIAA J. 3(8), 1428\u2013\n1431 (1965)\n\n\n\n262 Bibliography (Aerospace Applications Papers and Reports)\n\nR.G. Melton, Comparison of direct optimization methods applied to solar sail problems, in AIAA/AAS\nAstrodynamics Conference, Monterey, 5\u20138 Aug 2002. AIAA Paper No. 2002-4728\n\nR.G. Melton, D.S. Rubenstein, H.L. Fisher, Optimum detumbling of space platforms via a dynamic\nprogramming algorithm, in AIAA Guidance, Navigation and Control Conference, Williamsburg,\n18\u201320 Aug 1986. AIAA Paper No. 86-2154\n\nR.G. Melton, K.M. Lajoie, J.W. Woodburn, Optimum burn scheduling for low-thrust orbital transfers.\nJ. Guid. Control Dyn. 12(1), 13\u201318 (1989)\n\nA. Miele, Flight mechanics and variational problems of a linear type. J. Aerosp. Sci. 25(9), 581\u2013590\n(1958)\n\nA. Miele, M.W. Weeks, M. Ciarcia?, Optimal trajectories for spacecraft rendezvous. J. Optim. Theory\nAppl. 132, 353\u2013376 (2007)\n\nW.E. Miner, J.F. Andrus, Necessary conditions for optimal lunar trajectories with discontinuous\nstate variables and intermediate point constraints. NASA technical memorandum, TM X-1353,\nWashington, D.C., Apr 1967\n\nR.S. Nah, S.R. Vadali, E. Braden, Fuel-optimal, low-thrust, three-dimensional Earth-Mars trajecto-\nries. J. Guid. Control Dyn. 24(6), 1100\u20131107 (2001)\n\nM. Okutsu, C.H. Yam, J.M. Longuski, Low-thrust trajectories to Jupiter via gravity assists from\nVenus, Earth, and Mars, in AIAA/AAS Astrodynamics Conference, Keystone, 21\u201324 Aug 2006.\nAIAA Paper No. 2006-6745\n\nB. Paiewonsky, Optimal control: a review of theory and practice. AIAA J. 3(11), 1985\u20132006 (1965)\nB. Paiewonsky, P.J. Woodrow, Three-dimensional time-optimal rendezvous. J. Spacecr. Rockets\n\n3(11), 1577\u20131584 (1966)\nS.W. Paris, J.P. Riehl, W.K. Sjauw, Enhanced procedures for direct trajectory optimization using non-\n\nlinear programming and implicit integration, in AIAA/AAS Astrodynamics Conference, Keystone,\n21\u201324 Aug 2006. AIAA Paper No. 2006-6309\n\nS.-Y. Park, S.R. Vadali, Touch points in optimal ascent trajectories with first-order state inequality\nconstraints. J. Guid. Control Dyn. 21(4), 603\u2013610 (1998)\n\nC. Park, V. Guibout, D.J. Scheeres, Solving optimal continuous thrust rendezvous problems with\ngenerating functions. J. Guid. Control Dyn. 29(2), 321\u2013331 (2006)\n\nH.J. Pernicka, D.P. Scarberry, S.M. Marsh, T.H. Sweetser, A search for low ?V Earth-to-Moon\ntrajectories, in AIAA/AAS Astrodynamics Conference, Scottsdale, 1\u20133 Aug 1994. AIAA Paper\nNo. 94-3772\n\nA.E. Petropoulos, J.M. Longuski, Shape-based algorithm for automated design of low-thrust, gravity-\nassist trajectories. J. Spacecr. Rockets 41(5), 787\u2013796 (2004)\n\nA.E. Petropoulos, R.P. Russell, Low-thrust transfers using primer vector theory and a second-order\npenalty method, in AIAA/AAS Astrodynamics Conference, Honolulu, 18\u201321 Aug 2008. AIAA\nPaper No. 2008-6955\n\nA.E. Petropoulos, G.J. Whiffen, J.A. Sims, Simple control laws for continuous-thrust escape or\ncapture and their use in optimisation, in AIAA/AAS Astrodynamics Conference, Monterey, 5\u20138\nAug 2002. AIAA Paper No. 2002-4900\n\nB.L. Pierson, C.A. Kluever, Three-stage approach to optimal low-thrust Earth-Moon trajectories. J.\nGuid. Control Dyn. 17(6), 1275\u20131282 (1994)\n\nM. Pontani, Simple methods to determine globally optimal orbit transfers. J. Guid. Control Dyn.\n32(3), 899\u2013914 (2009)\n\nM. Pontani, B.A. Conway, Optimal interception of evasive missile warheads: numerical solution of\nthe differential game. J. Guid. Control Dyn. 31(4), 1111\u20131122 (2008)\n\nW.F. Powers, Hamiltonian perturbation theory for optimal trajectory analysis. M.S. thesis, Depart-\nment of Aerospace Engineering and Engineering Mechanics, The University of Texas, Austin,\n1966\n\nW.F. Powers, On the order of singular optimal control problems. J. Optim. Theory Appl. 32(4), 479\u2013\n489 (1980)\n\nW.F. Powers, J.P. McDanell, Switching conditions and a synthesis technique for the singular saturn\nguidance problem. J. Spacecr. Rockets 8(10), 1027\u20131032 (1971)\n\n\n\nBibliography (Aerospace Applications Papers and Reports) 263\n\nW.F. Powers, B.D. Tapley, Canonical transformation applications to optimal trajectory analysis.\nAIAA J. 7(3), 394\u2013399 (1969)\n\nW.F. Powers, B.-D. Cheng, E.R. Edge, Singular optimal control computation. J. Guid. Control, 1(1),\n83\u201389 (1978)\n\nJ.E. Prussing, Optimal four-impulse fixed-time rendezvous in the vicinity of a circular orbit. AIAA J.\n7(5), 928\u2013935 (1969)\n\nJ.E. Prussing, Optimal two- and three-impulse fixed-time rendezvous in the vicinity of a circular\norbit. AIAA J. 8(7), 1221\u20131228 (1970)\n\nJ.E. Prussing, Optimal impulsive linear systems: sufficient conditions and maximum number of\nimpulses. J. Astronaut. Sci. 43(2), 195\u2013206 (1995)\n\nJ.E. Prussing, A class of optimal two-impulse rendezvous using multiple revolution Lambert\nsolutions. J. Astronaut. Sci. 48(2\u20133), 131\u2013148 (2000)\n\nJ.E. Prussing, J.-H. Chiu, Optimal multiple-impulse time-fixed rendezvous between circular orbits. J.\nGuid. Control 9(1), 17\u201322 (1986)\n\nJ.E. Prussing, S.L. Sandrik, Second-order necessary conditions and sufficient conditions applied to\ncontinuous-thrust trajectories. J. Guid. Control Dyn. (Engineering Note) 28(4), 812\u2013816 (2005)\n\nJ. Puig-Suari, Optimal mass flexible tethers for aerobraking maneuvers. J. Guid. Control Dyn. 20(5),\n1018\u20131024 (1997)\n\nU.P. Rajeev, M. Seetharama Bhat, S. Dasgupta, Predicted target flat Earth guidance algorithm for\ninjection in to a fixed ellipse using iteration unfolding, in AIAA Guidance, Navigation, and Control\nConference, Providence, 16\u201319 Aug 2004. AIAA Paper No. 2004\u20134902\n\nC.L. Ranieri, C.A. Ocampo, Optimization of roundtrip, time-constrained, finite burn trajectories via\nan indirect method. J. Guid. Control Dyn. 28(2), 306\u2013314 (2005)\n\nC.L. Ranieri, C.A. Ocampo, Indirect optimization of spiral trajectories. J. Guid. Control Dyn. 29(6),\n1360\u20131366 (2006)\n\nC.L. Ranieri, C.A. Ocampo, Indirect optimization of two-dimensional finite burning interplanetary\ntransfers including spiral dynamics. J. Guid. Control Dyn. 31(3), 720\u2013728 (2008)\n\nC.A. Renault, D.J. Scheeres, Optimal placement of statistical maneuvers in an unstable orbital\nenvironment, in AIAA/AAS Astrodynamics Conference, Monterey, 5\u20138 Aug 2002. AIAA Paper\nNo. 2002-4725\n\nH.M. Robbins, A generalized Legendre-Clebsch condition for the singular cases of optimal control.\nIBM J. Res. Dev. 11(4), 361\u2013372 (1967)\n\nR.D. Robinett, G.G. Parker, H. Schaub, J.L. Junkins, Lyapunov optimal saturated control for\nnonlinear systems. J. Guid. Control Dyn. 20(6), 1083\u20131088 (1997)\n\nJ. Rodr??guez-Canabal, M. Bello?-Mora, Cluster: consolidated report on mission analysis. Technical\nreport, ESOC CL-ESC-RP-0001, European Space Operation Centre, Darmstadt, July 1990\n\nI.M. Ross, Extremal angle of attack over a singular thrust arc in rocket flight. J. Guid. Control Dyn.\n(Engineering Note) 20(2), 391\u2013393 (1997)\n\nI.M. Ross, S.-Y. Park, S.D.V. Porter, Gravitational effects of Earth in optimizing ?V for deflecting\nEarth-crossing asteroids. J. Spacecr. Rockets 38(5), 759\u2013764 (2001)\n\nI.M. Ross, C. D\u2019Souza, F. Fahroo, J.B. Ross, A fast approach to multi-stage launch vehicle trajectory\noptimization, in AIAA Guidance, Navigation, and Control Conference, Austin, 11\u201314 Aug 2003.\nAIAA Paper No. 2003-5639\n\nR.P. Russell, Primer vector theory applied to global low-thrust trade studies. J. Guid. Control Dyn.\n30(2), 460\u2013472 (2007)\n\nR.P. Russell, C.A. Ocampo, Global search for idealized free-return Earth-Mars cyclers. J. Guid.\nControl Dyn. 28(2), 194\u2013208 (2005)\n\nR.P. Russell, C.A. Ocampo, Optimization of a broad class of ephemeris model Earth-Mars Cyclers.\nJ. Guid. Control Dyn. 29(2), 354\u2013367 (2006)\n\nR.P. Russell, N.J. Strange, Cycler trajectories in planetary moon systems. J. Guid. Control Dyn. 32(1),\n143\u2013157 (2009)\n\nL.L. Sackett, T.N. Edelbaum, Optimal high- and low-thrust geocentric transfer, in AIAA Mechanics\nand Control of Flight Conference, Anaheim, 5\u20139 Aug 1974. AIAA Paper No. 74-801\n\n\n\n264 Bibliography (Aerospace Applications Papers and Reports)\n\nC.G. Sauer Jr., Optimization of multiple target electric propulsion trajectories, in AIAA 11th\nAerospace Sciences Meeting, Washington, D.C., 10\u201312 Jan 1973. AIAA Paper No. 73-205\n\nC.G. Sauer Jr., Optimum solar-sail interplanetary trajectories, in AIAA/AAS Astrodynamics Confer-\nence, San Diego, 18\u201320 Aug 1976. AIAA Paper No. 76-792\n\nH. Schaub, J.L. Junkins, R.D. Robinett, New penalty functions and optimal control formulation for\nspacecraft attitude control problems. J. Guid. Control Dyn. 20(3), 428\u2013434 (1997)\n\nW.A. Scheel, B.A. Conway, Optimization of very-low thrust, many-revolution spacecraft trajectories.\nJ. Guid. Control Dyn. 17(6), 1185\u20131192 (1994)\n\nJ. Schoenmaekers, Cluster: fuel optimum spacecraft formation control, in ESA Symposium on\nSpace Flight Dynamics, Darmstadt, Dec 1991, ESA SP-326 (European Space Agency, 1991),\npp. 419\u2013425\n\nJ. Schoenmaekers, Post-launch optimisation of the SMART-1 low-thrust trajectory to the Moon, in\n18th International Symposium on Space Flight Dynamics, Munich, 11\u201315 Oct 2004, ESA SP-548,\npp. 505\u2013510\n\nJ. Schoenmaekers, D. Horas, J.A. Pulido, SMART-1: with solar electric propulsion to the Moon, in\n16th International Symposium on Space Flight Dynamics, Pasadena, 3\u20137 Dec 2001\n\nC.J. Scott, D.B. Spencer, Optimal reconfiguration of satellites in formation. J. Spacecr. Rockets 44(1),\n230\u2013239 (2007)\n\nS.L. Scrivener, R.C. Thompson, Survey of time-optimal attitude maneuvers. J. Guid. Control Dyn.\n17(2), 225\u2013233 (1994)\n\nM.R. Sentinella, L. Casalino, Hybrid evolutionary algorithm for the optimization of interplanetary\ntrajectories. J. Spacecr. Rockets 46(2), 365\u2013372 (2009)\n\nR. Serban, W.S. Koon, M. Lo, J.E. Marsden, L.R. Petzold, S.D. Ross, R.S. Wilson, Optimal control\nfor halo orbit missions. in IFAC Workshop on Lagrangian and Hamiltonian Methods for Nonlinear\nControl, Princeton University, Princeton, 16\u201318 Mar 2000\n\nH. Seywald, E.M. Cliff, Goddard problem in the presence of a dynamic pressure limit. J. Guid.\nControl Dyn. 16(4), 776\u2013781 (1993a)\n\nH. Seywald, E.M. Cliff, The generalized Legendre-Clebsch condition on state/control constrained\nArcs, in AIAA Guidance, Navigation, and Control Conference, Monterey, 11\u201313 Aug 1993b.\nAIAA Paper No. 93\u20133746\n\nH. Seywald, E.M. Cliff, Neighboring optimal control based feedback law for the advanced launch\nsystem. J. Guid. Control Dyn. 17(6), 1154\u20131162 (1994)\n\nH. Seywald, R.R. Kumar, Singular control in minimum time spacecraft reorientation. J. Guid. Control\nDyn. 16(4), 686\u2013694 (1993)\n\nH. Seywald, R.R. Kumar, E.M. Cliff, New proof of the Jacobi necessary condition. J. Guid. Control\nDyn. (Engineering Note) 16(6), 1178\u20131181 (1993)\n\nU. Shankar, E. Cliff, H. Kelley, Singular perturbations analysis of optimal climb-cruise-dash, in AIAA\nGuidance, Navigation, and Control Conference, Monterey, 17\u201319 Aug 1987. AIAA Paper No.\n87-2511\n\nU. Shankar, E. Cliff, H. Kelley, Relaxation oscillations in aircraft cruise-dash optimization, in AIAA\nGuidance, Navigation, and Control Conference, Minneapolis, 15\u201317 Aug 1988a. AIAA Paper\nNo. 88-4161\n\nU. Shankar, E. Cliff, H. Kelley, Aircraft cruise-dash optimization: periodic versus steady-state\nsolutions, in AIAA Guidance, Navigation, and Control Conference, Minneapolis, 15\u201317 Aug\n1988b. AIAA Paper No. 88-4162\n\nH. Shen, P. Tsiotras, Time-optimal control of axisymmetric rigid spacecraft using two controls. J.\nGuid. Control Dyn. 22(5), 682\u2013694 (1999)\n\nH. Shen, P. Tsiotras, Optimal two-impulse rendezvous using multiple-revolution Lambert solutions.\nJ. Guid. Control Dyn. 26(1), 50\u201361 (2003)\n\nJ.A. Sims, A.J. Staugler, J.M. Longuski, Trajectory options to Pluto via gravity assists from Venus,\nMars, and Jupiter. J. Spacecr. Rockets 34(3), 347\u2013353 (1997)\n\nJ.A. Sims, P.A. Finlayson, E.A. Rinderle, M.A. Vavrina, T.D. Kowalkowski, Implementation of a\nlow-thrust trajectory optimization algorithm for preliminary design, in AIAA/AAS Astrodynamics\nConference, Keystone, 21\u201324 Aug 2006. AIAA Paper No. 2006-6746\n\n\n\nBibliography (Aerospace Applications Papers and Reports) 265\n\nT. Singh, S.R. Vadali, Robust time-optimal control: frequency domain approach. J. Guid. Control\nDyn. 17(2), 346\u2013353 (1994)\n\nJ.L. Speyer, A.E. Bryson Jr., Optimal programming problems with a bounded state space. AIAA J.\n6(8), 1488\u20131491, (1968)\n\nS.A. Stanton, B.G. Marchand, Finite set control transcription for optimal control applications. J.\nSpacecr. Rockets 47(3), 457\u2013471 (2010)\n\nR.G. Stern, Singularities in the analytic solution of the linearized variational equations of elliptical\nmotion. Technical report, Report RE-8, Experimental Astronomy Laboratory, Massachusetts\nInstitute of Technology, Cambridge, May 1964\n\nR. Stevens, I.M. Ross, Preliminary design of Earth-Mars cyclers using solar sails. J. Spacecr. Rockets\n42(1), 132\u2013137 (2005)\n\nK.S. Tait, Singular problems in optimal control. PhD thesis, Harvard University, Cambridge, 1965\nZ. Tan, P.M. Bainum, Optimal linear quadratic Gaussian digital control of an orbiting tethered\n\nantenna/reflector system. J. Guid. Control Dyn. 17(2), 234\u2013241 (1994)\nB.D. Tapley, V. Szebehely, J.M. Lewallen, Trajectory optimization using regularized variables. AIAA\n\nJ. 7(6), 1010\u20131017 (1969)\nD.-R. Taur, V. Coverstone-Carroll, J.E. Prussing, Optimal impulsive time-fixed orbital rendezvous\n\nand interception with path constraints. J. Guid. Control Dyn. 18(1), 54\u201360 (1995)\nJ.D. Thorne, C.D. Hall, Minimum-time continuous-thrust orbit transfers using the Kustaanheimo-\n\nStiefel transformation. J. Guid. Control Dyn. (Engineering Note) 20(4), 836\u2013838 (1997)\nS.G. Tragesser, A. Tuncay, Orbital design of Earth-oriented tethered satellite formations, in AIAA/AAS\n\nAstrodynamics Conference, Monterey, 5\u20138 Aug 2002. AIAA Paper No. 2002-4641\nS.G. Tragesser, J.M. Longuski, J. Puig-Suari, J.P. Mechalas, Analysis of the optimal mass problem for\n\naerobraking tethers, in AIAA/AAS Astrodynamics Conference, Scottsdale, 1\u20133 Aug 1994. AIAA\nPaper No. 94-3747\n\nS.G. Tragesser, J.M. Longuski, J. Puig-Suari, Global minimum mass for aerobraking tethers. J. Guid.\nControl Dyn. (Engineering Note) 20(6), 1260\u20131262 (1997)\n\nE. Tre?lat, Optimal control and applications to aerospace: some results and challenges. J. Optim.\nTheory Appl. 154(3), 713\u2013758 (2012)\n\nP. Tsiotras, Optimal regulation and passivity results for axisymmetric rigid bodies using two controls.\nJ. Guid. Control Dyn. 20(3), 457\u2013463 (1997)\n\nP. Tsiotras, H.J. Kelley, Goddard problem with constrained time of flight. J. Guid. Control Dyn. 15(2),\n289\u2013296 (1992)\n\nS.R. Vadali, J.L. Junkins, Spacecraft large angle rotational maneuvers with optimal momentum\ntransfer, in AIAA/AAS Astrodynamics Conference, San Diego, 9\u201311 Aug 1982. AIAA Paper No.\n82-1469\n\nS.R. Vadali, R. Sharma, Optimal finite-time feedback controllers for nonlinear systems with terminal\nconstraints. J. Guid. Control Dyn. 29(4), 921\u2013928 (2006)\n\nS.R. Vadali, R. Nah, E. Braden, I.L. Johnson Jr., Fuel-optimal planar Earth-Mars trajectories using\nlow-thrust exhaust-modulated propulsion. J. Guid. Control Dyn. 23(3), 476\u2013482 (2000)\n\nM. Vasile, E. Minisci, M. Locatelli, On testing global optimization algorithms for space trajectory\ndesign, in AIAA/AAS Astrodynamics Conference, Honolulu, 18\u201321 Aug 2008. AIAA Paper No.\n2008-6277\n\nM.A. Vavrina, K.C. Howell, Global low-thrust trajectory optimization through hybridization of a\ngenetic algorithm and a direct method, in AIAA/AAS Astrodynamics Conference, Honolulu, 18\u2013\n21 Aug 2008. AIAA Paper No. 2008-6614\n\nN.X. Vinh, Cuspidal point on the primer locus. AIAA J. 9(11), 2239\u20132244 (1971)\nN.X. Vinh, Minimum fuel rocket maneuvers in horizontal flight. AIAA J. 11(2), 165\u2013169 (1973a)\nN.X. Vinh, Integrals of the motion for optimal trajectories in atmospheric flight. AIAA J. 11(5),\n\n700\u2013703 (1973b)\nN.X. Vinh, Optimal control of orbital transfer vehicles, in AIAA Atmospheric Flight Mechanics\n\nConference, Gatlinburg, 15\u201317 Aug 1983. AIAA Paper No. 83-2092\nN.X. Vinh, D.-M. Ma, Optimal plane change by low aerodynamic forces, in AIAA Atmospheric Flight\n\nMechanics Conference, Portland, 20\u201322 Aug 1990. AIAA Paper No. 90-2831\n\n\n\n266 Bibliography (Aerospace Applications Papers and Reports)\n\nN.X. Vinh, C.-Y. Yang, J.-S. Chern, Optimal trajectories for maximum endurance gliding in a\nhorizontal plane. J. Guid. Control Dyn. 7(2), 246\u2013248 (1984)\n\nN.X. Vinh, J.R. Johannesen, K.D. Mease, J.M. Hanson, Explicit guidance of drag-modulated\naeroassisted transfer between elliptical orbits. J. Guid. Control Dyn. 9(3), 274\u2013280 (1986)\n\nN.X. Vinh, P.T. Kabamba, T. Takehira, Optimal interception of a maneuvering long range missile, in\nAIAA/AAS Astrodynamics Conference, Boston, 10\u201312 Aug 1998. AIAA Paper No. 98-4547\n\nB.J. Wall, B.A. Conway, Shape based approach to low-thrust rendezvous trajectory design. J. Guid.\nControl Dyn. 32(1), 95\u2013101 (2009)\n\nP.K.C. Wang, F.Y. Hadaegh, Optimal formation reconfiguration for multiple spacecraft, in AIAA\nGuidance, Navigation, and Control Conference, Boston, 10\u201312 Aug 1998. AIAA Paper No.\n98-4226\n\nL.J. Wellnitz, J.E. Prussing, Optimal trajectories for time-constrained rendezvous between arbitrary\nconic orbits, in AAS/AIAA Astrodynamics Conference, Kalispell, 10\u201313 Aug 1987. AAS Paper\nNo. 87-539\n\nJ.R. Wertz, Rapid interplanetary round trips at moderate energy, in International Astronautics\nFederation Congress, Vancouver, 4\u20138 Oct 2004. Paper No. IAC-04-Q.2.A.11\n\nJ.R. Wertz, T.L. Mullikin, R.F. Brodsky, Reducing the cost and risk of orbit transfer. J. Spacecr.\nRockets 25(1), 75\u201380 (1988)\n\nG. Whiffen, Mystic: implementation of the static dynamic optimal control algorithm for high-fidelity,\nlow-thrust trajectory design, in AIAA/AAS Astrodynamics Conference, Keystone, 21\u201324 Aug\n2006. Paper No. 06-2356\n\nB. Wie, C.-H. Chuang, J. Sunkel, Minimum-time pointing control of a two link manipulator. J. Guid.\nControl Dyn. 13(5), 867\u2013873 (1990)\n\nB. Wie, R. Sinha, J. Sunkel, K. Cox, Robust fuel- and time-optimal control of uncertain flexible space\nstructures, in AIAA Guidance, Navigation, and Control Conference, Monterey, 11\u201313 Aug 1993.\nAIAA Paper No. 93-3804\n\nP. Williams, Optimal control of a tethered payload capture maneuver, in 41st AIAA/ASME/SAE/ASEE\nJoint Propulsion Conference, Tucson, 10\u201313 July 2005. AIAA Paper No. 2005-4114\n\nP. Williams, Optimal deployment/retrieval of a tethered formation spinning in the orbital plane.\nJ. Spacecr. Rockets 43(3), 638\u2013650 (2006a)\n\nP. Williams, Optimal deployment and offset control for a spinning flexible tethered formation, in\nAIAA Guidance, Navigation, and Control Conference, Keystone, 21\u201324 Aug 2006b. AIAA Paper\nNo. 2006-6041\n\nS.N. Williams, V. Coverstone-Carroll, Mars missions using solar electric propulsion. J. Spacecr.\nRockets 37(1), 71\u201377 (2000)\n\nE.A. Williams, W.A. Crossley, Empirically-derived population size and mutation rate guidelines\nfor a genetic algorithm with uniform crossover. in Soft Computing in Engineering Design and\nManufacturing, ed. by P.K. Chawdhry, R. Roy, R.K. Pant (Springer, London/New York, 1998),\npp. 163\u2013172\n\nP. Williams, P. Trivailo, On the optimal deployment and retrieval of tethered satellites, in 41st\nAIAA/ASME/SAE/ASEE Joint Propulsion Conference, Tucson, 10\u201313 July 2005. AIAA Paper No.\n2005-4291\n\nP. Williams, C. Blanksby, P. Trivailo, Tethered planetary capture maneuvers. J. Spacecr. Rockets\n41(4), 603\u2013613 (2004)\n\nR.S. Wilson, K.C. Howell, M. Lo, Optimization of insertion cost for transfer trajectories to libration\npoint orbits, in AIAA/AAS Astrodynamics Conference, Girdwood, 16\u201319 Aug 1999. AAS Paper\nNo. 99-041\n\nB. Woo, V.L. Coverstone, M. Cupples, Low-thrust trajectory optimization procedure for gravity-\nassist, outer-planet missions. J. Spacecr. Rockets 43(1), 121\u2013129 (2006)\n\nL.J. Wood, Perturbation guidance for minimum time flight paths of spacecraft, in AIAA/AAS\nAstrodynamics Conference, Palo Alto, 11\u201312 Sept 1972. AIAA Paper No. 72-915\n\nL.J. Wood, Second-order optimality conditions for the Bolza problem with both endpoints variable.\nJ. Aircr. 11(4), 212\u2013221 (1974)\n\n\n\nBibliography (Aerospace Applications Papers and Reports) 267\n\nL.J. Wood, A.E. Bryson Jr., Second-order optimality conditions for variable end time terminal control\nproblems. AIAA J. 11(9), 1241\u20131246 (1973)\n\nC.H. Yam, J.M. Longuski, Reduced parameterization for optimization of low-thrust gravity-assist\ntrajectories: case studies, in AIAA/AAS Astrodynamics Conference, Keystone, 21\u201324 Aug 2006.\nAIAA Paper No. 2006-6744\n\nH. Yan, K.T. Alfriend, S.R. Vadali, P. Sengupta, Optimal design of satellite formation relative motion\norbits using least-squares methods. J. Guid. Control Dyn. 32(2), 599\u2013604 (2009)\n\nS. Zimmer, C. Ocampo, Use of analytical gradients to calculate optimal gravity-assist trajectories.\nJ. Guid. Control Dyn. 28(2), 324\u2013332 (2005a)\n\nS. Zimmer, C. Ocampo, Analytical gradients for gravity-assist trajectories using constant specific\nimpulse engines. J. Guid. Control Dyn. 28(4), 753\u2013760 (2005b)\n\n\n\nIndex\n\nA\nAbnormal problem, 106, 107, 109\nAccelerated climb, 135, 136\nAccessory minimum problem, 124\nAdjoined method, 63, 64, 69, 71, 80, 83, 87\nAdmissible function\n\nprovocative example involving, 28\u201336\nAircraft\n\ncrosswind, in a, 35, 58\nequations of motion, 131\nfree-body diagram, 131, 133\nperformance optimization, 131\u2013140\n\nAnderson, J.D. Jr., 140\nApollo guidance system, 80\nAstronaut transfer, 127\nAthans, M., 107\nAtmospheric drag, 19, 157\u2013163\n\nB\nBead on a wire, 128\nBell, E.T., 24\nBerkovitz, L.D., 106, 107\nBernoulli, J., 23\u201325, 37, 39, 56\nBi-elliptic transfer, 10\u201312\nBi-linear tangent steering law, 77, 150, 207, 209\nBi-parabolic transfer, 10\u201312, 17\nBliss, G.A., 27, 167\nBoat crossing a river, Zermelo\u2019s problem of,\n\n34\u201335, 58\u201359, 73\nBolza, O., 26, 167\nBoundary conditions, 12, 21, 44, 45, 50, 52, 53,\n\n55\u201357, 61\u201363, 65, 67, 68, 88, 90, 92, 102,\n126, 136, 149\u2013150, 153, 157, 171\u2013172,\n200, 201, 206\n\nBrachistochrone problem, 23\u201326, 37, 39, 41\u201345\nBreakwell, J.V., 193, 199\n\nBryson, A.E. Jr., 5, 26, 51, 52, 63, 64, 69, 70,\n92, 96, 105, 122, 126, 155, 156, 167,\n176, 186, 187\n\nbvp4c. See MATLAB\n\nC\nCalculus of variations, 25, 39, 43, 56, 57, 127,\n\n186, 199, 209\nCandidate optimal solution, 119\nCharacteristic velocity, 155, 196\nCitron, S.J., 53, 63, 64, 82, 97\nClasses of functions, 29, 33, 34\nConjugate point, 63, 121\u2013127, 167\nConservation\n\nof angular momentum, 8\nof total mechanical energy, 8, 24\n\nConstant\nacceleration, 19, 75, 145, 146, 148, 155, 156,\n\n161\nHamiltonian, 47, 58, 89\u201390, 93, 138, 164,\n\n202, 206\nmass flow rate, 161, 195, 198, 209\nspecific impulse (CSI) engine, 195, 196, 198,\n\n199, 202, 206, 207, 209\nthrust, 19, 76, 91, 127, 145, 148, 155, 161,\n\n195, 198, 199, 206, 207, 209\nConstraints\n\nequality, 175\ninequality, 23, 175, 176\nstate variable inequality (SVIC), 211\n\nContensou, P., 187\nContinuous, 1, 6, 28\u201331, 33, 56, 78, 95, 97, 101,\n\n102, 105, 106, 121, 127, 148, 167, 170,\n173, 195, 202\u2013204, 206, 209\u2013211\n\nContinuously differentiable, 29, 33, 56, 95,\n105\n\nJ.M. Longuski et al., Optimal Control with Aerospace Applications,\nSpace Technology Library 32, DOI 10.1007/978-1-4614-8945-0,\n\u00a9 Springer Science+Business Media New York 2014\n\n269\n\n\n\n270 Index\n\nControl\nadmissible, 23, 28, 29, 32, 37, 47, 96, 97,\n\n102, 105, 106, 127, 211\nbang-bang, 86, 88, 95, 105, 179, 201\nblip, 96, 119\nbounded, 48, 56, 85, 86, 89, 95, 106, 164,\n\n175\u2013191\ninterior, 84, 112, 127\nmagnitude, 32, 160, 198, 200, 201\nunbounded, 48, 56, 78, 84\u201385, 95, 96, 102,\n\n105, 128\nunconstrained, 47, 48, 51, 55, 56\n\nControl-effect weighting factor, 70\nConway, B.A., 7, 12, 193, 196\nCookbook for optimization problems, 82\u201389,\n\n102\nCorner, 4, 29, 31, 167\u2013171, 173\u2013174, 202, 203,\n\n211\nCost\n\nfunction, 1, 3, 22, 26, 28, 29, 36, 44, 47,\n51\u201353, 57, 63, 69, 89, 108, 109, 111, 114,\n120, 124, 142, 195\u2013198, 205, 208\n\nfunctional for rocket engines, 195\u2013198\nsensitivity to change in initial state, 51\n\nCostates, 50, 56, 65, 76, 79, 81, 90, 106, 108,\n125, 126, 128, 156, 157, 159, 160, 164,\n173, 199, 209\n\nCusp, 203\nCycloid, 24, 43\n\nD\nDenham, W., 139\nDido, Princess, 176\nDifferential form of the transversality condition,\n\n53, 55, 63, 64, 66, 71, 79, 83\u201384, 87,\n108, 109, 123, 137, 143, 159, 172, 179\n\nDirac delta function, 29, 30, 37, 102, 202\nDiscontinuous jumps, 29, 31, 97, 173\nDive, 135\u2013137, 139, 166\nDrag, 19, 20, 131, 134\u2013136, 140, 157\u2013162, 165\nDrag coefficient, 158\n\nE\nEdelbaum, T.N., 10\nEffective exhaust velocity, 13, 14, 141, 193,\n\n194\nElectric rocket engine, 194\nEnergy height, 135, 136, 138, 139, 166\nEnergy method, 135\nEuler-Lagrange equation, 25, 26, 39, 41\u201345, 49,\n\n56, 71, 74, 76, 83, 87, 90, 105, 122, 123,\n125, 142, 159, 167, 177, 178, 183, 189\n\nEuler-Lagrange theorem, 39\u201359, 61\u201393, 95, 99,\n102, 112, 116, 137, 168, 170\n\nEwing, G.M., 97, 101, 106\nExcess power, 135, 136, 138\u2013140, 166\nExhaust power, 197\nExponential atmosphere, 158, 161, 162\nExtremum, 1\n\nF\nFalb, P.L., 107\nFinal endpoint state specified, 68\nFinal time specified, 65\nFinite dimensions, problem of, 1\nFirst-order necessary conditions, 4, 124, 126,\n\n198\u2013206\nFirst variation, 39, 40, 42, 44\nFlat-Earth\n\nlaunch including drag, 157\u2013163\nproblem, 19, 21, 75, 78, 79, 82, 209\n\nFlat Earth Society, 19\nFlat-Moon\n\nanalytical solution, 165\nproblem, 75\nTPBVP solution, 157, 165\n\nFlight envelope, 131, 132\nFourier series, 57\nFox, C., 126\n\nG\nGeneralized functions, 31, 37\nGeneralized Legendre-Clebsch condition, 86,\n\n91, 187\u2013190, 211\nGeosynchronous-Earth orbit (GEO), 238\nGlobal minimum, 114, 115\nGoh, B.S., 187\nGravitational field\n\ngeneral central, 5, 209\nstatic, 206, 209\nuniform, 23, 24, 75, 140, 148, 149, 163, 166,\n\n206, 207, 209\u2013211\nGravity gradient matrix, 199\u2013202, 209\nGravity loss, 148, 195\nGreenwood, D.T., 43\n\nH\nHamilton\u2019s principle, 25\nHandelsman, M., 204, 210\nHarland, D.M., 5\nHestenes, M.R., 53, 63, 106, 107\nHigh-thrust, 193\u2013195, 202\nHilbert, 57\nHoelker, R.F., 10\n\n\n\nIndex 271\n\nHohmann\ntransfer, 5\u201312, 17, 28, 156, 166\ntransfer extensions, 10\u201312\nVetchinkin transfer, 5\n\nHohmann, W., 5\nHo, Y.C., 5, 26, 51, 52, 63, 64, 69, 70, 92, 96,\n\n105, 122, 126, 139, 155, 156, 167, 176,\n186, 187\n\nHull, D.G., 26, 27, 63, 97, 113, 126, 168, 176\n\nI\nImpulse function, 30\nImpulse time, 196, 203, 204\nImpulsive thrust, 148, 195, 196, 203, 208\u2013210\nIndex of performance, 1, 22, 26, 124\nInfinite dimensions, problem of, 1, 20\nInitial boundary conditions, 102\nIntegration by parts, 42, 53, 56, 99, 152, 169\nIntegration of equations of motion, 145\u2013146,\n\n150\u2013156\nIntermediate thrust (IT) arc, 201, 202, 206, 207,\n\n209\u2013211\nIon engines, 194\nIT arc. See Intermediate thrust (IT) arc\n\nJ\nJacobi condition, 121, 122, 167\n\nK\nKaplan, W., 30\nKelley-Contensou condition, 187\nKelley, H.J., 187\nKenneth, P., 53\nKopp, R.E., 187\n\nL\nLagrange, 25\u201328, 37, 39, 42, 48, 50\u201352, 56, 65,\n\n102, 127, 200\nLagrange multipliers, 3\u20135, 16, 17\nLagrangian, 25, 26\nLanczos, C., 25, 42, 57\nLaunch\n\ninto circular orbit, 19\u201321, 75, 148, 157\ntime-optimal, 148\u2013163, 165\nof a Titan II rocket, 161, 162\n\nLawden, D.F., 141, 143, 146, 167, 174, 193,\n199\u2013202, 204, 207\u2013209\n\nLawden\u2019s necessary conditions, 167, 199, 204,\n209\n\nLawden\u2019s primer vector, 174, 193, 200, 202,\n204, 207, 209\n\nLegendre-Clebsch condition, 84, 86, 91, 112,\n116, 118, 119, 122, 124, 127, 128, 137,\n167, 187\u2013190, 211\n\nLeibniz\u2019 rule, 49, 56, 97, 98, 169\nLeitmann, G., 122, 207\nLEO. See Low-Earth orbit (LEO)\nLinear tangent steering law, 150\nLion, P.M., 204, 210\nLocal minimum, 1, 114, 115, 126\nLotka-Volterra model, 36\nLow-Earth orbit (LEO), 161\nLow-thrust, 194, 195\nLow-thrust LEO to GEO spiral, 161\nLunar takeoff, 155, 162, 164, 165\n\nM\nMagnetohydrodyamic (MHD) engine, 194\nMarec, J.P., 187, 196, 197, 209\nMATLAB, 155, 157, 162, 164\nMATLAB two-point boundary-value solver,\n\nbvp4c, 157, 164\nMaximization of the range of a rocket, 140\u2013148\nMaximum\n\naltitude of a rocket, 163, 164\npayload, 20, 22, 75\npower, 197\nradius orbit transfer, 92\nrange equation, 147\u2013148\nsatellite mass, 20\nthrust (MT) arc, 201, 209\nturn rate, 187\u2013189\n\nMayer, 25\u201328, 37, 102, 164\nMcGill, R., 53\nMcShane, E.J., 96, 105, 127\nMeasurable function, 95, 105, 106\nMechanical impulse, 194\nMHD engine. See Magnetohydrodyamic (MHD)\n\nengine\nMidcourse impulse, 204\nMiele, A., 134, 187\nMinimum\n\npropellant cost, 7, 198\ntime to climb, 67\u201368, 136\u2013139, 163, 166\nwetness while running in the rain, 191\n\nMoon launch, 20, 75, 157, 167\nMoyer, A.G., 187\nMultistage rocket, 14\n\nN\nN1 and N2 neighborhoods, 114, 115, 122\nNecessary conditions\n\nfor an extremum, 1\nfor an optimal impulsive trajectory, 202\u2013208\nfour sets of, 167\n\n\n\n272 Index\n\nNewton, 5, 21, 24, 133\nNon-existence of a conjugate point, 167\nNormal problem, 107\nNT arc. See Null-thrust (NT) arc\nNull-thrust (NT) arc, 201, 209\n\nO\nOne-parameter family, 39, 40, 47, 56, 168\nOptimal\n\nconstant specific impulse trajectory,\n198\u2013202, 206\n\ncontrol problems with constraints, 114,\n175\u2013176\n\ncontrol theory, 1, 19\u201337, 163, 199\nfinal time, 45\npath, 39, 43, 45, 96, 97, 182\nrocket trajectories, 174, 193\u2013211\nthrust acceleration vector, 205, 209\ntrajectories in a uniform field, 206\u2013208\n\nOscillator with bounded control, 182, 184\n\nP\nParameter optimization, 1\u201317, 19, 57, 114,\n\n115\nParameter optimization with constraints, 3\u201312\nParametric equations, 43\nPegasus, 131\nPhase plane analysis, 179, 185, 186\nPiecewise\n\ncontinuous, 28\u201331, 56, 95, 102, 105, 121,\n127\n\nsmooth, 29, 31\nPierre, D.A., 53, 106, 107\nPlasma arc engine, 194\nPL engines. See Power limited (PL) engines\nPontryagin, L.S., 105, 107, 127\nPontryagin\u2019s Minimum Principle, 95, 105\u2013107,\n\n211\nPopulation dynamics, 36\nPower contours, 139, 140\nPower limited (PL) engines, 195, 204\nPredator-prey problem, 36\nPrimer vector equation, 193, 200\u2013210\nProcess equations, 16, 26, 46, 48, 56, 89, 125,\n\n135, 138, 163, 164\nProper minimum, 63, 122, 126\nPrussing, J.E., 7, 12, 121, 124, 193, 196, 202,\n\n204, 206\n\nR\nRadioisotope thermoelectric generator, 194, 204\nReachable set, 29, 75, 82, 139, 208\n\nRectangle\nof maximum area, 17\nof maximum perimeter, 4, 5, 17\n\nThe Right Stuff, 131\nRobbins, H.M., 187\nRocket equation, 13, 14, 193, 204\nRoss, I.M., 107\n\nS\nSandrik, S.L., 121, 124, 206\nSatellite launch, 19\u201322, 25, 26, 41, 75, 90,\n\n148\u2013163\nScale height, 158, 165\nScaling equations of motion, 134\nSecond-order necessary condition, 13, 121\u2013122\nShooting method, 81\u201382\nShortest path on a sphere, 63, 122, 126\nShternfeld, A., 10\nSilber, R., 10\nSingular arc, 86, 91, 178, 183, 184, 186\u2013190,\n\n201\nSnell\u2019s law of optics, 58, 93\nSolar sails, 194\nSpacecraft attitude control problem, 176, 177,\n\n181, 182\nSpaceShipOne, 131\nSpace Shuttle, 19\nSpecific impulse, 13, 16, 19, 141, 194, 195,\n\n198\u2013202, 204\u2013206\nSpeyer, J.L., 139\nSplit boundary conditions, 61, 62, 90\nStandard free fall, 13, 19, 161, 194\nState\n\nequations, 35, 56, 74, 80, 83, 90, 128, 199\nregulator problem, 70\n\nSteady climb, 134\nSteering law, 20, 22, 25, 37, 56, 77, 80, 150,\n\n153, 154, 165, 166, 207, 209\nStengel, R.F., 36\nStopping condition, 53, 54, 64\nStrengthened Jacobi condition, 122\nStrong\n\nextremal, 114\u2013116, 211\nvariation, 97, 119\u2013121, 127\n\nSubsonic aircraft, 131, 132\nSufficient conditions, 1, 2, 5, 13, 84, 112\u2013115,\n\n121\u2013122, 204, 206\nSupersonic aircraft, 131, 132, 139, 166\nSwitching\n\ncurve, 180, 182, 186, 191\nfunction, 86, 87, 108, 109, 127, 164, 178,\n\n179, 183, 184, 188, 189, 201\u2013203, 208,\n210\n\n\n\nIndex 273\n\nT\nTait, K.S., 187\nTerminal\n\nconstraint, 26, 46, 50\u201354, 57, 63\u201364, 83, 87,\n106, 200, 201\n\ncost, 26, 54, 56, 57\nThree-impulse trajectory, 204, 205\nThrust-limited engine, 195\nTime-varying mass, 134, 161, 162\nTPBVP. See Two-point boundary-value problem\n\n(TPBVP)\nTrajectory optimization, 19, 37, 41, 56, 91, 95,\n\n96, 107, 146\u2013147, 163, 182, 183, 185,\n191, 193, 199, 204, 206\u2013211\n\nTranscendental equation, 146\nTransversality condition\n\nalgebraic form of, 56, 63, 69, 83\ndifferential form of, 53, 55, 63, 64, 66, 71,\n\n79, 83, 87, 108, 109, 123, 137, 143, 159,\n172, 179\n\nfor flat-Earth problem, 79\nTwo-point boundary-value problem (TPBVP),\n\n52, 56, 61\u201364, 66\u201368, 71, 72, 79\u201382,\n90\u201392, 102, 109, 111, 156, 157, 160\u2013162,\n165\n\nU\nUlivi, P., 5\nUn-adjoined method, 63\u201367, 69, 83\u201384\nUnit impulse, 30\nUnsteady climb, 134, 135\n\nV\nVagners, J., 27, 63, 97, 101, 106, 168, 176\nVariable specific impulse (VSI) engine, 195,\n\n204, 205, 209\n\nVariable specific impulse magnetoplasma rocket\n(VASIMR), 194\n\nVariation\nnear a corner, 168, 170\none-sided, 168, 173\nspecial, 96, 97, 100, 102, 172\nstrong, 97, 119\u2013121, 127\ntwo-sided, 168, 173\nweak, 97, 112, 121, 127\n\nVaried path, 41, 43, 45, 50, 99\nVASIMR. See Variable specific impulse\n\nmagnetoplasma rocket (VASIMR)\nVinh, N.X., 133, 140\nVSI engine. See Variable specific impulse (VSI)\n\nengine\n\nW\nWeak\n\nbut not strong minimum, 116\u2013121\nextremal, 114\u2013116, 211\nand strong neighborhoods, 115\nvariation, 97, 112, 121, 127\n\nWeierstrass condition, 61, 78, 91, 95\u2013103, 105,\n116, 118, 121, 127, 167\n\nWeierstrass-Erdmann corner conditions,\n167\u2013174, 202, 203, 210, 211\n\nWeighting factor, 70, 131\n\nZ\nZermelo\u2019s problem\n\naircraft in a crosswind, 35, 58\nboat crossing a river, 34, 73\n\nZoom climb, 135\u2013137, 139, 166\n\n\n\tPreface\n\tAcknowledgments\n\tAbout the Authors\n\tContents\n\t1 Parameter Optimization\n\t1.1 Introduction\n\t1.2 Parameter Optimization with Constraints\n\t1.2.1 Lagrange Multipliers\n\t1.2.2 Parameter Optimization: The Hohmann Transfer (1925)\n\t1.2.3 Extensions of the Hohmann Transfer (1959)\n\t1.2.4 The Bi-parabolic Transfer\n\n\t1.3 Exercises\n\tReferences\n\n\t2 Optimal Control Theory\n\t2.1 Optimal Launch of a Satellite\n\t2.2 General Form of the Problem\n\t2.3 The Problems of Bolza, Lagrange, and Mayer\n\t2.3.1 Transformation from Lagrange to Mayer\n\t2.3.2 Transformation from Mayer to Lagrange\n\n\t2.4 A Provocative Example Regarding Admissible Functions\n\t2.5 Summary\n\t2.6 Exercises\n\tReferences\n\n\t3 The Euler-Lagrange Theorem\n\t3.1 The Variation\n\t3.2 The Euler-Lagrange Equation and the Brachistochrone Problem\n\t3.3 The Euler-Lagrange Theorem\n\t3.3.1 Proof Outline of the Euler-Lagrange Theorem\n\t3.3.2 Summary of the Euler-Lagrange Theorem\n\t3.3.3 Alternate Form of the Transversality Condition\n\n\t3.4 Summary\n\t3.5 Exercises\n\tReferences\n\n\t4 Application of the Euler-Lagrange Theorem\n\t4.1 Introduction\n\t4.2 Two-Point Boundary-Value Problem (TPBVP)\n\t4.3 Two Approaches to Terminal Constraints\n\t4.4 Transversality Condition\n\t4.4.1 Case 1 Final Time Specified\n\t4.4.2 Case 2 Final State Specified\n\t4.4.3 Case 3 Final Endpoint Specified\n\n\t4.5 General Case of Supplying Needed B.C.s\n\t4.5.1 Adjoined Method\n\t4.5.2 Un-adjoined Method\n\n\t4.6 Examples\n\t4.7 A ``Cookbook'' for Optimization Problems\n\t4.7.1 Examples of Step 4\n\n\t4.8 Constant Hamiltonian\n\t4.9 Summary\n\t4.10 Exercises\n\tReferences\n\n\t5 The Weierstrass Condition\n\t5.1 Introduction\n\t5.2 Statement of the Weierstrass Necessary Condition\n\t5.3 Proof Outline of the Weierstrass Necessary Condition\n\t5.4 Summary\n\t5.5 True or False Quiz for Chaps.1\u20135\n\tReferences\n\n\t6 The Minimum Principle\n\t6.1 Statement of the Minimum Principle\n\t6.1.1 Problem Statement\n\t6.1.2 Pontryagin's Minimum Principle\n\t6.1.3 Examples\n\n\t6.2 Legendre-Clebsch Necessary Condition\n\t6.3 Notes on Necessary and Sufficient Conditions\n\t6.4 Weak and Strong Extremals\n\t6.5 An Example of a Weak but Not Strong Minimum\n\t6.6 Second-Order Necessary and Sufficient Conditions\n\t6.7 Examples Illustrating the Concept of a Conjugate Point \n\t6.8 Summary\n\t6.9 Exercises\n\tReferences\n\n\t7 Some Applications\n\t7.1 Aircraft Performance Optimization\n\t7.2 Maximization of the Range of a Rocket\n\t7.2.1 Integration of Equations of Motion When f Is Constant\n\t7.2.2 The Optimal Trajectory\n\t7.2.3 Maximum Range Equation\n\n\t7.3 Time Optimal Launching of a Satellite\n\t7.3.1 Integration of the EOMs\n\t7.3.2 TPBVP \n\t7.3.3 Flat-Earth Launch Including Atmospheric Drag\n\n\t7.4 Summary\n\t7.5 Exercises\n\tReferences\n\n\t8 Weierstrass-Erdmann Corner Conditions\n\t8.1 Statement of the Weierstrass-Erdmann Corner Conditions\n\t8.2 Proof Outline of Weierstrass-Erdmann Corner Conditions\n\t8.3 Summary\n\tReferences\n\n\t9 Bounded Control Problems\n\t9.1 Optimal Control Problems with Constraints\n\t9.2 Examples of Bounded Control Problems\n\t9.3 Singular Arcs\n\t9.4 Summary\n\t9.5 Exercises\n\tReferences\n\n\t10 General Theory of Optimal Rocket Trajectories\n\t10.1 Introduction\n\t10.2 Equations of Motion\n\t10.3 High and Low-Thrust Engines\n\t10.4 Cost Functionals for Rocket Engines\n\t10.5 First-Order Necessary Conditions\n\t10.5.1 Optimal Constant Specific Impulse Trajectory\n\t10.5.2 Optimal Impulsive Trajectory \n\t10.5.3 Optimal Variable Specific Impulse Trajectory \n\n\t10.6 Optimal Trajectories in a Uniform Field\n\t10.7 Summary\n\t10.8 Exercises\n\t10.9 True or False Quiz for Chaps.6\u201310\n\tReferences\n\n\tAppendices\n\tA Time-Optimal Lunar Ascent\n\tA.1 MATLAB's Two-Point Boundary-Value Solver\n\tA.2 Solution Method\n\tA.3 MATLAB Code\n\n\tB Time-Optimal Launch of a Titan II\n\tB.1 Scaling the TPBVP\n\tB.2 Solution Method\n\tB.3 Results\n\tB.4 MATLAB Code\n\n\tC Optimal Low-Thrust LEO to GEO Circular Orbit Transfer\n\tC.1 Optimization Problem\n\tC.2 Scaling the Equations of Motion\n\tC.3 Applying the Euler-Lagrange Theorem\n\tC.4 Boundary Conditions and the TPBVP\n\tC.5 Results\n\tDiscussion of Results\n\tC.6 MATLAB Code\n\tExecutable File\n\n\tReference\n\tD Curious Quotations\n\n\tBibliography (Books)\n\tBibliography (Aerospace Applications Papers and Reports)\n\tIndex\n\n\n\n"}