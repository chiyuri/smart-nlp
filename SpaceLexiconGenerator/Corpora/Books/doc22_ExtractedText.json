{"content": "\nLecture Notes in Control and Information Sciences 460\n\nAdvances in Control \nSystem Technology \nfor Aerospace \nApplications \n\nEric Feron   Editor\n\n\n\nLecture Notes in Control and Information\nSciences\n\nVolume 460\n\nSeries editors\n\nFrank Allg\u00f6wer, Stuttgart, Germany\nManfred Morari, Z\u00fcrich, Switzerland\n\nSeries Advisory Boards\n\nP. Fleming, University of Sheffield, UK\nP. Kokotovic, University of California, Santa Barbara, CA, USA\nA.B. Kurzhanski, Moscow State University, Russia\nH. Kwakernaak, University of Twente, Enschede, The Netherlands\nA. Rantzer, Lund Institute of Technology, Sweden\nJ.N. Tsitsiklis, MIT, Cambridge, MA, USA\n\n\n\nAbout this Series\n\nThis series aims to report new developments in the fields of control and information\nsciences\u2014quickly, informally and at a high level. The type of material considered\nfor publication includes:\n\n1. Preliminary drafts of monographs and advanced textbooks\n2. Lectures on a new field, or presenting a new angle on a classical field\n3. Research reports\n4. Reports of meetings, provided they are\n\n(a) of exceptional interest and\n(b) devoted to a specific topic. The timeliness of subject material is very\n\nimportant.\n\nMore information about this series at http://www.springer.com/series/642\n\nhttp://www.springer.com/series/642\n\n\nEric Feron\nEditor\n\nAdvances in Control System\nTechnology for Aerospace\nApplications\n\n123\n\n\n\nEditor\nEric Feron\nSchool of Aerospace Engineering\nGeorgia Institute of Technology\nAtlanta, GA\nUSA\n\nISSN 0170-8643 ISSN 1610-7411 (electronic)\nLecture Notes in Control and Information Sciences\nISBN 978-3-662-47693-2 ISBN 978-3-662-47694-9 (eBook)\nDOI 10.1007/978-3-662-47694-9\n\nLibrary of Congress Control Number: 2015944442\n\nSpringer Heidelberg New York Dordrecht London\n\u00a9 Springer-Verlag Berlin Heidelberg 2016\nThis work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part\nof the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations,\nrecitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission\nor information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar\nmethodology now known or hereafter developed.\nThe use of general descriptive names, registered names, trademarks, service marks, etc. in this\npublication does not imply, even in the absence of a specific statement, that such names are exempt from\nthe relevant protective laws and regulations and therefore free for general use.\nThe publisher, the authors and the editors are safe to assume that the advice and information in this\nbook are believed to be true and accurate at the date of publication. Neither the publisher nor the\nauthors or the editors give a warranty, express or implied, with respect to the material contained herein or\nfor any errors or omissions that may have been made.\n\nPrinted on acid-free paper\n\nSpringer-Verlag GmbH Berlin Heidelberg is part of Springer Science+Business Media\n(www.springer.com)\n\n\n\nPreface\n\nOn June 11 and 12, 2012, several engineers and researchers from industry and\nacademia met at the Georgia Institute of Technology to discuss the present and\nfuture of aerospace decision and control. This workshop was hosted by the School\nof Aerospace Engineering and the Decision and Control Laboratory. Featured in\nthis workshop were aircraft and spacecraft control and autonomy, air traffic control\nand management, and embedded software verification and validation. From this\nworkshop came the five essays printed thereafter.\n\nWhether focusing on aeronautical or space applications, the decision and control\nsciences of today largely supersede the servomechanism theory that used to be, and\nstill is, taught in all aerospace undergraduate curricula. Yet, the concern for\nmathematical rigor and safety present in even the most basic control course is the\nfertile ground upon which new disciplines, such as autonomy, can develop with a\ngenuine concern for applicability to aerospace systems. In this volume, the reader\nwill find a broad variety of topics that all share highly dynamical, real-time, and\nsafety- or mission-critical decision-making as core elements.\n\nWhen looking at the space adventure, the reader will see that autonomy is\nbecoming, de facto, the prime mechanism through which humanity can project its\nmind and soul onto faraway, extraterrestrial destinations. In an increasingly tech-\nnological world, the reader will, however, get some appreciation for the gap that\nseparates the extremely high promise of autonomy technology for aerial applica-\ntions from our ability to understand it well enough to let it take over part of our\noverhead traffic. Likewise, the reader will get an appreciation for the astonishing\nrange of control issues raised by air transportation, including optimal control,\nqueuing systems, and combinations of the above.\n\nProfessor Gary Balas understood, perhaps better than anyone else in the trade,\nthe vastly expanded scope that the decision and control sciences need to cover to\naddress the challenges that aerospace engineering faces today. He presided over the\nfast transformation of the aerospace decision sciences by fostering a climate of\nopenness toward the new aerospace decision and control sciences, whether they are\n\nv\n\n\n\nnamed autonomy, software analysis, air traffic control, or human-centric systems,\nwithin his own University of Minnesota and the Department of Aerospace\nEngineering and Mechanics, which he led with enthusiasm and humor. This volume\nis dedicated to his memory.\n\nAtlanta Eric Feron\nMarch 2015\n\nvi Preface\n\n\n\nContents\n\n1 Spacecraft Autonomy Challenges for Next-Generation\nSpace Missions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\nJoseph A. Starek, Beh\u00e7et A\u00e7?kme?e, Issa A. Nesnas\nand Marco Pavone\n1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n\n1.1.1 High-Level Challenges and High-Priority\nTechnologies for Space Autonomous Systems . . . . . . 3\n\n1.2 Relative Guidance Algorithmic Challenges for Autonomous\nSpacecraft . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.1 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.2.2 Need . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.2.3 State of the Art. . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.2.4 Challenges and Future Directions . . . . . . . . . . . . . . . 11\n\n1.3 Extreme Mobility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n1.3.1 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n1.3.2 Need . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n1.3.3 State of the Art. . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n1.3.4 Challenges and Future Directions . . . . . . . . . . . . . . . 24\n\n1.4 Microgravity Mobility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n1.4.1 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n1.4.2 Need . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n1.4.3 State of the Art. . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n1.4.4 Challenges and Future Directions . . . . . . . . . . . . . . . 35\n\n1.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\nReferences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n\n2 New Guidance, Navigation, and Control Technologies\nfor Formation Flying Spacecraft and Planetary Landing . . . . . . . 49\nFred Y. Hadaegh, Andrew E. Johnson, David S. Bayard,\nBeh\u00e7et A\u00e7?kme?e, Soon-Jo Chung and Raman K. Mehra\n2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n\nvii\n\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec16\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec16\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec18\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec18\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec19\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec19\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec20\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec20\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec21\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec21\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec22\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec22\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec23\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec23\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec24\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec24\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec25\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec25\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec26\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Sec26\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_1#Bib1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec1\n\n\n2.2 GN&C Technologies for Planetary Landing in Hazardous\nTerrain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n2.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n2.2.2 Design Considerations . . . . . . . . . . . . . . . . . . . . . . . 52\n2.2.3 Case Study 1: Mars Robotic System . . . . . . . . . . . . . 53\n2.2.4 Case Study 2: Crewed Lunar System. . . . . . . . . . . . . 55\n2.2.5 System Comparison . . . . . . . . . . . . . . . . . . . . . . . . 57\n\n2.3 Phase Synchronization Control of Spacecraft Swarms . . . . . . . 58\n2.3.1 Problem Statement\u2014Controlling the Phase\n\nDifferences in Periodic Orbits. . . . . . . . . . . . . . . . . . 59\n2.3.2 Phase Synchronization Control Law with Adaptive\n\nGraphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n2.3.3 Main Stability Theorems and Simulation Results . . . . 62\n\n2.4 Application of Probabilistic Guidance to Swarms\nof Spacecraft Operating in Earth Orbit. . . . . . . . . . . . . . . . . . 64\n2.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n2.4.2 Probabilistic Guidance Problem . . . . . . . . . . . . . . . . 65\n2.4.3 Probabilistic Guidance Algorithm (PGA) . . . . . . . . . . 66\n2.4.4 Adaptation of PGA to Earth Orbiting Swarms . . . . . . 68\n\n2.5 Nonlinear State Estimation And Sensor Optimization\nProblems for Detection of Space Collision Events. . . . . . . . . . 70\n2.5.1 LEO Sensor Constellation Design and Collision\n\nEvent Testbed . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n2.5.2 Satellite Collision Modeling and Estimation . . . . . . . . 73\n\n2.6 Conclusion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\nReferences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n\n3 Aircraft Autonomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nPiero Miotto, Leena Singh, James D. Paduano, Andrew Clare,\nMary L. Cummings and Lesley A. Weitz\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n\n3.1.1 Challenges to the Safe Integration of UAVs\nin the National Airspace . . . . . . . . . . . . . . . . . . . . . 83\n\n3.1.2 Technical Enhancements for Safe Insertion\nof UAVs in the NAS . . . . . . . . . . . . . . . . . . . . . . . 84\n\n3.2 On-Board Air Autonomy Systems Needs . . . . . . . . . . . . . . . . 86\n3.2.1 Challenges to Integration of UAVs in the NAS . . . . . 86\n3.2.2 Technical Enhancements for Improved In-Air\n\nautonomy\u2014Key Technologies . . . . . . . . . . . . . . . . . 87\n3.2.3 Conclusions: A Road-Map to Address\n\nthe Technical Challenges . . . . . . . . . . . . . . . . . . . . . 89\n3.3 Human-Automation Collaboration . . . . . . . . . . . . . . . . . . . . . 92\n\n3.3.1 Challenges in the Collaborative Human-Automation\nScheduling Process . . . . . . . . . . . . . . . . . . . . . . . . . 92\n\nviii Contents\n\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec11\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec11\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec13\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec13\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec14\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec14\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec15\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec15\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec16\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec16\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec18\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec18\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec18\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec19\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec19\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec23\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Sec23\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_2#Bib1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec9\n\n\n3.3.2 Candidate Methods in Human-Automation\nCollaborative Scheduling . . . . . . . . . . . . . . . . . . . . . 94\n\n3.3.3 Technical Enhancements needed for Humans\nInteractions with Scheduling Algorithms . . . . . . . . . . 95\n\n3.3.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n3.4 Autonomy Evolution for Air Traffic Control . . . . . . . . . . . . . 98\n\n3.4.1 Challenges and Limitations of Current Air Traffic\nManagement System . . . . . . . . . . . . . . . . . . . . . . . . 99\n\n3.4.2 Enhancements Made Within ATC System . . . . . . . . . 99\n3.4.3 Technical Enhancements needed in the Evolution\n\nof Airborne and Ground-Based Technologies . . . . . . . 101\n3.4.4 Conclusions and Proposed Road-Map . . . . . . . . . . . . 103\n\nReferences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n\n4 Challenges in Aerospace Decision and Control:\nAir Transportation Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\nHamsa Balakrishnan, John-Paul Clarke, Eric M. Feron,\nR. John Hansman and Hernando Jimenez\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n4.2 Key NextGen Topics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n4.3 Supporting Technology Research Challenges . . . . . . . . . . . . . 111\n\n4.3.1 Design of Automation with Graceful\nDegradation Modes . . . . . . . . . . . . . . . . . . . . . . . . . 112\n\n4.3.2 System Verification and Validation (V&V) . . . . . . . . 112\n4.3.3 Large-Scale, Real-Time Optimization Algorithms . . . . 113\n4.3.4 Multi-Objective, Multi-Stakeholder, Optimization\n\nFrameworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n4.4 Domain-Specific Research Challenges . . . . . . . . . . . . . . . . . . 114\n\n4.4.1 Airport Arrival Management . . . . . . . . . . . . . . . . . . 114\n4.4.2 Airport Departure Processes . . . . . . . . . . . . . . . . . . . 116\n4.4.3 The Trip is Not Over: Passenger Management\n\nin the Terminals . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n4.4.4 Domain-Specific Contributions: Abstract Modeling\n\nApproaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\nReferences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n\n5 From Design to Implementation: An Automated,\nCredible Autocoding Chain for Control Systems . . . . . . . . . . . . . 137\nTimothy Wang, Romain Jobredeaux, Heber Herencia,\nPierre-Lo\u00efc Garoche, Arnaud Dieumegard, \u00c9ric Feron\nand Marc Pantel\n5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\n5.2 Credible Autocoding Framework . . . . . . . . . . . . . . . . . . . . . 139\n\n5.2.1 Input and Output Languages of the Framework . . . . . 141\n\nContents ix\n\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec11\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec11\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec11\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec13\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec13\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec14\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec14\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec14\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec15\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec15\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec16\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec16\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec16\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_3#Bib1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec12\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec17\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec20\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec20\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Sec20\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_4#Bib1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec1\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec2\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec3\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec3\n\n\n5.3 Control Semantics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\n5.3.1 Control System Stability and Boundedness. . . . . . . . . 143\n5.3.2 Prototype Tool-Chain . . . . . . . . . . . . . . . . . . . . . . . 143\n5.3.3 Control Semantics in Simulink and Gene-Auto . . . . . . 144\n5.3.4 Annotation Blocks and Behaviors in the Model . . . . . 146\n5.3.5 Closed-Loop Stability with Bounded Input. . . . . . . . . 147\n5.3.6 Expressing the Observer-Based Fault-Detection\n\nSemantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\n5.3.7 Control Semantics at the Level of the C Code . . . . . . 149\n5.3.8 Closed Loop Semantics . . . . . . . . . . . . . . . . . . . . . . 150\n5.3.9 Control Semantics in PVS . . . . . . . . . . . . . . . . . . . . 151\n\n5.4 Autocoding with Control Semantics . . . . . . . . . . . . . . . . . . . 153\n5.5 Building the Input Model. . . . . . . . . . . . . . . . . . . . . . . . . . . 153\n5.6 Basics of Program Verification . . . . . . . . . . . . . . . . . . . . . . . 154\n\n5.6.1 Hoare Logic and Deductive Verification . . . . . . . . . . 156\n5.6.2 Predicate Transformers . . . . . . . . . . . . . . . . . . . . . . 157\n5.6.3 Strongest Post-condition . . . . . . . . . . . . . . . . . . . . . 159\n\n5.7 Translation Process for a Simple Dynamical System . . . . . . . . 159\n5.8 Gene-Auto+: A Prototype Credible Autocoder . . . . . . . . . . . . 161\n\n5.8.1 Gene-Auto: Translation . . . . . . . . . . . . . . . . . . . . . . 161\n5.8.2 Translation of Annotative Blocks . . . . . . . . . . . . . . . 162\n\n5.9 Translation and Insertion of the System Block . . . . . . . . . . . . . 164\n5.10 Translation of the Quadratic Blocks . . . . . . . . . . . . . . . . . . . 165\n\n5.10.1 Types of Quadratic Blocks. . . . . . . . . . . . . . . . . . . . 165\n5.10.2 Insertion of Ellipsoid Objects . . . . . . . . . . . . . . . . . . 165\n\n5.11 Computing the Strongest Post-condition. . . . . . . . . . . . . . . . . 167\n5.11.1 Affine Transformation . . . . . . . . . . . . . . . . . . . . . . . 168\n5.11.2 S-Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\n5.11.3 Verification of the Strongest Post-condition . . . . . . . . 172\n\n5.12 Automatic Verification of Control Semantics . . . . . . . . . . . . . 172\n5.12.1 From C Code to PVS Theorems . . . . . . . . . . . . . . . . 173\n5.12.2 Theory Interpretation . . . . . . . . . . . . . . . . . . . . . . . . 175\n5.12.3 Generically Discharging the Proofs in PVS . . . . . . . . 176\n5.12.4 The pvs-ellipsoid Plugin to Frama-C . . . . . . . . 177\n5.12.5 Checking Inclusion of the Propagated Ellipsoid . . . . . 177\n\n5.13 Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\n5.14 Conclusion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\nReferences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\n\nx Contents\n\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec4\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec5\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec6\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec7\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec8\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec9\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec10\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec11\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec11\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec14\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec14\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec15\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec15\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec18\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec18\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec19\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec19\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec20\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec20\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec21\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec21\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec22\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec22\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec23\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec23\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec24\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec24\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec25\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec25\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec26\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec26\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec27\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec27\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec28\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec28\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec29\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec29\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec30\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec30\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec31\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec31\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec32\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec32\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec33\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec33\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec34\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec34\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec35\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec35\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec36\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec36\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec37\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec37\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec38\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec38\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec39\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec39\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec40\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec40\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec41\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec41\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec42\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec42\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec43\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Sec43\nhttp://dx.doi.org/10.1007/978-3-662-47694-9_5#Bib1\n\n\nContributors\n\nBeh\u00e7et A\u00e7?kme?e Jet Propulsion Laboratory, California Institute of Technology,\nPasadena, California; University of Texas at Austin, Austin, TX, USA\n\nHamsa Balakrishnan Massachusetts Institute of Technology, Cambridge, MA,\nUSA\n\nDavid S. Bayard Jet Propulsion Laboratory, California Institute of Technology,\nPasadena, California\n\nSoon-Jo Chung University of Illinois at Urbana-Champaign, Urbana, IL, USA\n\nAndrew Clare Massachusetts Institute of Technology, Cambridge, MA, USA\n\nJohn-Paul Clarke Georgia Institute of Technology, Atlanta, GA, USA\n\nMary L. Cummings Duke University MEMS, Durham, USA\n\nArnaud Dieumegard ENSEEIHT, Toulouse, France\n\nEric M. Feron Georgia Institute of Technology, Atlanta, GA, USA\n\nPierre-Lo\u00efc Garoche ONERA\u2014The French Aerospace Lab, Toulouse, France\n\nFred Y. Hadaegh Jet Propulsion Laboratory, California Institute of Technology,\nPasadena, California\n\nR. John Hansman Massachusetts Institute of Technology, Cambridge, MA, USA\n\nHeber Herencia General Electric Global Research, Clifton Park, NY, USA\n\nHernando Jimenez Georgia Institute of Technology, Atlanta, GA, USA\n\nRomain Jobredeaux Georgia Institute of Technology, Atlanta, GA, USA\n\nAndrew E. Johnson Jet Propulsion Laboratory, California Institute of\nTechnology, Pasadena, California\n\nRaman K. Mehra Scientific Systems Company, Inc., Woburn, MA, USA\n\nxi\n\n\n\nPiero Miotto Draper Laboratory, Cambridge, MA, USA\n\nIssa A. Nesnas Jet Propulsion Laboratory, Pasadena, CA, USA\n\nJames D. Paduano Aurora Flight Sciences, Cambridge, MA, USA\n\nMarc Pantel ENSEEIHT, Toulouse, France\n\nMarco Pavone Stanford University, Palo Alto, CA, USA\n\nLeena Singh Draper Laboratory, Cambridge, MA, USA\n\nJoseph A. Starek Stanford University, Palo Alto, CA, USA\n\nTimothy Wang Georgia Institute of Technology, Atlanta, GA, USA\n\nLesley A. Weitz Mitre Corporation CAASD, New Jersey, USA\n\nxii Contributors\n\n\n\nChapter 1\nSpacecraft Autonomy Challenges\nfor Next-Generation Space Missions\n\nJoseph A. Starek, Beh\u00e7et A\u00e7?kmes?e, Issa A. Nesnas and Marco Pavone\n\n1.1 Introduction\n\nIn early 2011, in an effort to streamline future resource allocation and refine its\nplans, NASA\u2019s Office of the Chief Technologist (OCT) released a set of technology\nroadmaps with the aim of fostering the development of concepts and cross-cutting\ntechnologies addressing NASA\u2019s needs for the 2011\u20132021 decade and beyond [101,\n103]. This set was organized into 14 technology areas (TA01 through TA14), divided\ninto a total of 64 technology subareas. In an attempt to engage the external techni-\ncal community and enhance the development program in light of scarce resources,\nNASA reached out to the National Research Council (NRC) to review the program\u2019s\nobjectives and prioritize its list of technologies. In January 2012, the NRC released\nits report entitled \u201cRestoring NASA\u2019s Technological Edge and Paving the Way for\na New Era in Space,\u201d which reviewed an initial 320 technologies [48]. The NRC\nreport revolved around three technology objectives:\n\nJ.A. Starek \u00b7 M. Pavone (B)\nStanford University, Palo Alto, CA, USA\ne-mail: pavone@stanford.edu\n\nJ.A. Starek\ne-mail: jstarek@stanford.edu\n\nB. A\u00e7?kmes?e\nUniversity of Texas at Austin, Austin, TX, USA\ne-mail: behcet@austin.utexas.edu\n\nI.A. Nesnas\nJet Propulsion Laboratory, Pasadena, CA, USA\ne-mail: nesnas@jpl.nasa.gov\n\n\u00a9 Springer-Verlag Berlin Heidelberg 2016\nE. Feron (ed.), Advances in Control System Technology\nfor Aerospace Applications, Lecture Notes in Control\nand Information Sciences 460, DOI 10.1007/978-3-662-47694-9_1\n\n1\n\n\n\n2 J.A. Starek et al.\n\n\u2022 Technology Objective A: Extend and sustain human activities beyond low Earth\norbit. Invest in technologies to enable humans to travel throughout the solar system,\nincluding surviving longer space voyages, arriving and working effectively at\nspecific extraterrestrial destinations, and finally returning to Earth safely;\n\n\u2022 Technology Objective B: Explore the evolution of the solar system and the poten-\ntial for life elsewhere (in situ measurements). Investigate technologies that enable\nhumans and robots to perform in situ measurements on other planetary bodies as\nwell as on Earth analogues (i.e. astrobiology);\n\n\u2022 Technology Objective C: Expand understanding of Earth and the universe\n(remote measurements). Develop technologies for capturing remotemeasurements\nfrom platforms that orbit or fly-by Earth and other planetary bodies, and from other\nin-space and ground-based observatories.\n\nIn its study, the NRC defined evaluation criteria that included assessments of tech-\nnological benefit, alignment with NASA, non-NASA aerospace, and non-aerospace\nnational needs, technical risk and reasonableness, sequencing and timing (factoring\nin requisite technologies), and development time and effort required to achieve each\ngoal. By the final ranking, the NRC had whittled the selection to a group of 16 top\npriorities for technology.\n\nWhile the NRC report provides a systematic and thorough ranking of the future\ntechnology needs for NASA, it does not discuss in detail the technical aspects of\nthe prioritized technologies (which is clearly beyond the scope of the report). This\nchapter, building upon the NRC report and an earlier assessment of NASA\u2019s needs\nin terms of guidance, navigation, and control technologies [14], aims at provid-\ning such technical details for a selected number of high-priority technologies in the\nautonomous systems area. Specifically, this chapter focuses on technology area TA04\n\u201cRobotics, Tele-Robotics, and Autonomous Systems\u201d and discusses in some detail\nthe technical aspects and challenges associated with three high-priority TA04 tech-\nnologies: \u201cRelative Guidance Algorithms,\u201d \u201cExtreme Terrain Mobility,\u201d and \u201cSmall\nBody/Microgravity Mobility.\u201d\n\nThis chapter is structured as follows. The rest of this section provides a high-level\ndescription of the high-priority technologies for TA04. Then, Sects. 1.2\u20131.4 focus,\nrespectively, on technical discussions of \u201cRelative Guidance Algorithms,\u201d \u201cExtreme\nTerrain Mobility,\u201d and \u201cSmall Body/Microgravity Mobility,\u201d each categorized as top\npriorities of TA04 and which represent the key areas of expertise of the authors.\nFinally, Sect. 1.5 draws conclusions with a summary of the technical challenges\nfacing the engineering community and the unsolved technical areas that must be\naddressed to help NASA meet its vision. Each technology section follows the same\nstructure: Scope, Need, State of the Art, and Challenges and Future Directions.\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 3\n\n1.1.1 High-Level Challenges and High-Priority Technologies\nfor Space Autonomous Systems\n\nWhile the guidance, navigation and control of spacecraft has resulted in numerous\nsuccessful space missions, its use in fully autonomous operations has thus far been\nlimited, with mission planners often opting for ground-in-the-loop interventions for\nmaneuver refinements and corrections, wherever possible. Where ground-in-the-\nloop control is not feasible, as in the cases of rendezvous about other planets or\natmospheric entry, descent and landing for instance, autonomous operations are often\nrestricted tominimal scope in order tominimize the impact of a very costly validation\nand verification process. In spite of numerous autonomous operation successes, a\nnumber of anomalies have occurred during shuttle operations [57] and other recent\nautonomous demonstration missions, e.g. [20, 38, 65, 77], that point to the need\nfor development and maturation in this area. This serves to illustrate the degree of\ndifficulty of autonomous navigation and control in space applications and on a broad\nscale the significant challenges that must be overcome in aerospace engineering.\n\nNASA has repeatedly identified robotic, autonomous, and sensing systems as\nenabling technologies over its history, spanning as far back as the Gemini program\nin the 1960s [108]. For spaceflight, many valuable proposed technologies, including\nreal-time autonomous decision-making, opportunistic science, and human-robotic\ncooperation, are being investigated but have not yet been flight-tested. Analogously,\nfor roving applications, the capability does not yet exist for traversing extreme lunar,\nMartian, or dusty terrains, including polar cold traps, high-grade surfaces, andmicro-\ngravity environments [9]. The advancement of robotics and autonomous systemswill\nbe central to the transition of space missions from current ground-in-the-loop (geo-\ncentric) architectures to self-sustainable, independent systems, a key step necessary\nfor outer-planet exploration and for overcoming the many difficulties of interplane-\ntary travel [123]. Drawing similar conclusions in their technological report, the NRC\nhighlighted TA04 \u201cRobotics, Tele-Robotics, and Autonomous Systems\u201d specifically\nas a high-priority technology area, recognizing its importance in broadening access\nto space and expanding humanity\u2019s presence in the solar system.\n\nThe roadmap for TA04 was broken into seven technology subareas: sensing\nand perception; mobility; manipulation; human-systems integration; autonomy;\nautonomous rendezvous and docking (AR&D); and robotics, tele-robotics, and\nautonomous systems engineering. Within this context, the NRC identified the fol-\nlowing six top challenges for robotics and autonomous systems (quoted from [48]):\n\n\u2022 Rendezvous: develop the capability for highly reliable, autonomous rendezvous,\nproximity operations, and capture/attachment to (cooperative andnon-cooperative)\nfree-flying space objects;\n\n\u2022 Maneuvering: enable robotic systems to maneuver in a wide range of NASA-\nrelevant environmental, gravitational, and surface and subsurface conditions;\n\n\n\n4 J.A. Starek et al.\n\n\u2022 In Situ Analysis and Sample Return: develop subsurface sampling and analysis\nexploration technologies to support in situ and sample return science missions;\n\n\u2022 Hazard Avoidance: develop the capabilities to enable mobile robotic systems to\nautonomously and verifiably navigate and avoid hazards;\n\n\u2022 Time-Delayed Human-Robotic Interactions: achieve more effective and safe\nhuman interaction with robotic systems (whether in proximity or remotely) that\naccommodates time-delay effects;\n\n\u2022 Object Recognition and Manipulation: develop means for object recognition\nand dexterous manipulation that support engineering and science objectives.\n\nThis list is consistent with the recommendations of NASA\u2019s previous Vision for\nSpace Exploration [92], the recommendations referenced forNASAAutomatedRen-\ndezvous and Capture operations [108], the lessons learned from Apollo Guidance\nNavigation and Control (GN&C) [84], and the technology priorities described for\nthe future of rovers [9].\n\nIn light of these six challenges, and of the general technology objectives pre-\nsented at the beginning of this section, eight specific high-priority technologies were\nidentified in the TA04 Roadmap:\n\n\u2022 Technology 4.2.1, Extreme Terrain Mobility.\n\u2022 Technology 4.2.4, Small Body/Microgravity Mobility.\n\u2022 Technology 4.3.2, Dexterous Manipulation.\n\u2022 Technology 4.3.6, Robotic Drilling and Sample Processing.\n\u2022 Technology 4.4.2, Supervisory Control.\n\u2022 Technology 4.5.1, Vehicle Systems Management and Fault Detection Isolation\n\nand Recovery (FDIR).\n\u2022 Technology 4.6.2, Relative Guidance Algorithms.\n\u2022 Technology 4.6.3, Docking and Capture Mechanisms/Interfaces.\n\nTechnology advances in these areas will help towards accomplishing Technology\nObjectives A, B, and C by improving access to space, increasing available mass-to-\nsurface, and enhancing robotic maneuvering capabilities, autonomous rendezvous\nand docking, and precision landing, all of which were labeled top engineering road-\nblocks that must be overcome to meet NASA\u2019s goals.\n\nThe remainder of this chapter is devoted to clarifying precisely what needs to\nbe addressed for the three specific subcategories \u201cRelative Guidance Algorithms,\u201d\n\u201cExtreme Terrain Mobility,\u201d and \u201cSmall Body/Microgravity Mobility,\u201d according to\nthe best knowledge and expert opinions of the authors. The benefits, current state of\nthe art techniques, and technical aspects and challenges of each are discussed in detail\nto better prepare the technical community for delivering on these advancements and\nmeeting the needs of next-generation space missions.\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 5\n\n1.2 Relative Guidance Algorithmic Challenges\nfor Autonomous Spacecraft\n\nRelative guidance algorithmswere categorized by theNRCas the top-ranked technol-\nogy for robotics, tele-robotics, and autonomous systems; their improvement would\nmark a tremendous milestone for robustifying and augmenting current capabilities\nin autonomous guidance and control.\n\n1.2.1 Scope\n\nGuidance is the process of real-time planning of spacecraft state trajectories in both\ntranslational and rotational motion. This involves computing desired sets of transla-\ntional and rotational states and corresponding control forces and torques as a function\nof time. Control, or more specifically feedback control, is responsible for following\nthese trajectories based on real-time state updates in the presence of disturbances,\nmeasurement noise, and model uncertainties. Together they are referred to as Guid-\nance, Navigation, and Control (GN&C, or just G&C). This section addresses the\ntechnical details and challenges for relative guidance of autonomous spacecraft in\nfour key space-based areas:\n\n\u2022 Planetary Entry, Descent, and Landing (EDL)\n\u2022 Proximity Operations for Primitive Bodies\n\u2022 Autonomous Rendezvous and Docking (AR&D)\n\u2022 Autonomous Inspection and Servicing (AIS)\nIn each of these applications, the guidance problem can be posed as an optimal\ncontrol problem with dynamics describing the motion of the spacecraft as well as\nconstraints on the vehicle state and controls. This can be expressed generically as\nfollows:\n\nProblem G&C: Generic Autonomous Spacecraft Guidance Optimal Control\nProblem\n\nmin\nt f ,u\n\nJ (x(t), u(t), t) = K (x(t f ), t f ) +\n? t f\n\nt0\nL(x(t), u(t), t) dt\n\nsubject to x?(t) = f (x(t), u(t), t)\nu(t) ? U (t)\nx(t) ? X (t), for all t ? [t0, t f ]\n\nwhere x ? Rn is the state of the spacecraft, u ? Rm is the control input, t ? R\nis time, J : Rn+m+1 ? R is the cost-functional (which combines terminal and\nincremental additive cost functions K and L), f : Rn+m+1 ? Rn defines the\n\n\n\n6 J.A. Starek et al.\n\ndynamics, and U : R ? Rm and X : R ? Rn are set-valued maps defining\nspacecraft control and state constraints. Due to the existence of system dynamics\nand constraints, the resulting optimal control problem must be solved numerically\n[15, 45] via an optimization algorithm after a proper discretization [66, 128]. Tomeet\nthe guidance challenges of next-generation space missions, onboard algorithms will\nneed to meet the following specifications:\n\n\u2022 Real-time implementability: Algorithms must be implemented and executed on\nreal-time processors in a reasonable amount of time.\n\n\u2022 Optimality: Given that feasible solutions exist, an optimal solution x?(t) that\nminimizes (at least approximately) the cost function J is desired.\n\n\u2022 Verifiability: There must be design metrics that accurately describe the perfor-\nmance and robustness of GN&C algorithms, with accompanying methods for\nverifying these metrics.\n\n1.2.2 Need\n\nAutonomous spacecraft maneuvering, especially in proximity of artificial objects\n(e.g. satellites, debris, etc.) or solar system bodies (e.g. asteroids, comets, irregular\nsatellites, etc.), is a key enabler for the majority of future NASA missions [48, 101].\nIn some cases this arises from obvious physical mission constraints, notably signal\ntransmission delays to and from Earth. A very good example is Mars atmospheric\nEntry, Descent, and Landing (EDL), arguably one of the most tightly-constrained\ncontrol sequences in modern spaceflight, which prohibits human intervention due to\na nearly 26 minute two-way signal communication time that far exceeds the typical\nseven-minute descent duration. Similarly, close proximity operations around small\nbodies, many of which travel beyond the extent of Mars orbit, require autonomous\nguidance for the same reason. In other instances, the need for autonomy derives from\na desire to increase mission frequency, robustness, and reliability. This includes Low\nEarth Orbit missions, such as Autonomous Rendezvous and Docking (AR&D) and\nAutonomous Inspection and Servicing (AIS). As space access improves through\ncommercialization, the increased scheduling conflicts and labor overhead associated\nwith ground-in-the-loop spacecraft guidance are expected to become prohibitively\nexpensive. The risk of human error will increase as well. Spacecraft autonomy can\ncircumvent these issues, as well as enable greater mission variety and improve the\ncommercial and scientific return from space.\n\n1.2.3 State of the Art\n\nCurrent state-of-the-art techniques for autonomous spacecraft maneuvering include\nApollo guidance (particularly phase-plane logic, glideslope, and sliding-mode con-\ntrollers), Model Predictive Control (MPC) [2, 17, 27, 99, 104], and Artificial\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 7\n\nPotential Functions (APFs) [7, 16, 87]. Unfortunately, such techniques, while\nvaluable in static uncluttered settings, appear to fall short in scenarios where time-\nvarying constraints (such as neighboring debris or other spacecraft), logical modes\n(e.g., safety modes), and complex maneuvering (e.g., terrain sampling or manipu-\nlation) become key features of the problem setup. In these cases, robotic motion\nplanning techniques, though currently unproven in spaceflight, could provide a valu-\nable alternative [81, 118]; they are hence discussed here as well. Brief synopses\nof each these methods are presented in Sects. 1.2.3.1\u20131.2.3.4 below, together with\nhighlights of recent autonomous demonstration missions in Sect. 1.2.3.5.\n\n1.2.3.1 Apollo Guidance\n\nThe COLOSSUS Program, developed by MIT for NASA\u2019s Apollo Program, called\nupon three Digital AutoPilot (DAP) systems to stabilize and control the Apollo Com-\nmand Service Module (CSM) as part of its Primary Guidance Navigation and Con-\ntrol System (PGNCS) [132]. The techniques used, now considered part of classical\ncontrol, formed one of the earliest successful deployments of spacecraft autonomy.\nBlock-diagram schematics of the Apollo CSM control logic can be seen in Fig. 1.1.\nThese Digital AutoPilot systems are each briefly described to provide context for\nmore modern control techniques:\n\n\u2022 Orbital Re-entry Digital Autopilot (ENTRY DAP): assumed control of theCom-\nmand Module (CM) after separation from the Service Module (SM) and handled\nall Command Module flight maneuvers beginning with reorientation into Entry\n\nFig. 1.1 Illustrations of one of the earliest successful spacecraft autonomous control systems for\nthe NASA Apollo Command Service Module (CSM). a Block diagram logic used by Reaction\nControl System thrusters to control CSM attitude. Here ?d represents the reference attitude angle,\n?e the attitude error, ? an attitude bias, ? the attitude rate, and ?? the attitude rate estimate. b Phase-\nplane logic schematic. For double-integrator models, this design can be shown to drive the rate and\nattitude errors plotted on the x- and y-axes to the box-like area near the origin. The logic works by\nbreaking the plane into disjoint zones, inside of which the spacecraft is pre-programmed to torque\npositively or negatively (solid white areas) or coast (shaded region); horizontal lines represent zero-\nacceleration trajectories or \u201ccoasting arcs,\u201d while parabolas represent lines of constant acceleration.\nImages courtesy of [132]\n\n\n\n8 J.A. Starek et al.\n\nattitude up until drogue chute deployment. The autopilot called pairs of thrusters\ndistributed along the rim of the base of the Command Module, as well as an addi-\ntional pair near the tip for pitch-down control. The first phase of operation marked\nexoatmospheric mode, using various combinations of rate damping, attitude-hold,\nand attitude-control depending on the pitch angle value. Phase-plane logic con-\ntrollers1 (attitude rate versus attitude error)with biased deadzones drove the system\nto desired error tolerances. Once drag rose above 0.05g, atmospheric mode was\ninitiated. In this regime, roll control was maintained using a complex phase plane\nincorporating a straight control line, maximum velocity boundaries, and constant-\nacceleration switching lines, while yaw and pitch reverted to rate-damping using\na yaw rate versus roll rate phase plane logic and a simple relay with deadband,\nrespectively. The purpose of ENTRY DAP was to maintain the component of lift\nin the trajectory plane needed to target a desired landing site given the vehicle\u2019s\ncurrent position and velocity.\n\n\u2022 Reaction-Control System Digital Autopilot (RCS DAP): Responsible for con-\ntrolling the attitude and attitude rates of the Command Service Module during\ncoasting flight, both with or without the Lunar Module (LM) stage attached. The\nDigital AutoPilot employed for pitch, yaw, and roll control four clusters, called\nquads, of four Reaction-Control System thrusters each, using a phase-plane logic\ncontroller with nonlinear switching lines, a central deadband, and built-in hys-\nteresis. The timing and firing commands of individual thrusters were issued by a\nthruster-selection logic responsible for resolving Digital AutoPilot rotation com-\nmands with translation commands and executing them as economically as possi-\nble according to the distribution of functional thrusters available. A second-order\nangular-rate Kalman filter was used to compute estimates of angular velocity by\nweighted sum of (1) extrapolated values of previous estimates and (2) derivations\nfrom gimbal angle measurements.\n\n\u2022 Thrust-Vector-Control Digital Autopilot (TVC DAP): Used to control the Com-\nmand ServiceModule during powered flight, both with or without the Lunar Mod-\nule attached. Pitch and yaw were adjusted by actuating the gimbal servos of the\nmain engine, while a separate autopilot called TVC ROLL DAP controlled the\nCommand Service Module attitude and rate about the roll axis during powered\nflight via the Reaction-Control System thruster quads. TVC DAP fed estimates of\nattitude rate and angle errors to pitch and yaw compensation filters, with various\ncombinations of attenuation and phase stabilization depending on the configura-\ntion of the Command ServiceModule due to the changes in overall center-of-mass\nposition, bending modes, and fuel slosh instabilities. TVC ROLL DAP used an\n\n1Phase-plane controllers are typically used to determine stabilizing on-off control inputs for one\ndegree-of-freedom differential systems by defining a coordinate plane of two state variables (typi-\ncally a state error and its corresponding state rate error) and a set of switching curves with accom-\npanying \u201cdeadband,\u201d \u201chysteresis,\u201d etc. in such a way as to partition the space into disjoint control\nregions that drive the system to within certain limits of the coordinate plane origin. Figure1.1 shows\na schematic of the phase-planes used by the Apollo missions.\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 9\n\nadaptation to the phase-plane switching logic of RCS DAP in free flight, modified\nwith ideal parabolic switching curves for roll axis attitude-hold within a small\ntolerance. A number of logical constraints were additionally enacted in order to\nconserve fuel and minimize the risk of thruster failures.\n\n1.2.3.2 Model Predictive Control\n\nModel predictive control (MPC) is a feedback lawbased on the repeated solution of an\noptimal control problem (i.e. ProblemG&C) that uses an assumed dynamicsmodel f\nand the current state set as the initial condition. This problem is solved to yield a finite-\nhorizon control trajectory that optimizes the predicted state response over the duration\nof a planning period or time horizon. Once solved, however, only the initial control\nsegment is actually applied, after which the problem is reinitialized and the process\nrepeats until convergence to the goal. This characteristic renewal procedure over a\nrepeatedly updated horizon is what gives MPC its other common names: receding\nhorizon optimal control or moving horizon optimal control. This concept allows\none to design a feedback controller on the basis of nearly any open-loop optimal\ncontrol approach, improving its robustness and imparting it the ability to handle\ndisturbances and mitigate error growth. Even without prior disturbance modeling,\none can demonstrate under appropriate assumptions thatMPCcan lead to closed-loop\nstability and state convergence to the target [86]. Other advantages of MPC include\nthe ability to handle pointwise-in-time state and control constraints, the capability\nto withstand time delays, and reconfiguration in the presence of degradations and\nfailure modes [25, 26]. As the robustness properties of MPC are contingent on fast\nresolvability, open-loop controllers for vehicle guidance for the most part must be\nrestricted to convex optimization routines.Another common choice for usewithMPC\nschemes in autonomous spacecraft guidance is Mixed-Integer Linear Programming\n(MILP) [22, 110], which are essentially solvers for linear optimization problems\nwith embedded discrete variables to handle simple logical constraints such as mode\nswitching and collision-avoidance.\n\n1.2.3.3 Artificial Potential Functions\n\nThe artificial potential function (APF) method [7, 16, 87] transforms the guidance\nproblem into particle motion within a potential field. Attractive potentials are used\nfor goal regions, while repulsive potentials are used for obstacles\u2014the value of occu-\npying a particular state is then represented by the sum of individual terms. A gradient\nascent/descent routine is often called to trace a feasible path from any initial state,\nwhich, when tuned appropriately, will safely circumnavigate neighboring obstacles\nand converge to a goal. Alternatively, an optimal control problem may be formed to\nplan a path that minimizes the path integral along the gradient force field (analogous\nto minimum-work in physical systems). The approach benefits greatly from the abil-\nity to react in real-time to environmental changes through adjustments in individual\n\n\n\n10 J.A. Starek et al.\n\npotential functions. Some difficulty lies in adjusting each function such that the\nspacecraft behaves as desired (i.e. ensuring sufficient margin from obstacles, rapid\nconvergence, etc.). However, the main drawback of APFs is their well-known sus-\nceptibility to converge to local minima, which cannot be avoided without additional\nheuristic techniques. This tendency can be mitigated by attempting random walks\nout of local wells, or instead relying on a global optimization routine for open-loop\ncontrol, with an artificial potential function method called for closed-loop feedback\n(i.e. trajectory-following, bubble methods [109], or real-time path modification [23],\nfor instance).\n\n1.2.3.4 Spacecraft Motion Planning\n\nMotion planning constitutes a class of algorithms used to generate sequences of deci-\nsions, called plans, that safely navigate robots from given initial states to a set of\ntarget states called goals. The framework is sufficiently general that it applies equally\nwell to spacecraft and rovers as it does to traditional robots [80]. Motion planning\ntechniques can be classified into two categories: exact (combinatorial) algorithms\nand approximate (sampling-based) algorithms. Exact approaches develop a strategy\nbased on an explicit representation of the unsafe region of the state space, which\nallows them to guarantee a solution if one exists. Techniques typically involve the\nformation of roadmaps, which are topological graphs that efficiently capture the con-\nnectivity of points in the obstacle-free state space. Exact algorithms are often limited\nto problems of low-dimensionality, polygonally-shaped obstacles, and static envi-\nronments. Sampling-based algorithms, on the other hand, forgo explicit construction\nof the unsafe state space and instead explore pathways via a sampling procedure, with\nsafety verified by a \u201cblack-box\u201d collision-detection routine. In many ways this idea\nis computationally advantageous; however, it has the obvious drawback that weaker\nnotions of correctness and completeness must be tolerated\u2014existence of solutions\ncannot be guaranteed in finite time without drawing an infinite set of samples. Promi-\nnent examples of sampling-based algorithms include Probabilistic Roadmaps (PRM)\n[76], the family of Rapidly-Exploring Random Tree (RRT) algorithms [80, 81], and\nFastMarching Trees (FMT?) [68] together with its kinodynamic versions [115, 116].\nSampling-based motion planning algorithms such as these have been shown under\nmild conditions to quickly and uniformly explore the collision-free state space. Some\nof them (e.g., RRT? [75] and FMT? [68]) have the added benefit of asymptotic opti-\nmality; that is, they guarantee convergence to an optimal solution as the number of\nsamples goes to infinity.\n\n1.2.3.5 Recent Demonstration Missions\n\nA handful of autonomous maneuvering missions have demonstrated at least a few\nof these state-of-the-art methods (combined with digital logic). Prominent examples\ninclude JAXA\u2019s ETS-VII [77, 102], AFRL\u2019s XSS-10 [38], DARPA\u2019s Orbital Express\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 11\n\n[65], NASA\u2019s DART [111], and JAXA\u2019s Hayabusa [51, 135]. Sadly, notable guid-\nance and control anomalies and mishaps occurred during the latter three missions,\nin some cases spelling their end [20, 77, 135]. The DART spacecraft, for instance,\nbegan using much more propellant than expected during proximity operations and\ninitiated a series of maneuvers for departure and retirement, but eventually collided\nwith the MULBCOM satellite [20]. This suggests that presently autonomous space-\ncraft navigation and maneuvering, even in static environments with well-understood\ndynamics, is still in its technological infancy [22, 48].\n\n1.2.4 Challenges and Future Directions\n\nMany technical hurdles remain to be solved before autonomous spacecraft relative\nguidance can become a mature technology. This section begins in Sect. 1.2.4.1 with\na summary of the most important relative guidance challenges concerning general\nspaceflight, from which the discussion is specialized to two key areas: Planetary\nEntry, Descent, and Landing (EDL) in Sect. 1.2.4.2, and Proximity Operations in\nSect. 1.2.4.3, a blanket term that encompassesAutonomousRendezvous andDocking\n(AR&D), Autonomous Inspection and Servicing (AIS), and close-range operations\nabout primitive bodies.\n\n1.2.4.1 General Relative Guidance Challenges\n\nThe main guidance challenge for next-generation autonomous spacecraft is to solve\nthe guidance and control problem (Problem G&C) with the appropriate dynamics\nand constraints onboard and in real-time. This onboard capability will enable the\nexecution of missions with a much higher level of autonomy, ultimately prolonging\nmission times, increasing mission frequencies, decreasing costs, and returning more\nscientific data. Furthermore, it will allow the spacecraft designer to fully utilize the\nperformance envelope, thereby maximizing achievable performance.\n\nThe most important technical challenges to meet this ambitious goal are:\n\n\u2022 Implementability: Developing robust, real-time implementable, and verifiable\nonboard optimization algorithms for the solution of Problem G&C;\n\n\u2022 Verifiability: Developing design metrics and verification and validation methods\nfor real-time optimization-based guidance and control algorithms;\n\n\u2022 Formation Flight: Extending guidance techniques to multiple collaborative\nvehicles;\n\n\u2022 Testing: Demonstrating next-generation autonomous algorithms in representative\nflight testing.\n\nMeeting these challenges will require development of new mathematical formula-\ntions and algorithms for robust, real-time implementation and for ground analysis.\nFor example, if one can express Problem G&C as a convex optimization problem for\n\n\n\n12 J.A. Starek et al.\n\na given application, then one can employ Interior Point Method algorithms (IPMs)\nto achieve globally-optimal solutions [21, 98], as well as improve runtime execution\nspeeds by 2\u20133 orders of magnitude [85]. This clearly motivates the use of real-\ntime convex optimization for relative guidance whenever possible, either in the ideal\ncase through lossless convexification (as in [58], for example) or through reasonable\nconvex approximations, particularly for complex, difficult, or hazardous problems\nwhere the important need is a reasonably-good feasible solution obeying all mission\nconstraints.\n\nVerifiability of solution methods is also another interesting and important chal-\nlenge. In classical linear feedback control, one has prescribed design metrics such\nas phase and gain margin specifications that serve as useful targets in the design of\nfeedback controllers. It is relatively straightforward to check whether these require-\nments are satisfied at design time. In the case of more complex guidance algorithms,\non the other hand, such general metrics do not exist. A good example can be given in\nthe context of Mars precision landing, for which the trajectory designer must direct a\nvehicle from any initial state at the end of the parachute phase to a target on the Mars\nsurface with zero velocity. Suppose the expected set of initial conditions at the start\nof powered descent is Ipd . Define Ic as the set of all initial conditions from which\nthe lander can reach the target, assuming fixed control parameters such as propellant\nmass fraction, thrust-to-weight ratio, fuel consumption rate, etc. Then verification\nsimply requires checking whether the following set inclusion relationship holds:\n\nIpd ? Ic.\n\nThe next question is how to generate Ic for a given set of design parameters. Exact\napproaches devised for discrete systems conduct systematic searches through a finite\nstate-space, collecting information about reachable sets and the properties of the\nstates traversed [33, 136]. However, due to the exponential growth in state-space\nsize with dimension, this is infeasible for continuous or high-dimensional systems.\nIn such instances, one must resort to approximate techniques, collectively called\nreachability analysis, for computing the set Ic. Clearly one approach is exhaustive\nsearch of sample points in the set; however, this is very time consuming and not\nusable at design time. Many efficient alternatives have been developed, however,\nincluding (1) optimal control and Lyapunov-based theory [53], (2) state abstraction,\nin which state-space size is reduced by grouping states together through omission of\nless useful details [82], (3) propagation of conservative over-approximations to the\ntrue sets [120], and (4) convexification of Problem G&C through exploitation of the\nproblem structure.\n\nThe next challenge is to extend guidance techniques to multiple collaborative\nvehicles. This complicates problem formulation and solution methods, rendering\ncomplex problems even more so when real-time solutions are demanded. The diffi-\nculty lies in the coupling between the safety of each vehicle to the future trajectories\nof all of its neighbors. This is often resolved in the literature by forming a hierarchy\nin planning, in which one vehicle neglects its neighbors and develops a plan, the\nsecond then develops a plan assuming the first\u2019s path is fixed, the third designs a path\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 13\n\nunder the consideration of the first and second, and so on. However, this technique\nmakes the key assumption that all current and future state information of each vehi-\ncle is freely communicable to all other vehicles. As this illustrates, multiple vehicle\ncollaboration and guidance entails the need for communication and scheduling. This\ngenerates the question of which control architecture, or rather communication archi-\ntecture, ismost suitable to the application. Control architectures vary fromeither fully\nindividualized control called distributed control, or fully dependent control called\ncentralized control, in which one vehicle or mothership determines the plans for all\nother vehicles. A number of methods have been developed to handle multiple space-\ncraft guidance, including specialized formation or coordination controllers (e.g. [13,\n127]), passive/active relative orbit formulations (e.g. Clohessy-Wiltshire-Hill equa-\ntions, halo orbits about libration points) [5, 55], optimal formation reconfigurations\n[113], rigid body or quasi-rigid body rotation planning [19], potential-based meth-\nods [31] and behavioral planning [67]. Much of the literature focuses on simple\nformation flight architectures, such as leader-follower formations. Formation flight\nand collaborative decision-making remain highly active areas of research.\n\nIn summary, the key for autonomous relative guidance is having robust solution\ntechniques that can be made efficient for real-time implementation. Though some of\nthese techniques may not be implementable on current space-qualified flight com-\nputers, the natural increase in onboard computational power and the use of multiple\nprocessors with algorithm parallelization could enable their use in the not-too-distant\nfuture. Therefore, priority in researchmust first be to develop robust solutionmethods\nfor the right problems with appropriate constraints. Subsequently, these algorithms\nshould be customized for flight implementation. Finally, a rigorous process (prefer-\nably combined with flight testing) should be established for solution verification and\nvalidation.\n\nThe following Sects. 1.2.4.2\u20131.2.4.3 specialize the general challenges of this sub-\nsection to planetary EDL and proximity operations, each illustrating the types of\ndifficult, mission-critical control maneuvers that typically lie at the cutting edge of\nmodern spacecraft autonomy research.\n\n1.2.4.2 Challenges for Planetary Entry, Descent, and Landing\n\nThis section focuses on the GN&C challenges associated with planetary missions,\nfirst highlighting the difficulties of Mars and Moon landings before extending to\nother planetary bodies.\n\nThe main purpose of any planetary landing GN&C system is to execute a con-\ntrolled deceleration from orbital or interplanetary velocities to near-rest conditions.\nFor a typical Mars EDL mission, this begins with an entry phase (see Fig. 1.2) that\ncancels most of the planetary relative velocity. Once slowed to supersonic speeds, a\nparachute is deployed. Then at a prescribed altitude (e.g. approx. 2km for the Mars\nScience Laboratory (MSL)), the parachute is discarded and the Powered Descent\n(PD) phase is initiated. At this point, passive descent during the parachute phase\ncoupled with atmospheric density and weather uncertainties cause the predicted\n\n\n\n14 J.A. Starek et al.\n\nParachute Phase\n\nPowered Descent (PD) Phase \n\nEntry Phase\n\nLanding \nlocation\n\nError accumulated during \nentry and parachute phases\n\nOptimal Large Divert\n\nLanding \nerror\n\nDivert with\nApollo algorithms\n\nState of the lander at the start of PD \nphase cannot be predetermined:\nAutonomous guidance is needed \nfor the corrective divert\n\nFig. 1.2 Optimal Powered Descent Guidance (PDG) will enable planetary precision landing.\nThese algorithms search over all physically possible diverts to find a fuel optimal one, significantly\nimproving divert capability over current state-of-the-art onboard algorithms\n\npositions and velocities relative to the target to disperse significantly (e.g. on the\norder of 8\u201310km with a velocity trigger (used during the MSL mission) or 5\u20136km\nwith a range trigger at the start of the parachute phase [130]). To achieve preci-\nsion landing (roughly 1km of position error or less at touchdown), an autonomous,\nreal-time Powered Descent Guidance (PDG) algorithm is required to continuously\nredirect the vehicle towards the surface target. In manned missions, the challenges\nare magnified and still largely unsolved. Though robotic landers can weigh as little\nas about 2 metric tons, they are expected to require as much as 50 metric tons in\nthe manned case, which essentially precludes any passive means of deceleration.\nSuccessful planetary descent of such heavy landers will necessitate active control\nstarting at supersonic speeds early in the EDL entry phase.\n\nFor planets or moons without an atmosphere, a solid rocket is typically used for\nlander deceleration in a Braking Burn phase, which is then followed by a Powered\nDescent controlled by liquid fuel propulsion for final landing. The process is com-\nplicated by the fact that solid rockets must burn all of their fuel to completion once\ninitiated. Significant uncertainty generally exists in the associated burn-time, leading\nto uncertainty in the vehicle state relative to the target at the end of the burn phase.\nAnalogous to atmospheric entry and descent, the Powered Descent phase is designed\nto correct for any error accumulated during the solid rocket phase; autonomous PD\nguidance algorithms must be called to guide the lander as close as possible to the\ngiven surface target in order to achieve optimal landing accuracies.\n\nIn all planetary or lunar landing missions, the associated autonomous guidance\nproblems for translational motion can be expressed as highly-constrained optimal\ncontrol problems [3, 18, 119]. Written in terms of Problem G&C, the guidance\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 15\n\nequations can be represented as follows: Let x = (x1, x2, x3), where x1 ? R3 and\nx2 ? R3 are the position and velocity, respectively, relative to the target in the\nrotating frame of Mars, and x3 > 0 is the lander mass. The guidance problem can\nbe formulated as,\n\nx? = f (t, x, u) = A(?)x + B\n(\n\ng(x1) + u\nx3\n\n)\n\nX (t) =\n\n???\n??\n\n{x | x(t) = x0} for t = t0\n{x\n\n??? ? n?Tx1(t) ? ?T x1(t)? and ?x2(t)? ? V?\n}\n\nfor t ? (t0, t f )\n{x | H x(t) = a} for t = t f\n\nU (t) =\n{\n\nu\n??? ?1 ? ?u? ? ?2 and n?Tu ? ?u? cos?\n\n}\n\nwhere A(?) defines the Newtonian motion in a rotating framewith fixed rotation rate\n? and g : R3 ? R3 defines the gravitational field. Here X (t) captures initial and\nfinal state constraints, along with constraints during the maneuver (known as \u201cglide\nslope\u201d constraints [18]). The control vector norm has both an upper bound ?2 and a\nnonzero lower bound ?1 due to the fact that the thrusters cannot be operated reliably\nbelow a prescribed value. The other constraint on the thrust vector is that it has to\nremain in a cone defined by the unit surface norm, n? ? R3, and half-angle ? in order\nto avoid any possibility of rotating the lander excessively, which could interfere with\nsensors that must be directed towards the surface. Note that the vehicle is assumed\nto be a point mass with a thrust vector attached to it. This simplification is a valid\none since the attitude control authority and bandwidth are much higher than those\nfor translation, so that the vehicle can quickly adjust its orientation any time a thrust\nvector is commanded.\n\nAs one does not know with certainty the initial relative state x0 into which\nthe lander will inserted from interplanetary flight, this problem must be solved\nautonomously in real-time on-board the spacecraft. To accommodate this, some\nauthors have developed simplified, approximate versions of this problem that lend\nthemselves to analytical solutions [40, 78, 88, 91, 122]; however, to certify preci-\nsion guidance across the entire landing envelope (the initial conditions from which\nit is physically possible to land), one must explicitly account for the full set of con-\nstraints. Unfortunately, the control constraints U (t) define a non-convex set (due to\n?1 > 0), which further emphasizes, as previously described, the benefits of lossless\nconvexification techniques [1, 3, 18, 59] and convex relaxations that are solvable\nusing Interior Point Methods (IPMs). The lossless convexification-based algorithm\n[3] has already been demonstrated successfully by NASA JPL. See [72\u201374] for\nflight videos. These test flights successively demonstrated increasingly aggressive\noptimal divert maneuvers, starting from 100m for unoptimized flight and ending\nwith the longest possible optimal divert of 750m, showing strong evidence that\nperformance boundaries can be pushed to the ultimate physical limits via onboard\noptimization.\n\n\n\n16 J.A. Starek et al.\n\n1.2.4.3 Challenges for AR&D, AIS, and Proximity Operations About\nPrimitive Bodies\n\nInAR&D,AIS, and close proximity operations near space objects (such as spacecraft\nor primitive celestial bodies) that are cooperative or otherwise, the primary guidance\nobjective is to compute a state trajectory that safely brings the spacecraft as close\nas needed (including docking) to its target object while consuming as little fuel as\npossible and avoiding any nearby hazards. In general, this introduces many difficult,\nnon-convex trajectory constraints into the optimal control problem given by Problem\nG&C [110]. A detailed list of examples are included here to illustrate the point:\n\n\u2022 Constraining sensor field-of-view: Often in proximity operations it is necessary\nto keep the target, spacecraft or primitive body in the field-of-view (FOV) of\nonboard sensors. This can be represented mathematically as:\n\nn? \u00b7 (r ? rT ) ? cos??r ? rT ?\n\nwhere n? is the unit vector describing the sensor boresight, r is the position vector\nof the spacecraft, rT is the position vector of the target body, and ? is the half-\ncone angle defining the FOV. This constraint couples the attitude and translational\ndynamics through n?, which is determined by the orientation of the spacecraft. To\nsee this explicitly, if the position vectors are resolved in a rotating reference frame,\ne.g. LVLH (Local-Vertical-Local-Horizontal), and n? is resolved in a spacecraft\nfixed frame, then the equation above can be re-expressed as,\n\n(r ? rT )TC(q)n? ? cos??r ? rT ?\n\nwhere q is the quaternion describing the attitude of the spacecraft, and C(q) is\nthe directional cosine matrix that takes a vector in the spacecraft body reference\nframe to the LVLH frame.\n\n\u2022 Avoiding plume impingement: Impingement of thruster exhaust plumes onneigh-\nboring spacecraft poses a serious threat that can jeopardize sensitive optical\ndevices, generate large force perturbations and disturbance torques, and disrupt\nthermal blankets and coatings [56]. Prevention requires restricting thrusters that\nare pointed towards neighboring vehicle(s) from firing below a prescribed relative\ndistance. Unfortunately, this imposes a loss of control authority and necessitates\nspecial guidance or escape plans that never apply thrust forces directed away from\nthe target when in close proximity. This constraint exists for primitive bodies as\nwell due to scientific contamination concerns, i.e. during sample return.\nRepresented mathematically, plume impingement constraints can be stated as, for\ni = 1, . . . , nt ,\n\nui = 0 when\n{\n\n(r ? rT )TC(q)t?i ? cos?p?r ? rT ?\n?r ? rT ? ? Rp\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 17\n\nwhere nt is the number of thrusters, ui is the thruster force command, t?i is the unit\nvector for the thruster direction in a spacecraft fixed frame, ?p is the plume cone\nangle, and Rp is the maximum effective plume radius (plume is effective if the\ntarget is in this radius).\n\n\u2022 Handling thruster force upper and lower (impulse bit) bounds: Due to fuel\nenergy storage limitations and nozzle design constraints, it is evident that all\nthrusters have finite upper bounds on the amount of force that they can provide.\nThere is also a minimum nonzero force or impulse (impulse bit) that imposes a\nlower bound on deliverable thrust; this means that arbitrarily small forces cannot\nbe applied using thrusters. This limits the control precision that can be achieved,\nwhich can be critical during docking or proximity operations.\nThese constraints, when using force commands, can be expressed as, for j =\n1, . . . , nt ,\n\nu j?{0} ? [u j,1, u j,2] where u j,1 > 0 and u2, j > u j,1 are min. and max. thrusts\n\n\u2022 Avoiding collisions: Nothing can be more catastrophic to a spacecraft mission\nthan collisions, which damage or destroy participating vehicles and often mark an\nimmediate mission failure. For AR&D and AIS, the collision avoidance constraint\ncan be described as follows,\n\nr ? rT /? ?c\nwhere rT is the position vector for the target and ?c is a set of relative positions\nthat lead to collisions. For a two-spacecraft scenario as in AR&D and AIS, this\ncan be simply a collision ball defined as?c = {z : ?z? ? Rc} for some prescribed\nvalue of Rc. In proximity operations around primitive bodies, this region can be\nmuch more complicated due to their irregular and often ill-defined shapes.\n\n\u2022 Providing required thruster silence times: As thrusters fire, large errors are\nintroduced into the state estimation due to process noise at the instance of firings.\nOften after each burn there must be a prescribed period of thruster silence to allow\nthe state estimator to filter this noise and re-converge to a prescribed level of\naccuracy.\nOne approach to impose prescribed thruster silence is to have zero controls in\nprescribed time periods during a maneuver, i.e.,\n\nFi (t) = 0, ?i = 1, . . . , nt when t ?\n?\n\nj=1,...,ns\nTj , (1.1)\n\nwhere Tj , j = 1, . . . , ns form a disjoint set of zero-thrust time intervals.\n\u2022 Using minimal fuel: Every spacecraft mission is constrained by a finite supply of\nfuel that must be transported with the scientific payload. The high cost of access to\nspace currently inhibits the ability to refuel or resupply spacecraft, for themost part\nisolating them and imposing a mission lifetime synonymous with remaining fuel.\nThis not only affectsmission lifetime but alsomission capability. For example, AIS\n\n\n\n18 J.A. Starek et al.\n\nmissions seek tomaximize total inspection time,which has a direct correspondence\nwithmaximizing fuel efficiency. For primitive bodies, using fuel efficiently implies\nlonger observation times and more attempts for surface contact.\n\n\u2022 Guaranteeing safety: A trajectory solution is needed that can ensure spacecraft\nand mission safety at all times, for both the vehicle and its neighbors. Guarantees\nare typically classified into two forms: passive safety, in which coasting arcs ema-\nnating from points along the nominal guidance trajectory are certified as safe, or\nactive safety, in which safe actuated abort sequences called collision avoidance\nmaneuvers (CAMs) are enforced [46, Sect. 4.4]. In either case, hard (determinis-\ntic) safety constraints are required to guarantee viable escape options in the event\nof thruster allocation errors (misfirings, stuck-on or stuck-off valves, canted noz-\nzles, etc.), unexpected environmental changes and disturbances, or even complete\nsystem shutdown. Often in practice this is achieved through ad-hoc open-loop tra-\njectory design (guided by significant technical expertise). However, an automated\napproach, potentially using optimal control techniques [22], positively-invariant\nsets [26, 54, 131], motion planning with safe samples [49], or some combination\nof all three [118], will be needed in the future in order to achieve truly autonomous\nAR&D and AIS capability.\n\n\u2022 Handling uncertainties: Thruster firings, aerodynamic drag in low Earth orbits,\nsolar radiation pressure, and camera measurements can introduce uncertainties in\nrelative state knowledge and control accuracy. As the spacecraft nears its target,\nthese uncertainties can induce violations in any of the aforementioned mission\nconstraints. Conversely, relative state accuracy typically improves as relative sep-\naration decreases. Hence one should embed in autonomous guidance and control\nalgorithms the capability to handle any expected uncertainty directly, i.e. one\nshould incorporate strategies to handle all \u201cknown unknowns.\u201d\n\nDue to potential coupling between translational and attitude dynamics, one must\nconsider both sets of dynamics in Problem G&C. This complicates the problem due\nto the inherent nonlinearity in the attitude dynamics, leading to nonlinear equality\nconstraints after discretization. Having nonlinear equality constraints means having\nnon-convex constraints, causing the resulting parameter optimization problem to\nbe a non-convex optimization problem. This complicates the numerical solution\nof Problem G&C significantly. Another source of non-convexity is the collision\navoidance constraint; its incorporation can also dramatically complicate the solution\nalgorithm for the same reason.\n\nAs a consequence of the nature of these constraints, convexification approaches\nfor AR&D, AIS, and proximity operations appear less suitable in this case than for\nEntry, Descent, and Landing problems due to the errors incurred through relaxation.\nHence new tools will be needed.\n\nIt is in this context precisely that motion planning algorithms (Sect. 1.2.3.4) have\nthe potential to shine. Numerous studies have already been conducted assessing their\nfeasibility for realistic spacecraft proximity operation scenarios [49, 50, 81, 106,\n118]. Though not yet flown on spacecraft hardware, their efficacy has already been\nproven in real-world systems with challenging dynamics, namely onboard real-time\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 19\n\nguidance of urban vehicles during the 2007 DARPA Urban Challenge. Several win-\nning entrants to the 60-mi autonomous urban driving race used motion planning as\ntheir primary guidance logic, including CMU\u2019s winning Boss car with Anytime-\nD?, Stanford\u2019s 2nd-place Junior car with hybrid A?, and MIT\u2019s 4th-place Talos car\nwith RRTs [24, 79, 83, 90, 126]. The ability of these algorithms to handle such\ndiverse constraints while providing robustness certificates in real-time applications\nis promising for autonomous spacecraft control.\n\n1.3 Extreme Mobility\n\nAmong the top technical challenges of technology area TA04 is maneuvering in\ndiverseNASA-relevant environments\u2014a task that encompasses awide range of envi-\nronmental, gravitational, and topographical conditions. Space exploration in such\nenvironments is enabled by three types of maneuvering: surface mobility, above-\nsurface mobility, and below-surface mobility. We focus here on the part of surface\nmobility called extreme-terrain mobility, which pertains to terrains with extreme\ntopographies, large distributions of hazards, and/or unique regolith types. During\nthe 2012 NRC review process, two different review boards ranked \u201cextreme-terrain\nmobility\u201d a high-priority2 technology forNASA to developwithin the next five years.\nThis section discusses the technical aspects and challenges associated with meeting\nthis goal.\n\n1.3.1 Scope\n\nExtreme-terrain mobility refers to surface mobility over a range of terrain topogra-\nphies and regolith properties on bodies with substantial gravity fields. Examples of\nsuch topographies and regolith types include highly-sloped crater walls and floors,\ncold traps, gullies, canyons, very soft and friable terrains, and terrain with extreme\nrock densities. It is worth noting that other extreme environmental conditions may\nalso be present at such sites, such as extreme temperatures or pressures. Extreme-\nterrain mobility covers capabilities that enable access and egress to such extreme\nterrains, safe traverses to designated targets, loitering for in situ measurements,\nand sample collection and extraction. Extreme-terrain mobility encompasses diverse\nplatforms that may include wheeled, legged, snake, hopping, tracked, tethered and\nhybrid platforms. Surface guidance, navigation and control for such diverse plat-\nforms depend in part on the nature and constraints for the mobility approach. While\naccess to and sampling from extreme terrains can also be accomplished through\nabove-surface mobility, a key feature of extreme-terrain access is loitering at targets\n\n2The National Research Council study panel ranked extreme-terrain mobility 6th, while its steering\ncommittee ranked it 8th [48, Table3.7, p. 88].\n\n\n\n20 J.A. Starek et al.\n\nof interest for in situ measurements. Since the NRC defined and prioritized above-\nsurface mobility separately from extreme mobility, we only address the latter in this\nsection.\n\n1.3.2 Need\n\nExtreme-terrain mobility would be an enabling technology for both science and\nhuman space exploration missions. For science missions, some of the most com-\npelling targets for future exploration within our solar system lie in terrains that are\ninaccessible to state-of-the-art robotic platforms, including NASA\u2019s Mars Explo-\nration Rovers [94] and the Mars Science Laboratory [93] rover.\n\nFor example, the recent discovery of recurring slope lineae (RSL), such as those\nobserved in Newton crater on Mars, are on steep slopes (25?\u201340?) that are hundreds\nof meters down from the crater rim. In situ analysis and sample capture of these out-\nflow deposits align with the science priorities that are described in both the Decadal\nSurvey [103] and the goals of MEPAG [35]. Similarly, successive flybys by the Mars\nGlobal Surveyor revealed dynamic processes in the form of bright gully deposits\non the walls of two separate unnamed Martian craters.3 In situ samples of these\nflows would likely lead to new insights into Martian geology. Moreover, methane\nplumes that have been discovered over hazardous terrain on Mars are intriguing\nresearchers who are now attempting to ascertain whether the source is geological or\nbiological in nature4; this represents another question that extreme-terrain mobility\ncould potentially answer.\n\nAnother compelling scientific site that lies within extreme terrain was discovered\nby NASA\u2019s Cassini spacecraft, which revealed what scientists believe to be a cry-\novolcano on the surface of Titan.5 Direct sampling of cryovolcanic ejecta along its\nsteep slopes would shed new light on the processes underlying cryovolcanism, as\nwell as provide valuable access to material from Titan\u2019s interior.\n\nA third example is from the LCROSS experiment. By impacting the lunar surface\nand analyzing the ejected debris, the LCROSSmission found evidence of water ice in\ntheMoon\u2019s permanently shadowed Cabeus Crater6 [34]. The shadowed regions lie at\nthe bottom of a long, steep slope. These lunar cold traps, which have never received\na single photon of sunlight, are believed to hold water ice within a few centimeters\n\n3New Gully Deposit in a Crater in the Centauri Montes Region (2006). URL: http://www.nasa.gov/\nmission_pages/mars/images/pia09028.html. Retrieved January 14th, 2011.\n4MartianMethane Reveals the Red Planet is Not a Dead Planet (2009). URL: http://www.nasa.gov/\nmission_pages/mars/news/marsmethane.html. Retrieved January 15th, 2011.\n5Flyover of Sotra Facula, Titan (2011). URL: http://www.nasa.gov/mission_pages/cassini/\nmultimedia/pia13695.html. Retrieved January 8th, 2011.\n6Ten Cool Things Seen in the First Year of LRO (2010). URL: http://www.nasa.gov/mission_pages/\nLRO/news/first-year_prt.htm. Retrieved February 3, 2011.\n\nhttp://www.nasa.gov/mission_pages/mars/images/pia09028.html\nhttp://www.nasa.gov/mission_pages/mars/images/pia09028.html\nhttp://www.nasa.gov/mission_pages/mars/news/marsmethane.html\nhttp://www.nasa.gov/mission_pages/mars/news/marsmethane.html\nhttp://www.nasa.gov/mission_pages/cassini/multimedia/pia13695.html\nhttp://www.nasa.gov/mission_pages/cassini/multimedia/pia13695.html\nhttp://www.nasa.gov/mission_pages/LRO/news/first-year_prt.htm\nhttp://www.nasa.gov/mission_pages/LRO/news/first-year_prt.htm\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 21\n\nFig. 1.3 Comparing\nhorizontal and vertical\naccess to stratigraphic layers.\nSome deeper layers may not\nbe accessible via horizontal\ntraverses\n\nof the surface. At high-probability locales such as these, the assessment of in situ\nresources in terms of presence confirmation, abundance mapping, and extraction\npossibilities would be critical for precursor missions ahead of human exploration\n[129]. Other features such as lunar vents [60] and lava tubes are also potential sites\nfor future exploration. Lava tubes, through observations of skylights on the Moon\nand on Mars, could potentially serve as future temporary habitats for astronauts,\nproviding them with protection from space radiation [63]. The exploration of lava\ntubes could also be of scientific interest for similar reasons.\n\nA new generation of robotic explorers is needed to explore these extreme ter-\nrains in order to access, probe, measure, extract and return samples. Traversing and\nloitering on steep, exposed substrate slopes reaching up to 90? would enable the\nexamination of stratigraphic layers of exposed bedrock [35] and icy bodies. While\ncurrent practice relies on long traverses across the surface to access these layers\n(Fig. 1.3), direct access of exposed strata enables close examination of the interface\nbetween stratigraphic layers, which, due to substantially less weathering, would offer\nmore details compared to what may be obtained through horizontal traverse alone\n[36].\n\nTraversing and loitering on slopes of granular and mixed media up to the angle of\nrepose enables access to locales such as the sites of putative \u201cwater\u201d seeps on Mars\n(Fig. 1.4). Traversing across and through alluvial fans for in situ examination would\nfurther our understanding of the underlying physical processes and composition of\nthe ejectedmaterial [35]. As detailed topography of such fansmay not bewell-known\na priori, robust and versatile mobility platforms are required for their exploration.\nUnfortunately, through the course of accessing such extreme terrain, hazards such as\nsinking into soft regolith or falling via landslides could be encountered. The ability to\nreliably avoid or survive such events in order to maintain an acceptable risk posture\nbecomes a key feature of these platforms.\n\nExtreme-terrain exploration could be embarked upon with remote robotic assets\nor could very well be part of human exploration missions. Extreme-terrain robots\nwould extend astronaut surface access to regions deemed too risky for human access.\nThey would also enable robotic precursor missions to explore hazardous sites likely\nto harbor needed resources for future habitation. Lunar robotic missions to extreme\nterrain could be operated from cis-Lunar orbit. Future human missions to Mars\ncould tele-operate robotic assets from stations on Phobos, a body significantly more\n\n\n\n22 J.A. Starek et al.\n\nFig. 1.4 Examples of extreme terrains on Mars: recurring slope lineae (RSL) in Newton crater\nhypothesized to be briny seeps (left, NASA/JPL-Caltech/University of Arizona\u2014Mars Recon-\nnaissance Orbiter HiRISE, 2011), and a false-color image of Mars\u2019 Victoria crater showing steep\nslopes, scattered rocks, bedrock, and tall cliffs (right,NASA/JPL/Cornell\u2014MarsExplorationRover:\nOpportunity 2007)\n\naccessible than the Martian surface that would also provide astronauts relatively\nbetter protection from solar radiation.\n\nIn short, extreme mobility technologies enable access to otherwise denied areas.\nThis provides NASA with the capability to maneuver its surface vehicles in extreme\nterrain in order to \u201cfollow the water\u201d\u2014a high-priority science focus for Martian and\nlunar science missions that generalizes to many extraterrestrial surface exploration\nmissions, human or robotic [48].\n\nWhile the primary motivation and focus here has been on planetary and lunar\nexploration, robotic vehicles that can traverse extreme terrain may have ample ter-\nrestrial applications aswell, including in scientific research such as sampling of active\nvolcanoes and Antarctic slopes, in civil applications such as search-and-rescue, or\nin commercial ventures such as mining.\n\n1.3.3 State of the Art\n\nSignificant progress in terrestrial robot mobility has been made in recent years\ntowards handlingmore challenging terrains. However, efforts have primarily focused\non human-traversable terrains applicable to military purposes. For example, Boston\nDynamics\u2019 BigDog and LS3 used dynamically-stable gaits to negotiate rough terrain\nand slopes of up to 35? grade under rough and slippery conditions [42, 43]. They\nalso demonstrated robustness to external force disturbances sufficient to throw the\nplatform off-balance.\n\nFor space robotics, the constraints on mass and power as well as the desire\nto traverse more extreme terrain have limited the adoption of such technologies.\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 23\n\nNevertheless, a number of developments have aimed at contributing to our current\nunderstanding of the potential strategies for extreme-terrain mobility on planetary\nbodies.\n\nBoth legged and wheeled robots, as well as tethered and untethered robots, have\nbeen proposed for exploring extreme terrestrial and planetary landscapes, several of\nwhich have been built and fielded. For example, the Dante II robot [10] was a tethered\nlegged robot thatwas specifically engineered to descend into active volcanoes. Shigeo\nHirose\u2019s group has explored self-anchoring tethers and tethered tracked vehicles for\nemergency response [62], as well as tethered leg vehicles for fieldwork [52]. The\nJPL legged ATHLETE robot, designed to handle cargo in support of a sustained\nhuman presence on the moon, has traversed rocky and sloped terrain at a number\nof analog sites in California and Arizona, including Black Point Lava Flow [134].\nFor slopes greater than 20?, the ATHLETE rover would also use a tether. The Axel\nrovers7 [97], designed to explore very steep terrains, have demonstrated traversal\nof near-vertical slopes and sloped terrain littered with large boulders. Other robots\nthat use leg-mounted active anchors in lieu of tethers have been proposed [8] and\ndeveloped [105].\n\nIn addition to these legged robots, a number ofwheeled designs have also been pro-\nposed, ofwhich several prototypes have been built, fielded, and flown.One promising\nexample is a recurring mechanism configuration used in either a six-wheeled rocker-\nbogie suspension (e.g. the MER and MSL rovers) or in a four-wheeled scissor-like\nactive suspension that allows each wheel to be independently lifted off the ground.\nSuch platformswere designed to lower the center-of-mass to provide greater stability.\nOne such example is the Nanorover [70], a grapefruit-sized rover that was proposed\nfor exploring an asteroid surface as part of the MUSES-C mission. This rover had a\nsymmetric design and was capable of operating in an upside-down configuration. It\nactively controlled its center and was even capable of hopping on low-gravity plan-\netary bodies. Follow-on concepts included tethering the Nanorover to a Sojourner\nclass rover for future Mars missions. The architecturally-similar SCARAB rover\ndemonstrated an inch-worming maneuver that synchronized wheel and suspension\nmechanism motion to traverse high-slip terrains [11]. Despite this ability, steeper\nslopes will likely require additional external stabilization, such as through a tether.\nA four-wheeled tethered rover was demonstrated with Cliffbot [107]. Unfortunately,\nthis architecture required a minimum of three rovers. Two rovers would traverse the\nrim of a crater while a third rover, tethered to the other two, would descend into the\ncrater. Lateralmobilitywith two tetherswould generally be greater at closer distances\nto the rim, but this advantage diminishes as the rover descends deeper into the crater.\nThe Cliffbot used the rim rovers to manage the tethers, which, unlike designs that pay\nout their own tether, risks higher abrasion from constant rock-scraping. Moreover,\nthe Cliffbot cannot recover from tip-over, and the problem of planning the motions\nof two tethers adds extra complexity.\n\n7Axel Videos (2011). URL:http://www.youtube.com/watch?v=Ijjo1nW94tY. Retrieved October\n30th, 2014.\n\nhttp://www.youtube.com/watch?v=Ijjo1nW94tY\n\n\n24 J.A. Starek et al.\n\nOutside of four-wheeled rovers, a number of previous efforts dating to the early\n1970\u2019s have recognized the potential of two-wheeled rovers for steep terrains. Several\nefforts have converged on a robotic body morphology consisting of a simple axial\nbody with two wheels and a caster, as recently exemplified by the Scout robots [121],\ndesigned for military applications. A similar tethered rover with three large inflatable\nwheels was proposed for future Mars missions [89]. Independently conceived, the\nfamily of Axel rovers was initially developed a decade ago to provide modularity\nand separation between themost failure-pronemobility elements and their respective\nscience payloads [64, 95]. In 2006, the originalAxel roverwas retrofittedwith a tether\nand adapted with grouser wheels for extreme-terrain mobility on slopes [96]. Such\na configuration, with its symmetric design, has demonstrated potential for robust,\nflexible mobility and operations on challenging terrain. Its single tether wasmanaged\nby the same mechanism that controls an articulated boom. This family of rovers has\nalso included instrument bays housed inside the wheel hubs, which could be oriented\nin a turret-like fashion independent of wheel rotation.\n\nThe DuAxel concept included docking and undocking of the Axel rovers with\na central module, enabling both untethered mobility for extreme-terrain access and\ntethered mobility on steep terrains [97].\n\nWhile progress has been made with extreme-terrain mobility for terrestrial appli-\ncations, at the date of this writing, there has been no planetary mission that has\nattempted access to extreme terrains. State-of-the-art surface exploration platforms,\nsuch as the highly successful Spirit and Opportunity rovers as well as the most recent\nCuriosity rover, were all designed to operate on relatively flat and shallow-sloped\nterrains with slopes of less than 20? and 30? grade, respectively.\n\n1.3.4 Challenges and Future Directions\n\nTo date, planetary rovers have been designed to explore rocky but relatively flat\nregions and were not intended for terrains such as deep craters, canyons, fissures,\ngullies and cryovolcanoes. Such extreme terrains pose a unique set of challenges and\nrequirements for a robotic explorer. Researchers developing extreme-terrain surface\nspace robots have to contend with the system complexity that results from high\ndegrees of articulation, tether management, and the challenges associated with lim-\nited power, communication, mass, volume, and computation, as well as with terrain\nvariations that impact anchoring and other surface operations. Conventional, flat-\ntopography rover designs must be completely re-evaluated in the context of high-risk\nterrain missions.\n\nOne of themost significant challenges associatedwith extreme-terrain exploration\nderives from having to land proximal to but outside of the target site, demanding an\napproach from afar over diverse topographies that may require unique mobility aids\nsuch as tethers, anchors, and higher traction devices. To illustrate, Fig. 1.4 shows a\nground-level picture of Mars\u2019 Victoria Crater as imaged by the Opportunity Rover.\nTypical of Martian craters, Victoria consists of steep slopes, scattered rocks, exposed\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 25\n\nbedrock, and tall cliffs. Rocker-bogie class rovers such as Spirit, Opportunity or\nCuriosity were not designed for such terrain, and would not likely be well-suited to\nnavigate it. Such terrains would be very difficult to traverse since platform mobility\ndecreases with slope grade, particularly in areas of loose regolith where traction\nforces can be severely diminished. Given that a sand trap on relatively smooth terrain\nwas enough to ensnare the Spirit rover [6], even a small amount of loose soil on sloped\nterrain could prove insurmountable to traditional rovers trying to climb a crater wall\nagainst the forces of gravity. Extreme-terrain rovers must be able to operate robustly\nin such cases.\n\nAnother mobility hazard associated with traversing steep and rugged terrain is\ntip-over, a concern which must be taken into consideration when designing extreme\nterrain rovers. Tip-over can be caused by improper stabilization, or by other uncon-\ntrollable external factors such as wind, slippery ice, loose rocks, and many other\nenvironmental factors. In 1992, the eight-legged walking robot, Dante II, success-\nfully descended into Alaska\u2019s Mt. Spurr volcano using a winch-cable system [10].\nOn the ascent trip, however, the rover fell on its side under the influence of large\nlateral tether forces and was unable to right itself. Extreme-terrain rovers can reduce\nthe risk of tip-over by lowering their centers-of-mass and carefully planning safe\nroutes around obstacles so as to avoid tether entanglement and potential tip-over\nconditions. Alternatively, such rovers can be designed to operate in both upright\nand upside-down configurations, thereby eliminating the end-of-mission dangers of\ntip-over altogether.\n\nAnother challenge for extreme terrain mobility is power and communication.\nEnergy sources can be difficult to find in areas of extreme terrain. For example, the\nCabeus Crater located near the Moon\u2019s south pole lies in a state of near-perpetual\ndarkness, thus precluding the use of solar power. Even with consistent access to\nsunlight, cold-traps like caves and crevices along crater walls would be difficult to\ninvestigate for prolonged periods. Rough terrain consisting of tall peaks, deep craters,\nor canyons naturally restrict access to sunlight, and rovers charged with exploring\nthese regions must be able to survive on a limited energy budget. Such terrains also\npresent challenges for Earth-based communications with the rover, particularly in\nthe absence of an orbiting communication satellite.\n\nA problem that is unique to the robotic exploration of cold regions, such as the\nsurface of Europa and other icy moons, is heat dissipation. In addition to traditional\nvehicle thermal engineering for ultra-cold climates, robotic explorers designed for\nthese environments must minimize thermal pollution to nearby terrain so as to avoid\ndisrupting the scientific analysis of volatile components. They must also be designed\nwith sufficient exposed surface area to allow for adequate thermal regulation.\n\nDue to the hazardous nature of the environments and the unique mechanical,\nthermal, and avionics designs likely required for extreme-terrain mobility, advanced\ncontrol and autonomy strategies will be needed to operate extreme-terrain rovers\nsafely. This will require more sophisticated onboard sensing, perception, planning\nand computational capabilities than for state-of-the-art flat-topography rovers due\nto the larger variations in terrain, more complex dynamics, and tighter operational\nconstraints.Of all the avionics systems, flight-qualified processors typically represent\n\n\n\n26 J.A. Starek et al.\n\nthe bottleneck on computational capability and hence restrict the types of algorithms\nand approaches that may be considered. Unfortunately, the performance gap between\ncurrent standard commercial processors and flight processors remains quite large. In\nthe commercial sector, the trend is moving toward greater parallelism and multiple-\ncore processing. Achieving comparable levels of computation, power consumption,\nrobustness, and reliability with a similar form factor on space-rated processors in the\nface of increasing cost constraints remains an open problem.\n\nIn addition to these general challenges, each platform design would offer its own\nrange of capabilities and introduce its own sets of constraints to be addressed and\nrisks to be retired. A concerted and focused effort would be necessary to mature\ntechnology to readiness levels acceptable for future missions. Key areas of technol-\nogy investments for extreme-terrain access include: traversal to designated targets in\nextreme terrains, retro traverse for captured samples, control of tethered or anchor-\ning platforms including anchoring and deanchoring, avionics equipment built for\nhazardous terrain, traversability analysis and motion planning, and high-fidelity ter-\nrain modeling and simulation of extreme-terrain mobility. We now discuss in greater\ndetail the major technical hurdles and challenges of each, below.\n\n\u2022 Traverse Technologies: In the absence of higher precision and pinpoint land-\ning capabilities that could deliver a payload to the vicinity of an extreme ter-\nrain site, it becomes necessary to traverse a distance of at least several kilo-\nmeters to reach them by ground. In this case, technologies that would enable\nfaster autonomous traverse for flight systems become critically important. State-\nof-the-art platforms currently navigate the surface at a rate of 20\u201330 m/sol using a\ncomputationally-demanding procedure. They first process stereo imagery, gener-\nate three-dimensional maps, and assess terrain traversability. If feasible, they then\nplan their motions and finally conduct their traverse. This sequential process can\ntake up to several minutes for every half-meter step. This is primarily driven by\nthe limited on-board power and computation on today\u2019s flight-qualified processors\nand by the lack of dedicated processors for computationally-demanding applica-\ntions. Recent developments have made advances in migrating computationally-\nintensive vision processing and some navigation functions to flight-relevant field-\nprogrammable gate arrays (FPGAs). This also enables vision-based pose estima-\ntion (a.k.a. visual odometry) to run more frequently and consequently help build\nmore accurate maps that enhance the quality of the navigation. Higher quality\nmaps would enable rovers to handle more challenging terrain and execute tighter\nmaneuvers in rock fields, such as thread-the-needle type maneuvers where the\nrover negotiates a path between two tightly-spaced obstacles. As terrain topogra-\nphies become more uncompromising near extreme sites, algorithmic advances in\nsurface navigation become more critical to reach targets of interest. One such\nexample is driving upslope towards a crater\u2019s edge before deploying a tethered\npayload into the steeply-sloped interior of the crater wall. As mobility in extreme\nterrain is likely to become more dynamic, advances in computationally-efficient\nlocalization would be necessary to improve control and mapping. In the future,\nonboard sensing is likely to be fused with higher-resolution orbital imagery for\nassessing terrain traversability in more effective and automated ways.\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 27\n\n\u2022 Tethered/Anchored Mobility and Control: This brings us to a second tech-\nnology: tethered and anchored mobility. Highly-sloped terrains require strong and\nrobustmechanical support to counteract the effects of gravity. One approachwould\nbe to use an external means of mechanical support. Research in tethered mobil-\nity has included the design and management of both single and multi-tethered\nplatforms. Future studies would need to focus on strategies that preserve tether\nintegrity, improve coordination, minimize damage, and reduce the risk ofmultiple-\ntether entanglement. Other technologies would include tether tension and shape\nsensing to assist in pose estimation and identify high stress (i.e. \u201cpinch\u201d) points.\nAlgorithmswould have to becomemore sophisticated to incorporate this additional\nsensory information for control and motion planning. Anchoring, either alone or\nin combination with tethering, can be another means of providing mechanical\nsupport to climbing or rappelling platforms on highly-sloped terrains. This can\nbe particularly challenging when terrain properties vary or are not known a pri-\nori, and would likely require onboard sensing and assessment of anchor bearing\nstrengths. The development of technologies that enable multiple anchoring and\nde-anchoring across a wide range of terrain types would also be highly beneficial.\n\n\u2022 Avionics and Terrain Equipment: Given the limited communication windows\nand bandwidths, some level of control and autonomy would be necessary dur-\ning operations.While state-of-the-art rovers have demonstrated surface navigation\n(obstacle detection and avoidance) for hundreds of meters at a time across theMar-\ntian surface, such technology would have to be extended to extreme terrains where\nsystem dynamics from the challenging topographies and gravity vector direc-\ntion become relevant. The unique design of extreme terrain mobility may impose\nadditional challenges and constraints on sensor configurations, which would also\nrequire further development. Platforms that sportmultiple appendageswould likely\nrequire tool changes when transitioning from benign to extreme terrain. A hybrid\nlegged platform on wheels would likely call for a transition between wheels and\nanchors when conducting an excursion across extreme terrain. In addition, given\nthat extreme-terrain assets are more likely to be payloads rather than primary plat-\nforms due to the overall risk, their low mass constraints would drive a need for\nsmaller and lighter sensors, cameras, inertial measurement units, and other instru-\nments. Miniaturization of avionics equipment would increase payload capabili-\nties. Mission-dependent objectives in extreme terrain such as sample acquisition,\ncaching and handling present their own unique equipment challenges. Drilling and\ncoring require stabilization of the platform or some form of grappling to impart\nnecessary forces for percussion or coring, for instance.\n\n\u2022 Traversability Analysis and Motion Planning: Control, traversability analysis\nand path planning for an extreme terrain mobility platform takes on a newmeaning\nthan for traditional flat-slope mobility. In extreme terrains, motion may be more\nconstrained (especially for tethered systems), control may require more sophisti-\ncated dynamical models given the gravity field, and knowledge of regolith prop-\nerties may be more critical. As compared with state-of-the-art motion planners\nthat primarily consider terrain geometry and wheel characteristics for traversabil-\nity, long-duration excursions in extreme terrain would demand more sophisticated\n\n\n\n28 J.A. Starek et al.\n\nmotion planning techniques that accurately account for gravitational forces and\nthe effects of terrain properties. Model-predictive motion planners that incorpo-\nrate dynamics may well play an important role for executing more predictable and\ncontrollable maneuvers in some of the most difficult terrains.\n\n\u2022 High-Fidelity Terrain Modeling and Mobility Simulation: As a number of chal-\nlenges need to be addressed to characterize extreme-terrain mobility in a relevant\nenvironment, some elements would likely benefit from advances in physics-based\nmodeling and simulation tools. Recent and future advances in granular media sim-\nulations may prove quite effective in characterizing the interactions of the mobility\nplatforms (or components) with regolith across a range of terrain types and under\ndifferent gravity models. Given the hazardous environments and terrains, reli-\nable fault protection and recovery systems would become essential parts of the\nhardware, software, or operational scenario design. For example, recovery from\ntip-overs could be addressed via a mechanical design that operates from all stable\nstates or through an alternate operational strategy. With appropriate simulation\ntools to inform the design, such scenarios and strategies could be more readily\ninvestigated and evaluated.\n\nIn addition to mobility technologies themselves, there are a number of related\ntechnology areas complementary to and supportive of extreme terrainmobilitywhose\nadvances would have direct impact to mobility research. Brief discussions of a few\nof the more important of these related technology areas are provided here.\n\nEntry, Descent and Landing\n\nOne example is landing precision, which falls under the Entry, Descent and Landing\ntechnology area (TA-09); see Sect. 1.2.4.2 for a detailed description of relevant chal-\nlenges. The key subcategories of relevance within entry, descent and landing are: (a)\nsurface access to increase the ability to land at a variety of planetary locales and times;\n(b) precision landing that enables space vehicles to land with reduced error, and (c)\nsurface hazard detection and avoidance to increase the robustness of landing systems\nto surface hazards. Since exploring extreme terrains would first require reaching\nextreme sites, technologies that would reduce the traverse distance by shrinking the\nsize of the landing ellipse would not only increase the number of potential landing\nsites, they would also reduce the traverse distance requirement, and hence mission\nduration, to visit those sites. Further advances in the terminal descent phase, such as\npin-point landing (within 100 m) could change the nature of extreme terrain explo-\nration, enabling cheaper missions where the extreme-terrain platform could then be\nhoisted on a lander and its resources leveraged for power and communication.\n\nBelow-Surface Mobility\n\nA second related area is below-surface mobility, which addresses vehicles that would\ntransit under regolith, in caves, or immersed in bodies of liquid. For certain sit-\nuations, the same technologies developed for extreme-terrain mobility could be\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 29\n\nre-purposed for below-surface mobility applications. The exploration of collapsed\nlava tubes (caves) and lunar vents are two such potential scenarios. For example,\ntethered platforms originally designed for access to the interior of crater walls could\nalso potentially be reapplied to lava tube exploration.\n\nMicrogravity Mobility\n\nTechnologies developed formicrogravity mobility as discussed in Sect. 1.4, including\nanchoring, fixturing, and tethering, as well as articulated legged, tracked, wheeled\nand hybrid mechanisms, could additionally apply to extreme-terrain mobility appli-\ncations and vice versa. Details on microgravity mobility systems will be given in the\nsubsequent section.\n\n1.4 Microgravity Mobility\n\nThe National Research Council recommended small-body/microgravity mobility as\na high priority technology for NASA for the next five years. Initially, microgravity\nmobility was assigned amedium/low score due to the expensive nature of micrograv-\nity system development and testing and its limited applicability outside the aerospace\ncommunity.\n\nThe panel later elevated the priority of this technology from medium to high\nbecause the NASA 2010 Authorization Act (P.L. 111\u2013267) indicated that small body\nmissions (to near-Earth asteroids) should be an objective for NASA human space-\nflight beyond Earth orbit. If this goal is pursued as a high NASA priority, it would\nalso likely require precursor robotic missions to small-body surfaces with applica-\nble mobility capability. This section describes the benefit, technical aspects, and\nchallenges facing the robotics community today in achieving microgravity mobility.\n\n1.4.1 Scope\n\nSmall-body mobility concerns the spatial surface traversal of planetary bodies with\nsubstantially reduced gravitational fields for the purpose of science and human explo-\nration. This includes mobility on Near-Earth Objects (NEOs), asteroids, comets,\nirregularly-shaped objects, and planetary moons, including Phobos, Deimos, Ence-\nladus, and Phoebe, to name a few notable examples. Surface mobility platforms\nfor small bodies differ from their planetary counterparts because the microgravity\nenvironment largely influences their design. Microgravity can be leveraged as an\nasset for mobility, as in the case for hopping platforms, or overcome as a challenge,\nas in the case for wheeled rovers and anchoring systems. Microgravity mobility\nincludes hopping, wheeled, legged, hybrid and other novel types of mobility plat-\nforms. \u201cHoppers\u201d\u2014a term short for hopping mobility platforms\u2014move via many\ndiverse forms of actuation; examples include propulsive thrusters, spring-loaded\n\n\n\n30 J.A. Starek et al.\n\nmechanisms, and internal actuation, which effects platform motion using internally\nmoving parts that generate reactionary forces or changes in the platform center-of-\ngravity. Note that any impacts of hopping robots with the surface are unlikely to cause\ndamage due to the very low gravitational acceleration associated with small-body\nobjects. Broadly-speaking, revolutions in these hardware and mechanism designs,\nas well as improvements in multi-asset mission operations, low-power computing,\nand autonomous control algorithms, will be key to performing mobile missions in\nmicrogravitational environments.\n\n1.4.2 Need\n\nWeak gravitational fields (micro-g tomilli-g), characteristic of celestial small bodies,\nhamper the adoption of traditional robotic mobility systems and call for the develop-\nment of disruptively new technologies for both surface mobility and surface opera-\ntions. The National Research Council has designated these mobility technologies for\nsmall-body and microgravity environments as a high-priority for NASA given their\ndestination potential for human spaceflight beyond Earth orbit, an endeavor likely to\nrequire several precursor robotic missions. The relevance of enhancing small-body\nexploration in the context of future human exploration programs was highlighted in\nthe exploration roadmap published by the Small Bodies Assessment Group [100] and\nin the objectives of the Strategic Knowledge Gaps for Human Exploration [129]. The\nneed for these technologies is further emphasized by the fact that, to-date, no mobil-\nity system has ever been successfully deployed over the surface of a small body,8\n\nindicating that little is currently known about robotic operations in microgravity\nenvironments.\n\nSurface investigation of small bodieswith a low-mass platform for both large-scale\ncoverage and fine-scale maneuvers (i.e. from kilometers to meters), as enabled by\nmicrogravity mobility, would be monumental to the advancement of space missions.\nData obtained from recent missions to small bodies show that surface properties on\nmost small bodies evolve over scales ranging from hundreds of meters to as little\nas a few meters (Fig. 1.5 highlights the diversity in surface properties at a variety\nof scales for two representative objects); this is in contrast to the long-held idea\nthat the surfaces of small bodies are, in general, both chemically and physically\nhomogeneous.\n\nThe benefit of microgravity mobility to expected scientific return can be seen\nexplicitly in the recent decadal survey report for planetary science, which prioritized\nthree main cross-cutting themes for planetary exploration: (1) the characterization\n\n8Small-body soft landings of spacecraft orbiters and static landers have, however, been achieved;\nthe first was NASA\u2019s NEAR Shoemaker on asteroid Eros in 2001 [41], followed by two touchdowns\nof JAXA\u2019sHayabusa on asteroid Itokawa in 2005 [? ]. ESA\u2019s Rosettamission [125] achieved the first\nsuccessful deployment of a static lander, named Philae, over the surface of comet 67P/Churyumov-\nGerasimenko on November 12th, 2014 [44].\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 31\n\nFig. 1.5 Illustration of the diversity of landscapes and of physical and chemical properties encoun-\ntered at small bodies. a Asteroid Itokawa (observed by Hayabusa) exhibits lateral variations in\nalbedo at the regional scale due to the combination of space weathering and surface dynamics (left);\nhigh-resolution imaging of Itokawa reveals bright patches of \u201cfresh\u201d material excavated in discrete\nplaces with a spatial extent on the order of 1m, distributed with a spatial wavelength of a fewmeters\n(right). b Observations of comet Tempel 1 by Deep Impact also indicate regional variations in geo-\nlogical properties (left), with the presence of volatiles confirmed in a few discrete places (indicated\nby arrows, right)\n\nof the early solar system history, (2) the search for planetary habitats, and (3) an\nimproved understanding about the nature of planetary processes [103]. A growing\nnumber of ground and space observations have recently shed new light on the astro-\nbiological relevance of small bodies, indicating that the exploration of a selected\nsubset of small solar system bodies would collectively address all three themes [28,\n29]. The explorations of small bodies such as Near-Earth Objects and the moons of\nMars are also key components of the flexible path for human exploration. In general,\norigins science and the search for habitats revolve around characterizing planetary\nmaterial chemistry (elemental, isotopic, mineralogical, noble gas, organics, etc.).\nWhile some measurements could be obtained from remote platforms (such as space\ntelescopes or orbiting spacecraft), most require direct contact with (or close prox-\nimity to) the surface, called in situ measurement, for an extended period of time at\nmultiple locations [29]. This is also the case for the precursor science that enables\nhuman exploration, which first and foremost would require the detailed characteriza-\ntion of surface physics, including regolith mechanical properties, dust dynamics, and\nelectrostatic charging [129]. Though in situ exploration of small bodies is currently\nin its \u201ctechnological infancy,\u201d it is poised to become a major science enabler in the\nnear future, as the following several paragraphs serve to illustrate.\n\nAstronomical observations (such as seen in Fig. 1.6, made by ground-based and\nspace observatories), though particularly suited to characterizing the orbital prop-\nerties of large populations of objects, are insufficient for constraining the origins\nof single objects, as resonances can dramatically alter their orbital properties. As a\nresult, in situ exploration plays a pivotal role in determining the density distributions\nand dynamical properties of small bodies, while allowing more accurate character-\nization of volatile composition and isotopic ratios. Though isotopic ratios could be\ndetermined in some cases through mass spectrometry of outgassing material, most\nsmall bodies neither out-gas nor present enough exospheric density to allow such\nmeasurements. Hence for a large class of small bodies, the measurement of isotopic\n\n\n\n32 J.A. Starek et al.\n\nFig. 1.6 Illustration of the type of observations to be achieved by space missions in order to\nsuccessfully address the key science pertaining to the three cross-cutting themes highlighted in\nVision and Voyages. Note that in general we lack high resolution observations at the millimeter to\nmeter scale that can be best obtained by in situ exploration. Image courtesy of [29]\n\nratios requires in situ exploration. With appropriate instrumentation packages, this\ncapability would enable physical and chemical characterization of surface properties\nrelevant to both human and science exploration.\n\nFor a given science objective, in situ exploration at designated and multiple loca-\ntions should be an integral component of future missions, and techniques for such\noperations will need to be developed. Two motivating scientific examples are pre-\nsented here. First, the comet Hartley 2 exhibits two starkly different terrains: very\ngranular areas with vents and smooth areas that have been interpreted as wasting\nareas. Full characterization of the comet\u2019s surface would require sampling at each\nlocation. Second, the comet Tempel 1 presents four distinct geological units; in par-\nticular, it exhibits cryoflow features (products of its geological evolution) near areas\nthat appear to be less evolved andmay bemore representative of the original material\n(see Fig. 1.7). Spatially-extended exploration of Tempel 1 would be key to capturing\ninformation on the accretional environment of that object as well as on signatures of\nits long-term evolutionary processes.\n\nIn summary, in situ information enabled by surface mobility about the chemi-\ncal and physical heterogeneity of small bodies has the potential to lead to a much\nimproved understanding about their origins, evolution, and astrobiological relevance,\nyielding important ramifications for science and an expanded human presence in our\nsolar system.\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 33\n\nFig. 1.7 Illustration of the variety of landscapes found at comets. a Picture of Hartley 2 obtained\nby EPOXI showing a contrast in surface roughness between active and waste areas. b This close\nup shows the variations of physical properties, especially roughness, at all scales. c In this close-up\npicture of Tempel 1 observed by Deep Impact lateral variations in chemistry (ice and dust) occurs\non short spatial scales. Image courtesy of [29]\n\n1.4.3 State of the Art\n\nWhile there have been several attempts at small-body surfacemobility, as of this writ-\ning no such system has successfully explored the surface of a small body. Traditional\nforms of robotic mobility, such as wheels and legs, present bevies of new challenges\nwhen operated inmicrogravity. As a result, a number of innovative designs have been\nattempted using unconventional means of locomotion; for instance, NASA, RKA,\nESA, and JAXA have all attempted various forms of hopping strategies for traversing\nsmall bodies. In fact, three missions so far have included a robotic hopper as part of\ntheir payload: Phobos 2, Hayabusa, and Hayabusa 2. Their designs, as well as most\nattempts of hopping mobility, made use of two basic principles:\n\n1. Hopping using a sticking mechanism (thus jumping away from the surface).\n2. Hopping by moving an internal mass.\n\nPhobos 2 was a Soviet RKA mission launched in 1988, aimed at studying Mars\nand its moons Phobos and Deimos. The plan was to deploy in close proximity to the\nsurface of Phobos a 41-kg robotic hopper called PROP-F (see Fig. 1.8). Its actua-\ntion was based on a spring-loaded leg mechanism designed to adhere to the moon\u2019s\nsurface. Unfortunately, when Phobos 2 was within 50m of the Martian moon, com-\nmunication with the spacecraft was lost before PROP-F was deployed [112]. Several\nyears thereafter, the JAXA Hayabusa mission planned to carry JPL\u2019s Nanorover (see\nFig. 1.8), a four-wheeled rover with articulated suspension that was capable of roving\nand hopping. Unfortunately, the rover was canceled due to budgetary concerns. Sub-\nsequently, JAXA/ISAS developed the MINERVA rover, a 591g hopping rover that\nemployed for locomotion a single internal flywheel mounted on a turntable, which\nimparted control over the direction of each hop. The MINERVA design was rated to\nsurface traversal speeds as high as 0.1 m/s. Unfortunately, the MINERVA rover also\n\n\n\n34 J.A. Starek et al.\n\nFig. 1.8 a The PROP-F PhobosHopper. Image courtesy of [112]. bTheNanorover. Image courtesy\nof [71]\n\nfailed upon deployment [69]. Both Nanorover and MINERVA were solar-powered\nsystems and hence constrained to very limited power (on the order of a couple of\nWatts) and computation. Since then, a handful of other hopping designs have been\nattempted.NASA-JPLhas prototyped several generations of robotic hoppers actuated\nby surface adhesion. ESA developed a small hopper rover, calledMASCOT, actuated\nby spinning two eccentric masses. MASCOT is currently a part of the Hayabusa 2\nspacecraft payload [39, 124].\n\nAll of these platforms were designed for exploring extended areas; however, both\nof NASA\u2019s hopper prototypes [47, 71] (that relied on a combination of wheels\nand sticking mechanisms), ESA\u2019s hopper prototype, RKA\u2019s unsuccessful landers\nfor the exploration of Phobos, and JAXA\u2019s MINERVA lander did not allow for pre-\ncision traverses to designated targets. Controlled mobility and precise positioning of\ninstruments on the surfaces of small bodies are still active areas of current research.\nResearchers continue to examine several approaches to small-body mobility that\ninclude legged platforms with anchoring for traction [105, 133], as well as other\nforms of small-body leggedmobility that allow drilling and surface sample collection\n[61]. In addition, a team from Stanford, JPL, and MIT is currently developing an\ninternally actuated rover that encloses threemutually-orthogonal flywheels. Through\ncontrolled spinning of its internal flywheels, the rover can give rise to surface reaction\nforces that instigate rover tumbling (for fine mobility) or hopping (for large surface\ncoverage) in a controllable direction (see Fig. 1.9) [4].\n\nOther types of low gravity surface mobility have also been explored. Thrusters\nare the key actuation mechanism for the Comet Hopper (CHopper) mission concept,\none of the three preselections for the NASA 2016 Discovery-class mission to comet\n46P/Wirtanen [32]. The CHopper mission was designed to investigate changes in\nsurface properties with heliocentric distance and land multiple times (4\u20135 times) on\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 35\n\nFig. 1.9 A\nflywheel-actuated hopper\ndesigned for precise\nmaneuverability. Image\ncourtesy of Stanford\nUniversity\n\nthe surface of the comet, hopping twice each time before coming to a stop; however,\nit did not make the final selection.\n\n1.4.4 Challenges and Future Directions\n\nMicrogravity environments pose many challenges not only for mobility and manipu-\nlation at the surface of small bodies, but also for control, localization and navigation.\nRecent observations from both space mission and ground-based telescopes have\nrevealed a more diverse landscape than previously thought. Small body surfaces can\nrange from areas covered with a thick layer of fine regolith to ones with rocky and\nprotruded regions. What may seem like simple operations on bodies with substantial\ngravity fields, such as drilling or coring, can be quite difficult for a robot in micro-\ngravity, unless some form of fixturing or anchoring is used to impart necessary\nstabilization forces. The use of tethers or other aids could enhance control and\nimprove maneuvering precision, but they also yield the unfortunate side-effects of\nadded mass and complexity.\n\nTechnologies relevant for small body mobility include advanced mobility and\ncontrol techniques that would operate on a range of heterogeneous terrain types.\nThey would also include specialized techniques for localization of surface assets,\nwhich are likely to require support from an orbiter given the number of significant\nline-of-sight occlusions that result from the large topographic changes characteristic\nof many small bodies. Localization is particularly complex for hopping and tumbling\nsystems due to the discrete, impulsive changes in pose that result from actuation. The\norbiter, hosting spacecraft, or \u201cmothership,\u201d is also likely to be used for asset surface\ndeployment; as a result, advances in control strategies exploiting synergistic opera-\ntions between them and themothership could also enhance assetmapping andmotion\nplanning, while simultaneously alleviating their computational load. To date, most\nof the proposed architectures involving in situ mobile platforms rely on decoupled\nmission operations, in the sense that the mothership is essentially used as a commu-\nnication relay (a sort of \u201cbent pipe\u201d). This either requires sophisticated capabilities\non-board the mobile assets for perception, localization and surface navigation, or\n\n\n\n36 J.A. Starek et al.\n\nleads to platforms with limited maneuverability (when such onboard capabilities are\nnot implemented). Coupled, hierarchical approaches, on the other hand, would allow\nend-to-endminimalistic design ofmobile assets by redistributing their computational\ntasks. Here the functions that require wide-area information, such as perception and\nplanning, are assigned to the mothership, while functions that rely solely on local\ninformation, such as obstacle avoidance, are assigned to the mobile platforms.\n\nTo facilitate the discussion of microgravity systems, classification of mobility\nplatforms is divided into four groups according to their primary actuationmechanism.\n\n\u2022 Thruster Mobility: Thruster actuation for small body exploration involves the use\nof thrusters for control of far operations, with occasional visitations by de-orbit\nonto the surface of the object. Once finished on the surface, sorties conclude when\nthe spacecraft lifts off and resumes far operations. The premise is that landed oper-\nations allow an extended period of time for scientific data collection, while return\nto orbit can benefit the selection of and traversal to new scientifically-meaningful\nlanding sites. Possible drawbacks of this architecture include the risk of damage\nto the lander during landing operations, the constrained number of visit locations\ndue to a fixed fuel budget, and the limited surface mobility (which, combined with\nlanding ellipse uncertainties, could limit the platform\u2019s ability to target specific\nsites of interest). Furthermore, for science missions, contamination of the landing\nsite from thruster exhaust could potentially interfere with scientific measurements\nunless the lander had an alternate means of mobility or of reaching pristine terrain.\nTo overcome these limitations, it has been suggested to use a thruster-actuated\nmother spacecraft that deploys hopping rovers for surface mobility [37]. The main\ndrawbacks of this approach are its mechanical and operational complexity, and the\nfact that hovering at very low gravities can be extremely challenging.\n\n\u2022 Wheeled Mobility: Wheeled vehicles have been quite successful on bodies with\nsubstantial gravity like the Moon and Mars, demonstrating as many as tens of\nkilometers in driving distance. However, gravitational accelerations in the milli-g\nto micro-g range limit their practicality for small body applications. Because of\nvery low traction, wheeled vehicles are constrained to extremely low speeds of less\nthan 1.5 mm/s [71], a major issue that prevents fast mobility in microgravity. Other\nconcernswithwheeled vehicles are the complications inmaintainingwheel surface\ncontact (required for fine mobility and precision navigation to selected targets)\nand wheel mechanism sensitivity to dust contamination and external conditions\nthat could cause the wheels to become \u201cstuck.\u201d Furthermore, surface bumps that\ncause loss of contact can result in uncontrolled tumbling, a potentially catastrophic\nsituation for roving in deep space.\n\n\u2022 Legged Mobility: Leggedmobility systems facemany challenges inmicrogravita-\ntional environments. The primary drawbacks of legged systems are their mechani-\ncal and operational complexity, the need for some form of anchoring system, and a\nstrong dependence of performance on regolith properties [30, 117]. Unfortunately,\nas surface characteristics and regolith physics are largely unknown before launch,\ndesigning legs with good grasping properties is challenging. On the positive side,\nlegged systems would provide very precise mobility.\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 37\n\n\u2022 Hopping Mobility: Hopping rovers, or \u201choppers,\u201d are perhaps the most promis-\ning technology for future missions to microgravitational environments. Their key\nadvantage is that, with a fairly simple actuation mechanism, they are capable of\nlarge surface coverage with relatively little control effort. Moreover, they are less\nsensitive to the regolith properties of small body objects. Indeed, unlike other\ntypes of actuation, hopper designs seek to exploit the low gravity to their advan-\ntage, rather than facing it as a constraint. A particularly useful bonus of internal\nactuation mechanisms on hopper platforms is self-containment of moving parts,\nwhich significantly reduces the problemof dust contamination and thermal control.\nOne of the potential drawbacks to hopping mobility, however, is precision maneu-\nvering for targeted instrument placement and sampling hard surfaces. In spite of\nthis, if one is able to devise control strategies for fine mobility, hopping robots\nwith internal actuation could represent a good trade-off between performance and\ncomplexity (see also an analogous conclusion in [114]).\n\nUnlike typical rover developments targeted for larger bodies, development of\nmicrogravity technologies calls for specialized test beds (see Fig. 1.10), which are\nexpensive and have operational constraints. As a result, a necessary task for micro-\ngravity technologieswouldbe the development of high-fidelity simulations and cross-\nvalidation with results from experimental test beds and environments. High-fidelity\nphysics-based simulations of the regolith and its interaction with the platforms, such\nas granular media microgravity simulations, would play a significant role in enhanc-\ning our understanding of small-body mobility.\n\nSeveral subsidiary technologies would also be relevant to microgravity mobility.\nRobotic mobility advancements are strongly correlated with a number of fields, par-\nticularly power and energy regulation, thermal control, structural material\ndevelopment, planning and guidance algorithms, and telemetry and sensing. Each of\nthese subcategories and their benefits to microgravity mobility is described below.\n\nPower Supply\n\nMobility platforms, like all space-based applications, are tightly constrained by avail-\nable power. This is particularly apt for operations in microgravity. For example, the\n\nFig. 1.10 A six\ndegree-of-freedom gravity\noffload test bed for testing\nmobility platforms in\nemulated microgravity.\nImage courtesy of Stanford\nUniversity\n\n\n\n38 J.A. Starek et al.\n\naverage power consumption for a Phobos-like environment is on the order of 15W.\nFor mobility systems functioning primarily off of batteries, with no recharging capa-\nbility and assuming current state-of-the-art technology, lifetimes would be limited to\na couple of days at the most. Future efforts should explore life-expanding power sub-\nsystem approaches, most likely including hybrid systems of multiple power sources.\nTo increase microgravity assets\u2019 lifetimes beyond 48 hours, it may be necessary to\nconsider a combination of solar panels and secondary batteries. The critical concerns\nfor this system would be the available solar cell area and the possibility of solar cell\nregolith dust build-up. Contact with the surface or the use of thrusters that stir up\ndust may make solar cell/secondary battery choices unacceptably risky. Given the\nuncertainty of the dust environment, it may be that miniaturized Radioisotope Ther-\nmoelectric Generators (RTGs) would provide a lower-risk power alternative, despite\nthe cost and regulatory issues. Recent breakthroughs in this field might make this\noption viable. Another alternative technology that appears promising are advanced\nregenerative fuel cell systems.\n\nThermal Control\n\nThermal requirements differ widely depending on the environment being explored.\nContinuing with the example of Phobos, the moon\u2019s rapid movement (7.66 h orbital\nperiod) helps to average out the hot and cold exposure experienced on its surface.\nFirst-order estimates show a thermal time constant on the order of the orbital period,\nwith an average temperature slightly above freezing [29]. Hence, at least for Pho-\nbos and other short-period small bodies, passive thermal protection with additional\ncoatings and multi-layer insulation could be acceptable. On the other hand, for the\ncase of slowly-rotating NEOs, Radioisotope Heater Units (RHUs) may be required\nif worst-case temperatures fall below minimum values allowed for electrical heaters\nconsistent with the planned electrical power system. An RTG or RHU would most\nlikely require a heat switch designed to prevent overheating during the pre-launch\nand cruise phases. During surface operations, mobile assets would also need to be\nisolated against heat exchange with the ground.\n\nShielding Against Electrostatic Effects\n\nElectrostatic effects arising from solar wind and plasma build-up inDebye sheaths on\nthe dusty surfaces of celestial objects have the potential to wreak havoc on the electri-\ncal components of space vehicles. However, if the electrostatic field has a potential\nless than 100 V (as appears typical for most small bodies), electrostatic charging\nshould not represent a significant problem for deployed rovers\u2019 operations, e.g. dur-\ning telecommunications between mobile rovers and their mothership, arguably the\nmost sensitive subsystem to static. For hoppers in continuous tumbles, any net accu-\nmulated charge should rapidly reach an equilibrium with the surface. The only phase\nthat could represent a risk to such designs is the night-day transition; a possible\nsolution would be to turn off all telecommunications and allocate an initial phase\nfor the hopper to \u201cshake\u201d itself by tumbling. Other potential mitigation strategies\nfor static electricity include: (1) encapsulating hoppers or thruster-actuated mobile\nassets in a wire cage that would prevent communications equipment from touching\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 39\n\nthe ground, or (2) automatic off-switches that activate when mobile assets are not in\ncommunication with the mothership.\n\nLocalization and Navigation\n\nLocalization and navigation are key challenges, particularly for unmapped environ-\nments such as small bodies, which have not yet been fully characterized. During local\nnavigation across the terrain, existing localization approaches for rolling or walk-\ning robots may apply, such as the use of extended Kalman Filters to fuse celestial\nsensor data and optical-flow measurements [12]. Through dynamic sensors such as\nMEMS inertial measurement units, accelerometers, gyroscopes, and contact sensors,\nmobility platforms could also reconstruct their trajectory and hence determine their\ncurrent position. One or more sun sensors or star trackers could be incorporated for\nattitude determination; thruster-actuated mobility platforms may be able to employ\nhorizon sensors as well during far operations. However, dynamic sensing approaches\nmay be subject to large position errors due to sensor drift. This motivates the use of\nimaging sensors, which can map the local environment to assess terrain hazards and\nidentify nearby rocks and features to help with localization. Depending on the geo-\nmetrical constraints of mobile assets, vision may not be feasible or ideal. Small and\ncompact platforms would capture images from low vantage points, resulting in large\nocclusions and significant geometric variations. They also constrain the baseline for\nstereo vision (thus limiting depth perception). For hopping platforms, the contin-\nuously rotating fields of view would make mapping and localization particularly\nchallenging and would call for new, less resource-intensive algorithms.\n\nMulti-asset mission architectures, which employ a hosting spacecraft or moth-\nership together with minimalistic mobile rovers, demand special attention. Given\nthe low-mass, small-scale construction and the limited computational capabilities of\nsuch rovers, localization should rely on novel synergistic mission operations wherein\nthe mothership and its daughter assets share the responsibility for localization and\nmapping. As this scenario is unprecedented, this presents some unique opportuni-\nties for technology development in the area of hierarchical synergistic operations.\nWithin this architecture, localization of the rovers could be achieved through fusion\nof sensors onboard both the mothership and its daughter assets, with the mothership\nbearing the primary responsibility for rover localization. To keep the complexity,\ncomputation and power of the mobility assets to a minimum, the rovers should be\nresponsible only for local perception and carry a minimal suite of navigational sen-\nsors. The major hurdle associated with this architecture is its sensitivity to reliable\ntelecommunication.\n\nOn-Board Handling and Telemetry\n\nDue to the largely uncertain environment on small-body objects, successful attempts\nat communication for control commands are likely to be sporadic and discontinuous.\nThis poses a significant challenge, particularly for multi-asset operations. Irregu-\nlar line-of-sight with the mothership would force each mobile platform to operate\nautonomously, collecting, compressing, and storing data in between available uplink\nopportunities. In low radiation environments, an FPGA, small micro-controller or\n\n\n\n40 J.A. Starek et al.\n\nmicro-processor solution would be a favorable choice with relatively high-density\nmemory. The nature of the scientific payload would naturally allow for a high degree\nof sequential operation with the initial uplink of accelerometer data, followed by in\nsitu data.\n\n1.5 Conclusions\n\nThis chapter has addressed some of the engineering aspects and challenges associ-\nated with technology area TA04 \u201cRobotics, Tele-Robotics, and Autonomous Sys-\ntems,\u201d expanding the discussion of the 2011 NRC Report on top technology pri-\norities for NASA\u2019s Office of the Chief Technologist to a more detailed, technical\nscope. Specifically, this chapter has discussed the \u201cRelative Guidance Algorithms,\u201d\n\u201cExtreme-TerrainMobility,\u201d and \u201cSmall-Body/MicrogravityMobility\u201d technologies\nwithin the autonomous systems area, motivating the importance of each, highlighting\ncurrent state-of-the-art methods, and outlining the major technical hurdles facing the\naerospace engineering and robotics communities.\n\nSpacecraft guidance and control has attained a sufficient level of maturity that the\nmajority of remaining technological advancement lies in on-board guidance capa-\nbility and performance. Robust, real-time implementable, and verifiable optimiza-\ntion algorithms for \u201cRelative Guidance,\u201d as discussed in the second section of this\nchapter, are necessary to address situations involving delayed communications, time-\nvarying obstacles, elevated mission risk, and tight maneuver tolerances. Important\napplications on the forefront of today\u2019s capability include planetary entry, descent,\nand landing, autonomous rendezvous and docking, autonomous inspection and ser-\nvicing, and proximity operations about small bodies. Enhanced autonomy in these\ndifficult applications will require the extension ofmodern state-of-the-art techniques,\nincluding Mixed-Integer Linear Programming, Model Predictive Control, Artificial\nPotential Functions, andmotion planning algorithms, aswell as the invention of novel\napproaches. As described in the chapter, prospective approaches will need to be able\nto deal with logical modes, handle complex state-control constraints, and provide\ncertificates of algorithm correctness and convergence rates, all while providing hard\nguarantees of mission safety\n\nIn addition to spacecraft, future science and human exploration missions will\nheavily rely on autonomous control of mobile systems operating on and in proximity\nof extreme, hazardous landscapes of extraterrestrial bodies, including deep craters,\ncanyons, fissures, gullies and cryovolcanoes. The discussion in the third section of\nthis chapter on \u201cExtreme Terrain Mobility\u201d prompts for further technology advance-\nments toward the development of affordable and versatile mobility platforms that\nwould enable access to otherwise inaccessible areas, capable of safely traversing to\nmultiple and designated targets, loitering for in situ measurements, and harvesting\nsamples from extreme terrains. Conventional, flat-topography rover designs must be\nre-evaluated in the context of such high-risk missions in order to avoid the dangers\nof tip-over, loose regolith, and other uncompromising terrain hazards. The advance-\n\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 41\n\nments described in this chapter revolved around novel traverse technologies, teth-\nered mobility and control (including anchoring and fixturing deployment and man-\nagement), avionics and terrain equipment, traversability analysis, motion planning\ntechniques, and lastly high-fidelity terrainmodeling andmobility simulation.Motion\nplanning algorithms and control laws must be developed so that both fine mobility\nand instrument pointing can be reliably achieved over extreme terrains with narrower\ntargets on motion accuracy.\n\nThe subject of mobility was extended further in the final section of the chapter\nto the specialized case of microgravity. Weak gravitational fields are characteristic\nof celestial small bodies, whose unique environments call for dramatically different\nmodes of operation. \u201cSmall Body/Microgravity Mobility\u201d constitutes mobile opera-\ntions on Near-Earth Objects (NEOs), asteroids, comets, irregularly-shaped objects,\nand planetary moons, enabling the access to and study of entirely new and highly-\nprized scientific sites, including Phobos, Deimos, Enceladus, and Phoebe. Micro-\ngravity introduces a number of new and difficult challenges. Simple operations such\nas drilling or coring can be quite difficult unless some form of fixturing or anchor-\ning is used to impart necessary stabilization forces. Rovers relying on traditional\nmobility concepts (such as wheels and legs) originally developed for high-gravity\nenvironments cannot be used without significant modifications. On the other hand,\nlow gravity enables entirely new types of mobility, namely thruster-actuated locomo-\ntion and hopping by surface impact and/or internal actuation mechanisms. Concur-\nrent technological maturation of key subsystems is needed to enable these extreme\napplications of engineering. Research must be done to identify power supply options\nto increase mobility platform lifetimes, further develop communication and local-\nization strategies, improve thermal control and electrostatic shielding, and enable\non-board handling and telemetry. Finally, trades between monolithic and multi-asset\nmission architectures will be needed to determine the most appropriate balance of\ncomputational load for localization, mapping and motion planning between mobile\nassets and potential host spacecraft; this paradigm-shifting approach for synergistic\nmission operations directly exploits small bodies\u2019 low gravity in the design process,\nrather than facing it as a constraint, a key design perspective that will need to be\nadopted in order to enable small-body missions.\n\nAcknowledgments The development of this chapter was partially supported by an Early Career\nFaculty grant from NASA\u2019s Space Technology Research Grants Program (Grant NNX12AQ43G),\nby the NASA Innovative Advanced Concepts program (Grant NNX14AT49G), and by JPL under\nthe R&TD, CIF, and CAP programs. The authors wish to acknowledge insightful discussions with\nDr. Cinzia Zuffada (JPL), Dr. Tom Cwik (JPL), and Dr. Jonas Zmuidzinas (JPL). Government\nsponsorship acknowledged.\n\nReferences\n\n1. A\u00e7?kmes?e, B., Blackmore, L.: Lossless Convexification of a Class of Optimal Control Prob-\nlems with Non-convex Control Constraints. Automatica 47(2), 341\u2013347 (2011)\n\n\n\n42 J.A. Starek et al.\n\n2. A\u00e7ikmes?e, B., Carson, J.M., Bayard, D.S.: A Robust Model Predictive Control Algorithm\nfor Incrementally Conic Uncertain/Nonlinear Systems. International Journal on Robust and\nNonlinear Control 21(5), 563\u2013590 (2011)\n\n3. A\u00e7?kmese, B., Ploen, S.R.: Convex ProgrammingApproach to PoweredDescent Guidance for\nMars Landing. AIAA Journal of Guidance, Control, and Dynamics 30(5), 1353\u20131366 (2007)\n\n4. Allen, R., Pavone, M., McQuin, C., Nesnas, I. A. D., Castillo-Rogez, J. C., Nguyen, T.-N.,\nand Hoffman, J. A. Internally-Actuated Rovers for All-Access Surface Mobility: Theory and\nExperimentation. Proc. IEEE Conf. on Robotics and Automation, pp. 5481\u20135488. Karlsruhe,\nGermany, 2013\n\n5. Ardaens, J.-S., D\u2019Amico, S.: Spaceborne Autonomous Relative Control System for Dual\nSatellite Formations. AIAA Journal of Guidance, Control, and Dynamics 32(6), 1859\u20131870\n(2009)\n\n6. Arvidson, R. E., Bell, J. F., Bellutta, P., Cabrol, N. A., Catalano, J. G., Cohen, J., Crumpler,\nL. S., Des Marais, D. J., Estlin, T. A., and Farrand, W. H. e. a. Spirit Mars Rover Mission:\nOverview and Selected Results from the Northern Home Plate Winter Haven to the Side of\nScamander Crater. Journal of Geophysical Research, vol. 115 (E7), 2010\n\n7. Badawy, A., McInnes, C.R.: On-Orbit Assembly Using Superquadric Potential Fields. AIAA\nJournal of Guidance, Control, and Dynamics 31(1), 30\u201343 (2008)\n\n8. Badescu, M., Bao, X., Bar-Cohen, Y., Chang, Z., Dabiri, B. E., Kennedy, B., and Sherrit,\nS. Adapting the Ultrasonic/Sonic Driller/Corer for Walking/Climbing Robotic Applications.\nSPIE Smart Structures and Materials, pp. 160\u2013168. San Diego, CA, 2005\n\n9. Bajracharya, M., Maimone, M.W., Helmick, D.: Autonomy for Mars Rovers: Past, Present,\nand Future. IEEE Computer 41(12), 44\u201350 (2008)\n\n10. Bares, J.E.,Wettergreen, D.S.: Dante II: Technical Description, Results, and Lessons Learned.\nInternational Journal of Robotics Research 18(7), 621\u2013649 (1999)\n\n11. Bartlett, P., Wettergreen, D. S., andWhittaker, W. Design of the SCARABRover for Mobility\nand Drilling in the Lunar Cold Traps. i-SAIRAS, pp. 3\u20136. ESA, Hollywood, CA, 2008\n\n12. Baumgartner, E. T., Schenker, P. S., Leger, C., and Huntsberger, T. L. Sensor-fused Navi-\ngation and Manipulation from a Planetary Rover. SPIE Symposium on Sensor Fusion and\nDecentralized Control in Robotic Systems, vol. 3523, pp. 125\u2013134. Boston, MA, 1998\n\n13. Beard,R.W.,Lawton, J.,Hadaegh, F.Y.:ACoordinationArchitecture for Spacecraft Formation\nControl. IEEE Transactions on Control Systems Technology 9(6), 777\u2013790 (2001)\n\n14. Beauchamp, P.M., Cutts, J. A., Quadrelli, M.,Wood, L., Riedel, J. E., McHenry, M. C., Aung,\nM., Volpe, R., and Cangahuala, L. Guidance Navigation and Control Technology Assessment\nfor Future Planetary Science Missions. AIAA SPACE Conferences & Exposition. San Diego,\nCA, 2013\n\n15. Betts, J.T.: Survey of Numerical Methods for Trajectory Optimization. AIAA Journal of\nGuidance, Control, and Dynamics 21(2), 193\u2013207 (1998)\n\n16. Bevilacqua, R., Lehmann, T., Romano, M.: Development and Experimentation of LQR/APF\nGuidance and Control for Autonomous Proximity Maneuvers of Multiple Spacecraft. Acta\nAstronautica 68(7\u20138), 1260\u20131275 (2011a)\n\n17. Bevilacqua, R., Romano, M., Curti, F., Caprari, A. P., and Pellegrini, V. Guidance Navigation\nand Control for Autonomous Multiple Spacecraft Assembly: Analysis and Experimentation.\nInt. Journal of Aerospace Engineering, pp. 1\u201318, 2011b\n\n18. Blackmore, L., A\u00e7?kmes?e, B., Scharf, D.P.: Minimum Landing-Error Powered-Descent Guid-\nance for Mars Landing using Convex Optimization. AIAA Journal of Guidance, Control, and\nDynamics 33(4), 1161\u20131171 (2010)\n\n19. Blake, C. Dynamics and Control of Satellite Formations Using a Quasi-rigid Body Formula-\ntion. Ph.D. thesis, McGill University, Montreal, Quebec, CA, 2008\n\n20. Board, D. M. I. Overview of the DART Mishap Investigation Results. Tech. rep., NASA,\n2006. Available at http://www.nasa.gov/pdf/148072main_DART_mishap_overview.pdf\n\n21. Boyd, S. and Vandenberghe, L. Convex Optimization. Cambridge University Press, 2004\n22. Breger, L., How, J.P.: Safe Trajectories for Autonomous Rendezvous of Spacecraft. AIAA\n\nJournal of Guidance, Control, and Dynamics 31(5), 1478\u20131489 (2008)\n\nhttp://www.nasa.gov/pdf/148072main_DART_mishap_overview.pdf\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 43\n\n23. Brock, O. and Khatib, O. Real-time Re-planning in High-Dimensional Configuration Spaces\nUsing Sets of Homotopic Paths. Proc. IEEE Conf. on Robotics and Automation, vol. 1, pp.\n550\u2013555. San Francisco, CA, 2000\n\n24. Buehler, M., Iagnemma, K., and Singh, S. (eds.). The DARPAUrban Challenge: Autonomous\nVehicles in City Traffic, vol. 56 of Tracts in Advanced Robotics. Springer, 1st edn., 2010\n\n25. Camacho, E. F. andBordons, C.NonlinearModel PredictiveControl:An IntroductoryReview.\nFindeisen,R.,Allg\u00f6wer, F., andB., L.T. (eds.),Assessment andFutureDirections ofNonlinear\nModel Predictive Control, vol. 358 of Lecture Notes in Control and Information Sciences, pp.\n1\u201316. Springer, 2007\n\n26. Carson, J. M., A\u00e7ikmes?e, B., Murray, R. M., and MacMynowski, D. G. A Robust Model\nPredictive Control Algorithm with a Reactive Safety Mode. Chung, M. J. andMisra, P. (eds.),\nIFAC World Congress, vol. 17, pp. 13175\u201313181. Gangnam-gu Seoul, South Korea, 2008\n\n27. Carson III, J. M., A\u00e7?kmes?e, B., Blackmore, L., and Wolf, A. A. Capabilities of Convex\nPowered-Descent Guidance Algorithms for Pinpoint and Precision Landing. IEEEAerospace\nConference, pp. 1\u20138. Big Sky, MT, 2011\n\n28. Castillo-Rogez, J. C. and Lunine, J. I. Small Habitable Worlds. Impey, C., Lunine, J. I., and\nFunes, J. (eds.), Frontiers of Astrobiology, chap. 10, p. 331. Cambridge University Press,\nCambridge, UK, 2012\n\n29. Castillo-Rogez, J. C., Pavone, M., Nesnas, I. A. D., and Hoffman, J. A. Expected Sci-\nence Return of Spatially-Extended In-situ Exploration at Small Solar System Bodies. IEEE\nAerospace Conference, pp. 1\u201315. Big Sky, MT, 2012\n\n30. Chacin, M., Mora, A., and Yoshida, K. Motion Control of Multi-Limbed Robots for Asteroid\nExploration Missions. Proc. IEEE Conf. on Robotics and Automation, pp. 3037\u20133042. Kobe,\nJapan, 2009\n\n31. Chang, D. E., Shadden, S. C., Marsden, J. E., and Olfati-Saber, R. Collision Avoidance for\nMultiple Agent Systems. Proc. IEEE Conf. on Decision and Control, vol. 1, pp. 539\u2013543.\nMaui, HI, 2003\n\n32. Clark, B. C., Sunshine, J. M., A\u2019Hearn, M. F., Cochran, A. L., Farnham, T. L., Harris, W.\nM., McCoy, T. J., and Veverka, J. NASA Comet Hopper Mission. LPI Asteroids, Comets,\nMeteors, vol. 1405, p. 8131. Baltimore, MD, 2008\n\n33. Clarke,E.,Grumberg,O., andLong,D.VerificationTools forFinite-StateConcurrent Systems.\nde Bakker, J. W., de Roever, W.-P., and Rozenberg, G. (eds.), A Decade of Concurrency\nReflections and Perspectives, Lecture Notes in Computer Science, chap. 19, pp. 124\u2013175.\nSpringer, 1994\n\n34. Colaprete, A., Schultz, P., Heldmann, J., Wooden, D., Shirley, M., Ennico, K., Hermalyn, B.,\nMarshall, W., Ricco, A., and Elphic, R. C. e. a. Detection of Water in the LCROSS Ejecta\nPlume. Science, vol. 330 (6003): pp. 463\u2013468, 2010\n\n35. Committee, M.E.P.A.G.M.G.: Mars Science Goals, Objectives, Investigations, and Priorities:\n2010. Tech. rep, NASA (2010)\n\n36. Conrad, P. G. Steep Terrain and the Evolution of Martian Surface Environments: Implications\nfor Habitability. Workshop on Mission Concepts for Accessing and Sampling High-Risk\nTerrain. Keck Institute for Space Studies, Pasadena, CA, 2009\n\n37. Cunio, P. M., Alibay, F., Meira, P., Sheerin, T., Lanford, E., Krupczak, E., and Hoffman, J. A.\nOptions in the Solar System for Planetary Surface Exploration via Hopping. IEEE Aerospace\nConference, pp. 1\u201310. Big Sky, MT, 2011\n\n38. Davis, T.M. andMelanson, D. XSS-10Microsatellite Flight Demonstration ProgramResults.\nJr., P. T. and Wright, M. (eds.), Proc. of SPIE, vol. 5419 of SPIE Spacecraft Platforms and\nInfrastructure, pp. 16\u201325. Orlando, FL, 2004\n\n39. Dietze, C., Herrmann, F., Ku\u00df, S., Lange, C., Scharringhausen, M., Witte, L., van Zoest,\nT., Yano, H.: Landing and Mobility Concept for the Small Asteroid Lander MASCOT on\nAsteroid 1999 JU3. Czech Republic, Int. Astronautical Congress. Prague (2010)\n\n40. D\u2019Souza, C. An Optimal Guidance Law for Planetary Landing. AIAA Conf. on Guidance,\nNavigation and Control. New Orleans, LA, 1997\n\n\n\n44 J.A. Starek et al.\n\n41. Dunham, D. W., Farquhar, R. W., McAdams, J. V., Holdridge, M., Nelson, R., Whittenburg,\nK., Antreasian, P., Chesley, S., Helfrich, C., and Owen, W. M. e. a. Implementation of the\nFirst Asteroid Landing. Icarus, vol. 159 (2): pp. 433\u2013438, 2002\n\n42. Dynamics, B. BigDog - The Most Advanced Rough-Terrain Robot on Earth. http://www.\nbostondynamics.com/robot_bigdog.html, 2012a. Accessed 01 September 2012\n\n43. Dynamics,B. LS3 -LeggedSquadSupport Systems. http://www.bostondynamics.com/robot_\nls3.html, 2012b. Accessed 01 September 2012\n\n44. ESA. Touchdown! Rosetta\u2019s Philae Probe Lands on Comet. http://www.esa.int/Our_\nActivities/Space_Science/Rosetta/Touchdown!_Rosetta_s_Philae_probe_lands_on_comet,\n2014\n\n45. Fahroo, F., Ross, I.M.: Direct Trajectory Optimization by a Chebyshev Pseudospectral\nMethod. AIAA Journal of Guidance, Control, and Dynamics 25(1), 160\u2013166 (2002)\n\n46. Fehse, W. Automated Rendezvous and Docking of Spacecraft, vol. 16. Cambridge University\nPress, 2003\n\n47. Fiorini, P., Burdick, J.: The Development of Hopping Capabilities for Small Robots.\nAutonomous Robots 14(2), 239\u2013254 (2003)\n\n48. for NASA Technology Roadmaps, S. C. NASA Space Technology Roadmaps and Priorities:\nRestoring NASA\u2019s Technological Edge and Paving the Way for a New Era in Space. Tech.\nrep., NRC,Washington, D.C., 2012. Available at http://www.nap.edu/openbook.php?record_\nid=13354\n\n49. Frazzoli, E.: Quasi-RandomAlgorithms for Real-Time SpacecraftMotion Planning andCoor-\ndination. Acta Astronautica 53(4\u201310), 485\u2013495 (2003)\n\n50. Frazzoli, E., Dahleh,M.A., Feron, E., andKornfeld, R.ARandomizedAttitude SlewPlanning\nAlgorithm for Autonomous Spacecraft. AIAA Conf. on Guidance, Navigation and Control,\npp. 1\u20138. Montreal, Quebec, Canada, 2001\n\n51. Fujiwara, A., Kawaguchi, J., Yeomans, D.K., Abe, M., Mukai, T., Okada, T., Saito, J., Yano,\nH., Yoshikawa, M., Scheeres, D.J., Barnouin-Jha, O., Cheng, A.F., Demura, H., Gaskell,\nR.W., Hirata, N., Ikeda, H., Kominato, T., Miyamoto, H., Nakamura, A.M., Nakamura, R.,\nSasaki, S., Uesugi, K.: The Rubble-Pile Asteroid Itokawa as Observed by Hayabusa. Science\n312(5778), 1330\u20131334 (2006)\n\n52. Fukushima, E.F., Kitamura, N., Hirose, S.: Development of Tethered Autonomous Mobile\nRobot Systems for Field Works. Advanced Robotics 15(4), 481\u2013496 (2001)\n\n53. Gayek, J. E. A Survey of Techniques for Approximating Reachable and Controllable Sets.\nProc. IEEE Conf. on Decision and Control, pp. 1724\u20131729. Brighton, England, 1991\n\n54. Gaylor, D. E. and Barbee, B. W. Algorithms for Safe Spacecraft Proximity Operations. AAS\nMeeting, vol. 127 of Advances in the Astronautical Sciences, pp. 1\u201320. Seattle, WA, 2007\n\n55. Gill, E., Montenbruck, O., D\u2019Amico, S.: Autonomous Formation Flying for the PRISMA\nMission. AIAA Journal of Spacecraft and Rockets 44(3), 671\u2013681 (2007)\n\n56. Goodman, J.L.: History of Space Shuttle Rendezvous and Proximity Operations. AIAA Jour-\nnal of Spacecraft and Rockets 43(5), 944\u2013959 (2006)\n\n57. Goodman, J. L. Lessons Learned From Seven Space Shuttle Missions. Tech. Rep. NASA/CR-\n2007-213697, United Space Alliance, Houston, TX, 2007\n\n58. Harris,M.W.,A\u00e7?kmes?e, B.: Lossless convexification of non-convex optimal control problems\nfor state constrained linear systems. Automatica 50(9), 2304\u20132311 (2014a)\n\n59. Harris, M.W., A\u00e7?kmes?e, B.: Maximum Divert for Planetary Landing Using Convex Opti-\nmization. Journal of Optimization Theory & Applications 162(3), 975\u2013995 (2014b)\n\n60. Hawke, B. R., Giguere, T. A., Gaddis, L. R., Gustafson, O., Lawrence, S. J., Stopar, J. D.,\nPeterson, C. A., Bell, J. F., and Robinson, M. S. e. a. Localized Pyroclastic Deposits in the\nGrimaldi Region of the Moon. LPI Science Conference Abstracts, vol. 43, p. 1749. The\nWoodlands, TX, 2012\n\n61. Helmick, D., Douillard, B., Bajracharya, M.: Small Body Surface Mobility with a Limbed\nRobot. IEEE/RSJ Int. Conf. on Intelligent Robots & Systems. Chicago, IL (2014)\n\n62. Hirose, S., Fukushima, E.F.: Snakes and Strings: New Robotic Components for Rescue Oper-\nations. International Journal of Robotics Research 23(4\u20135), 341\u2013349 (2004)\n\nhttp://www.bostondynamics.com/robot_bigdog.html\nhttp://www.bostondynamics.com/robot_bigdog.html\nhttp://www.bostondynamics.com/robot_ls3.html\nhttp://www.bostondynamics.com/robot_ls3.html\nhttp://www.esa.int/Our_Activities/Space_Science/Rosetta/Touchdown!_Rosetta_s_Philae_probe_lands_on_comet\nhttp://www.esa.int/Our_Activities/Space_Science/Rosetta/Touchdown!_Rosetta_s_Philae_probe_lands_on_comet\nhttp://www.nap.edu/openbook.php?record_id=13354\nhttp://www.nap.edu/openbook.php?record_id=13354\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 45\n\n63. Horz, F. Lava Tubes - Potential Shelters for Habitats. Mendell, W. W. (ed.), Lunar Bases\nand Space Activities of the 21st Century, vol. 6, chap. 6, pp. 405\u2013412. Lunar and Planetary\nInstitute, Houston, TX, 1985\n\n64. Howard, A., Nesnas, I. A. D., Werger, B., and Helmick, D. A Novel Reconfigurable Robotic\nExploratoryVehicle forNavigationonRoughTerrain. Proc. of the Int. SymposiumonRobotics\nand Applications, pp. 1\u20136. Seville, Spain, 2004\n\n65. Howard, R. T., Heaton, A. F., Pinson, R. M., and Carrington, C. K. Orbital Express Advanced\nVideo Guidance Sensor. IEEE Aerospace Conference, pp. 1\u201310. Big Sky, MT, 2008\n\n66. Hull, D.G.: Conversion of Optimal Control Problems into Parameter Optimization Problems.\nAIAA Journal of Guidance, Control, and Dynamics 20(1), 57\u201360 (1997)\n\n67. Izzo, D., Pettazzi, L.: Autonomous and Distributed Motion Planning for Satellite Swarm.\nAIAA Journal of Guidance, Control, and Dynamics 30(2), 449\u2013459 (2007)\n\n68. Janson, L. and Pavone, M. Fast Marching Trees: A Fast Marching Sampling-Based Method\nfor Optimal Motion Planning in Many Dimensions. International Symposium on Robotics\nResearch, 2013\n\n69. JAXA. Hayabusa Mission. http://hayabusa.jaxa.jp/e/index.html, 2000\n70. Jones, R., Wilcox, B.: Nanorover Technology and the MUSES-CN Mission. Tech. rep, JPL\n\n(1997)\n71. Jones, R., Wilcox, B.: The MUSES CN Rover and Asteroid Exploration Mission. Tech. rep,\n\nJPL (2000)\n72. JPL and Masten Space Systems. 500 meter Xombie Divert Test Flight for G-FOLD\n\n(Guidance for Fuel Optimal Large Divert) Validation. http://www.youtube.com/watch?v=\n1GRwimo1AwY, 2012a\n\n73. JPL and Masten Space Systems. 650 meter Xombie Divert Test Flight for G-FOLD\n(Guidance for Fuel Optimal Large Divert) Validation. http://www.youtube.com/watch?v=\nWU4TZlA3jsg, 2012b\n\n74. JPL andMasten Space Systems. 750meter Xombie Divert Test Flight for G-FOLD (Guidance\nfor Fuel Optimal Large Divert) Validation. http://www.youtube.com/watch?v=jl6pw2oossU,\n2012c\n\n75. Karaman, S. and Frazzoli, E. Optimal Kinodynamic Motion Planning using Incremental\nSampling-based Methods. Proc. IEEE Conf. on Decision and Control, pp. 7681\u20137687, 2010\n\n76. Kavraki, L.E., \u0160vestka, P., Latombe, J.C., Overmars, M.H.: Probabilistic Roadmaps for Path\nPlanning inHigh-Dimensional Spaces. IEEETransactions onRobotics andAutomation 12(4),\n566\u2013580 (1996)\n\n77. Kawano, I., Mokuno, M., Kasai, T., Suzuki, T.: Result of Autonomous Rendezvous Docking\nExperiment of Engineering Test Satellite-VII. AIAA Journal of Spacecraft and Rockets 38(1),\n105\u2013111 (2001)\n\n78. Klumpp, A.R.: Apollo Lunar Descent Guidance. Automatica 10(2), 133\u2013146 (1974)\n79. Kuwata,Y., Teo, J., Fiore,G.,Karaman, S., Frazzoli, E.,How, J.P.: Real-TimeMotionPlanning\n\nWith Applications to Autonomous Urban Driving. IEEE Transactions on Control Systems\nTechnology 17(5), 1105\u20131118 (2009)\n\n80. LaValle, S. M. Planning Algorithms. Cambridge University Press, 2006\n81. LaValle, S.M., Kuffner, J.J.: Randomized Kinodynamic Planning. International Journal of\n\nRobotics Research 20(5), 378\u2013400 (2001)\n82. Lefebvre, M.-A., Gu\u00e9guen, H.: Hybrid Abstractions of Affine Systems. Nonlinear Analysis:\n\nTheory, Methods & Applications 65(6), 1150\u20131167 (2006)\n83. Leonard, J., How, J.P., Teller, S., Berger, M., Campbell, S., Fiore, G., Fletcher, L., Frazzoli,\n\nE., Huang, A., Karaman, S., Koch, O., Kuwata, Y., Moore, D., Olson, E., Peters, S., Teo, J.,\nTruax, R.,Walter,M., Barrett, D., Epstein, A.,Maheloni, K.,Moyer, K., Jones, T., Buckley, R.,\nAntone, M., Galejs, R., Krishnamurthy, S., Williams, J.: A Perception-Driven Autonomous\nUrban Vehicle. Journal of Field Robotics 25(10), 727\u2013774 (2008)\n\n84. Major, L. M., Brady, T. M., and Paschall, S. C. Apollo Looking Forward: Crew Task Chal-\nlenges. IEEE Aerospace Conference, pp. 1\u20138. Big Sky, MT, 2009\n\nhttp://hayabusa.jaxa.jp/e/index.html\nhttp://www.youtube.com/watch?v=1GRwimo1AwY\nhttp://www.youtube.com/watch?v=1GRwimo1AwY\nhttp://www.youtube.com/watch?v=WU4TZlA3jsg\nhttp://www.youtube.com/watch?v=WU4TZlA3jsg\nhttp://www.youtube.com/watch?v=jl6pw2oossU\n\n\n46 J.A. Starek et al.\n\n85. Mattingley, J., Boyd, S.: Real-time Convex Optimization in Signal Processing. IEEE Signal\nProcessing Magazine 27(3), 50\u201361 (2010)\n\n86. Mayne,D.,Rawlings, J., Rao,C., Scokaert, P.:ConstrainedModel PredictiveControl: Stability\nand Optimality. Automatica 36(6), 789\u2013814 (2000)\n\n87. McInnes, C. R. Potential Function Methods for Autonomous Spacecraft Guidance and Con-\ntrol. AAS Astrodynamics Specialist Conference, pp. 2093\u20132109. Halifax, Nova Scotia,\nCanada, 1995\n\n88. Meditch, J.S.: On the Problem of Optimal Thrust Programming for a Lunar Soft Landing.\nIEEE Transactions on Automatic Control 9(4), 477\u2013484 (1964)\n\n89. Miller, S. L., Bell, J. L., Graf, J. E., and Matousek, S. E. Potential Future Mars Missions.\nAIAA SPACE Conferences & Exposition. Long Beach, CA, 2000\n\n90. Montemerlo, M., Becker, J., Bhat, S., Dahlkamp, H., Dolgov, D., Ettinger, S., Haehnel, D.,\nHilden, T., Hoffmann, G., Huhnke, B., et al.: Junior: The Stanford Entry in the Urban Chal-\nlenge. Journal of Field Robotics 25(9), 569\u2013597 (2008)\n\n91. Najson, F. and Mease, K. D. A Computationally Inexpensive Guidance Algorithm for Fuel-\nEfficient Terminal Descent. AIAA Journal of Guidance, Control, and Dynamics, vol. 29 (4),\n2006\n\n92. NASA. The Vision for Space Exploration. http://www.nasa.gov/pdf/55583main_vision_\nspace_exploration2.pdf, 2004\n\n93. NASA. Mars Science Laboratory Curiosity Rover. http://marsprogram.jpl.nasa.gov/msl/,\n2011a. Retrieved January 8th, 2011\n\n94. NASA. Spirit and Opportunity, Mars Exploration Rovers. http://www.nasa.gov/mission_\npages/mer/, 2011b. Retrieved January 8th, 2011\n\n95. Nesnas, I.A.D.: Reconfigurable Exploratory Robotic Vehicles. NASA Tech Briefs 25(7), 56\n(2001)\n\n96. Nesnas, I. A. D., Abad-Manterola, P., Edlund, J. A., and Burdick, J. W. Axel Mobility Plat-\nform for Steep Terrain Excursions and Sampling on Planetary Surfaces. IEEE Aerospace\nConference, pp. 1\u201311. Big Sky, MT, 2008\n\n97. Nesnas, I.A.D., Matthews, J.B., Abad-Manterola, P., Burdick, J.W., Edlund, J.A., Morrison,\nJ.C., Peters, R.D., Tanner, M.M., Miyake, R.N., Solish, B.S., et al.: Axel and DuAxel Rovers\nfor the Sustainable Exploration of Extreme Terrains. Journal of Field Robotics 29(4), 663\u2013685\n(2012)\n\n98. Nesterov, Y., Nemirovsky, A.: Interior-point Polynomial Methods in Convex Programming.\nSIAM, Philadelphia, PA (1994)\n\n99. Nolet, S., Kong, E., and Miller, D. W. Design of an Algorithm for Autonomous Docking with\na Freely Tumbling Target. Motaghedi, P. (ed.), Proc. of SPIE, vol. 5799 of SPIE Modeling,\nSimulation, and Verification of Space-based Systems, pp. 123\u2013134. Orlando, FL, 2005\n\n100. Nuth, J., Fernandez,Y.,Britt,D., Zolensky,M.,Moore,M.,Nesvomy,D.,Abell, P.,Dankanich,\nJ., Sykes, M., et al. Roadmap for Small Bodies Exploration. Tech. rep., Small Bodies Assess-\nment Group, 2011. Available at http://www.lpi.usra.edu/sbag/roadmap/\n\n101. OCT, N. NASA Space Technology Roadmaps. Tech. Rep. TA04 - Robotics, Tele-Robotics\nand Autonomous Systems, NASA, 2013\n\n102. Oda, M. ETS-VII: Achievements, Troubles and Future. i-SAIRAS, pp. 1\u20137. ESA, Montreal,\nQuebec, Canada, 2001\n\n103. on the Planetary Science Decadal Survey, C. Vision and Voyages For Planetary Science in the\nDecade 2013\u20132022. Tech. rep.,NRC,Washington,D.C., 2011.Available at http://solarsystem.\nnasa.gov/2013decadal/\n\n104. Park, H., Di Cairano, S., and Kolmanovsky, I. V. Model Predictive Control for Spacecraft\nRendezvous and Docking with a Rotating/Tumbling Platform and for Debris Avoidance.\nAmerican Control Conference, pp. 1922\u20131927. San Francisco, CA, 2011\n\n105. Parness,A., Frost,M., Thatte,N.,King, J.P.,Witkoe,K.,Nevarez,M.,Garrett,M.,Aghazarian,\nH., Kennedy, B.: Gravity-Independent Rock-Climbing Robot and a Sample Acquisition Tool\nwith Microspine Grippers. Journal of Field Robotics 30(6), 897\u2013915 (2013)\n\nhttp://www.nasa.gov/pdf/55583main_vision_space_exploration2.pdf\nhttp://www.nasa.gov/pdf/55583main_vision_space_exploration2.pdf\nhttp://marsprogram.jpl.nasa.gov/msl/\nhttp://www.nasa.gov/mission_pages/mer/\nhttp://www.nasa.gov/mission_pages/mer/\nhttp://www.lpi.usra.edu/sbag/roadmap/\nhttp://solarsystem.nasa.gov/2013decadal/\nhttp://solarsystem.nasa.gov/2013decadal/\n\n\n1 Spacecraft Autonomy Challenges for Next-Generation Space Missions 47\n\n106. Phillips, J. M., Kavraki, L. E., and Bedrossian, N. Spacecraft Rendezvous and Docking with\nReal-Time, Randomized Optimization. AIAA Conf. on Guidance, Navigation and Control,\npp. 1\u201311. Austin, TX, 2003\n\n107. Pirjanian, P., Leger, C., Mumm, E., Kennedy, B., Garrett, M., Aghazarian, H., Farritor, S.,\nand Schenker, P. Distributed Control for a Modular, Reconfigurable Cliff Robot. Proc. IEEE\nConf. on Robotics and Automation, vol. 4, pp. 4083\u20134088. Washington D.C., 2002\n\n108. Polites, M. E. An Assessment of the Technology of Automated Rendezvous and Capture in\nSpace. Tech. Rep. NASA/TP-1998-208528, NASA, 1998\n\n109. Quinlan, S. and Khatib, O. Elastic Bands: Connecting Path Planning and Control. Proc. IEEE\nConf. on Robotics and Automation, vol. 2, pp. 802\u2013807. Atlanta, GA, 1993\n\n110. Richards, A., Schouwenaars, T., How, J.P., Feron, E.: Spacecraft Trajectory Planning With\nAvoidance Constraints Using Mixed-Integer Linear Programming. AIAA Journal of Guid-\nance, Control, and Dynamics 25(4), 755\u2013765 (2002)\n\n111. Rumford, T. E. Demonstration of Autonomous Rendezvous Technology (DART) Project\nSummary. Jr., P. T. and Shoemaker, J. (eds.), Proc. of SPIE, vol. 5088 of SPIE Space Systems\nTechnology and Operations, pp. 10\u201319. Orlando, FL, 2003\n\n112. Sagdeev, R.Z., Zakharov, A.V.: Brief History of the Phobos Mission. Nature 341(6243), 581\u2013\n585 (1989)\n\n113. Scharf, D. P., Hadaegh, F. Y., and Ploen, S. R. A Survey of Spacecraft Formation Flying\nGuidance and Control, Part II: Control. American Control Conference, vol. 4, pp. 2976\u20132985.\nBoston, MA, 2004\n\n114. Scheeres, D. J. Close Proximity Operations for ImplementingMitigation Strategies. Planetary\nDefense Conference, pp. 1\u201311. AIAA, Orange County, CA, 2004\n\n115. Schmerling, E., Janson, L., Pavone, M.: Optimal sampling-based motion planning\nunder differential constraints: the drift case with linear affine dynamics (2014).\nhttp://arxiv.org/pdf/1405.7421.pdf\n\n116. Schmerling, E., Janson, L., Pavone, M.: Optimal sampling-based motion planning under\ndifferential constraints: the driftless case. In: Proceedings of the IEEEConference onRobotics\nand Automation (2015)\n\n117. Seeni, A., Schafer, B., Rebele, B., and Tolyarenko, N. Robot Mobility Concepts for Extrater-\nrestrial Surface Exploration. IEEE Aerospace Conference, pp. 1\u201314. Big Sky, MT, 2008\n\n118. Starek, J. A., Barbee, B. W., and Pavone, M. A Sampling-Based Approach to Spacecraft\nAutonomous Maneuvering with Safety Specifications. AAS GN&C Conference. Brecken-\nridge, CO, 2015\n\n119. Steinfeld, B.A., Grant, M.J., Matz, D.A., Braun, R.D., Barton, G.H.: Guidance, Navigation,\nand Control System Performance Trades for Mars Pinpoint Landing. AIAA Journal of Space-\ncraft and Rockets 47(1), 188\u2013198 (2010)\n\n120. Stipanovic, D.M., Hwang, I., Tomlin, C.J.: Computation of an Over-Approximation of the\nBackward Reachable Set Using Subsystem Level Set Functions. Dynamics of Continuous\nDiscrete and Impulsive Systems 11, 397\u2013412 (2004)\n\n121. Stoeter, S.A., Papanikolopoulos, N.: Kinematic Motion Model for Jumping Scout Robots.\nIEEE Transactions on Robotics and Automation 22(2), 397\u2013402 (2006)\n\n122. Topcu, U., Casoliva, J., Mease, K.D.: Minimum-Fuel Powered Descent for Mars Pinpoint\nLanding. AIAA Journal of Spacecraft and Rockets 44(2), 324\u2013331 (2007)\n\n123. Truszkowski, W.F., Hinchey, M.G., Rash, J.L., Rouff, C.A.: Autonomous and Autonomic\nSystems: A Paradigm for Future Space ExplorationMissions. IEEE Transactions on Systems,\nMan, & Cybernetics. Part C: Applications & Reviews 36(3), 279\u2013291 (2006)\n\n124. Tsuda, Y., Yoshikawa, M., Abe, M., Minamino, H., Nakazawa, S.: System Design of the\nHayabusa 2 \u2013 Asteroid Sample Return Mission to 1999 JU3. Acta Astronautica 91, 356\u2013362\n(2013)\n\n125. Ulamec, S., Biele, J.: Surface Elements and Landing Strategies for Small Bodies Missions -\nPhilae and Beyond. Advances in Space Research 44(7), 847\u2013858 (2009)\n\n126. Urmson, C., Anhalt, J., Bagnell, D., Baker, C., Bittner, R., Clark, M.N., Dolan, J., Duggins,\nD., Galatali, T., Geyer, C., et al.: Autonomous Driving in Urban Environments: Boss and the\nUrban Challenge. Journal of Field Robotics 25(8), 425\u2013466 (2008)\n\nhttp://arxiv.org/abs/http://arxiv.org/pdf/1405.7421.pdf\n\n\n48 J.A. Starek et al.\n\n127. VanDyke, M.C., Hall, C.D.: Decentralized Coordinated Attitude Control Within a Formation\nof Spacecraft. AIAA Journal of Guidance, Control, and Dynamics 29(5), 1101\u20131109 (2006)\n\n128. Vlassenbroeck, J., Dooren, R.V.: A Chebyshev Technique for Solving Nonlinear Optimal\nControl Problems. IEEE Transactions on Automatic Control 33(4), 333\u2013340 (1988)\n\n129. Wargo, M. J. HEOMD Strategic Knowledge Gaps: Planning for Safe, Effective, and Efficient\nHuman Exploration of the Solar System. http://science.nasa.gov/media/medialibrary/2012/\n05/04/HEOMD_Strategic_Knowledge_Gaps_Mike_Wargo.pdf, 2012\n\n130. Way, D. On the Use of a Range Trigger for the Mars Science Laboratory Entry, Descent, and\nLanding. IEEE Aerospace Conference, pp. 1\u20138. Big Sky, MT, 2011\n\n131. Weiss, A., Baldwin, M., Petersen, C., Erwin, R. S., and Kolmanovsky, I. V. Spacecraft Con-\nstrained Maneuver Planning for Moving Debris Avoidance Using Positively Invariant Con-\nstraint Admissible Sets. American Control Conference, pp. 4802\u20134807. Washington, DC,\n2013\n\n132. Widnall, W. S. Apollo Guidance Navigation and Control: Guidance System Operations Plan\nforMannedCMEarthOrbital and LunarMissions Using ProgramCOLOSSUS I and Program\nCOLOSSUS IA. Tech. Rep. R-577 Section 3, MIT Instrumentation Laboratory, Cambridge,\nMA, 1968\n\n133. Wilcox, B. H. ATHLETE: A Cargo-Handling Vehicle for Solar System Exploration. IEEE\nAerospace Conference, pp. 1\u20138. Big Sky, MT, 2011\n\n134. Wilcox, B.H., Litwin, T., Biesiadecki, J., Matthews, J., Heverly, M., Morrison, J., Townsend,\nJ., Ahmad, N., Sirota, A., Cooper, B.: ATHLETE: A Cargo Handling andManipulation Robot\nfor the Moon. Journal of Field Robotics 24(5), 421\u2013434 (2007)\n\n135. Yano, H., Kubota, T., Miyamoto, H., Okada, T., Scheeres, D., Takagi, Y., Yoshida, K., Abe,\nM., Abe, S., Barnouin-Jha, O., Fujiwara, A., Hasegawa, S., Hashimoto, T., Ishiguro, M.,\nKato, M., Kawaguchi, J., Mukai, T., Saito, J., Sasaki, S., Yoshikawa, M.: Touchdown of the\nHayabusa Spacecraft at the Muses Sea on Itokawa. Science 312(5778), 1350\u20131353 (2006)\n\n136. Yu, J. X. and Cheng, J. Graph Reachability Queries: A Survey. Managing and Mining Graph\nData, pp. 181\u2013215, 2010\n\nhttp://science.nasa.gov/media/medialibrary/2012/05/04/HEOMD_Strategic_Knowledge_Gaps_Mike_Wargo.pdf\nhttp://science.nasa.gov/media/medialibrary/2012/05/04/HEOMD_Strategic_Knowledge_Gaps_Mike_Wargo.pdf\n\n\nChapter 2\nNew Guidance, Navigation, and Control\nTechnologies for Formation Flying\nSpacecraft and Planetary Landing\n\nFred Y. Hadaegh, Andrew E. Johnson, David S. Bayard,\nBeh\u00e7et A\u00e7?kmes?e, Soon-Jo Chung and Raman K. Mehra\n\n2.1 Introduction\n\nThe recent landing of the massive Mars Science Laboratory (MSL) rover Curiosity\nwas made possible by the sky-crane touch down system. The sky-crane used a high\nrate, six degree-of-freedom guidance, navigation, and control (GN&C) system to\nslowly place the rover on the surface, detect touchdown, and fly away. MSL clearly\nshowed the advantages of on-board closed loop GN&C and has opened the door for\ninfusion of new GN&C technologies into the next Mars lander missions as well as\nother future spacecraft missions. However, MSL was not equipped with the capa-\nbilities of pin-point landing and local hazard avoidance. This chapter begins with a\nreview of recent advances in perception technologies for on-board Hazard Detection\n(HD) and Terrain Relative Navigation (TRN) in Sect. 2.2. The HD and TRN percep-\ntion technologies will enable the next Mars lander missions to recognize landmarks\nfor pin-point landing or detect landing hazards on the fly for local hazard avoidance.\n\nF.Y. Hadaegh (B) \u00b7 A.E. Johnson \u00b7 D.S. Bayard \u00b7 B. A\u00e7?kmes?e\nJet Propulsion Laboratory, California Institute of Technology, Pasadena, California\ne-mail: fred.y.hadaegh@jpl.nasa.gov\n\nA.E. Johnson\ne-mail: aej@jpl.nasa.gov\n\nD.S. Bayard\ne-mail: david.s.bayard@jpl.nasa.gov\n\nB. A\u00e7?kmes?e\ne-mail: behcet@austin.utexas.edu\n\nS.-J. Chung\nUniversity of Illinois at Urbana-Champaign, Urbana, IL, USA\ne-mail: sjchung@illinois.edu\n\nR.K. Mehra\nScientific Systems Company, Inc., Woburn, MA, USA\ne-mail: rkm@ssci.com\n\n\u00a9 Springer-Verlag Berlin Heidelberg 2016\nE. Feron (ed.), Advances in Control System Technology\nfor Aerospace Applications, Lecture Notes in Control\nand Information Sciences 460, DOI 10.1007/978-3-662-47694-9_2\n\n49\n\n\n\n50 F.Y. Hadaegh et al.\n\nThis chapter also considers the problem of flying a swarm of spacecraft in Earth\norbit. Distributed spacecraft systems can collectively match or exceed the capability\nof a more complex monolithic space system. Spacecraft swarms [11, 27] will push\nthe envelope of the existing formation flying spacecraft concepts by increasing the\nnumber of spacecraft comprising the swarm by one or two orders of magnitude\n(100\u20131000s), hence maximizing the benefit of distributed spacecraft systems.\n\nThe swarm approach opens up the possibility for enablingmany newmission con-\ncepts like creating massively distributed large space apertures, distributed antennas,\ndecentralized sensing networks, anti-satellite disruptors, and geometric arrangements\noptimized for decoy/camouflage. Moreover, spacecraft swarms can be controlled to\nexhibit desired complex behaviors, which cannot be achieved by a single space-\ncraft. Spacecraft swarms are motivated by nature and are examples of bio-inspired\nengineering systems. Examples from nature include a colony of ants searching for\nfood, or a swarm of bees protecting a bee hive from intruders. Swarming behaviors\nobserved in nature inspire and guide the development of efficient coordination and\ncontrol algorithms for spacecraft swarms.\n\nIn order to construct desired formations of spacecraft swarms and permit coordi-\nnated maneuvers of spacecraft, the distributed controller needs to efficiently handle\na large of number of spacecraft in the network. Two methods are presented to deal\nwith the added complexity of large number of spacecraft. First, if the aim is to control\nthe relative motions of the spacecraft to generate desired formations of spacecraft\nswarms, the new method of automatically generating evolving network topologies,\npresented in Sect. 2.3, can be used to determine the flowof control information among\nthe spacecraft. Second, Sect. 2.4 presents the novel approach of driving the swarm\nto a desired density distribution in a prescribed region of the configuration space.\nInstead of controlling individual spacecraft, the probabilistic guidance approach con-\ntrols the average number of spacecraft per unit volume, ensuring that spatial averages\nconverge to the desired density distribution. The swarm guidance and control meth-\nods described in Sects. 2.3 and 2.4 are predicated on an effective solution to (a)\ndetect potential changes in existing orbital trajectories that may lead to damaging\ncollisions; and (b) localize, track, and assess trajectories headed towards collisions.\nHence, Sect. 2.5 expands on necessary models, simulations, and methods for deriv-\ning, evaluating, and comparing such optimal constellations that satisfy the stated\nobjectives (a) and (b) for various swarm collision scenarios.\n\n2.2 GN&C Technologies for Planetary Landing\nin Hazardous Terrain\n\n2.2.1 Introduction\n\nAll robotic landers to date, includingMSL, have landed blindly. They have measured\naltitude and surface relative velocity and used these measurements for soft landing,\nbut they have not had the ability to recognize landmarks for pin-point landing or\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 51\n\ndetect landing hazards on the fly for local hazard avoidance. Blind landing has forced\nmissions to select landing ellipses that are free of hazards. This greatly constrains the\npossible landing locations and either limits the science to what is possible in benign\nterrain or requires the addition of a long traverse roving capability. For example,\nMSL landed on the flat and smooth Gale Crater floor and will have to drive out of\nits 10 kilometer landing ellipse to reach the most interesting science locations.\n\nHazard Detection and Avoidance (HDA) [19, 21] is an on-board function that\ncollects sensor data to map the landing site, applies an algorithm to determine the\nsafest place to land and then guides the vehicle to the safe landing site. HDA enables\nthe selection of landing ellipses that have a large number of know hazards that\ncan be avoided with a small divert (10\u2013100m divert). It also enables landing at\npossibly hazardous locations with limited reconnaissance. HDA requires perception\ntechnology for on-board Hazard Detection (HD) and GN&C technology to land the\nvehicle precisely at the safe landing site.\n\nIn contrast, Pin-Point Landing (PPL) is an on-board function that collects sensor\ndata and matches this data to a map of the landing ellipse generated before landing.\nThis match is then used to obtain a map-relative position fix. From this position fix,\nthe lander can compute a trajectory that guides the vehicle to the landing site (1\u201310km\ndivert). There is no active detection of hazards on-board, but PPL can be used to avoid\nlarge hazards in the landing ellipse. It can also be used for precision deployment of\nsurface assets (e.g., the multi-mission Mars Sample Return architecture or building\nup a lunar outpost). PPL requires Terrain Relative Navigation (TRN) perception\ntechnology [3, 8, 24, 28] and GN&C technology for fuel optimal powered descent\nguidance.\n\nFigure2.1 shows a variety of planetary landing sites that can be made accessible\nby pin-point landing or hazard detection and avoidance. For planetary science, PPL\n\nFig. 2.1 Planetary landing sites that require pin-point landing or hazard detection and avoidance\n\n\n\n52 F.Y. Hadaegh et al.\n\nand HDA will enable access to dust flows on comets and asteroids, seepage features\non the side of a crater wall on Mars, the boulder strewn source of water plumes on\nEnceladus and the cracked andfissured icy terrain ofEuropa. Formanned exploration,\nthese technologies will enable access to the peaks of permanent light near the rugged\nlunar south pole which are ideal locations for a lunar outpost due to the constant\nillumination for solar power generation and thermal management and possible near\nsources of volatiles for in-situ resource utilization. It should be noted that the Apollo\nlunar program recognized the need for pin-point landing and hazard detection to\navoid small and large hazards, but the capability was implemented manually.\n\nThe focus of this section is on the TRN and HD perception technologies; whereas\nGN&C technologies for powered descent are described in another chapter.\n\n2.2.2 Design Considerations\n\nThe lander\u2019s flight system and descent and landing approach greatly influence TRN\nand HD design. The trajectory has a major impact on TRN and HD system design\nbecause it dictates the time available for data collection and processing, the ranges\nand off nadir angles for sensor operation, and the attitude rates and velocities for\ntracking. The mechanical design of the lander sets thresholds on the hazard detection\ncapability by dictating the tolerable surface slope and roughness at touchdown. The\nperformance of the lander\u2019s GN&C and propulsion system provide constraints on\ndivert sizes and accuracy, which affect the overall pin-point landing accuracy and safe\nlanding site size. Since TRN and HD algorithms require extensive processing in a\nshort amount of time, it is necessary to have a dedicated, possibly high performance,\nprocessor. The size of the lander will also influence the mass, power and volume\navailable for the TRN and HD system.\n\nThe environment plays an important role as well. The transmission properties of\nthe atmosphere and the reflectivity of the terrainwill influence sensor range and image\ncontrast. If present, dust can reduce sensor range or addnoise to sensormeasurements.\nThe size and distribution of terrain features (rocks, craters, scarps, hills, etc.) will\ndetermine the density of safe landing areas and influence the area needed for HD\nimaging and PPL divert distances. During passive approaches, the terrain as well as\nthe illumination will influence the appearance of the imaged scene. PPL requires a\nmap made prior to landing; while the performance of TRN depends on the pixel size\nand quality of the map data. Passive TRN approaches could require rendering of a\ndigital elevation map to generate an image for matching, which makes them more\nsensitive to map quality than active sensor based approaches [8].\n\nBecause planetary landings occur only once, it is difficult if not impossible to test\nsystem performance prior to the actual landing. TRN and HD systems must undergo\nextensive validation and must be designed from the bottom up to be robust. Bolton\nTRN and HD systems, composed of sensors, processors and algorithms with a low\nbandwidth interface to the spacecraft, facilitate validation because the entire system\ncan be tested in the field under relevant conditions without the rest of the spacecraft.\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 53\n\nBolt on systems also localize the timing of sensor data and alignment of sensors,\nwhich greatly simplifies integration with the spacecraft.\n\nThe mission specific design constraints flow down into requirements on the sen-\nsors (field of view, number of pixels, maximum range, measurement errors, etc.),\nalgorithms (position accuracy, detection rates, map size, etc.) and processing (clock\nspeed, memory, etc.). As the design space is quite large, there is no generic system for\nTRN and HD. Instead TRN and HD need to be tailored to each specific application.\nSince algorithms and sensors have already been developed that meet TRN and HD\nrequirements, the focus has now moved to the development of complete systems.\nBelow, we describe two systems under development: one for Mars robotic landing\nand the other for crewed lunar landing.\n\n2.2.3 Case Study 1: Mars Robotic System\n\nMars landers have an entry phase which is used to reduce most of the surface velocity\nand, in the case of MSL, reduce the landing ellipse size down to 10Km radius. After\nentry, a parachute is deployed and the heat-shield is ejected. At this point sensors\ncan image the ground and the TRN function can start. The parachute descent phase\nlasts from 10km altitude to 2Km altitude, with vertical velocities near 100m/s and\nhorizontal velocities less than 30m/s. Toward the end of the parachute descent, the\noff nadir angle is less than 20? and attitude rates are less than 20?/s. TRN processing\ncompletes when powered descent starts around 2km. Powered descent performs a\nTRN commanded large divert and then goes into a vertical descent phase around\n250m with a 30m/s vertical velocity. HD occurs quickly at the start of vertical\ndescent, when the off-nadir angle is low and the nominal landing site is directly\nbelow. Once the safe site is identified, the lander targets it with a small divert. The\nentire descent from heat-shield separation to landing, takes on the order of 100s.\n\nMars landing typically occurs during the day and at low latitudes, to have direct\ncommunication with Earth during landing, so that more accurate and mature camera\nbased TRN approaches can be employed. As was done for MSL, a 1m digital ele-\nvation map with co-registered images can be generated using Mars Reconnaissance\nOrbiter images. This high resolutionmap enabled TRN accuracy in the order of 10m.\n\nRobotic landers are small with touchdown areas in the order of 10m2, but Mars is\nalso hazardous with plenty of rocks, scarps and craters. Assuming the MSL hazard\ntolerance of 55cm rocks and 22? slopes, studies of theMSL landing sites have shown\nthat a 12 \u00d7 12m hazard map generated with a single flash LIDAR image followed\nby a 6m divert greatly reduced the chances of landing on a hazard.\n\nBased on these constraints, the LanderVision System (LVS)was conceivedwithin\nNASA\u2019s Science Mission Directorate as a tightly integrated bolt-on smart sensor\nsystem that has well defined path to flight implementation [20]. The LVS measures\nterrain relative position, velocity, attitude and altitude while also detecting landing\nhazards. The LVS sensor suite includes an imaging camera for the landmark recog-\nnition required for terrain relative position estimation and image-to-image feature\n\n\n\n54 F.Y. Hadaegh et al.\n\ntracking for horizontal velocity estimation [28]. A dual use flash LIDAR is used\nfor near surface hazard detection and long distance ranging, for measuring altitude\nthrough the entire descent. An inertial measurement unit (IMU) propagates vehicle\nmotion between image and LIDAR measurements, so that high rate state informa-\ntion can be provided to the spacecraft. The sensors are tightly integrated with a high\nperformance computer that performs all processing required for TRN, HD, altimetry\nand velocimetry. The current best estimates for the LVSmass and power are 8kg and\n65W respectively.\n\nThe LVS is optimized to generate robust and accurate measurements from a min-\nimal suite of sensors. Each sensor serves multiple purposes, which reduces mass,\nvolume and development costs. The flash LIDAR is the ideal sensor for hazard\ndetection because it can generate all the data required with a single, low noise, range\nimage taken at long distances [23, 29]. By decreasing the width of the laser illumi-\nnation, the flash LIDAR can also be used to measure range at high altitude, thereby\nremoving the need to add a separate altimeter [22]. The camera provides images of\nlandmarks for position estimation [8]. It also provides image-to-image feature tracks\nfor velocity estimation, which eliminates the need for a separate velocimeter. Finally,\nthe IMU provides the attitude propagated from the spacecraft\u2019s cruise phase that is\nneeded to start TRN and it also allows for high rate updates of the entire navigation\nstate, which is required for closed loop powered descent guidance.\n\nThe LVS sensors have low development risks. Cameras and IMUs have already\nflown on many missions and are not a concern for development. Advanced\nScientificCorporation (ASC) has developed aflashLIDAR, and, underNASAfunded\nSmall Business Innovative Research Grants, ASC has also built a prototype of a flash\nLIDAR that satisfies the LVS requirements and also uses parts with flight equiva-\nlents [29]. Through extensive field testing, the ASC flash LIDAR has demonstrated\nthat it can detect hazards at low altitude (\u00a1 500m) [23] andmeasure accurate ranges at\nhigh altitude (up to 8km) [22]. Given all these advances toward flight qualification,\nthe flash LIDAR is also a fairly low risk sensor.\n\nThe computational tasks are done using aflight qualified processor and aField Pro-\ngrammable Gate Array (FPGA). The FPGA interfaces with the sensors for fast data\nacquisition and accurate timing. The FPGA also stores the computationally intensive\nsoftware vision modules for image normalization, homography-based image warp-\ning, image interest operator, frequency domain image correlation and spatial domain\nimage correlation. These high speed modules are used for terrain relative position\nand horizontal velocity estimation. The processor coordinates the flow of data from\nthe sensors and the processing of modules on the FPGA. It also runs the navigation\nfilter [28] that fuses inertial, imaging and range measurements and interfaces with\nthe spacecraft to receive LVS commands and sends back navigation states and safe\nlanding site locations. The interface between the compute element and the sensors\nhas high bandwidth with tight constraints on timing and data latency. In contrast,\nthe interface with the spacecraft is simpler, with a low data rate and relaxed timetag\nrequirements.\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 55\n\nFig. 2.2 Mars robotic lander vision system concept of operation and components\n\n2.2.4 Case Study 2: Crewed Lunar System\n\nThe Autonomous Landing and Hazard Avoidance Technology (ALHAT) project\nunder NASA\u2019s Human Exploration and Operations Mission Directorate is devel-\noping sensors and algorithms to increase safety during crewed and un-crewed lunar\nlandings [15]. ALHAT\u2019s charter is to develop a system that can land anywhere, under\nany lighting conditions and the lunar south pole is a challenging case that has focused\nthe ALHAT development. Operation under any lighting conditions has resulted in a\nsystem that employs active sensors for TRN and HD (Fig. 2.2).\n\nFollowing the approach used for Apollo, crewed lunar landing starts with a de-\norbit maneuver that places the lander on a long shallow trajectory to the surface.\nDuring descent, attitude rates are very low and velocities start at 2000m/s near orbit.\nWhen the lander reaches 15Km altitude, the braking burn begins and the LIDAR\nis activated to take range measurements. For TRN, the ranges are combined into an\nelevation contour and this contour is matched with a digital elevation map to obtain\na position fix [22, 24]. Based on the TRN measurement, a trajectory is computed\non board to clean up the trajectory dispersions (<1km). This process repeats until\naround 1\u20132km range and 30m/s velocity, at which point the lander pitches up for\nlanding and crew viewing of the landing site.\n\nThe hazard detection phase begins at 1Km slant range and 30? angle from hor-\nizontal. As shown in Fig. 2.3, the ALHAT Hazard Detection System (HDS) raster\nscans a gimbaled flash LIDAR across a 100\u00d7 100m area; the LIDAR combines the\nflash LIDARdetector fromASCwith large collection optics and a high power laser to\n\n\n\n56 F.Y. Hadaegh et al.\n\nFig. 2.3 The ALHAT hazard detection system concept of operation and hardware components\n\nobtain the 1Km imaging range required for ALHAT [3]. The multiple flash LIDAR\nimages are stitched together into a single digital elevation map (DEM) using the\nonboard navigation solution for coarse placement and a LIDAR data-driven align-\nment process for fine alignment. The DEM is then passed to an HD algorithm that\ndetects multiple safe landing sites for a lander with a touchdown area around 200m2\n\nand sensitive to rocks greater than 30cm high and slopes greater than 12?.\nOnce a single safe site is selected by the crew, a trajectory is generated to bring\n\nthe vehicle to a point 30m above the target. The HDS then performs Hazard Relative\nNavigation (HRN) [23] to keep the lander on trajectory to the safe site. During HRN,\nthe LIDAR is pointed at a prominent elevation feature near the landing site, and\nthe feature position is tracked during descent to provide safe site relative navigation\nupdates. The tracked feature actually changes during descent to keep the tracked\nfeature in front of the lander and deal with the large change in sensor footprint.\nDue to dust kicked up by the propulsion system, the vehicle descends the final 30m\nusing inertial sensors only. Fortunately, the HRN measurements and velocity from\na Doppler LIDAR velocimeter, also developed in ALHAT [3], provide navigation\nstate that is accurate enough to seed this inertial propagation and bring the lander to\nwithin 1m of the selected safe landing site.\n\nThere are boulder fields on the Moon, but the more prevalent hazards are small\ncraters and steep slopes. The best lunar terrain maps have been generated from Lunar\nReconnaissance Orbiter (LRO) data. LRO is in a polar orbit and has provided a polar\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 57\n\nDEM with a ground resolution of 25m. Near the equator, stereo imaging from the\nLRO Narrow Angle Camera must be used to generate DEMs of sufficient resolution\nfor TRN.\n\nThe hazard detection data collection and processing must be completed in 10s\nto leave time for safe site selection by the pilot. The HDS uses a hybrid processing\napproach to meet this requirement. An FPGA collects and times the data from the\nsensors. The FPGA then passes the data to a multi-core general purpose processor\nwhich runs all of the algorithms for DEM generation, HD and HRN [32]. The mul-\nticore processor allows parallelization of time consuming processes and is straight\nforward to program.\n\n2.2.5 System Comparison\n\nFigure2.4 shows a side-by-side comparison the LVS and ALHAT systems. The LVS\nhas less challenging requirements because of the daytime landing, small size of\nthe robotic lander and the significant hazard tolerance of the lander. These enabled a\nsystem that canperformTRNwith themature computer vision algorithms and sensors\nderived from the Descent Image Motion Estimation System on Mars Exploration\nRover [25] and HD with a single flash LIDAR image, which mitigates the need for a\ngimbal or stitching of flash LIDAR images. Since the LVS is being developed for the\n\nFig. 2.4 A comparison of TRN and HD systems for Mars robotic missions and Lunar crewed\nmissions\n\n\n\n58 F.Y. Hadaegh et al.\n\nnext Mars lander (2016\u20132022), the design focused on using components that could\nbe flight qualified in the short term. Amajor early design choice to maintain the short\nduration path to flight was the selection of an FPGA based processor architecture\nover one utilizing multi-core processing.\n\nThe requirements on theALHAT system aremore challenging thanwhat is needed\nfor robotic landing and the infusion period is farther in the future (2020\u20132030).\nConsequently, the ALHAT development has focused more on meeting performance\nrequirements and less on detailed path to flight designs. The ALHAT system must\ndetect hazards from far away, with high resolution over a large area to safely land the\n\u2019not very hazard tolerant\u2019 crewed lunar lander. This drove the design to a gimbaled\nflash LIDAR and the associated increase in complexity, mass and power. The \u2019any\nlighting condition\u2019 requirement drives the TRN approach to use the less mature\nLIDARsensors and contourmatching algorithm.Themulti-core processing approach\nis better from flexibility and ease of programming stand point, but its path to flight\nrequires flight qualification of rad-hard processors.\n\nBoth the LVS and ALHAT developments are needed to meet short and long term\ngoals ofNASA.Moreover, TRNandHDremain fertile technologydevelopment areas\nfor applications beyond planetary landing. Proximity operations around comets and\nnear earth asteroids will use very similar algorithms and sensors. Satellite servicing\nand orbital debris mitigation could probably use similar algorithms and sensors. On\nthe Earth, autonomous helicopters are being developed for cargo delivery and ship\nboard landing, that will rely on TRN and HD functions to deal with unknown and\nunprepared landing sites. For all of these application domains, TRN and HD can be\nexpanded to include additional sensing modalities like high frequency radar, thermal\nimaging and multi-return scanning LIDAR.\n\n2.3 Phase Synchronization Control of Spacecraft Swarms\n\nThe objective of this section is to present an effective method for automatically\ngenerating evolvingnetwork topologies that determinehowcontrol informationflows\namong the agents, thereby reducing the complexity of controlling a large number of\nspacecraft in the swarm. Directed graphs are used instead of undirected graphs to\naccount for heterogeneous sensing or communication capabilities of spacecraft in\nthe swarm network.\n\nWe review the recent results from our prior work [7, 9\u201311, 13, 27] in this section.\nThe proposed framework of adaptive graphs is useful especially when we deal\nwith a large number of spacecraft that perform arbitrary reconfiguration maneuvers.\nAnother benefit of the proposed method is that the required gain for stabilization is\nsmaller than the gain of an uncoupled control law by employing an adaptive graph\nLaplacian. Also, the error bound of the proposed synchronization control law is\nshown to be smaller than that of an uncoupled tracking control law. This justifies\nthe use of a synchronization framework that can help to maintain a desired shape,\neven if individual spacecraft are shifted from their desired locations, as illustrated in\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 59\n\nFig. 2.5 Swarm deployment to relative elliptical orbits called Passive Relative Orbits (PROs) (left);\nPhase synchronization control of multiple spacecraft following elliptical orbits in the LVLH frame\n(right)\n\nFig. 2.5. The high-fidelity nonlinear dynamic model of swarm spacecraft motions,\nthat include the effects of both Earth\u2019s oblateness and air drag in LEO [27], is used\nto derive the nonlinear stability proof of robust synchronization of coupled Euler-\nLagrange equations, first derived in [9, 13].\n\n2.3.1 Problem Statement\u2014Controlling the Phase Differences\nin Periodic Orbits\n\nConsider multiple spacecraft following some relative elliptical orbits as shown in\nFig. 2.5. We use the term relative, since the elliptical motions are generated in the\nlocal-vertical local-horizontal (LVLH) frame attached to the chief orbital motion.\nHence, it should not be confusedwith an elliptical orbit around the Earth. The relative\norbital motions (qtr, j ? R3, 1 ? j ? p) in the LVLH frame, of each (possibly\nheterogeneous) spacecraft comprising the swarm network, is governed by\n\nm j I3q?tr, j + Ctr, j (\u0153(t))q?tr, j + Gtr, j (qtr, j ,\u0153(t)) + Dtr, j (qtr, j , q?tr, j ,\u0153(t)) = ?tr, j\n(2.1)\n\nwhere m j is the mass of each spacecraft and the nonlinear terms, including the\ngraviation orces with J2 effects and the dissipative forces due to air drag, are given\nin [27]. In particular, the vector of six orbital parameters, \u0153(t), which defines the\norigin of the LVLH frame, as shown in Fig. 2.5, is governed by \u0153? = f\u0153(\u0153) [27].\nFurthermore, the attitude dynamics of each spacecraft can be represented by the EL\nform as\n\nMrot, j (qrot, j )q?rot, j + Crot, j (qrot, j , q?rot, j )q?rot, j + Grot, j (qrot, j ,\u0153(t)) = ?rot, j\n(2.2)\n\nwhere the attitude vector qrot, j can be represented by the first three values of\nquaternions or the modified Rodrigues parameters [9]. note that we can combine\n\n\n\n60 F.Y. Hadaegh et al.\n\nFig. 2.6 Transformation of elliptical orbit in 3D to two circles for phase rotation\n\nthe dynamics of (2.1) and (2.2) to derive the dynamics of q j = (qTrot, j , qTtr, j )T.\nSince Ctr, j (\u0153(t)) is skew-symmetric, M?rot, j (qrot, j )?2Crot, j (qrot, j , q?rot, j ) is also\nskew-symmetric. This property is essential for the stability proof used in this section.\n\nFuel efficient, J2-invariant elliptical orbits in the LVLH frame can be written as\nqd,tr (t) = (xe sin(nt + ?e0), ye cos(nt + ?e0), ze sin(nt + ?z0))T and they are used\nas the desired elliptical trajectory [27].\n\nIn this section, the complexity of controlling multiple spacecraft is reduced by\nsetting a common phase angle for each desired elliptical orbit (?1 and ?2, as shown in\nFig. 2.5). This common phase difference in each ellipse also sets some safe collision-\nfree distance between each pair of spacecraft. For spacecraft swarm applications,\nsuch as sparse aperture arrays, it is more important to maintain a formation shape,by\nensuring constant phase differences between the spacecraft, than exactly following\na desired elliptical trajectory. Such a phase control of oscillators, called engineered\ncentral pattern generators, has been successfully applied to control multi-joint loco-\nmotive systems [12, 13, 26]. Hence we define a common phase angle in an elliptical\norbit in 3D. It turns out that qd,tr (t) can be transformed into q?d,tr (t)in the new\nx ?-y?-z? frame, comprised of a circular motion in the x ?-y? plane and a sinusoidal\nfunction in the z? axis (see (Fig. 2.6) and [10] for details).\n\nWe can now perform a phase rotation by applying a rotation matrix T j?1 =\nIn?3 ? T(( j ? 1)?)? R(( j ? 1)?) for both the x ?-y? frame and the z? and Z ?, where\nZ ? is introduced to perform this phase rotation on the z? coordinate [10]. For the\nattitude dynamics of qrot, j , we do not apply phase synchronization, although it is\nalso a straightforward extension (see [9]).\n\nThe control objective is to drive the tracking control error for each j , v??j =\nTTj?1s??j =\n\n[\nv?j v?j Z ?\n\n]\n= TTj?1q???j ? q???d + ???(TTj?1q??j ? q??d) or v?j exponentially\n\nto zero. In other words, in the presence of modeling errors, we should show\n\nlim\nt??\n\n???v?j (t)\n??? ? ?T . The phase synchronization control should yield a smaller syn-\n\nchronization error than the trackin gerror, such that for each connected pair j and k,\n\nlim\nt??\n\n???v?j (t) ? v?k(t)\n??? ? ?S < ?T .\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 61\n\nA conventional consensus controller without tracking control, results in undesir-\nable drifting of the synchronized states. Then, the synchronization control ensures a\nsmaller synchronization error that helps to maintain a formation shape as shown in\nFig. 2.5. In contrast with prior work, this section uses an adaptive control scheme to\nautomatically compute a time-varying network topology. In other words, the adap-\ntive Laplacian matrix determines not only which neighbors each member should\ncommunicate with, but also the actual values of the time-varying gains.\n\n2.3.2 Phase Synchronization Control Law with Adaptive\nGraphs\n\nThe matrices and functions in (2.1) and (2.2) are converted to the new x ?-y?-z? frame\nby the matrix R f that defines q?j = R f q j and q?d = R f qd . Then, the dynamics in\nthe new frame and the controllers are given as\n\nM ??j (q j )q???j + C ??j (q j , q? j )q???j + G ??j (q j ) + D??j (q j , q? j ) =\n[\n\nR f ? j (t)\n? j Z ?\n\n]\n(2.3)\n\n[\nR f ? j (t)\n\n? j Z ?\n\n]\n= M ??j (q j )q???j,r + C ??j (q j , q? j )q???j,r + G ??j (q j )\n\n+ D??j (q j , q? j ) ? (k1 + c j j (t))s??j ? T j?1W ??j ({v??}, n? j )c j (2.4)\n\nwhereW ??j ({v??}, n? j ) =\n[?n? j1v?1 \u00b7 \u00b7 \u00b7 ?n? j ( j?1)v?j?1 ?n? j ( j+1)v?j+1 \u00b7 \u00b7 \u00b7 ?n? j pv?p] and\n\nc j j (t) =\np?\n\nk=1,k \t= j\nn? jk(t)\n\n??c jk(t)??. Also, c j = [c j1 c j2 \u00b7 \u00b7 \u00b7 c j ( j?1) c j ( j+1) \u00b7 \u00b7 \u00b7 c jp]T\n\nis adapted by c? j =\n?\n\nj\n\nProj\n(\n\nc j , WTj ({v?}, n? j )v?j\n)\n\n?\n?\n\nj\n\nSc j (c j )c j .\n\nThe nonnegative function n? j =\n[\nn? j1 \u00b7 \u00b7 \u00b7 n? j p\n\n]T sets the adaptation rate based on the\nrelative distance with its neighbors and the synchronization errors. Note that n? j p is\na nonzero scalar only if the relative distance is within the maximum communication\nor sensing distance (d jk ? dlimit, j ): for j \t= k,\n\nn? j p\n(???v?j ? v?k\n\n??? , d jk\n)\n\n=\ntanh\n\n(\n? j\n\n???v?j ? v?k\n???\n)\n\n+ n?0\n1 + n?0\n\n1 ? tanh\n(\n? j (d2jk ? r2c, j )\n\n)\n\n1 + tanh(? j r2c, j )\n(2.5)\n\nFurthermore, each positive element of the diagonal matrix Sc j switches to zero if the\ndistance is outside the communication/sensing boundary or the corresponding c jk\nexceeds the maximum allowable value. This means that outside the communication\nboundary, the coupling gain exponentially tends to zero.\n\n\n\n62 F.Y. Hadaegh et al.\n\nThe closed-loop systems from (2.3) and (2.4) are coupled through a diffusive\nterm in each controller, whose coupling gains are computed by an adaptive control\nlaw. Then, the information flow in the network is epitomized by the adaptive graph\nLaplacian matrix [L(t)]a defined [L(t)]a = diag(\n\n[\nc11 \u00b7 \u00b7 \u00b7 cpp\n\n]\n)? In +[c(t)]where\n\n[c(t)] =\n\n?\n????\n\n0 ?n?12(t)c12(t) \u00b7 \u00b7 \u00b7 ?n?1p(t)c1p(t)\n?n?21(t)c21(t) 0 \u00b7 \u00b7 \u00b7 ?n?2p(t)c2p(t)\n\n...\n...\n\n. . .\n...\n\n?n? p1(t)cp1(t) ?n? p2(t)cp2(t) \u00b7 \u00b7 \u00b7 0\n\n?\n???? ? In (2.6)\n\nNote that many elements of [c(t)] are zero, since many pairs of the agents have no\ndirected communication link. Hence, [L(t)]a of a large network will inevitably be a\nsparse matrix.\n\n2.3.3 Main Stability Theorems and Simulation Results\n\nTheorem 2.1 ([10]) The network EL systems from (2.3) and (2.4) globally expo-\nnentially converge to their desired trajectories with bounded errors such that the\n\ndistance R2(t) =\n? (TTj?1q??j )?\n\nq?d\n??z? between each (TTj?1q??j )? = [In 0n\u00d71]TTj?1q??j\n\nand the desired trajectory q?d(t) exponentially tends to the ball of radius R2(t) ?\n?max([H(q)])\n\n???k0?min([H(q)]) (?{?d}?) with a contraction rate of k0/?max ([H(q)]) for s??j and ???\nfor q??j , if each diagonal element ?k of Sc j satisfies ?k > k0 for the design parameter\nk0 > 0 chosen, and if\n\nk1(t) ? k0 + min\n(\ndegon?mcmax/2,\n\n?\n2mn(mn + dego)n?mcmax\n\n)\n(2.7)\n\nNote that cmax denotes the known boundary value of ci j , used for the adaptive control\nlaw, and dego ? p ? 1 the maximum out-degree of each member (vertex). The out-\ndegree for each vertex defines how many other agents are receiving information\nfrom that member. Also, mn is the maximum in-degree of each system, that is, the\nmaximum number of nonzero elements in each row of [c(t)].\n\nThe results of Theorem 2.1 can also be applied when the adaptive graph Laplacian\n[L(t)]a is augmenting a certain (fixed) baseline digraph constructed by a graph\nLaplacian [L(k1, k2)] in the closed-loop system. For this purpose, the main control\nlaw (2.4) can be modified as\n\n[\nR f ? j (t)\n\n? j Z ?\n\n]\n=M ??j (q j )q???j,r + C ??j (q j , q? j )q???j,r + G ??j (q j )\n\n+ D??j (q j , q? j ) ? (k1 + c j j (t))s??j +\n?\n\nk?N j\nk2s??k ? T j?1W ??j c j\n\n(2.8)\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 63\n\nwhere k1 > 0, k2 > 0. The fixed baseline topology is determined by the set of\n(incoming) neighbors N j .\n\nTheorem 2.2 Adaptive coupling gain augmentation. For the closed-loop system\nobtained by (2.3) and (2.8), Theorem 2.1 holds by replacing k1 in (2.7) by ?min([L(k1,\nk2)]sym) by using Weyl\u2019s theorem [18].\n\nWe now show that the proposed control law guarantees both faster convergence\nand smaller error bounds of synchronization between the coupled variables than\nthose of tracking control.\n\nTheorem 2.3 ([10]) Faster synchronization. A balanced graph with the symmetric\nLaplacian matrix [L(t)]b can be constructed for each [L(t)]a as\n\n[L(t)]b =\n(\n[L(t)]a + [L(t)]Ta\n\n)\n/2 ? diag\n\n(\n[L(t)]Ta [1, 1, . . . , 1]T/2)\n\n)\n\nIf Theorem 2.1 holds, there exists a subset\n(\nVTss{v?tr } = 0\n\n)\nof the original synchroniza-\n\ntion manifold,\n(\nVTs {v?tr } = 0\n\n)\n, with Vss being a subset of orthonormal eigenvectors\n\n(Vs) of [L(t)]b such that\n1. synchronization occurs faster than tracking:\n\n?s = k1 + ?min(V\nT\ns [L]a,symVs)\n\n?max([1]T[M ?][1]) > ?t =\nk1\n\n?max(VTs [M ?]Vs)\n(2.9)\n\n2. the synchronization error is smaller than the tracking error if the disturbance\nfield is more co-directional (i.e.,\n\n??[1]Td(t)?? > ??VTssd(t)\n??):\n\n? VTs {v?tr }\n0\n\n??ys? ? ?max(V\nT\ns [M ?]Vs)\n\n??VTs d(t)\n??\n\n?min(VTs [M ?]Vs)(k1 + ?min(VTs [L]a,symVs))\n(2.10)\n\nHence, the control objective in Sect. 2.3.1 is met despite disturbances and modeling\nerrors. Again, the benefit of Theorem 2.3 is that a formation shape on relative ellip-\ntical orbits can be maintained more precisely than tracking some desired positions.\nMoreover, the adaptive graphs of communication or relative sensing connections are\nautomatically determined by synchronization errors and relative distances. Figure2.7\nshows a result of simulation of reconfiguring 275 spacecraft moving in the LVLH\nrelative frame by using (2.1) and the proposed adaptive phase-synchronization con-\ntrol (2.4). Also, the figure shows the changes in the network topology during the\nreconfiguration maneuver, due to changes in the adaptive graph Laplacian matrix.\nThese results demonstrate that spacecraft can automatically determine in a distributed\nmanner, an evolving digraph topology of a large network of spacecraft swarms based\non the synchronization errors and relative distances. The adaptive graph Laplician\nmatrix represents a time-varying digraph that considers the heterogeneous capabil-\nities of communication or relative sensing among the spacecraft members in the\n\n\n\n64 F.Y. Hadaegh et al.\n\nFig. 2.7 Reconfiguration of 275 spacecraft using the proposed control law (left); Change of the\nnetwork topology when we reconfigure32 spacecraft (Images taken from [10])\n\nswarm network. The objective of phase synchronization control is to maintain a\ndesired phase difference on a periodic orbit. This implies that the complexity of con-\ntrolling such a large number of spacecraft moving in relative elliptical orbits reduces\nto setting a proper phase difference. Interestingly, this method of phase synchro-\nnization is conceptually similar to phase synchronization of CPG oscillators that\ngenerate phase synchronized rhythms in a self-sustained fashion on spinal cords of\nvertebrates [12, 30].\n\n2.4 Application of Probabilistic Guidance to Swarms\nof Spacecraft Operating in Earth Orbit\n\n2.4.1 Introduction\n\nThis section reviews the theory behind a probabilistic guidance approach to guiding\nan arbitrary swarm of agents [1], and reviews its application to coordinating a space-\ncraft swarm operating in Earth orbit [2]. The main idea is to drive the swarm to a\ndesired density distribution in a prescribed region of the configuration space. Rather\nthan control individual spacecraft, the probabilistic guidance approach controls the\naverage number of spacecraft per unit volume, ensuring that spatial averages converge\nto the desired targeted density distribution (see Fig. 2.8 for an example scenario). The\ntargeted density distribution is achieved as an emergent behavior of the swarm, and\nis associated mathematically with achieving a statistical steady-state condition, i.e.\na fixed point of a spatial Markov process.\n\nIn its simplest form, the probabilistic guidance approach is completely decen-\ntralized and does not require communication or collaboration between spacecraft.\nSpecifically, spacecraft make statistically independent probabilistic decisions based\nsolely on their own state, which ultimately guides the swarm toward the desired tar-\ngeted density distribution. In addition to being completely decentralized, the prob-\nabilistic guidance approach has a novel autonomous self-repair property: Once the\ndesired swarm density distribution is attained, the spacecraft automatically repair\ndamage to the swarm distribution without collaborating and without explicit knowl-\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 65\n\nFig. 2.8 In this example\nscenario, thousands of\nspacecraft are deployed in\nEarth orbit. First they match\ntheir periods to ensure that\nthey do not quickly drift\napart. Then they configure\nthemselves in order to\nachieve a desired prescribed\npattern. The motion of this\npattern is determined by the\nEarth orbital dynamics\n\nedge that damage has occurred. First, the probabilistic guidance method is reviewed\nfor swarms operating in deep space. Then an adaptation of the probabilistic guid-\nance concept relevant to Earth orbiting swarms is reviewed, where orbital dynamics\nare explicitly considered based on Hill\u2019s equations. An illustrative example is given\nshowing theoretical swarm convergence and emergent behaviors.\n\n2.4.2 Probabilistic Guidance Problem\n\nThis sectiondescribes the swarmdistributionguidanceproblem.Thephysical domain\nover which the swarm agents are distributed is denoted as R. It is assumed that region\nR is partitioned as the union of m disjoint sub-regions, which are referred to as bins:\n\nRi , i = 1, . . . , m, such that R =\nm?\n\ni=1\nRi\n\nLet an agent have position r(t) at time index t . Let x(t) be a vector of probabilities\nsuch that the sum of its entries is one and the i\u2019th element x[i](t) is the probability\nof the event that this agent will be in the i\u2019th bin Ri at time t ,\n\nx[i](t) := Prob(r(t) ? Ri ) (2.11)\n\nThe time index t will also be referred to as the \u201cstage\u201d in the remainder of the section.\nConsider a swarm comprised of N agents. Each agent is assumed to act independently\n\n\n\n66 F.Y. Hadaegh et al.\n\nof the other agents, so that (2.11) holds for N separate events,\n\nx[i](t) := Prob(rk(t) ? Ri ), k = 1, . . . , N\n\nwhere rk(t) denotes the position of the k\u2019th agent at time index t , and the probabil-\nities of these N events are jointly statistically independent. We refer to x(t) as the\nswarm distribution. This is to be distinguished from the ensemble of agent positions\n{rk(t)}k=1:N which, by the law of large numbers, has a distribution that approaches\nx(t) as the number of agents N is increased.\n\nThe distribution guidance problem is defined as follows: Given any initial distrib-\nution x(0), it is desired to guide the agents toward a specified steady-state distribution\ndescribed by a probability vector v,\n\nlim\nt?? x[i](t) = v[i] for i = 1, . . . , m\n\nwhere v[i] ? 0,\nm?\n\ni=1\nv[i] = 1\n\nsubject tomotion constraints specified in terms of an adjacencymatrix Aa as follows:\n\nATa [i, j] = 0 ? r(t + 1) /? Ri when r(t) ? R j ,?t.\n\nHere, the adjacency matrix Aa of the edges of a directed graph specifies the\nallowable transitions between bins.\n\nThe desired distribution v has the following interpretation: We have m bins in\nthe physical space corresponding to where agents can be located, and the element\nv[i] is the desired probability of finding an agent in the i\u2019th bin. If there are N\nagents, then Nv[i] describes the expected number of agents to be found in the i\u2019th\nbin. Let n = [n[1], . . . , n[m]]T denote the actual number of agents in each bin.\nThen the number of agents n[i] found in the i\u2019th bin will generally be different from\nNv[i], although it follows from the independent and identically distributed (iid) agent\nrealizations that v = E[n]/N , and from the law of large numbers that n/N ?? v as\nN becomes large. Hence the vector v is a discrete probability distribution specifying\nthe desired average fraction of agents in each bin of the physical domain, which,\nin practice, will only be approximated by the histogram n/N of agents. However,\nthe nature of the approximation is that v is equal to the mean E[n/N ] of the agent\nhistogram, and by the law of large numbers, n/N ?? v as N becomes large.\n\n2.4.3 Probabilistic Guidance Algorithm (PGA)\n\nThe key idea of the probabilistic guidance law is to synthesize a column stochastic\nmatrix [6, 18] M , which we call Markov matrix for PGA, withv as its eigenvector\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 67\n\ncorresponding to its largest eigenvalue 1 [16, 18], that is, M must satisfy\n\nM ? 0, 1TM = 1T\n\nwhere 1 is a vector of ones. The entries of matrix M are defined as transition proba-\nbilities. Specifically, for any time instance,\n\nM[i, j] = Prob(r(t + 1) ? Ri |r(t) ? R j ), i, j = 1, . . . m\n\ni.e., an agent in bin j transitions to bin i between two consecutive stages with proba-\nbility M[i, j]. The matrix M determines the time evolution of the probability vector\nx as\n\nx(t + 1) = Mx(t), t = 0, 1, 2, . . . (2.12)\n\nNote that the probability vector x(t) stays normalized in the sense that the sum of\nits entries is one for all time instances. The probabilistic guidance problem becomes\none of designing a specific Markov process (2.12) for x that converges to a desired\ndistribution v.\n\nIt is desired for x(t) to asymptotically converge to v, i.e., for v to be a globally\nattractive stationary distribution for M . The main result of this section shows that\nasymptotic convergence to v is ensured by imposing an additional constraint on the\ndesign of matrix M , denoted as the spectral radius condition,\n\n?(M ? v1T) < 1 (2.13)\n\nThe synthesis of the Markov matrix for PGA can be achieved by using a vari-\nety of methods. Methods to synthesize PGA using convex optimization and the\n\u201cMetropolis-Hastings Algorithm\u201d have been developed in [1]. Once the Markov\nmatrix is synthesized, the following PGA can be used to implement it by providing\na copy of the matrix M to each of the agents, and then having each agent propagate\nits position as an independent realization of the Markov chain as follows:\n\nProbabilistic Guidance Algorithm (PGA)\n\n1. Each agent determines its current bin, e.g., rk(t) ? Ri .\n2. Each agent generates a random number z uniformly distributed in [0, 1].\n3. Each agent goes to bin j , i.e., rk(t + 1) ? R j , if\n\nj?1?\nl=1\n\nM[l, i] ? z ?\nj?\n\nl=1\nM[l, i].\n\nThe first step determines the agent\u2019s current bin number. The last two steps sample\nfrom the discrete distribution definedby the columnof M corresponding to the agent\u2019s\ncurrent bin number.\n\nThe following theorem (see [1, 2] for a proof) gives a necessary and sufficient\ncondition for asymptotic convergence of x to v for the generic PGA.\n\n\n\n68 F.Y. Hadaegh et al.\n\nTheorem 2.4 Consider the PGA below with column stochastic matrix M such that\nMv = v. Then for any at probability vector x(0), it follows that x(t) ?? v as\nt ? ? for the system in (2.11) if and only if Eq. (2.13) is satisfied.\n\nTheorem 2.4 is important because it indicates that a probabilistic guidance law for\na swarm is asymptotically convergent if andonly if the spectral radius condition (2.13)\nis satisfied. This condition has been interpreted in the context of Perron-Frobenius\ntheory and can be used as a basis for applying modern control theory to synthesizing\nasymptotically convergent swarm guidance laws in [2].\n\n2.4.4 Adaptation of PGA to Earth Orbiting Swarms\n\nWe consider spacecraft swarms in circular orbits around Earth. The dynamics of\neach spacecraft relative to the circular orbit are given by Hill\u2019s equations [31], also\nreferred to as the Clohessy Wiltshire equations,\n\nx? = 2? y? + 3?2x + fx\ny? = ?2?x? + fy\nz? = ??2z + fz\n\nHere x , y and z are the spacecraft\u2019s local-vertical local-horizontal (LVLH) cartesian\ncoordinates associated with an orbital frame, which is defined at a point on the orbit,\nand oriented such that the x-axis points in the zenith direction, the z-axis is normal\nto the orbital plane, and the y-axis completes the right-hand system; fx , fy and fz\nare the specific forces applied to each axis; and ? is the orbital frequency. From\nthe analytic solution to the Hill\u2019s equations it can be shown that the swarm remains\nbounded if all spacecraft initial states satisfy the following condition (in the absence\nof any other external forces than the central gravitational field),\n\n?6?x(0) ? 3y?(0) = 0\n\nIn this case, all the spacecraft are period matched. From this point on we will only\nconsider spacecraft swarms that are period matched. Furthermore, all spacecraft are\nassumed to be in-plane, i.e., z(t) = 0 for all t . This latter constraint is not necessary\nbut imposed to keep the discussion contained according to the space limitations. The\ncomplete generalization of all subsequent results to out-of-plane motion is given\nin [2]. We now define useful notion of a swarm that is Orbit Type Matched (i.e., an\nOTM swarm).\n\nDefinition 2.1 A swarm is referred to as a planar OTM swarm if it satisfies the\nfollowing conditions: For all i = 1, . . . , N ,\n1. Period Matched with parameter ?, y?i = ?2?xi (0)\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 69\n\n2. Centroid Matched with parameter yo, yo,i := yi (0) ? 2x?i (0)/? = yo\n3. zi (t) = 0 for all t\n\nA new set of position coordinates is introduced and denoted as Scaled Rotated\n(SR) coordinates that are instrumental in defining themotion of a planarOTMswarm:\n\n[\nx?(0)\ny?(0)\n\n]\n= RT(?t)S?1\n\n[\nx(t)\n\ny(t) ? yo\n]\nwhere R(?t) =\n\n[\ncos(?t) sin(?t)\n\n? sin(?t) cos(?t)\n]\n\n, S =\n[\n1 0\n0 2\n\n]\n\nNote that the coordinate transformation is time dependent while the SR coordinates\nof any spacecraft in a planar OTM swarm are time-invariant. In a planar OTM swarm,\nthere are only two degrees of freedom that determine the motion of each spacecraft.\nOut SR coordinates naturally capture this fact. Next we can describe the PGA adap-\ntation for in-plane OTM swarms, where each agent follows the following steps:\n\n\u2022 Step 1: At t , map current position (x(t), y(t)) in LVLH to SR coordinates r(t) =[\nx?(0), y?(0)\n\n]T\nt as,\n\nr(t) = RT(?t)S?1\n[\n\nx(t)\ny(t) ? yo\n\n]\n\n\u2022 Step 2: Determine current region R j s.t. r(t) ? R j , and propagate the Markov\nChain one step to calculate the next desired state r(t + 1) ? Ri using,\n\nM[i, j](t) = Prob(r(t + 1) ? Ri |r(t) ? R j )\n\n\u2022 Step 3: Map r(t + 1) back to LVLH according to,\n[\n\nx(t + 1)\ny(t + 1) ? yo\n\n]\n= S R(?(t + 1))r(t + 1)\n\n\u2022 Step 4: Complete the desired state in LVLH by OTM,\n\nz(t + 1) = 0\nx?(t + 1) = ?\n\n2\n(y(t + 1) ? yo)\n\ny?(t + 1) = ?2?x(t + 1)\n\n\u2022 Step 5: Command agent to new state [x, y, z, x?, y?, z?](t + 1).\n\u2022 Step 6: t ? t + 1, and go back to Step 1.\nThe idea behind this sequence of steps is to have each agent move according to a\nMarkov chain in SR coordinates. Physically, this corresponds to each agent moving\nfrom one Hill\u2019s trajectory to another in the plane of motion. Since the statistics of the\nswarm propagate as the Markov chain, the swarm will converge asymptotically to\nthe desired distribution v in SR coordinates, regardless of the initial distribution. The\nconverged asymptotic distribution in LVLH, in turn, will be a rotated and stretched\nversion of v, corresponding to the time-varying mapping from SR coordinates to\n\n\n\n70 F.Y. Hadaegh et al.\n\nFig. 2.9 An in-plane OTM swarm of 16,000 spacecraft in a near-circular Earth orbit starts as a\nuniform distribution and evolves over time into a representative (18 hexagon) large aperture pattern\n\nLVLH coordinates. Within this parameterization, PGA can guide the swarm to attain\na wide variety of shapes and distributions useful for a diverse range of potential\napplications. A simulation is performed that demonstrates 16,000 spacecraft in a\nnear-circular Earth orbit. The spacecraft start at a random initial distribution and\nconverge out to a prescribed swarm distribution. Figure2.9 shows four instances of\nthe swarm density evolution. A concluding remark is given in Sect. 2.6.\n\n2.5 Nonlinear State Estimation And Sensor Optimization\nProblems for Detection of Space Collision Events\n\nThe objective of the collision event detection and tracking is to prevent damaging\ncollisions of currently active LEO satellites with other space objects. This includes\nefficient detection and tracking of changes in trajectories of Resident Space Objects\n(RSOs) that might cause the collisions. The collision concept considered here is\npresented in Fig. 2.10. An important challenge in achieving the collision avoidance\nobjective is the possibility of a short warning time, that is, the time between the\nchange to a collision trajectory and the collision itself may be as short as a few\nminutes. In this case, we have very stringent requirements on timing of collision\nRSO\u2019s detection and estimation of its new dynamic state values that would allow\npossible effective avoidance actions.\n\nAn effective solution to the collision and avoidance problem is to design and\ndeploy constellations of LEO satellites equipped with EO/IR sensors that can: (1)\ndetect potential changes in existing orbital trajectories that may lead to damaging\ncollisions; and (2) localize, track, and assess trajectories headed towards collisions.\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 71\n\nFig. 2.10 Collision event concept: An event is a collision interval\n[\nt lm , t\n\nu\nm\n\n]\nduring which a RSO\n\ncan change from its current orbit (dark blue) to a collision trajectory (red) that leads to a collision\nlocation on the asset orbit (cyan). The collision interval is determined from a limit on the collision\nsatellite\u2019s change in velocity (?vm/s)\n\nWe have developed necessary models, simulations, and methods for deriving, eval-\nuating, and comparing such constellations and also derived optimal constellation\ndesigns that satisfy the stated objectives for given collision scenarios. In the follow-\ning sections, we give short summary of our results. In Sect. 2.5.1, we summarize the\ndesign of collision event testbed and candidate LEO sensor constellation designs.\nSatellite collision modeling and algorithms for tracking, collision detection, and\nsensor management are presented in Sect. 2.5.2.\n\n2.5.1 LEO Sensor Constellation Design and Collision Event\nTestbed\n\nThe scenario that we consider assumes that there are three asset satellites that can\npossibly collide with 23 other satellites during the day of April 1st of 2006. The\nthree satellites are AQUA, PARASOL, and AURA with the Two Line Elements\n(TLEs) given from the NORAD catalog (http://www.space-track.org). We derive\nLEO trajectories by using \u201cstandard\u201d Simplified General Perturbations-4 (SGP4)\npropagator [17] that may include higher fidelity orbital perturbations caused by envi-\nronmental factors such as gravity, atmosphere, and solar pressure and also satellite\nphysical properties such as ballistic coefficient. In a similar way,\n\nEO/IR sensor constellation design:We considered a large number of constellation\ndesigns for sensor orbits in order to obtain the best coverage of collision events with\nminimal number of sensors [34, 35]. We considered sensor constellation designs\n\nhttp://www.space-track.org\n\n\n72 F.Y. Hadaegh et al.\n\n(a) (b) (c)\n\nFig. 2.11 Three EO/IR constellations for collisions event comparisons: design in Fig. 2.11a is\nshown to be optimal for detecting collisions. a Np = 2, N s\n\np\n= 4. b Np = 3, N s\n\np\n= 2. c Np =\n\n3, N s\np\n\n= 3\n\nFig. 2.12 Testbed snapshot showing collision satellite OPS 0203 collidingwith satellite PARASOL\nat 11:26:06 (Hms) with collision trajectory length 21.4min and collision interval 28.42 min\n\nusing symmetry requirement, number of orbital planes Np, and number of satellites\nper orbital plane N s\n\np\n. An example of candidate constellations designs considered\n\nin [35] is shown inFig. 2.11.ByconsideringSpaceBasedVisible (SBV)observations,\nour analysis reported in [14] demonstrated that it is enough to have four observations\nof the collision satellite locations after the end of the event interval to determine if\nthe collision related to that event is going to happen or not. This result was derived\nby assuming that the time between observations is ?t = 50 s. Testbed simulation\nsnapshot for one of collision events is shown in Fig. 2.12.\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 73\n\n2.5.2 Satellite Collision Modeling and Estimation\n\nFrom a given TLE set, we derive six Kepler parameters (orbital elements) ?t =\n(?t , et , it ,?t , ?t , Mt ) that slowly change with time t ? 0, where the semi-major\naxis at and the eccentricity et , describe the form of the orbit, the mean anomaly Mt\ndefines the position along the orbit, and the three other elements that include the right\nascension of the ascending node ?t , the inclination it , and the argument of perigee\n?t , define the orientation of the orbit in space [26]. The derived state variable is\n?t =\n\n[\n??t , ?t\n\n]\nwhere the first six coordinates are derivatives of the Kepler parameters\n\n??t . More sophisticated stochastic modeling of the satellite states were derived and\napplied in [36] as extension of simplified statemodel in [35]. Themeasurementmodel\nof azimuth angle ?i, jt and elevation angle ?\n\ni, j\nt looking from j\u2019th sensor platform\n\ntoward i\u2019th collision satellite at time t ? 0, for ? i, jt =\n[\n?\n\ni, j\nt , ?\n\ni, j\nt\n\n]\n, is given by\n\n??\ni, j\nt = ? i, jt + ?a?i, jt , t ? 0,\n\nwhere the error standard deviation is ?a = 1 arcsec, and ?i, jt N? (0, I2) are normalized\nGaussian variables.\n\nA measurement is collected by a sensor only if the following three conditions are\nsatisfied: (a) the sensor points its CCD array toward the predicted location of the\ntarget; (b) the true location of the target is within the sensor field of view (FoV);\nand (c) the target has \u201cstar background\u201d looking from the sensor. Condition (c) is\nnecessary for accurate sensor attitude determination.\n\nFor each event interval, we collect observations to determine if the collision satel-\nlite has changed its trajectory to any one of the candidate collision trajectories. Since\nfor realistic bound on change in velocity (usually denoted by and called \u201cdelta v\u201d),\nthe collision can happen only on a small part of the asset\u2019s orbit and therefore, as\nan realistic approximation, we choose one point on the asset orbit as a location of\nthe collision that then corresponds to a unique intercept time. Then for any given\ntime inside the event interval, by using the Generalized Parametrized Battin (GPB)\nmethod presented in [35] and derived from [5], we can determine a unique collision\ntrajectory that is parametrized by ? (e.g. Kepler elements). By discretizing the event\ninterval at every second, we have a finite number of possible collision trajectories\nthat we denote by ?ql and its corresponding hypothesis by H\n\nq\nl , where superscript\n\nq denotes event (event index) and subscript l is an index of hypothesis for each\nevent. As time progresses (in our case at each second), we are creating hypotheses\ncorresponding to candidate collision trajectories. The zero hypothesis (l = 0) cor-\nresponds to the non-collision trajectory. Each hypothesized trajectory is initialized\nwith an appropriate uncertainty matrix to account for time discretization approxi-\nmation of the event interval. Also, each hypothesis is tracked by applying a given\ntracking algorithm, e.g. see a version described in Sect. 2.5.2.2. As observations are\ncollected, we calculate posterior probability of each hypothesis by applying the col-\nlision detection algorithm described in Sect. 2.5.2.2. The hypotheses with very small\n\n\n\n74 F.Y. Hadaegh et al.\n\n(a) (b) (c)\n\n(d) (e) (f)\n\nFig. 2.13 Hypotheses posteriors at each scan (50 s between scans) after the collision satellite\nmoved from its non-collision trajectory (hypothesis 0) to a collision trajectory (hypothesis 1): (a)\nafter t = 8s, collision probability is 0.055, i.e. collision threat is not detected; (b) after t = 58s,\ncollision probability is one, i.e. collision threat is detected; (c) after t = 108s, collision trajectory\nis singled out (probability ? 0.6); (d) after t = 158s, number of hypotheses decreases and true\ncollision trajectory probability is ? 0.7; (e) after t = 208s, true collision trajectory probability is\n> 0.8; (f) after t = 258s, true trajectory probability is one and all other hypotheses disappeared,\ni.e. collision trajectory is uniquely determined\n\nprobabilities are discarded and ones with higher probabilities are kept till they are\nfully resolved as shown in Fig. 2.13. The sensors management algorithm is discussed\nin Sect. 2.5.2.3.\n\n2.5.2.1 Tracking Algorithm\n\nA simplified version of state perturbation model and its corresponding filter are\nderived and demonstrated in [35]. The more advanced stochastic model of state\nperturbations, i.e. stochastic target state model, with nonlinear particle filter based\ntracking and estimation algorithm is derived and demonstrated in [36].\n\nTracking algorithms developed and demonstrated in [14, 33\u201336] consists of the\nfollowing five steps:\n\nStep 1: Initialization\nStep 2: Derivation of prediction state estimate\nStep 3: Estimation of optimal sensor parameters (Sensor Management and\n\nTracking)\nStep 4: Collection of measurements\nStep 5: Updating of state estimates\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 75\n\nNonlinear state and measurement equations are used in posterior propagation and\nupdate using Particle Filtering algorithms involving propagation of particle states and\nupdate of particle weights, respectively. The selected tracking results are summarized\nin Fig. 2.15.\n\n2.5.2.2 Collision Detection Algorithm\n\nThe collision detection algorithm is based on multi-hypothesis testing, using likeli-\nhood derivation and initialization [14] as follows:\n\n1. At time step k, we create N h,qk hypotheses for each current event q.\n2. For event q at time step k, we have hypothesis Hql that is associated with element\n\nset ?q,lk .\n3. From the measurement model, we derive hypotheses likelihoods:\n\nlog p(t, ?? i, jt |Hql )??\n1\n\n2? 2a\n??? i, jt ? ? jt\n\n(\n(?\n\nq,l\nt )\n\n)\n?2\n\nwhere ? jt\n(\n?\n\nq,l\nt\n\n)\nis an azimuth-elevation pair associated with hypothesis Hql and\n\np(t, \u00b7|Hql ). conditional probability of azimuth-elevation pairs given hypothesis\nHql at time t ? 0\n\n4. We derive hypotheses conditional posterior p(t, Hql |?t ) given all measurements\nYt up to the current time t ? 0 by using Bayes\u2019 Theorem and then select a set of\nhypotheses that have posteriors above a given threshold.\n\nSelected results from [14] are shown in Fig. 2.13 demonstrating the effectiveness\nof the collision detection algorithm. Assuming 50s between any two consecutive\nobservations (SBV scans), plots (a) and (b) in Fig. 2.13 demonstrate that it takes\ntwo measurements to get that probability of non-maneuver to be zero (hypothesis\nindexed by zero in Fig. 2.13). The rest of the plots (c)\u2013(f) of Fig. 2.13 demonstrate\nthat it takes extra two to four measurements (four to six from the change of the\ntrajectory) to uniquely determine the collision trajectory (hypothesis index one).\n\n2.5.2.3 Sensor Management Algorithm\n\nThe details of sensor management algorithms and its effectiveness for LEO col-\nlision detection and tracking using a SBV sensor platform are described in [14].\nThe algorithm is extended to disparate and dispersed sensors (radars and SBV plat-\nforms) and also its effectiveness is demonstrated for continuous tracking of LEO\nsatellites in [33]. Our sensor management algorithm is based on maximization of the\nPosterior Expected Number of Targets of Interest (PENTI) objective function fk(\u00b7)\nthat is information-theoretic representation of the expected number of well localized\n\n\n\n76 F.Y. Hadaegh et al.\n\nFig. 2.14 Results of sensor management for collision detection and tracking: (a) simulation snap-\nshot example of a typical LEO complex environment; and (b) number of observations per event\n\ntargets that are of tactical interest [26]. The sensor management is reduced to find-\ning pairs ( j1, l1), . . . , ( jn, ln) chosen from available sensors ( j1, . . . , jn) and targets\n(l1, . . . , ln) which are a subset of all collision satellites of interest.\n\nThe sensor management problem then consists in determining the pointing\nangles (?k, j1, . . . , ?k, jn ) that are approximate solution of the following optimization\nproblem:\n\n(?k, j1, . . . , ?k, jn ) = argmax\n? j1 ,...,? jn\n\nfk(? j1, . . . , ? jn ).\n\nThe sensor management simulation results are shown in plots (a) and (b) of\nFig. 2.14. Plot (a) of Fig. 2.14, is a snapshot of LEO complex environment that con-\nsists of EO/IR sensor platforms (blue squares), assets that are not currently in danger\nof collisions (green diamonds), assets that are in danger of being intercepted (magenta\ndiamonds), collision satellites that are in event interval (red circles), collision satel-\nlites that are not currently associated with any event (white circles), and collision\nsatellites that might be on collision trajectories (yellow circles). Possible observation\ncollections and actual observations are represented by yellow and dash black lines.\nIn plot (b) of Fig. 2.14, we show the total number of collected measurements for each\nevent.\n\nWe implemented and demonstrated multisensor-multitarget sensor management\nand multi-hypothesis based collision detection and tracking on the SSCI\u2019s LEO\nenvironment testbed [35]. The simulation results for sensor constellation in plot (a)\nof Fig. 2.11, are shown in plots (a)\u2013(c) of Fig. 2.15. Note that the standard deviations\nin plot (a) of Fig. 2.11 are very low (shades of blue) for all collision satellites during\ncollision intervals which indicates good observability of the collision events and\ntherefore excellent sensor management. Oscillatory property of location and velocity\nerrors indicates an accurate modeling of state dynamics [35]. All collision events are\ntracked with high accuracy and on a timely basis for effective collision avoidance.\nA conclusion is given in Sect. 2.6.\n\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 77\n\n2.6 Conclusion\n\nThis chapter discusses new guidance and control technologies for planetary land-\ning and guidance, navigation, estimation, and control for swarms of spacecraft in\nlow Earth orbit. In Sect. 2.2, we compared the Lander Vision System (LVS) and\nAutonomous Landing and Hazard Avoidance Technology (ALHAT) systems for\nplanetary landing applications. The LVS has less challenging requirements because\nof the day-time landing, small size of the robotic lander, and the significant hazard\ntolerance of the lander. These enabled a system that could perform TRN with the\nmature computer vision algorithms and other sensor measurements such as a single\nflash LIDAR image. On the other hand, the requirements on the ALHAT system are\nmore challenging. The ALHAT system must detect hazards from far away at high\nresolution over a large area to safely land the crewed lunar lander. This resulted in the\ndesign of a gimbaled flash LIDAR and the associated increase in complexity, mass,\nand power. In Sect. 2.3, the new formation control and phase synchronization strategy\nfor swarms of spacecraft was discussed, in which orbital and attitude motions could\nbemodeled as coupled Langrangian systemsmoving in elliptical periodic orbits. The\nadaptive control strategy of automatically computing evolving network topologies\neliminated the need for defining a fixed communication or relative sensing topol-\nogy on a digraph for synchronization stability. Such an evolving communication\nnetwork gave rise to the adaptive graph Laplacian matrix. The error bound of the\nproposed synchronization control law with an adaptive graph Laplacian was shown\nto be smaller than that of an uncoupled tracking control law. This justified the use of a\nsynchronization framework, for application where synchronization errors should be\nkept smaller than tracking errors, like stellar interferometry applications. In Sect. 2.4,\nthe Probabilistic Guidance Algorithm (PGA) was applied to the problem of guid-\ning swarms of spacecraft, operating under dynamic constraints imposed by being in\nEarth orbit. The main simplifying assumption was that all agents have nearly circu-\nlar orbits and they obey Hill\u2019s linearized equations of motion. A simulation example\nshowed the basic feasibility of the method. Due to space limitation, the discussion\nwas restricted to in-plane motion only, but references have been provided that gener-\nalized all results to the out-of-plane case. Section2.5 demonstrated that it is possible\n\nFig. 2.15 Collision events (left triangles and dots represent event intervals and right triangle repre-\nsents approximate intercept time) tracking and detection results: (a) estimation standard deviations;\n(b) location errors; and (c) velocity errors for all satellites\n\n\n\n78 F.Y. Hadaegh et al.\n\nto detect and avoid space collision events using a small number of space-based EO/IR\nsensors. We implemented realistic scenarios and models for LEO collisions, devel-\noped appropriate metrics for the evaluation of different EO/IR sensor constellations,\nand evaluated the tracking and sensor management performance for different LEO\nEO/IR sensor constellations. The constellation that is designed on two orbital planes\nwith four satellites on each offers the best compromise between the number of satel-\nlites and overall performance. The developed capabilities are expected to lead to\nsignificant improvement in Space Situational Awareness (SSA). The Space Based\nVisible sensors/constellations can be used for enhancing the capabilities of Space\nSurveillance Network (SSN). Future developments of an effective space surveillance\nsystem can utilize a swarm of spacecraft. The algorithms developed during our study\nwill be applicable to those designs and lead to cost-effective implementations.\n\nAcknowledgments The researchwas carried out in part at the Jet PropulsionLaboratory, California\nInstitute of Technology, under a contract with NASA. The following people are thanked for their\ncontributions: Saptarshi Bandyopadhyay and Daniel Morgan at UIUC; Milan Mandic at JPL; and\nAdel El-Fallah and Aleksandar Zatezalo at SSCI.\n\nReferences\n\n1. Acikmese, B., Bayard, D.: A markov chain approach to probabilistic swarm guidance. Am.\nControl Conf. (ACC) 2012, 6300\u20136307 (2012). doi:10.1109/ACC.2012.6314729\n\n2. Acikmese, B., Bayard, D.S.: Probabilistic guidance for swarms of autonomous agents. Tech-\nnical Report D-73778, Jet Propulsion Laboratory, JPL (2012)\n\n3. Adams, D., Criss, T., Shankar, U.: Passive optical terrain relative navigation using aplnav. In:\nAerospace Conference, 2008 IEEE, pp. 1\u20139 (2008). doi:10.1109/AERO.2008.4526303\n\n4. Amzajerdian, F., Pierrottet, D., Petway, L., Hines, G., Roback, V.: Lidar systems for precision\nnavigation and safe landing on planetary bodies. In: Proceedings of the SPIE, vol. 8192, pp.\n819, 202\u2013819 ,202\u2013207 (2011). doi:10.1117/12.904062. http://dx.doi.org/10.1117/12.904062\n\n5. An Introduction to the Mathematics and Methods of Astrodynamics. AIAA education series.\nAmerican Institute ofAeronautics andAstronautics, Reston (1999). http://opac.inria.fr/record=\nb1096182\n\n6. Berman, A., Plemmons, R.J.: Nonnegative Matrices in the Mathematical Sciences. SIAM,\nPhiladelphia (1994)\n\n7. Chang, I., Chung, S.J., Blackmore, L.: Cooperative control with adaptive graph laplacians for\nspacecraft formation flying. In: Decision and Control (CDC), 2010 49th IEEE Conference on,\npp. 4926\u20134933 (2010). doi:10.1109/CDC.2010.5717516\n\n8. Cheng, Y., Clouse, D., Johnson, A., Owen, W., Vaughan, A.: Evaluation and improvement\nof passive optical terrain relative navigation algorithms for pin-point landing. In: AAS Space\nFlight Mechanics Meeting (AAS-SFM 2011) (2011)\n\n9. Chung, S.J., Ahsun, U., jacques, E., Slotine, J.: Application of synchronization to formation\nflying spacecraft: Lagrangian approach. J. Guid. Control Dyn. 32(2), 512\u2013526 (2009)\n\n10. Chung, S.J., Bandyopadhyay, S., Chang, I., Hadaegh, F.Y.: Phase synchronization con-\ntrol of complex networks of lagrangian systems on adaptive digraphs. Automatica\n49(5), 1148\u20131161 (2013). doi:http://dx.doi.org/10.1016/j.automatica.2013.01.048. http://\nwww.sciencedirect.com/science/article/pii/S0005109813000496\n\n11. Chung, S.J., Hadaegh, F.Y.: Swarms of femtosats for synthetic aperture applications. In:\n4th International Conference on Spacecraft Formation Flying Missions and Technologies\n(SFFMT). St-Hubert, Quebec, Canada (2011)\n\nhttp://dx.doi.org/10.1109/ACC.2012.6314729\nhttp://dx.doi.org/10.1109/AERO.2008.4526303\nhttp://dx.doi.org/10.1117/12.904062\nhttp://dx.doi.org/10.1117/12.904062\nhttp://opac.inria.fr/record=b1096182\nhttp://opac.inria.fr/record=b1096182\nhttp://dx.doi.org/10.1109/CDC.2010.5717516\nhttp://dx.doi.org/10.1016/j.automatica.2013.01.048\nhttp://www.sciencedirect.com/science/article/pii/S0005109813000496\nhttp://www.sciencedirect.com/science/article/pii/S0005109813000496\n\n\n2 New Guidance, Navigation, and Control Technologies \u2026 79\n\n12. Chung, S.J., Slotine, J.J.: On synchronization of coupled hopf-kuramoto oscillators with phase\ndelays. In:Decision andControl (CDC), 201049th IEEEConference on, pp. 3181\u20133187 (2010).\ndoi:10.1109/CDC.2010.5717962\n\n13. Chung, S.J., Slotine, J.J.E.: Cooperative robot control and concurrent synchronization of\nlagrangian systems. Trans. Rob. 25(3), 686\u2013700 (2009). doi:10.1109/TRO.2009.2014125.\nhttp://dx.doi.org/10.1109/TRO.2009.2014125\n\n14. El-Fallah, A., Zatezalo, A., Mahler, R., Mehra, R.K., Pham, K.: Joint search and sensor man-\nagement of space based eo/ir sensors for leo event estimation. In: Proceedings of the SPIE, vol.\n7330, pp. 73,300N\u201373,300N\u201312 (2009). doi:10.1117/12.818292. http://dx.doi.org/10.1117/\n12.818292\n\n15. Epp, C., Robertson, E., Brady, T.: Autonomous landing and hazard avoidance technology\n(alhat). In: Aerospace Conference, 2008 IEEE, pp. 1\u20137 (2008). doi:10.1109/AERO.2008.\n4526297\n\n16. Fiedler, M.: Special Matrices and Their Applications in Numerical Mathematics. Dover, Mine-\nola (2008)\n\n17. Hoots, F.R., Schumacher, P.W., Glover, R.A.: History of analytical orbit modeling in the u. s.\nspace surveillance system. J. Guid. Control Dyn. 27(2), 174\u2013185 (2004). doi:10.2514/1.9161.\nhttp://dx.doi.org/10.2514/1.9161\n\n18. Horn, R.A., Johnson, C.R.: Matrix Analysis. Cambridge University Press, New York (1985)\n19. Huertas, A., Cheng, Y., Madison, R.: Passive imaging based multi-cue hazard detection for\n\nspacecraft safe landing. In: Aerospace Conference, 2006 IEEE, pp. 14 (2006). doi:10.1109/\nAERO.2006.1655794\n\n20. Johnson, A., Golombek, M.: Lander vision system for safe and precise entry descent and\nlanding. In: LPI Workshop on Concepts and Approaches for Mars Landing (2012)\n\n21. Johnson, A., Huertas, A., Werner, R., Montgomery, J.: Analysis of on-board hazard detection\nand avoidance for safe lunar landing. In: Aerospace Conference, 2008 IEEE, pp. 1\u20139 (2008)\n\n22. Johnson, A., Ivanov, T.: Analysis and testing of a lidar-based approach to terrain relative\nnavigation for precise lunar landing. In: AIAA Guidance Navigation and Control Conference\n(AIAA-GNC 2011) (2011)\n\n23. Johnson, A., Keim, J., Ivanov, T.: Analysis of flash lidar field test data for safe lunar landing.\nIn: Aerospace Conference, 2010 IEEE, pp. 1\u201311 (2010). doi:10.1109/AERO.2010.5447025\n\n24. Johnson, A., Montgomery, J.: Overview of terrain relative navigation approaches for precise\nlunar landing. In: Aerospace Conference, 2008 IEEE, pp. 1\u201310 (2008). doi:10.1109/AERO.\n2008.4526302\n\n25. Johnson, A.,Willson, R., Cheng, Y., Goguen, J., Leger, C., Sanmartin, M., Matthies, L.: Design\nthrough operation of an image-based velocity estimation system for mars landing. Int. J. Com-\nput. Vis. 74(3), 319\u2013341 (2007). doi:10.1007/s11263-006-0022-z. http://dx.doi.org/10.1007/\ns11263-006-0022-z\n\n26. Montenbruck, O., Gill, E.: Satellite Orbits, Models, Methods, and Applications. Springer, New\nYork (2005)\n\n27. Morgan, D., Chung, S.J., Blackmore, L., Acikmese, B., Bayard, D., Hadaegh, F.Y.: Swarm-\nkeeping strategies for spacecraft under J2 and atmospheric drag perturbations. J. Guid. Control\nDyn. 35(5), 1492\u20131506 (2012). doi:10.2514/1.55705. http://dx.doi.org/10.2514/1.55705\n\n28. Mourikis, A., Trawny, N., Roumeliotis, S., Johnson, A., Ansar, A., Matthies, L.: Vision-aided\ninertial navigation for spacecraft entry, descent, and landing. IEEE Trans. Robot. 25(2), 264\u2013\n280 (2009). doi:10.1109/TRO.2009.2012342\n\n29. Poberezhskiy, I., Johnson, A., Chang, D., Ek, E., Natzic, D., Spiers, G., Penniman, S., Short, B.:\nFlash lidar performance testing: configuration and results. In: SPIE Laser Radar Technology\nand Applications XVII (2012)\n\n30. Seo, K., Chung, S.J., Slotine, J.J.: Cpg-based control of a turtle-like underwater vehicle. Auton.\nRobots 28(3), 247\u2013269 (2010). doi:10.1007/s10514-009-9169-0. http://dx.doi.org/10.1007/\ns10514-009-9169-0\n\n31. Vallado, D., Clain, W.: Fundamentals of Astrodynamics and Applications. Col-\nl\u00e8ge custom series. McGraw-Hill, New York (1997). http://books.google.com/books?id=\nHuWMPwAACAAJ\n\nhttp://dx.doi.org/10.1109/CDC.2010.5717962\nhttp://dx.doi.org/10.1109/TRO.2009.2014125\nhttp://dx.doi.org/10.1109/TRO.2009.2014125\nhttp://dx.doi.org/10.1117/12.818292\nhttp://dx.doi.org/10.1117/12.818292\nhttp://dx.doi.org/10.1117/12.818292\nhttp://dx.doi.org/10.1109/AERO.2008.4526297\nhttp://dx.doi.org/10.1109/AERO.2008.4526297\nhttp://dx.doi.org/10.2514/1.9161\nhttp://dx.doi.org/10.2514/1.9161\nhttp://dx.doi.org/10.1109/AERO.2006.1655794\nhttp://dx.doi.org/10.1109/AERO.2006.1655794\nhttp://dx.doi.org/10.1109/AERO.2010.5447025\nhttp://dx.doi.org/10.1109/AERO.2008.4526302\nhttp://dx.doi.org/10.1109/AERO.2008.4526302\nhttp://dx.doi.org/10.1007/s11263-006-0022-z\nhttp://dx.doi.org/10.1007/s11263-006-0022-z\nhttp://dx.doi.org/10.1007/s11263-006-0022-z\nhttp://dx.doi.org/10.2514/1.55705\nhttp://dx.doi.org/10.2514/1.55705\nhttp://dx.doi.org/10.1109/TRO.2009.2012342\nhttp://dx.doi.org/10.1007/s10514-009-9169-0\nhttp://dx.doi.org/10.1007/s10514-009-9169-0\nhttp://dx.doi.org/10.1007/s10514-009-9169-0\nhttp://books.google.com/books?id=HuWMPwAACAAJ\nhttp://books.google.com/books?id=HuWMPwAACAAJ\n\n\n80 F.Y. Hadaegh et al.\n\n32. Villalpando, C., Johnson, A., Some, R., Oberlin, J., Goldberg, S.: Investigation of the tilera\nprocessor for real time hazard detection and avoidance on the altair lunar lander. In: Aerospace\nConference, 2010 IEEE, pp. 1\u20139 (2010). doi:10.1109/AERO.2010.5447023\n\n33. Zatezalo, A., El-Fallah, A., Mahler, R., Mehra, R.K., Brown, J.: Dispersed and disparate sensor\nmanagement for tracking low earth orbit satellites. In: Proceedings of the SPIE, vol. 7336, pp.\n73,360I\u201373,360I\u201312 (2009). doi:10.1117/12.819299. http://dx.doi.org/10.1117/12.819299\n\n34. Zatezalo, A., El-Fallah, A., Mahler, R., Mehra, R.K., Pham, K.: Optimal constellation design\nof low earth orbit (leo) eo/ir sensor platforms for space situational awareness. In: Proceedings\nof the SPIE, vol. 7330, pp. 73,300T\u201373,300T\u201311 (2009). doi:10.1117/12.818304. http://dx.doi.\norg/10.1117/12.818304\n\n35. Zatezalo, A., El-Fallah, A., Mahler, R., Mehra, R.K., Pham, K.: Eo/ir satellite constellations for\nthe early detection and tracking of collision events. In: Proceedings of the SPIE, vol. 7697, pp.\n76,970L\u201376,970L\u201312 (2010). doi:10.1117/12.851217. http://dx.doi.org/10.1117/12.851217\n\n36. Zatezalo, A., El-Fallah, A., Mahler, R., Mehra, R.K., Pham, K.D.: Multimodel filtering of\npartially observable space object trajectories. In: Proceedings of the SPIE, vol. 8050, pp. 80,\n500K\u201380,500K\u201312 (2011). doi:10.1117/12.884609. http://dx.doi.org/10.1117/12.884609\n\nhttp://dx.doi.org/10.1109/AERO.2010.5447023\nhttp://dx.doi.org/10.1117/12.819299\nhttp://dx.doi.org/10.1117/12.819299\nhttp://dx.doi.org/10.1117/12.818304\nhttp://dx.doi.org/10.1117/12.818304\nhttp://dx.doi.org/10.1117/12.818304\nhttp://dx.doi.org/10.1117/12.851217\nhttp://dx.doi.org/10.1117/12.851217\nhttp://dx.doi.org/10.1117/12.884609\nhttp://dx.doi.org/10.1117/12.884609\n\n\nChapter 3\nAircraft Autonomy\n\nPiero Miotto, Leena Singh, James D. Paduano, Andrew Clare,\nMary L. Cummings and Lesley A. Weitz\n\n3.1 Introduction\n\nThe word automatic is a compound of the Greek words auto which means\n\u201cself\u201d, and mao?, which means \u201cto be ready or eager\u201d, hence the word automatic\nliterally means \u201cacting on one\u2019s will or self-acting.\u201d Automation is the discipline\nbehind the design of automatic systems. Important strides have been made in the\narea of system automation. The word autonomy, on the other hand, is formed from\ncompounding the word auto with another Greek word nomos , which means\n\u201claw\u201d, hence autonomy literally means \u201cone who gives oneself its own law.\u201d Unlike\nautomation, very little has been done in the area of developingmanned and unmanned\naerospace systems that are truly autonomous. The focus of this chapter is to explore\n\nP. Miotto (B) \u00b7 L. Singh\nDraper Laboratory, Cambridge, MA 02139-3563, USA\ne-mail: pmiotto@draper.com\n\nL. Singh\ne-mail: lsingh@draper.com\n\nJ.D. Paduano\nAurora Flight Sciences, Cambridge, MA 02142-1050, USA\ne-mail: jpaduano@aurora.aero\n\nA. Clare\nMassachusetts Institute of Technology, Cambridge, MA, USA\ne-mail: andrew.clare@mit.edu\n\nM.L. Cummings\nDuke University MEMS, Durham, USA\ne-mail: m.cummings@duke.edu\n\nL.A. Weitz\nMitre Corporation CAASD, New Jersey, USA\ne-mail: lweitz@mitre.org\n\n\u00a9 Springer-Verlag Berlin Heidelberg 2016\nE. Feron (ed.), Advances in Control System Technology\nfor Aerospace Applications, Lecture Notes in Control\nand Information Sciences 460, DOI 10.1007/978-3-662-47694-9_3\n\n81\n\n\n\n82 P. Miotto et al.\n\nthe progress in aircraft automation and the challenges that lay ahead in our path\ntoward the development of truly autonomous aircraft systems.\n\nAutomation is increasing in every aspect of our society and in our daily lives. It is\nbeing entrusted with the management of complex operations in many wide-ranging\nsectors such as mass transit, medicine, finance, law enforcement, military, science,\netc. In mass transit, we have seen the automation of intra-airport rail systems and\neven a few city scale subway systems. In finance, banking operations are conducted\nvia Automatic Teller Machines (ATM) without human supervision. In the field of\nmedicine, automation is used in procedures such as the laser eye surgery and the\npost- surgical care of patients. Unmanned Vehicles (UVs) have also been success-\nfully employed in dangerous and remote environments, which has resulted in impor-\ntant scientific breakthroughs and discoveries. For example, underwater Unmanned\nVehicles (UUVs) have explored the deepest trenches of the ocean [75] and NASA\u2019s\nunmanned rovers have traversed the surface of Mars [55]. Scientists have studied\nglobal warming by surveying the polar ice caps [68] with UAVs, while civilian agen-\ncies have employed Unmanned Aerial Vehicles (UAVs) for border patrol [39] and\nfighting forest fires [16].\n\nThe importance of automation is clearly manifested in the military sector. UAVs\nhave enabled the military to run long endurance missions over hostile territory with-\nout placing a human pilot in harm\u2019s way. For this reason, they have become a key\ncomponent of aerial surveillance missions. UAVs are also playing an increasingly\nvital role in ground attacks. Unmanned Ground Vehicles, for example, have been\nutilized by soldiers and civilian bomb squads to investigate and defuse explosive\ndevices [56]. The military is now working to incrementally increase the employment\nof UAVs in cargo delivery, medical evacuation, and supply missions. They are set to\noperate alongside piloted aircraft in what the Air Force terms \u201csame base, same time,\nsame tempo\u201d operations. Further, automatic landing systems on aircraft have demon-\nstrated the ability to land jets on a moving ship deck in extremely low visibility and\nturbulent landing conditions with no pilot supervision. Automatic landing has proven\nso successful and practical that, today, the United States military trains twice asmany\nground operators for its unmanned aerial vehicles (UAVs) as pilots for its military\njets. The military is working to further enhance the autonomous capabilities of their\naircrafts. These enhancements include the abilities to perform unmanned mid-air\nrefueling, takeoff and landing of full-scale helicopter on unmapped terrain, low-\naltitude nap-of-the-earth flight, and pilotless medical-evacuation demonstrations.\n\nIn the commercial sector, automation has proven instrumental in reducing the\ncockpit crew fromfive to two. Current plans include even further reduction in piloting\noperations. In the words of the President and CEO of Boeing Commercial Airlines,\nJames Albaugh, when delivering the keynote address at the 2011 AIAA Modeling\nand Simulation Conference, a \u201cpilotless airliner\u201d is no longer a question of \u201cif\u201d but\nonly a matter of \u201cwhen\u201d. In the coming years, unmanned aircrafts are also expected\nto increase their footprint in civilian applications particularly in the \u201cdull, dirty and\ndangerous\u201d mission space. The goal is to employ UAVs to execute air-based storm\ndamage surveillance including infrastructure surveys, refugee evacuation, and trans-\nportation of cargo.\n\n\n\n3 Aircraft Autonomy 83\n\n3.1.1 Challenges to the Safe Integration of UAVs\nin the National Airspace\n\nIn order to achieve these goals, UAVs, whether fully autonomous or remotely piloted,\nwill have to demonstrate in recognizable and provable terms, not only their ability\nto perform the most routine missions in civilian airspace but also their ability to\noperate alongside manned aircraft in full conformance with the rules and constraints\nof national civil aviation. As of 2015, the FAA has allowed only very restrictive con-\nditions under which UAVs can operate during routine civilian operations. In order to\nmeet the requirements to operate in civilian airspace, it is paramount that we enhance\nthe technical capabilities of UAVs such that we can guarantee the safe integration of\nUAVs in the civilian and commercial sector. A safe and graceful integration will, as a\nresult, reduce the public\u2019s fear about the usage of UAVs and enable wide acceptance\namong the passengers and partners alike.\n\nThe differences between Military UAVs and the civilian ones are stark. Mili-\ntary UAVs leverage owned-and-operated satellite systems supplemented by undersea\ncables to link their ground controllers (at times, half a world away from the aircraft)\nwith low latency data and high-speed video transmission. Civilian UAVs, on the\nother hand, are forced to splice into the FCC-directed channels for all communi-\ncation. Insufficient ground-communication bandwidth caused by the fine frequency\nallocations spread between mobile phones and other communication infrastructure\nfundamentally limits the ability to coordinate operations between all aircraft in a\ncommon airspace and does not allow a civilian aircraft to transmit its data to ground\nstations thus preventing human backup takeover of the flight controls.\n\nBecause of these severe limitations, as of today, UAVs lack: the ability to\nautomatically detect and avoid nearby aircraft within visual range; a standard com-\nmunication capability between the ground stations of remotely piloted aircraft and\nfully automated ones; the logic and software, both onboard and within the ground-\nbased air traffic systems, that would allow autonomous air vehicles to share airspace\nwithmanned aircraft. These limitations prevent them from enteringmainstreamoper-\nations and ensuring the necessary safety error tolerance.\n\nThe current aviation infrastructure, since itwas conceived anddeveloped solely for\nhuman operators with multiple tiers of human-in-the-loop safety systems, presents\nan additional obstacle to the safe integration of UAVs in the civil sector. Modern air\ntraffic management protocols are neither suitable nor reliable enough to ensure safe\nincorporation into autonomous flightmonitoring and support. To simplymandate that\nanyUAVoperating within the National Air Space (NAS) bemonitored by a pilot who\ncan communicate with existing Air Traffic Control (ATC) systems and issue in-flight\ntrajectory updates or changes, is not a practical solution. This approach would simply\noverwhelm the communication frameworks, the human infrastructural capability and\nincrease the financial burdens of using UAVs which de facto obliterates the advan-\ntages of autonomy. However, the shared goal of the air traffic monitoring and control\nsystems currently under development in the European Union (SESAR or Single\n\n\n\n84 P. Miotto et al.\n\nEuropean Sky ATMResearch) and the United States (NextGen ATM) include provi-\nsions to support both military and civilian, national and international aircraft in the\nsame airspace.\n\n3.1.2 Technical Enhancements for Safe Insertion of UAVs\nin the NAS\n\nTo achieve a safe integration of UAVs in the NAS, the military has identified the\nfollowing enabling technologies: sense-and avoid technologies via communication-\nbased response and collision-avoidance capabilities; intent estimation of the other\naircraft; integrity management; terminal area sensing andVerification and Validation\n(V&V) of autonomous systems. Likewise, the FAA has instituted an unmanned\naircraft programoffice to determine the regulations that will accord UAVs permissible\nflight corridors. In Europe, SESAR has been formed to completely overhaul the\nEuropean airspace and its Air Traffic Management (ATM) system. For both sides\nof the Atlantic, the next generation of ATM system regulations will need to define\ncapabilities and conventions for handling both manned and unmanned aircrafts.\n\nThe need to develop sense-and-avoid (SAA) technologies stems from an FAA\nrequirement that expects the aircraft operator to be able to detect an aircraft within\nvisual range, andmaneuver to prevent collisions. Sense-and-avoid capabilities, there-\nfore, will need to span autonomous aircraft detection, fusing measurements from\nmultiple on-board sensors to detect and identify an \u201cintruder\u201d aircraft, take evasive\naction from the aircraft (according to regulation minimum separation standards),\nnotify air-traffic control and then land safely. Remotely piloted aircrafts, too, will\nneed to be fittedwith some SAA capability since high-bandwidth telecommunication\noperation is not practical due to bandwidth constraints in the large and the size of\nthe expected fleet. Although such implementations readily fall within present day\nautomation capabilities, they will need to be universally and uniformly instituted.\n\nNotwithstanding such implementations, aminimum threshold onguaranteed com-\nmunications capability will still need to be instituted in all autonomous aircraft,\ncivilian and military, to allow ground controllers to communicate with the aircraft in\nthe terminal area, and ensure rapid response to controller directives i.e. to receive,\nacknowledge, execute and request confirmation on all ATC commands according to\nthe same protocols and in the same timely fashion as the manned counterparts.\n\nIntent estimation is a derived capability required by the FAA to support terminal\narea operations. It involves fusing measurements from all proximity sensors with\nmodels of typical airfield operations to estimate the status and possible intent of\nother aircraft, and to ensure proactive rather than reactive actions conformal with the\nactions of piloted aircraft.\n\n\n\n3 Aircraft Autonomy 85\n\nFinally, once UAVs are included within the NAS, there will be a need for a\nreformulated ATC to handle a heterogeneous airspace as well as to scale to the\nnumbers of aircraft that will need to be supported.\n\nUnder current day practices, under normal flight conditions, military UAVs and\nautonomous air systems operate with an on-board autopilot and a mission manager\nflying a preplanned trajectory or performing way-point guidance under the approval\nof a ground-stationed human operator. Despite the capability of UAVs to perform\nchallenging ship-deck landing operations in uncertain lighting and turbulent weather\nconditions, a hand off to a human pilot is required under off-nominal conditions\nsuch as in rough weather or due to special airport operational requirements. Total\nautonomous flight control operations throughout the operating envelope and in the\npresence of systems failures will be necessary to expand the safe and reliable opera-\ntional envelope of the autonomous pilot; this will necessitate further development of\ncontrol, diagnostics, and mission planning systems [4, 14, 15, 36, 46, 60, 61, 71].\n\nIn the \u201cUnmanned Systems Integrated Roadmap FY2011-2036\u201d, the United\nStates Department of Defense has stated that top priorities for future research\ninclude increasing UV autonomy and developing advanced techniques for Manned-\nUnmanned teaming [29]. The road-map has outlined the following: the need for\nmore advanced autonomy, the desire for this autonomy to be flexible and adapt-\nable to dynamic and uncertain environments, the need for collaborative autonomy\nbetween multiple UVs, and the need for new Verification and Validation (V&V)\napproaches to certify increasingly complex autonomy [29, 53]. While the Depart-\nment of Defense is enthusiastic about autonomy, the road-map also cautioned that\n\u201cbecause artificial systems lack the human ability to step outside a problem and inde-\npendently reevaluate a novel situation based on commander\u2019s intent, algorithms that\nare extremely proficient at finding optimal solutions for specific problems may fail,\nand fail badly, when faced with situations other than the ones for which they were\nprogrammed [29]\u201d.\n\nThe ensuing three sections of this chapter tackle some of the challenges outlined in\nthis introduction. The first section titled \u201cOn-board air autonomy systems needs\u201d dis-\ncusses advancements in flight control system capabilities and flight-deck-automation\nthat will equip UAVs with the on-board functionality required of all aircraft operat-\ning within the NAS. The next section titled \u201cHuman-Automation Collaboration\u201d dis-\ncusses the algorithms required for the development of an effective human-automation\ncollaborative system for managing multiple UAVs in the airspace. The final section\ndiscusses issues in the modernization of the air traffic management system, and\npresents the challenges and the new technologies required to meet ever increasing\nair traffic demands. All three sections will talk about the key shortcomings in today\u2019s\nautonomous systems, and propose the most promising concepts to overcome these\nshortcomings. Each sectionwill include a roadmap for the safe development, testing,\nand integration of these technologies into fielded systems.\n\n\n\n86 P. Miotto et al.\n\n3.2 On-Board Air Autonomy Systems Needs\n\nChallenges for the autonomy and controls community have appeared in the form\nof Broad Agency Announcements (BAAs), discussions of next-generation warfare\nscenarios, and concepts that continue to resurface regarding desired capabilities. In\nthe present section, we first attempt to introduce these challenges with some attempt\nat organization. Then, we translate these challenges into technical challenges or\ntechnical approaches that show promise. The final part describes a road-map for\nmoving forward.\n\n3.2.1 Challenges to Integration of UAVs in the NAS\n\nThe continued expansion of UAVs in commercial operations is the key challenge\nidentified by Congress, users and providers alike for the next decade. For this to\nhappen, it is universally agreed that UAVs must achieve operation at man -rated lev-\nels of safety. To be sure, this translates to different requirements for different types\nof UAVs. For Predator/Global Hawk class UAVs to operate from civilian airports\nand to follow flight paths similar to those of civil transports, and thus be fully inte-\ngrated in the commercial sector, reliability levels will have to be higher than, for\nexample, for a 2 pound foam UAV, which will not need triplex redundancy. A more\ninteresting challenge regarding safety is posed by the 10 to 150 pound. range of\nvehicles. Although in this case the potential for injury and death is still very high,\nthe cost of the vehicle would be prohibitive were it required to meet the standards for\nlarge vehicles. To reach appropriate safety standards across the board, key technical\nchallenges previously mentioned in the introduction include: V&V for autonomous\nsystem, Sense & Avoid solutions, and FAA integration strategies and ConOps. Other\ntechnical challenges are listed below.\n\nProximity Operations:\n\nThis area of expansion in the employment of UAVs includes landing on ship decks\nor other moving vehicles, urban and indoor operation, autonomous refueling, and\nairborne launch and recovery. Many of these operations would place UAVs in envi-\nronments where, to date, they have never operated: in proximity to other vehicles\nor structures. Sensing, estimation, disturbance rejection, and control take on very\ndifferent requirements in this regime, and many challenges have yet to be met.\n\nGPS denied operation:\n\nThis is related to proximity operations in the sense that ProxOps often cannot rely\non GPS due to its lack of sufficient accuracy and the fact that relative position to\nobstacles is needed. Many of the sensing solutions are related to those that enable\nProxOps, such as vision-based control, but others such as signals of opportunity, are\nunique.\n\n\n\n3 Aircraft Autonomy 87\n\nAnti-Access Area Denial (A2AD):\n\nThis has been made a top priority by the Air Force. Autonomous systems are a\npotential solution to achieving the objective of area protection. Anti-Access refers to\nthe ability to prevent large scale access to a region, whereas AreaDenial describes the\nability to prevent tactical operation in the immediate area of an enemy force. Large\nteams of UAVs with unique properties could provide a way to overcome enemy\ncapabilities.\n\nProtection against \u201cSwarm\u201d Attacks:\n\nIn this context, \u201cSwarm\u201d refers to a set of vehicles (manned or unmanned) that\noverwhelms the protective \u201cpickets\u201d set up around large vessels at sea. This is an\nasymmetric threat; were enough low-tech vehicles to attack, just a few breaking\nthrough could create a USS Cole-like incident.\n\n3.2.2 Technical Enhancements for Improved In-Air\nautonomy\u2014Key Technologies\n\nThis section translates the high-level programmatic challenges outlined in Sect. 3.2.1\ninto technical challenges to the autonomy community and puts them in the context\nof technologies to be pursued and advanced.\n\nVision and LIDAR based estimation and control:\n\nVision andLIDAR systems havemade great strides in recent years and computational\ncapabilities needed to put them into flight to enable Sense-and-Avoid capabilities are\nnow available. Vision-based methods are divided roughly into optical flow or heuris-\ntic methods, feature-based methods, and perception- or semantic- based methods.1\n\nOptical flowmethods are bio-inspired and provide fast, reactive capabilities for guid-\nance through urban environments and obstacle detection and avoidance. Generally\nthey are not quantitative estimation techniques; nevertheless the amazing optical flow\n-driven capabilities of human and insect eyes, for enabling safe, proximal operations\nand threat detection, make this an important area of research. Feature-based meth-\nods consider \u2018features\u2019 in the environment that are easily detected and tracked by a\ncomputer, but otherwise have no identity to the computer. A rich set of such features\ncan be used for GPS-denied navigation, mapping/SLAM, and proximity operations.\nSemantics in vision refers to the idea of actually recognizing and classifying objects\nin the environment. Such ability can be used to identify, for instance, a landing site,\nimprove localization accuracy by looking for known objects in the environment, or\nto determine whether a landing site has suitable rigidity to allow a heavy helicopter\nto land without sinking into mud, gravel, etc.\n\n1This is the author\u2019s own taxonomy and terminology, a vision expert might divide it some other\nway.\n\n\n\n88 P. Miotto et al.\n\nAs with many technology areas, the number of approaches and applications is so\nwide that little or no attempt has been made to organize them in a rational way. Such\norganization would be appropriate at this stage. Aurora maintains the SPHERES\ntest-bed on the ISS to which a binocular camera system was recently added, as\nwell as an embedded system suitable for MAVs, which performs vision processing.\nThese platforms and associated vision-based ego- motion estimation and optical\nflow algorithms could be used as baselines to start the process of identifying best\napproaches to address various Proximity Operations challenges, strengthening those\napproaches, and making them available to the engineering community at large.\n\nAdaptive Control:\n\nAdaptive control has advanced by leaps and bounds in recent years, to the point that\nmany believe it is \u2018ready for prime time\u2019, that is, ready to become an integral part of\nthe next generation of autonomous vehicles. New vehicle configurations engineered\nto meet the challenges previously described 2 often do not live up to their potential\nbecause conventional control designmethods require toomuch work to bring to bear.\nA case in point: a hobbyist can hover and transition a foamy aircraft in light gusts,\nbut only a handful of autonomous systems have achieved this capability\u2014and these\nhave either been adaptive, have utilized motion capture, have required costly and\ntime-consuming engineering, and have utilized simplifications that reduced utility.\nAdaptive control is making its way into industry, but funding is needed to further the\ntransition from universities and NASA to industry. Reliability, and V&V challenges\nexist, and research is needed in this area. UAVs will benefit from these advancements\ntowards enabling safe flight in the presence of failures and/or executing \u201csafe abort\u201d\nin the presence of critical failures.\n\nOptimization-Based Control:\n\nOptimization based trajectory generation and following, path planning, and multi-\nvehicle coordination have all been researched actively over the past 10 or 15 years.\nMethods are making their way into applications across the board and, for problems\nlike A2AD and Swarms, there are a number of companies and institutions with\nstrong capabilities to address these challenges. For path planning and multi- vehicle\ncoordination, the remaining challenges appear to be logistics and system-integration.\nFor instance, many of the techniques implicitly rely on the existence of an existing\nad hoc network and, although many of these techniques are robust to brief outages\nor range-related drop-outs, they all require the existence of such a network. However\nthe military has not settled on or fielded a standard for the type of radios required\nto enable network- in-the-sky communication between many vehicles in the air. The\nlogistics of take-off and landing for a large team of UAVs also presents a challenge.\nThis area would need a \u201ckiller app\u201d, agreed upon by all funding agencies and that\ndoes not leave space for alternatives. Swarm protection may prove to be such a killer\n\n2Specifically, proximity operations, indoor operations, small vehicles that require severe gust\nrejection capability, and operations off of unequipped ship decks.\n\n\n\n3 Aircraft Autonomy 89\n\napp, and the Navy has made progress in the area of team-based anti-submarine and\nmine countermeasures. Other ways may, however, exist and should be investigated.\n\nAs to the area of trajectory generation and following, which here refers to maneu-\nvering along a non-equilibrium flight path to achieve a goal such as aircraft landing\nonto a pitching ship deck, maneuvering through an urban environment, or flare-to-\nland of a helicopter onto a highly sloped surface. Here, too, the tools seem up to the\nchallenge but questions about reliability have still been left unanswered. Advanced\nmethods such as falsification, or other efficient methods to replaceMonte Carlo, may\nbe appropriate for bringing these tools into applications.\n\nVerification and Validation:\n\nA recurring concern in the world of control systems is the high cost of turning\nconcepts into practice, due to the expensive nature of software, integration, and\ntesting costs [53]. By way of a number of short-cuts (motion capture, open-source\nsoftware, one-time integration), Universities have been able to develop and fine-\ntune a number of significant capabilities that seem ready for transition. Few of these\ncapabilities, however, at the present have found their way into actual air vehicles. The\ncomplexities of full-scale aircraft, the cost of hardware-in-the-loop simulation and\nvalidation, and the cost of code generation and validation in a flight critical setting\ncontinue to be severe obstacles and are perhaps the main obstacles for the realization\nof capabilities that are so close at hand.\n\nAlthough the current modus operandi may prove sufficient in the case of the\ngovernment being willing to pay the industry to implement an important capability,\nDARPA has prominently articulated the question if the development cycle really\nneeds to be so expensive, manpower hungry, and slow-moving. Some private indus-\ntries have attained higher levels of flexibility. Universities, too, have achieved impor-\ntant results in flight demonstrations. But, at present, it is still unclear how to lower\nthe cost of the implementation of such capabilities on full-scale vehicles.\n\nSelf-Aware Vehicles:\n\nSome of the challenges outlined earlier can be partially addressed by aircraft with\nproprioception capability, that is, the capability to sense their aerodynamic and/or\nstructural state. New, distributed sensor in and on the wings of small UAVs are giving\nthem gust rejection and maneuver capabilities that should be considered.\n\n3.2.3 Conclusions: A Road-Map to Address the Technical\nChallenges\n\nAny ideal road-map should have, as its goal, the creation of a codified base of capa-\nbilities, that is, a (hopefully diverse) set of companies, research labs, and universities\nable to perform the engineering tasks associated with a new capability on a regular\nbasis. The development process of miniature flight controls components serves as\nan example of such an ideal road-map. Through funded research, small business\n\n\n\n90 P. Miotto et al.\n\ninitiatives, and developments in the electronics industry, the integration of a small\nflight controller into a UAV is now a routine matter. This can be achieved in one of\nthe following ways: buy a turnkey system from a small company, create an inter-\nnal capability by hiring a few engineers with know-how and experience, or join an\nopen-source community that maintains a system. Similarly, 6-DOF nonlinear sim-\nulation of conventional flight vehicles is a well-established capability both reliable\nand attainable at a reasonable cost. For these and a number of other control-related\ntechnologies, \u201cpeople know how to do it\u201d.\n\nThe road-map to creation of such codified capabilities or shared industrial know-\nhow is difficult to pre-specify. Often these capabilities evolve in an organic way,\nwith little or no pre-planned road-map. For important technology efforts, the R&D\ncommunity has the responsibility of a more rational approach, i.e. we need to have\na clear vision of the capability we want to develop and of the specific steps that will\nlead us to attain such goal. Below are two examples of this model road-map.\n\nVision and LIDAR based estimation and control:\n\nThis is an area where a \u201ccapability goal\u201d is relatively easy to define. At present,\nwe lack the ability to systematically engineer vision-based approaches. Although\nattempts utilize simulations in 3D environments derived from video games, it is yet\nunclear whether these environments are applicable to the real world. No good tools\nor guidelines for hardware-in-the-loop or real-time simulation exist; this is especially\ntrue for LIDAR. Testing in realistic settings is often prohibitively difficult, except\nfor indoor flight. Thus a road-map to an engineering base for vision- and LIDAR-\nbased estimation and control is urgently needed.\n\nTo build such a road-mapwe first need to focus on the simulation issue and answer\nthe following questions: how can we simulate vision, and how does one validate the\nsimulation? Can we create a framework that is suitable for real-time or faster-than\nreal time operation, how can we capitalize on the gaming industry and apply it tothe\nreal world? The next step, which could be pursued in parallel, and might inform the\nfirst step, is the issue of sensor emulation: i.e., how can a simulation environment\ntake on the properties of a LIDAR or a camera, as either a bridge to or a mechanism\nfor hardware-in-the-loop testing? Finally, can a systematic methodology for testing\nagainst available video data, or testing under various canonical illumination, shadow,\nand other environmental conditions, be created?\n\nThere are a number of software tools for vision available and, at present, it is\nrelatively routine to do blob and edge detection, SIFT and SURF, and run various\nother vision algorithms. What is still missing and urgently needed is to bring these\ntools into a systematic engineering framework of design, build, test, iterate, and fly.\n\nVerification and Validation:\n\nAnother area where a clear end state can be formulated is Verification and Validation.\nLarge aerospace prime contractors have the knowledge to perform V&V and have\nmethodologies consistent with certification requirements; in other words, we have\na process in place for certifying manned aircraft. No such process, however, exists\nfor UAVs in the 10 to 150 pound class. While UAVs of this class are too heavy to\n\n\n\n3 Aircraft Autonomy 91\n\nignore from a safety perspective, they are too small and low cost to undergo the full\nmanned aircraft approach. We need a road-map to the creation of a framework for\nengineering certified small UAS.\n\nTo develop such a road-map, we first need to define the requirements entailed in\ncertifying small UAVs:\n\n1. what, for example, are the ConOps for its operation;\n2. what are the safety considerations;\n3. how could confining the operations of UAS make special-purpose certification\n\nfeasible and acceptable to the public.\n\nSuch a road-map, whenever given the FAA stamp of approval, would offer the frame-\nwork that would enable the development of a vibrant industry. Informed by such a\nroad-map, we could seek verification and validation methods that meet the specific\nneeds of small UAS and are not hampered by current regulations. The goal of such a\nroad-map would be to trade off reliability for cost of V&V for, if and when realistic\nset of ConOps and certification standards are put into place, the overall safety can\nbe met with a different set of reliability standards. To this end, engineering tools can\nbe adapted to meet the specific needs of the small UAS V&V problem. Finally, we\nneed to develop processes leading to certification consistent with the ConOps and\ntool envisioned.\n\nSimilar road-maps should be developed for the other challenges outlined in\nSect. 3.2.1 of this paper. We outline a feasible approach to road-map generation\nbased on the experience of past successes, two of which have been discussed in\nsome detail in the present paper. Previous experience leads us to believe that a suc-\ncessful road-map should have the following components:\n\n1. A clear vision of the end state being sought. This vision should be to solidify or\nstrengthen a capability within the industry, rather than a one-off demonstration\nor research thread with no clear conclusion.\n\n2. Buy-in from funding agencies and the technical community. Obviously a long-\nterm road-map requires funding, and this funding is predicated on agreement that\nthe sought after goals are appropriate and the roles of the agencies involved are\nclear. A technical working group to guide the process is also valuable.\n\n3. Realism. Goals and way points toward those goals should be clearly reachable.\nAt present, we too often are able to implement in a one-off fashion, so we know\nwhat can be done; we just don\u2019t know how to do these things routinely.\n\n4. Modularization and redundancy. One of the factors that enabled the success of the\nminiature flight avionics capability was the fact that many companies were trying\nto create these devices. Competition and a critical mass within the community\nare needed to create a \u2018sub-culture\u2019 of people and organizations that can do the\nengineering involved.\n\n\n\n92 P. Miotto et al.\n\n3.3 Human-Automation Collaboration\n\nAlthough in the past decade UAVs have proven key to a variety of missions and tasks\nboth in the military and in the commercial sector, significant obstacles still prevent\ntheir wider use. One problem is the large number of human operators required to\noperate them, a number that is often well in excess of that needed to operate a\ncomparable manned vehicle [42]. This obstacle can, however, be overcome through\nan increase in the autonomous capabilities of UVs [24].Many advancedUVs are able\nto execute basic movement and navigational tasks autonomously and can collaborate\nwith other UVs to complete higher level tasks, such as surveying a designated area [2,\n10]. The United States Department of Defense has for years envisioned inverting\nthe operator -to-vehicle ratio such that a single operator controls multiple UAVs\nsimultaneously [28]. This concept has now been extended to single operator control\nof multiple heterogeneous (air, sea, land) UVs [54].\n\nThis inversion of operators to vehicles will require the computational ability of\noptimization algorithms combined with the judgment and adaptability of a human\nsupervisor. Identifying the characteristics thatmake an algorithmsuitable for this kind\nof human-automation collaboration is essential for the development of an effective\nsystem. In order to begin to derive requirements for algorithms that can effectively\ncollaborate with humans, a survey of academic and industry publications was con-\nducted focusing on recently developed multiple UV scheduling algorithms [19]. The\ngoal of the survey was to determine the types and frequency of scheduling algorithms\nthat were currently in use in unmanned systems and to classify the characteristics\nand capabilities of these algorithms in terms of human-automation collaboration.We\nsummarize the results of that survey below to describe the state of the art in mul-\ntiple UV scheduling algorithms and to identify the important remaining challenges\ntowards the development of an effective human-automation collaborative system for\ncontrolling multiple UVs.\n\n3.3.1 Challenges in the Collaborative Human-Automation\nScheduling Process\n\nTo effectively control multiple semi-autonomous UVs, there exists the need for a\nsystematic method for scheduling tasks. For our purposes, scheduling is defined as\ncreating a temporal plan that assigns tasks among a teamofUVs and determineswhen\nthe tasks are to be completed. While there is no explicit focus on path planning, it is\nworth noting that path planning is coupled with the scheduling problem, due to the\nneed to estimate the amount of time needed for a UV to travel to a certain location\nto accomplish a task.\n\nA wide variety of optimization algorithms have been developed to address the\nproblem of scheduling tasks for multiple UVs. While varying in their method of\nformulating the scheduling problem and solving the optimization, all the approaches\n\n\n\n3 Aircraft Autonomy 93\n\nutilize an autonomous scheduler with little to no human input during the develop-\nment of the schedule. In the presence of unknown variables, possibly inaccurate\ninformation, and changing environments, these automated scheduling algorithms do\nnot always perform well [64, 66].\n\nThough fast and able to handle complex computation far better than humans, opti-\nmization algorithms are notoriously \u201cbrittle\u201d in that they can only take into account\nthose quantifiable variables, parameters, objectives, and constraints identified in the\ndesign stages that were deemed to be critical [67]. In a command and control situ-\nation such as one requiring the supervision of multiple UVs and where events are\noften unpredictable (e.g. weather changes, unexpected target movement), automated\nplanners have difficulty accounting for and responding to unforeseen changes in the\nenvironment [40, 58]. Additionally, the designers of optimization algorithms often\nmake a variety of assumptions when formulating the optimization problem, deter-\nmining what information to take into account, or, in the case of receding horizon\nalgorithms, deciding how far into the future to plan [8, 47].\n\nOne approach to deal with the \u201cbrittleness\u201d of these algorithms is to have a human\noperator and an algorithm develop schedules collaboratively. A number of studies\nhave shown that humans collaborating with algorithms can achieve higher perfor-\nmance than either the human or the algorithm alone under certain conditions [3, 25,\n27, 45, 49, 59, 63]. While extensive research has been conducted to develop better\nalgorithms for planning, comparatively little research has occurred on the methods\nby which human users utilize these tools, especially when working in dynamic,\ntime-critical situations with high information uncertainty [50]. Additionally, oper-\nators can become confused when working with automation, unaware of how the\n\u201cblack box\u201d algorithm has reached its solution or the assumptions made by the algo-\nrithm in modeling the problem. Moreover, generally humans play solely the role of\ndecision-maker and only approve or disapprove schedules,without any considera-\ntion to the way a human could actually aid an algorithm in improving a solution.\nFigure3.1 is a representation of the fact that there are often differences between the\nreal world, the automation/engineer\u2019s model, and the human operator\u2019s model of the\nworld. Designing an effective human-automation collaborative scheduling system\n\nFig. 3.1 Differences\nbetween real world,\nalgorithm\u2019s model, and\noperator\u2019s model of the\nworld\n\nReal\n\nWorld\n\nAlgorithm\u2019s\n\n(Engineer\u2019s)\n\nModel\n\nOperator\u2019s \n\nModel\n\n21\n\n3\n\n\n\n94 P. Miotto et al.\n\nHuman \noperator\n\nInterface\n\nScheduling \nalgorithm\n\nUnmanned \nVehicle\n\nUnmanned \nVehicle\n\nUnmanned\nVehicle\n\nEnvironment\n\nLegend\nInformation\n\nActions\n\nFig. 3.2 Human-automaton collaborative scheduling system diagram\n\ncould provide the ability to supervise multiple UVs while addressing the inherent\nbrittleness and opacity of algorithms. As shown in Fig. 3.2, the system could include\nthe human operator, the graphical interface which displays information to the oper-\nator and allows the operator to interact with the system, the scheduling algorithm,\nand the semi-autonomous UVs which act in the environment, all with information\nflowing between components. It should be noted that the scheduling algorithm could\nexist as a stand-alone component, as pictured, or as sub-system of each UV, as in\nmany decentralized systems [44, 76].\n\nIn the development of any complex system, the definition of requirements is a fun-\ndamental step in the systems engineering process [12]. While others have attempted\nto develop requirements for the graphical interfaces in human-automation collabora-\ntion [23, 37, 44, 67], few have attempted to develop requirements for the scheduling\nalgorithms to be used in such systems.\n\n3.3.2 Candidate Methods in Human-Automation\nCollaborative Scheduling\n\nA survey of 117 publications within academia and industry on multiple UV schedul-\ning algorithms was completed in order to determine the types and frequency of\nscheduling algorithms that are currently in use, and to classify the characteristics\nand capabilities of these algorithms [19]. The survey spanned the years 2006-2011,\nin order to emphasizewhat is currently in use or in development [19]. Papers included\nin the survey were chosen based on searching for resource allocation or scheduling\nalgorithms specifically meant for assigning tasks to multiple UVs in real-time.\n\nA brief summary of the results is presented here to identify the primary algorithms\nthat are available for use in human-automation collaborative scheduling systems and\nhighlight the areas where more research is necessary to enhance the capabilities of\nsuch systems.\n\nWe began by examining the methods chosen for solving the combinatorial opti-\nmization problem and the guarantees of optimality made by these methods. Among\n\n\n\n3 Aircraft Autonomy 95\n\nthe typical nonlinear optimization search methods, meta-heuristic methods and\nmarket-based auction algorithms were the most popular technique to solve a vari-\nety of scheduling problems. Also, Dynamic Vehicle Routing (DVR) methods using\nVoronoi partitions were identified as a potential solutionmethod that could guarantee\na certain level of performance without the need to re-plan constantly in a dynamic\nenvironment. DVRmethods produce policies or decision rules, as opposed to specific\ntask assignments, typically by optimizing the expected value of performance.\n\nNon-deterministic scheduling algorithms, while potentially sub-optimal, have\nfaster computational times and scale better to larger problems. Thus, meta-heuristic\nand auction-based algorithms can provide a good balance of performance and compu-\ntational speed for larger missions. Branch and bound or other \u201citerative\u201d approaches\nthat monotonically improve the schedule with further iterations favor smaller num-\nbers of vehicles and tasks. Thus, deterministic algorithms, which do not necessarily\nscale well to larger problems, are adequate for simpler missions. These algorithms\nare likely also easier to certify for systems that must operate with real vehicles.\n\nIn general, more centralized algorithms have been developed than decentralized\nones, but interest has increased recently in decentralized algorithms for their potential\nability to scale to larger problems, reduce communication bandwidth, and maintain\nrobustness to single node failure [41]. Algorithm developers are also shifting their\nfocus towards methods that have the capability to schedule tasks for heterogeneous\nUVs in order to support cooperation between air, land, and seaUVoperations. Finally,\nthere is growing interest in algorithms which can take into account uncertainty, espe-\ncially algorithms designed for generating robust schedules and providing estimates\nof the certainty of the schedule. This class of algorithms will be essential for success-\nful operations in dynamic environments with new tasks emerging, changing weather,\nand potential UV failures.\n\n3.3.3 Technical Enhancements needed for Humans\nInteractions with Scheduling Algorithms\n\nIn comparison to the extensive literature on developing scheduling algorithms for\nmultiple UV control, there is relatively little research on human interaction with\nthese planners. Caves [17] demonstrated that humans guiding a Rapidly-Exploring\nRandom Tree (RRT) algorithm in the development of paths for multiple UVs could\ndecrease time to solution; however, operators had difficulty understanding the con-\nstraints that such algorithms would impose on physical paths. Forest et al. [37, 69],\nfound that operators working with a human-guided algorithm to create a pre-mission\nschedule for multiple UVs gave the highest subjective ratings to the interface where\nthey had the most control of the objective function of the algorithm. Clare et al. [20]\nfound a similar result in an experiment where operators were allowed to modify the\nobjective function of a real-time decentralized scheduling algorithm throughout a\nmission. While overall system performance did not change, operators had increased\n\n\n\n96 P. Miotto et al.\n\ntrust and acceptance of the planner [20].Hanson et al. [43] found that humanoperators\npaired with an algorithm for scheduling multiple UVs desired a greater understand-\ning of why the algorithmmade certain recommendations. Miller et al. [51] developed\nthe Playbook\u2122 human-automation integration architecture, which identified a set of\ncommon tasks performed by semi-autonomous UVs, grouped them into \u201cplays\u201d, and\nprovided the operator with a set of play templates to utilize. Cummings et al. [26]\ndemonstrated that when humans are allowed to coach a decentralized multiple UV\nscheduler, overall system performance can improve up to 50% as compared to an\nunassisted planner. Ryan [63] has shown that when coupled with human expert rea-\nsoning, an integer linear programming algorithm can produce superior schedules for\nmultiple manned and unmanned vehicles as compared to just the algorithm alone.\n\nFrom this sparse literature, as well as more literature on human interaction with\nalgorithms in other domains like transportation planning [3, 67], space satellite\nscheduling [26], and industrial process control [17, 41], five challenges have been\nidentified in understanding how to best design automated schedulers in order to\ncapitalize on the strengths of human induction and judgment, which are critical in\nresolving uncertainty in dynamic environments.\n\nEmergent Behaviors:\n\nWhile near-optimal algorithms have obvious performance benefits, the emergent\nbehavior of an algorithm is a significant concern when pairing a human operator\nwith a scheduling algorithm. An open question is how human operators react to the\nunpredictability of working with these types of algorithms, where the algorithm\u2019s\nbehavior is non-deterministic. Caves [17] showed that operators can become quickly\nfrustrated with such an approach to the detriment of overall performance.\n\nA prime concern for any human operator collaborating with a scheduling algo-\nrithm is gaining a sufficient understanding of how the algorithm created the solu-\ntion [57]. Increasing automation transparency may be difficult with the use of prob-\nabilistic, meta-heuristic and auction algorithms, whereas deterministic solvers such\nas greedy algorithms often emulate the method by which humans would choose to\nsolve the problem [9]. Would a human operator collaborating with an \u201cinferior\u201d, but\nunderstandable algorithm perform better than a human operator collaborating with\na more \u201cadvanced\u201d but less predictable and more opaque algorithm? More research\nis needed into how well human operators can understand the method by which the\nalgorithm reached its solution.\n\nBehavior Modeling:\n\nComputationalmodels of humanbehaviorwhencollaboratingwith advanced schedul-\ning algorithms are needed. In contrast to purely theoretical or conceptual models,\nthese models typically leverage computer simulations to both promote deeper under-\nstanding of how human operators behave and provide testable predictions about\nhuman behavior under different circumstances [38]. These models could be used by\ndesigners of future UV systems to predict the relative impact of different algorithm\narchitectures, human-automation collaborative strategies, and training methods on\nsystem performance, saving time and money in the design process. It is also possible\n\n\n\n3 Aircraft Autonomy 97\n\nthat these models could help to generate a set of recommendations for the developers\nof scheduling algorithms, based on model predictions of which algorithm character-\nistics have the greatest positive impact on the collaborative scheduling process.\n\nOperator Situation Awareness:\n\nIn a human-automation collaborative scheduling system, a central node is necessary\nfor a human operator to maintain situation awareness. It remains an open question\nwhether decentralized algorithms maintain their proposed advantages over central-\nized algorithms when used by a human operator due to the need for a centrally\nconnected node. While decentralized systems may be capable of continuing a mis-\nsion even with a communication interruption, the need for consistent updates to the\nhuman operator and the need for approval for major schedule changes or critical\nevents such as weapons release from the operator may negate some of the proposed\nadvantages of decentralized algorithms.\n\nTrusted Autonomy:\n\nHuman trust in the algorithm is a crucial driver of performance in ahuman-automation\ncollaborative scheduling system [21]. Human trust in the algorithm can fluctuate due\nboth to the operator\u2019s initial trust level in the algorithm and the behavior of the\nalgorithm throughout the mission [38]. Providing operators with certainty estimates\ncould be beneficial to both system performance [11] and developing appropriate\ntrust [48] between the operator and scheduling algorithm. Further research is neces-\nsary into human trust in advanced scheduling algorithms and how different methods\nof displaying algorithm certainty estimates impact the operator\u2019s ability to effectively\nmake decisions under time pressure.\n\nVehicle Health Monitoring:\n\nWhenmonitoringmultipleUVs, the need to assess the health and status of the vehicles\ndrives much of the operator\u2019s workload. Health monitoring is a very significant\nproblem for single operator control of multiple UVs and even with highly automated\nvehiclesmaydriveworkload to unacceptably high levels [21].More highly automated\nhealth monitoring, error detection, and self-repair algorithms are necessary before\nsingle operator control of multiple UVs becomes feasible.\n\n3.3.4 Conclusions\n\nThe goal of this effort is to begin to identify algorithm characteristics that could sup-\nport real-time human-automation collaborative schedule creation for multiple UVs\nin uncertain environments. While some algorithms may provide optimal schedules\nalmost instantaneously, an algorithm may lack certain characteristics that are essen-\ntial for effective human-automation collaboration. Our goal is to analyze how these\nscheduling algorithms can successfully be paired with a human operator to operate\nin real-world scenarios.\n\n\n\n98 P. Miotto et al.\n\nWe have highlighted five critical areas that should be considered when teaming an\nautomated scheduler with a human operator. Most importantly, the human represents\na source of information that can resolve uncertainty for many schedulers and should\nbe treated as a core system component who adds value to the solution quality instead\nof simply approving it.\n\nFinally, a systems-level significant issue not specifically addressed by exam-\nining human or algorithm attributes is the regulatory aspect of the adoption of\nnon-deterministic algorithms for UV scheduling [72]. How does one certify that\nan algorithm with no guarantee of repeatability is safe or ready for deployment in\nsafety critical missions? While some have begun to propose methods of perform-\ning V&V on advanced autonomy [5], further work is necessary before the military\nand the Federal Aviation Administration (FAA) will certify advanced autonomy for\nreal-world operations.\n\n3.4 Autonomy Evolution for Air Traffic Control\n\nAir TrafficControl (ATC) operations began in 1936with fifteen controllersmanaging\nflights across US airspace to ensure that aircraft were not on conflicting routes. At\nthat time, air traffic controllers managed flights by contacting airline dispatchers\nto get information about aircraft locations and routes because radar surveillance\nsystems were not yet in place [1]. ATC operations continued to evolve over the next\nseveral decades to meet increasing levels of air traffic and enabled by advances in\ncommunication, navigation and surveillance (CNS) systems. For several decades a\nground-based radar surveillance system has provided air traffic controllers with the\nnecessary information (e.g., position, velocity, and flight-plan data) to safely separate\nand manage flights across the National Airspace System (NAS). Advances in flight\ncontrol systems (FCS) on the aircraft have also evolved to better help pilots manage\ntheir aircraft in a safe and efficientmanner. For example, FlightManagement Systems\n(FMSs) are able to compute precise trajectories that optimize for fuel use and flight\ntime as a function of aircraft weight and predicted wind conditions [70].\n\nAdvances in CNS systems are continuing today with the development of some\nkey technologies, such as Controller-Pilot Datalink Communications (CPDLC),\nglobal navigation satellite systems (GNSS), and Automatic Dependent Surveillance-\nBroadcast (ADS-B). CPDLC is a text-based system that alleviates congestion on\nvoice frequencies and is expected to reduce errors in interpreting voice-based com-\nmunications between air traffic controllers and pilots. GNSS receivers on-board air-\ncraft allow for more precise navigation in the airspace, eliminating the dependence\non ground-based navigation aids that have previously constrained aircraft to cer-\ntain routes. ADS-B is a key component technology in the modernization of US and\nEuropean ATC operations. ADS-B transmitters on-board an aircraft will transmit the\naircraft\u2019s position and velocity, derived from aGNSS, for use by air traffic controllers\nand ground-based automation systems. Additionally, aircraft that are equipped with\nADS-B receiverswill receiveADS-Bmessages fromother aircraft in the surrounding\n\n\n\n3 Aircraft Autonomy 99\n\nairspace enabling the development of avionics that leverage the increased situation\nawareness in the cockpit [32].\n\n3.4.1 Challenges and Limitations of Current Air Traffic\nManagement System\n\nDespite the continued advancement of key technologies on the ground and on the\nflight deck intended to increase safety and efficiency, ATC operations remain human\ncentric with air traffic controllers ultimately providing oversight and direction to\npilots to safely manage flights and avoid conflicts in the airspace. Whereas new\ntechnologies enable increased automation in ground-support tools for air traffic con-\ntrollers and in flight-deck systems for pilots, the humans in each of those domains\nmust be provided with sufficient information to accurately assess a situation and take\naction if necessary [65]. Overriding safety objectives prevent excessive reliance on\nautomation alone in a system with many uncertainties, such as weather, differences\nin aircraft performance, and the potential for automation failures. The Air France\n447 accident is one example of human error due to an over-reliance on flight-deck\nautomation and the information provided by the automation [7].\n\nThe Federal Aviation Administration\u2019s NextGen and Europe\u2019s SESAR (Single\nEuropean Sky ATM Research) programs are efforts to transform and modernize\nUS and European air traffic management operations, respectively, to meet increas-\ning air traffic demands with traffic levels forecasted to double in the next twenty\nyears [33]. Increasing traffic demands will be addressed by developing new ATC\noperational concepts that leverage advanced CNS technologies while also improv-\ning safety and efficiency for aircraft operators. In the US, there are several ongoing\nefforts to improve ground automation to help air traffic controllers more efficiently\nmanage flows of aircraft, and there are efforts to improve flight-deck technologies to\nenable the reallocation of air-traffic-controller tasks to the airborne domain.\n\n3.4.2 Enhancements Made Within ATC System\n\nThe Time-based Flow Management (TBFM) program is one effort to improve\ndecision-support tools for air traffic controllers during metering operations, where\naircraft are being managed to meet a Scheduled Time of Arrival (STA) at a desig-\nnated point in the airspace [31]. Metering operations are typically used when traffic\ndensity reaches a level that operations are constrained by airspace capacity, and\nthe STAs help ensure a consistent flow of traffic through the airspace. The ground-\nbased automation generates a sequence and schedule of aircraft in the airspace using\ntrajectory-modeling and scheduling algorithms, and the air traffic controller is pro-\nvided with the amount of time that each flight must be delayed or make up to meet its\n\n\n\n100 P. Miotto et al.\n\nSTA. The air traffic controller would then employ various techniques (e.g., issuing\nspeed changes or path modifications) for each aircraft to meet their STAs. However,\nuncertainties in the environment, such as convective weather, may cause significant\nerrors in trajectory modeling and other functions causing air traffic controllers to\nrevert to less efficient modes of operation (e.g., placing flights in holding patterns).\nProposed enhancements to ground-based automation include 3D-Path Arrival Man-\nagement (3D-PAM), developed by the National Aeronautics and Space Administra-\ntion (NASA), which adds the calculation of speed and path-stretching advisories for\naircraft to more precisely meet their STAs while reducing air-traffic-controller work-\nload [22]. In the proposed 3D-PAM concept, the ground-automation still provides\nthe speed and path-stretching advisories to the air traffic controller to communicate\nto the pilots, keeping the air traffic controller in the loop.\n\nSeveral flight-deck enhancements have been proposed to enable the allocation of\nsome tasks to the pilot. Currently, some aircraft are equipped with a Required Time\nof Arrival (RTA) functionality in the FMS that determines the speeds and the vertical\nprofile that the aircraft should fly to meet an ATC-provided STA at a point [6]. In\nthat case, the management of the aircraft\u2019s speeds to meet an overall operational\nobjective is allocated to the airborne domain (i.e., the pilot and the avionics). The\nInterval Management (IM) concept is another flight-deck concept that uses avionics\nto help the flight crew achieve and maintain a spacing interval (in distance or time)\nrelative to an ATC-specified target aircraft [35, 62]. The IM avionics rely on ADS-\nB technology to receive the target aircraft\u2019s state information. Other flight-deck\nconcepts, enabled by the information provided by ADS-B, have explored the use\nof a Cockpit-Display of Traffic Information (CDTI) to increase the flight crew\u2019s\nawareness of surrounding traffic and to provide guidance to support the flight crew\u2019s\nsafe and efficient management of the aircraft [13, 30, 52].\n\nThe 3D-PAM, RTA, and IM concepts may all be used to address a similar opera-\ntional objective: provide precise and consistent delivery of aircraft to a point (e.g., the\nterminal boundary). However, the control objectives and task allocations are different\nfor the three concepts, as shown in Table3.1. In each case, the overall operational\nobjective is managed by the ground domain (i.e., the air traffic controller with sup-\nporting ground automation), and some tasksmay be allocated to the airborne domain.\n\nTable 3.1 Task allocation and control objectives of flight deck enhancements\n\nConcept Control objective Task allocation\n\n3D-PAM Meet STA at a point Speeds calculated by ground automation and\ncommunicated to pilot by air traffic controller\n\nRTA Meet STA at a point STA provided to pilot by air traffic controller; speeds\n(and vertical trajectory, if necessary) calculated by\navionics\n\nIM Achieve spacing interval\nrelative to target aircraft\n\nTarget aircraft and relative spacing interval provided to\npilot by air traffic controller; speeds calculated by\navionics\n\n\n\n3 Aircraft Autonomy 101\n\nFurthermore, in the IM concept, the spacing is relative to a target aircraft resulting\nin a decentralized control solution, which is in contrast to the RTA concept where an\naircraft meets its STAs independently of how the preceding aircraft meets its STA.\nWhereas the IM concept must address issues with string stability [73], that is not a\nconcern for the 3D-PAM and RTA concepts.\n\n3.4.3 Technical Enhancements needed in the Evolution\nof Airborne and Ground-Based Technologies\n\nThere are several challenges that must be addressed as a part of the ATC operational\nand technological evolution, including:\n\n1. the determination of the appropriate allocation of tasks between the ground\ndomain (i.e., air traffic controllers and supporting ground automation) and the\nairborne domain (i.e., pilots and supporting avionics);\n\n2. themethods to synchronize informationbetween thegroundandairbornedomains;\n3. the approach to managing mixed-equipage operations;\n4. and, the provision of necessary and sufficient information to the human operators\n\nto ensure situational awareness.\n\nThese challenges are not independent of each other, and as will be demonstrated\nhere, the investigation of one challenge may inform another.\n\nTask Allocation Strategies:\n\nAs previously described, advances in CNS systems and flight-deck automation will\nenable some tasks to be allocated to the aircraft that were previously managed by\nair traffic controllers. For example, in the IM concept, the controller could identify\na target aircraft and request that an appropriately-equipped aircraft follow the target\naircraft with a 90second spacing interval. The flight crewwould enter the appropriate\ninformation into the avionics and would ensure that the guidance is followed to\nachieve and maintain a 90second spacing relative to its target aircraft. In this case,\nthe air traffic controller still identifies the overall operational objective: to ensure\nconsistent and precise spacing between aircraft; however, the management of the\nspacing relative to the target aircraft, which is one component of the overall objective,\nwould be the responsibility of the flight crew. There are several different proposed\nconcepts currently under development by the FAA, and in some of these concepts,\nthe task allocation remains much as it is today, with controllers leveraging decision-\nsupport tools to manage traffic. In other concepts, such as IM, tasks are reallocated\nbecause it is believed that improved flight-deck automation will enable more efficient\noperations.\n\nInformation Synchronisation:\n\nA major challenge that must be addressed is the synchronization of information used\nby the airborne and ground domains. Inconsistent information used by the flight-deck\n\n\n\n102 P. Miotto et al.\n\nand ground automation may lead to inconsistent or unexpected behavior, which will\nlikely limit the usability of automation systems and will lead to distrust by human\noperators. For example, inconsistencies in the wind information used to model air-\ncraft trajectories can lead to significant differences in trajectory times. In RTA flight\ntrials, the ground automation modeled trajectory times to determine feasible STAs\nfor aircraft entering terminal airspace. In the RTA operation, the air traffic controller\nprovided a ground-derived STA to a flight crew, and the flight crew entered the STA\ninto the RTA function in the FMS. In some cases, inconsistencies between the wind\ninformation in the ground automation and in the avionics resulted in the avionics\ndeclaring the STA to be infeasible because the required speeds were outside of the\naircraft\u2019s performance envelope [34]. Reference [18] describes a proposedmethod for\nsynchronizing aircraft trajectories between the airborne and ground domains, lever-\naging CPDLC and ADS-C technologies, to ensure consistent trajectory predictions.\n\nMixed Equipage Operations:\n\nAvionics standards that support NextGen operations, such as theRTAor IMconcepts,\nare currently being developed. However, there is no mandate for airline operators\nto equip their fleets with more advanced flight-deck systems. Without a mandate,\nequipage is driven by economic incentives; and therefore, it is expected, for the\nforeseeable future, that air traffic operations will consist of a mix of aircraft: some\nthat are equipped with avionics to support applications like RTA or IM and some\nthat are not. In mixed-equipage operations, the air traffic controllers will need to\nknow the equipage capabilities of the different aircraft in order to provide appropriate\ninstructions (e.g., provide anSTA to anRTA-equipped aircraft and a target aircraft and\nrelative spacing interval to an IM-equipped aircraft). Furthermore, the combination of\ndifferent applications within a single operation, in order to best leverage the available\naircraft equipage, must be studied to understand any adverse effects that may arise\nwhen combining different concepts. Reference [74] presents some considerations for\na mixed-equipage IM operation, where some aircraft are equipped with IM avionics\nand other aircraft are managed by supporting ground automation. Whereas aircraft\nthat are equipped with IM avionics will implement speeds relative to a target aircraft\nto support the overall operational objective, the air traffic controller will provide\nspeeds, calculated by the ground automation, to unequipped aircraft to meet STAs\nat a point. Therefore, the mixed-equipage operation combines two different spacing\nconcepts: relative spacing (i.e., spacing relative to a target aircraft) and absolute\nspacing (i.e., spacing to an absolute time at a point in space), and performance\ndifferences in the two concepts can result in unexpected behavior in the combined\noperation that should be accounted for in the ground automation or in procedures\nthat the air traffic controllers follow.\n\nOperator Situational Awareness:\n\nThe information needs of the human operators to accurately assess the state of the\noperation are a major part of the research for any new ATC operational concept.\nAir-traffic-controller and pilot inputs remain a significant part of the entire research\nand development process of any new concept. Feedback from the human operators,\n\n\n\n3 Aircraft Autonomy 103\n\ne.g., through human-in-the-loop simulations and fields tests, helps to determine what\ninformation must be displayed to the human to ensure that the guidance provided by\nthe ground automation or the avionics is appropriate and will not adversely affect the\nsafety of the operation. Keeping the human in the loop (i.e., the air traffic controller\nor the pilot) provides an added level of safety to ensure that uncertainties that result\nin unacceptable guidance will not get passed on to the aircraft.\n\n3.4.4 Conclusions and Proposed Road-Map\n\nA road-map is proposed for the evolution of ATC operations and the evolution of\nsupporting ground and flight-deck automation.\n\nStep 1 Develop and select concepts to address different airspace objectives (e.g.,\nprovide a consistent flow of aircraft into terminal airspace or precisely space\naircraft at the runway threshold).\nBecause of differences in traffic demand, airspace design, and weather con-\nditions across the US NAS, some ATC operational concepts may be better\nsuited to address certain airspace objectives than others (i.e., one concept\nmay not be suitable for all operations). Furthermore, a number of concepts\nmay be combined to best leverage the expected variation in aircraft equipage.\n\nStep 2 Evaluate the mixed-equipage operation to identify challenges in combining\ndifferent concepts that could require different aircraft equipage.\nThe identified challenges in the mixed-equipage operation may be addressed\nthrough improvements or enhancements in the ground automation or through\nprocedures, to support the air traffic controller\u2019s management of the opera-\ntion, or through modifications to the avionics.\n\nStep 3 Define steps in the evolution from today\u2019s operation to the proposed opera-\ntion.\nIntermediate steps in the evolution of the operational concept, where the\nground automation is providing increasing levels of information and the\nflight-deck avionics is providing guidance for situationswith increasing com-\nplexity, may help the human operators to trust the automation.\n\nStep 4 Conduct operational evaluation throughout the evolution from today\u2019s oper-\nation to the final, proposed operation.\nThe operational evaluation would be comprised of data gathering to:\n\n(I) evaluate the effectiveness of the ground automation and the avionics,\nespecially in the presence of uncertainties such as weather;\n\n(II) evaluate the effectiveness of the information provided to the human\noperators to aid in their assessments of the operation.\n\nThis proposed road-map seeks to address the challenges identified in the previous\nsection, while acknowledging the challenges of increasing the role of automation in\na human-centric system. Hesitation to take the human out of the loop in air traffic\n\n\n\n104 P. Miotto et al.\n\noperations does, in fact, slow the evolution to higher levels of autonomy. However,\nwe must ask whether traffic demands, as well as safety and efficiency goals, can be\nreached without complete autonomy in the foreseeable future.\n\nReferences\n\n1. At 75, America\u2019s air traffic control system keeps getting better. http://fastlane.dot.gov/2011/\n07/air-traffic-control-at-75.html (2011)\n\n2. Alighanbari, M., How, J.: Robust decentralized task assignment for cooperative UAVs. In:\nAIAA Conference on Guidance, Navigation, and Control Conference, Keystone, CO, pp. 21\u2013\n24 (2006)\n\n3. Anderson, D., Anderson, E., Lesh, N., Marks, J., Mirtich, B., Ratajczak, D., Ryall, K.: Human-\nguided simple search. In: AAAI/IAAI, pp. 209\u2013216 (2000)\n\n4. Atkins, E.M.: The benefits and risks of increased autonomy in air and space systems. In: 9th\nGerman-American Frontiers of Engineering Symposium (2006)\n\n5. Atkins, E.M.: Intelligent systems for unmanned aircraft safety certification. In: AIAA\nAerospace Sciences Meeting, Nashville, TN (2012)\n\n6. Balaskrishna, M., Becher, T., MacWilliams, P., Klooster, J., Kuiper, W., Smith, P.: Seattle\nrequired time of arrival flight trials. In: Proceedings of the 30th Digital Avionics Systems\nConference, Seattle, WA, p. 2D4-1 (2011)\n\n7. BEA: Final Report: On the accident on 1st June 2009 to the Airbus A330\u2013203 registered F-\nGZCP operated by Air France flight AF 447 Rio de Janeiro-Paris. Technical report, Bureau\nd\u2019Enqu\u00eates et d\u2019Analyses pour la S\u00e9curit\u00e9 de l\u2019Aviation Civile (2012)\n\n8. Bellingham, J., Richards, A., How, J.P.: Receding horizon control of autonomous aerial vehi-\ncles. In: American Control Conference, 2002. Proceedings of the 2002, vol. 5, pp. 3741\u20133746.\nIEEE (2002)\n\n9. Bertuccelli, L., Beckers, N., Cummings, M.L.: Developing operator models for UAV search\nscheduling. In: AIAA Conference on Guidance Navigation, and Control Conference, Toronto,\nCanada (2010)\n\n10. Bertuccelli, L.F., Choi,H.L., Cho, P.,How, J.: Real-timemulti-UAV task assignment in dynamic\nand uncertain environments. In: AIAA Conference on Guidance, Navigation, and Control,\nChicago, IL (2009)\n\n11. Bisantz, A.M., Cao, D., Jenkins, M., Pennathur, P.R., Farry, M., Roth, E., Potter, S.S., Pfautz,\nJ.: Comparing uncertainty visualizations for a dynamic decision-making task. J. Cogn. Eng.\nDecis. Mak. 5(3), 277\u2013293 (2011)\n\n12. Blanchard, B.S., Fabrycky, W.J.: Systems Engineering and Analysis, 3rd edn. Prentice Hall,\nUpper Saddle River (1998)\n\n13. Bone,R.: Cockpit display of traffic information (CDTI) assisted visual separation (CAVS): Pilot\nacceptability of a spacing task during a visual approach. In: Proceedings of the 6thUSA/Europe\nAir Traffic Management Research and Development Seminar, Baltimore, MD, vol. 122 (2005)\n\n14. Butterworth-Hayes, P.: Conversations with Patrick Ky. Aerosp. Am. (2012)\n15. Butterworth-Hayes, P.: A long road for UAS integration in Europe. Aerosp. Am. (2012)\n16. Casbeer, D.W., Kingston, D.B., Beard, A.W., Mclain, T.W., Li, S.M., Mehra, R.: Cooperative\n\nforest fire surveillance using a team of small unmanned air vehicles. Int. J. Syst. Sci. 37, 360\n(2006)\n\n17. Caves, A.: Human-automation collaborative RRT for UAV mission path planning. Technical\nreport, Massachusetts Institute of Technology (2010)\n\n18. Chan, D.S.K., Brooksby, G.W., Hochwarth, J., Klooster, J.K., Torres, S.: Air-ground trajectory\nsynchronization? metrics and simulation results. In: Proceedings of the 30th Digital Avionics\nSystems Conference, Seattle, WA (2011)\n\nhttp://fastlane.dot.gov/2011/07/air-traffic-control-at-75.html\nhttp://fastlane.dot.gov/2011/07/air-traffic-control-at-75.html\n\n\n3 Aircraft Autonomy 105\n\n19. Clare, A.S., Cummings, M.L., Bertuccelli, L.F.: Identifying suitable algorithms for human-\ncomputer collaborative scheduling of multiple unmanned vehicles. In: AIAA Aerospace Sci-\nences Meeting (2012)\n\n20. Clare, A.S., Cummings, M.L., How, J.P., Whitten, A.K., Toupet, O.: Operator object function\nguidance for a real-time unmanned vehicle scheduling algorithm. J. Aerosp. Comput. Inf.\nCommun. 9(4), 161\u2013173 (2012)\n\n21. Clare, A.S., Macbeth, J.C., Cummings, M.L.: Mixed-initiative strategies for real-time schedul-\ning of multiple unmanned vehicles. In: American Control Conference, 2012. Proceedings of\nthe 2012, pp. 676\u2013682. IEEE (2012)\n\n22. Coppenbarger, R., Dyer, G., Hayashi, M., Lanier, R., Stell, L., Sweet, D.: Development and\ntesting for efficient arrivals in constrained airspace. In: Proceedings of the 27th International\nCouncil of the Aeronautical Sciences, Nice, France (2010)\n\n23. Cummings, M.L., Bruni, S.: Collaborative human-automation decision making. In: Handbook\nof Automation LXXVI, pp. 437\u2013448. Springer (2009)\n\n24. Cummings, M.L., Bruni, S., Mercier, S., Mitchell, P.J.: Automation architecture for single\noperator, multiple UAV command and control. Int. Command. Control. J. 1(2), 1\u201324 (2007)\n\n25. Cummings, M.L., Clare, A.S., Hart, C.S.: The role of human-automation consensus in multiple\nunmanned vehicle scheduling. Hum. Factors 52(1), 17\u201327 (2010)\n\n26. Cummings, M.L., How, J., Whitten, A., Toupet, O.: The impact of human-automation col-\nlaboration in decentralized multiple unmanned vehicle control. Proc. IEEE 100(3), 660\u2013671\n(2012)\n\n27. Cummings, M.L., Thornburg, K.T.: Paying attention to the man behind the curtain. IEEE\nPervasive Comput. 10(1), 58\u201362 (2011)\n\n28. DoD: Unmanned aircraft systems (UAS) roadmap, 2005\u20132030. Technical report, Office of the\nSecretary of Defense (2005)\n\n29. DoD:Unmanned aircraft systems roadmap2011\u20132036.Technical report,Office of theSecretary\nof Defense (2011)\n\n30. Domino, D.A., Tuomey, D.,Mundra, A., Smith, A.: Air ground collaboration through delegated\nseparation: Application for departures and arrivals. In: Integrated Communications Navigation\nand Surveillance Conference (ICNS), 2010, pp. G5\u20131. IEEE (2010)\n\n31. Federal Aviation Administration: Concept of use for time-based flow management (TBFM).\nTechnical report, United States Department of Transportation (2009)\n\n32. Federal Aviation Administration: Airworthiness approval of automation dependent\nsurveillance-broadcast (ADS-B) out systems (advisory circular 20\u2013165). Technical report,\nUnited States Department of Transportation (2010)\n\n33. Federal Aviation Administration: FAA aerospace forecast: Fiscal years 2011\u20132031. Technical\nreport, United States Department of Transportation (2011)\n\n34. Federal Aviation Administration: Flight trials assessment for 4 dimensional flight management\nsystem trajectory based operations. Technical report, United States Department of Transporta-\ntion (2011)\n\n35. Federal Aviation Administration: Arrival interval management\u2014spacing (IM-s) concept of\noperations for the mid-term timeframe, version 3. Technical report, United States Department\nof Transportation (2012)\n\n36. Finnegan, P.: UAV sector faces sweeping changes. Aerosp. Am. (2012)\n37. Forest, L.M., Kahn, A., Thomer, J., Shapiro, M.: The design and evaluation of human-guided\n\nalgorithms for mission planning. In: Human Systems Integration Symposium (2007)\n38. Gao, J., Lee, J.D.: Extending the decision field theory to model operators? reliance on automa-\n\ntion in supervisory control situations. IEEE Trans. Syst. Man and Cybern.\u2014Part A: Syst. Hum.\n36(5), 943\u2013959 (2006)\n\n39. Girard, A.R., Hedrick, J.K.: Border patrol and surveillance missions using multiple unmanned\nair vehicles. In: Proceedings of the IEEE Conference on Decision and Control (2004)\n\n40. Guerlain, S.A.: Using the critiquing approach to cope with brittle expert systems. In: Human\nFactors and Ergonomics Society 39th Annual Meeting (1995)\n\n\n\n106 P. Miotto et al.\n\n41. Choi, H.-L.: Consensus-based decentralized auctions for robust task allocation. IEEE Trans.\nRobot. 25(4), 912\u2013926 (2009)\n\n42. Haddal,C.C.,Gertler, J.:Homeland security:Unmannedaerial vehicles andborder surveillance.\nTechnical report, Congressional Research Service (2010)\n\n43. Hanson, M.L., Roth, E., Hopkins, C.M., Mancuso, V.: Developing mixed-initiative interac-\ntion with intelligent systems: Lessons learned from supervising multiple UAVs. In: AIAA 1st\nIntelligent Systems Technical Conference (2004)\n\n44. How, J.P., Fraser, C., Kulling, K.C., Bertuccelli, L.F., Toupet, O., Brunet, L., Bachrach, A.,\nRoy, N.: Increasing autonomy of UAVs. IEEE Robot. Autom. Mag. 16(2), 43\u201351 (2009)\n\n45. Johnson, K., Ren, L., Kuchar, J.K., Oman, C.M.: Interaction of automation and time pressure\nin a route replanning task, In: International Conference on Human-Computer Interaction in\nAeronautics (HCI-Aero) (2002)\n\n46. Keller, J.: Air Force looks for machine autonomy to enable UAVs and piloted aircraft to work\nand play well together. Mil. Aerosp. Electron. (2010)\n\n47. Layton, C., Smith, P.J., McCoy, C.E.: Design of a cooperative problem-solving system for\nen-route flight planning\u2014an empirical evaluation. Hum. Factors 36(1), 94\u2013116 (1994)\n\n48. Lee, J.D., See, K.A.: Trust in automation: designing for appropriate reliance. Hum. Factors\n46(1), 50\u201380 (2004)\n\n49. Malasky, J., Forest, L.M., Kahn, A.C., Key, J.R.: Experimental evaluation of human-machine\ncollaborative algorithms in planning for multiple UAVs. In: Systems, Man and Cybernetics,\n2005 IEEE International Conference on, vol. 3, pp. 2469\u20132475. IEEE (2005)\n\n50. Marquez, J.J.: Human-automation collaboration: decision support for lunar and planetary\nexploration. Technical report, Massachusetts Institute of Technology (2007)\n\n51. Miller, C., Funk, H.,Wu, P., Goldman, R.,Meisner, J., Chapman,M.: The playbook approach to\nadaptive automation. In: Human Factors and Ergonomics Society 49th Annual Meeting (2005)\n\n52. Mundra, A., Cooper, W., Smith, A., Audenaerd, L., Lunsford, C.: Potential benefits of a paired\napproach procedure to closely spacing parallel runways in instrument and marginal visual\nconditions. In: Proceedings of the 27th Digital Avionics Systems Conference, St Paul, MN\n(2008)\n\n53. National Research Council: Autonomy Research for Civil Aviation: Toward a New Era of\nFlight. The National Academies Press, Washington (2014)\n\n54. National Safety Board: Autonomous vehicles in support of naval operations. Technical report,\nNational Research Council (2005)\n\n55. Norris, J., Powell, M., Vona, M., Backes, P., Wick, J.: Mars exploration rover operations with\nthe science activity planner. In: Proceedings of the 2005 IEEE International Conference on\nRobotics and Automation, pp. 4618\u20134623 (2005)\n\n56. Odedra, S., Prior, S.D., Karamanoglu, M.: Investigating the mobility of unmanned ground\nvehicles. In: International Conference on Manufacturing and Engineering Systems (2009)\n\n57. Parasuraman, R., Riley, V.: Humans and automation: use, misuse, disuse, abuse. Hum. Factors:\nJ. Hum. Factors Ergon. Soc. 39(2), 230\u2013253 (1997)\n\n58. Polson, P., Smith, N.: The cockpit cognitive walkthrough. In: 10th Symposium on Aviation\nPsychology (1999)\n\n59. Ponda, S., Ahmed, N., Luders, B., Sample, E., Hoossainy, T., Shah, D., Campbell, M., How, J.:\nDecentralized information-rich planning and hybrid sensor fusion for uncertainty reduction in\nhuman-robot missions. In: AIAA Conf. on Guidance, Navigation, and Control, Portland, OR,\npp. 8\u201311 (2011)\n\n60. Rediess, H.A., Garg, S.: Autonomous civil aircraft\u2014the future of aviation?Aerosp. Am. (2006)\n61. Ross, P.E.: When will we have unmanned commercial airliners?. IEEE Spectr. (2011)\n62. RTCA: Safety Performance, and Interoperability Requirements Document for Airborne\n\nSpacing\u2014Flight-Deck Interval Management (ASPA-FIM). RTCA, Washington (2011)\n63. Ryan, J.C.: Assessing the performance of human-automation collaborative planning systems.\n\nTechnical report, Massachusetts Institute of Technology (2011)\n64. Scott, S.D., Lesh, N., Klau, G.W.: Investigating human-computer optimization. In: Proceedings\n\nof the SIGCHI Conference on Human Factors in Computing Systems. CHI \u201902, pp. 155\u2013162.\nACM, New York, NY, USA (2002)\n\n\n\n3 Aircraft Autonomy 107\n\n65. Sheridan, T.B.: Next generation air transportation systems: Human-automation interaction and\norganizational risks. In: Proceedings of the Resilience Engineering Symposium, Antibes-Juan-\nLes-Pins, France (2008)\n\n66. Silverman, B.G.: Human-computer collaboration. Hum.-Comput. Interact. 7(2), 165\u2013196\n(1992)\n\n67. Smith, P., McCoy, E., Layton, C.: Brittleness in the design of cooperative problem-solving\nsystems: the effects on user performance. IEEE Trans. Syst. Man, and Cybern.\u2014Part A, Syst.\nHum. 27(3), 360\u2013371 (1997)\n\n68. Sweeten, B.C., Royer, D., Keshmiri, S.: Meridian UAV flight perfomance anlaysis using ana-\nlytical and experimental data. In: AIAA Infotech@Aerospace Conference, Seattle, WA, vol.\n1899 (2009)\n\n69. Thorner, J.L.: Trust-based design of human-guided algorithms. Technical report,Massachusetts\nInstitute of Technology (2007)\n\n70. Walter, R.: Chapter 15: Flight Management Systems, Chap. 15, pp. 1\u201325. CRC Press, Boca\nRaton (2001)\n\n71. Webster, M., Cameron, N., Jump, M., Fisher, M.: Towards certification of autonomous\nunmanned aircraft using formal model checking and simulation. In: AIAA\nInfotech@Aerospace Conference, Garden Grove, CA (2012)\n\n72. Weibel, R.E., Hansman, R.J.: An integrated approach to evaluating riskmitigationmeasures for\nUAV operational concepts in the NAS. In: AIAA Infotech@Aerospace Conference, Arlington,\nVA (2005)\n\n73. Weitz, L.A., Hurtado, J.E.: String stability analysis of selected speed control laws for interval\nmanagement. In: AIAA Conference on Guidance, Navigation, and Control, Minneapolis, MN\n(2012)\n\n74. Weitz, L.A., Katkin, R., Moertl, P., Penhallegon, W.J., Hammer, J.B., Bone, R.S., Peterson,\nT.: Considerations for interval management operations in a mixed-equipage environment. In:\nProceedings of the AIAA Aviation Technology, Integration, and Operations Conference, Indi-\nanapolis, IN (2012)\n\n75. Westwood, J.: Global prospects for AUVs. In: Offshore Technology Conference (2001)\n76. Whitten, A.K.: Decentralized planning for autonomous agents cooperating in complex mis-\n\nsions. Technical report, Massachusetts Institute of Technology (2010)\n\n\n\nChapter 4\nChallenges in Aerospace Decision\nand Control: Air Transportation Systems\n\nHamsa Balakrishnan, John-Paul Clarke, Eric M. Feron,\nR. John Hansman and Hernando Jimenez\n\n4.1 Introduction\n\nThe Next Generation Air Transportation System (NextGen) is the FAA\u2019s vision of\nhow the nation\u2019s aviation system will operate in 2025 and beyond [40]. In 2004, the\nNational Airspace System (NAS) was already operating near capacity, and demand\nwas expected to grow two- to threefold over the following 20 years. The NextGen\ninitiative was established in 2003 in order to meet the challenges presented by the\npredicted increase in demand. It represents a substantial and long-term change in the\nmanagement and operation of the US air transportation system, and involves both the\nleveraging of existing technologies and the development of new ones. This includes\nsatellite-based navigation and control of aircraft, advanced digital communications,\nadvanced infrastructure for greater information sharing, and enhanced connectivity\nbetween all components of the air transportation system. The overarching objectives\nof NextGen are to improve the safety, speed and efficiency, and to mitigate the envi-\nronmental impacts of air transportation, while accommodating increased demand.\n\nH. Balakrishnan (B) \u00b7 R.J. Hansman\nMassachusetts Institute of Technology, Cambridge, MA, USA\ne-mail: hamsa@mit.edu\n\nR.J. Hansman\ne-mail: rjhans@mit.edu\n\nJ.-P. Clarke \u00b7 E.M. Feron \u00b7 H. Jimenez\nGeorgia Institute of Technology, Atlanta, Georgia\ne-mail: johnpaul@gatech.edu\n\nE.M. Feron\ne-mail: feron@gatech.edu\n\nH. Jimenez\ne-mail: hernando.jimenez@asdl.gatech.edu\n\n\u00a9 Springer-Verlag Berlin Heidelberg 2016\nE. Feron (ed.), Advances in Control System Technology\nfor Aerospace Applications, Lecture Notes in Control\nand Information Sciences 460, DOI 10.1007/978-3-662-47694-9_4\n\n109\n\n\n\n110 H. Balakrishnan et al.\n\nThere are similar ongoing efforts in Europe as well, as part of the Single European\nSky Air Traffic Management Research (SESAR) initiative [22].\n\nThe safe and efficient functioning of the air transportation system requires the\nsmooth integration of the technological (which are generally computer-based) and\nphysical elements of the system. This requirement will be even greater in NextGen,\nwith an increase in the level of automation in all parts of the system, ranging from\nthe aircraft themselves, to the ground infrastructure, communication systems, and\nair traffic controller decision support tools. Air transportation is a prime example of\na system with computational as well as physical elements, also known as a Cyber-\nPhysical System (CPS). Research on fundamental CPS issues is therefore critical to\nthe successful development and implementation of next generation air transportation\nsystems worldwide. Recognizing this need, the US National Science Foundation\n(NSF) initiated discussions amongst researchers studying air transportation systems\n[5]. The main objectives of the study were:\n\n\u2022 Identifying key challenges related to the NextGen and its successors.\n\u2022 Determining a logical path from the safety-critical problems faced by NextGen to\na list of fundamental research topics.\n\nIt is worth noting that many of the fundamental research topics in air transporta-\ntion systems are closely related to broader CPS problems, further emphasizing the\nimportance of this research, and the need for developing solutions.\n\n4.2 Key NextGen Topics\n\nThe initial survey of the research community identified nine key topics of discussion,\nas shown below in Fig. 4.1. The topics included the decomposition of the system by\nphases of flight (Airspace Management, and Airport and Terminal-area Operations),\ndecomposition by function (Traffic Flow Management, and Communication, Navi-\ngation and Surveillance), system-level performance concerns (Safety, Interactions\n\nFig. 4.1 The nine key\nNextGen topics that were\nidentified Humans and Automation \n\nAirspace Management \n\nAirport and Terminal Area Ops \n\nTraffic Flow Management \n\nCommunications, Navigation and \nSurveillance Systems \n\nNew Vehicles in the NAS \n\nSafety \n\nMetrics \n\nInternational Operations \n\n2. \n\n3. \n\n4. \n\n5. \n\n6. \n\n7. \n\n1. \n\n8. \n\n9. \n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 111\n\nbetween Humans and Automation, and Metrics), interoperability in an increasingly\nglobal environment (International Operations), and the future challenges that will be\nimposed by the changing face of demand (New Vehicles in the NAS). Because many\ndifferent divisions of the system into such topic areas are possible, similar research\nissues were raised independently in multiple discussion groups: for example, the\nneed for frameworks to assess system risk and vulnerability was seen as a key issue\nin the context of safety, CNS systems, international operations, and the introduction\nof new types of vehicles into the NAS.\n\n4.3 Supporting Technology Research Challenges\n\nEach of the previously-mentioned NextGen topics presents fundamental research\nproblems that need to be tackled. There are many recurring themes, i.e., the same\nresearch problems are critical to several topics. This result is not surprising, and\nit emphasizes the very interconnected nature of air transportation. However, this\nobservation also shows the need to solve the identified research problems in a holistic\nmanner, paying attention to the different elements of the system, in order to obtain\nsolutions that can be implemented in the real world. A bipartite mapping of some of\nthe critical research issues to the NextGen topics is shown in Fig. 4.2.\n\nDesign of automation with graceful degradation modes \n\nMetrics \n\nCommunications, Navigation \nand Surveillance \n\nModels of human operator cognitive complexity \nTheory of single operator-multi process control \n\nDesign and analysis of architectures to support mixed \nhuman- and automation-based decision making \n\nStochastic network models for complex systems \n\nLarge scale, real time, deterministic, \nrobust or stochastic optimization algorithms \n\nHeterogeneous sensor placement, data fusion, and \nassessment of the value of information \n\nMulti-objective, multi-stakeholder optimization frameworks \nSystem architectures that facilitate distributed decision-\n\nmaking; study of incentives for information sharing \n\nFlexible service provision in a large system-of-systems \n\n Risk analysis and robustness in net-centric info. systems \n\nFundamental understanding of wake vortex dynamics \n\nEstimation of resource capacity (accounting for weather, \noperator limitations, vehicle mix, mixed equipage, etc.) \n\nHumans and Automation \n\nAirspace Management \n\nAirport and Terminal Area Ops \n\nTraffic Flow Management \n\nNew Vehicles in the NAS \n\nSafety \n\nInternational \n\nRisk and vulnerability assessment frameworks \n\nDynamics of consensus on metrics and tradeoffs \nMetrics representation at various levels of system \n\nmaturity / level of abstraction \n\nEvaluation of performance and conformance \n\nSafety diagnosis/health monitoring methods for CPS\n\nSystem verification, validation and certification\n\nFig. 4.2 A mapping of research issues (nodes on the left) to NextGen topics (nodes on the right)\n\n\n\n112 H. Balakrishnan et al.\n\nIt is useful to consider the mapping of research problems to NextGen topics using\ndifferent \u201clenses\u201d, each centered on a particular research problem. We now con-\nsider the views through four such \u201clenses\u201d, namely, ones centered on the problems\nof the design of automation with graceful degradation modes, the verification, val-\nidation and certification of aviation systems, the development of large scale, real\ntime, deterministic, robust or stochastic optimization algorithms, and the design of\nmulti-objective, multi-stakeholder optimization frameworks. The objective of the\nfollowing discussions is to describe each research problem, assess its relevance to\nNextGen, discuss its relevance to other or more general cyber-physical systems, and\nfinally, describe ongoing research efforts within the aviation community to solve this\nproblem and the research directions adopted for the same problem in other CPS.\n\n4.3.1 Design of Automation with Graceful Degradation Modes\n\nGraceful degradation is a core concern for NextGen, and is relevant to several of\nthe identified NextGen topics: Humans and Automation, Safety, Airspace Manage-\nment, and CNS (Communication, Navigation and Surveillance). Considering CNS\nand airspace management, a particular challenge arises from hardware breakdowns,\nwhose ability to gracefully degrademay liewith the hardware itself (via some form or\nredundancy), or with a combination of hardware and operations reconfiguration (for\nexample, existing procedures to handle sudden losses of radar coverage, temporary\nairport shutdown such as San Francisco in july 2013, or loss of airspacemanagement,\nsuch as Chicago\u2019s approach control in 2014). Fundamental research topics associated\nwith mitigating such graceful degradation include fault detection and isolation, as\nwell as adaptive control, taken in its most general sense - the sense carried by this\nresearch volume and previously covered in [76].\n\nConsidering humans, automation, and safety, the notion of graceful degradation\nis perceived to be intimately connected with human operators and their interaction\nwith automation. In other terms, the entire human + automation system is considered\nto be degrading, and graceful degradation must be considered with the whole system\nin mind. In the context of safety, graceful degradation is concerned more with a\nnominal human being able to properly handling several machine modes, such as\nnominal or alternative control laws in a jetliner, or handling several aircraft projected\non a computer screen [29].\n\n4.3.2 System Verification and Validation (V&V)\n\nThis broad topic relates to Humans and Automation, Safety, and Communication,\nNavigation, and Surveillance (CNS). In the context of humans and automation, the\nissue is that system breakdown is typically not in human performance or automation\nper se, or their interface, but rather in work constructs that are too complex, or too\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 113\n\nbrittle, to provide efficient, repeatable, robust operations. Thus, it is important to\ndevelop system verification and validation techniques that apply to both the humans\nand the environment they interact with. This novel observation has served as the basis\nfor several research projects, including those supported by NASA\u2019s airspace safety\nprogram.\n\nIn the broad context of safety, there are several well-known issues in V&V. The\nevolutionary nature of NextGen encourages the use of compositional approaches in\nsoftware and system design/verification. For example, there is the need to be able to\nintegrate/replace subsystems and technologies without having to re-certify the whole\nsystem. Such wishful thinking, however, must also accept the limits established\nby system theory, which has shown long ago that compositionality of system sub-\nelements to form a system often does not imply compositionality of verification and\nvalidation of the same sub-elements to prove the system is safe. The underlying\nquestion is whether the air transportation is closer to a large supply chain or the\nInternet, where modularity of design and analysis have proved particularly efficient,\nor more like one of these modular, complex flexible structures like the International\nSpace Station or the most recent commercial aircraft, where compositionality of\nverification and validation has eluded researchers and engineers for years, and re-\nexamination of the entire system is necessary each time a new module is added or\na new version is designed [35]. Moreover, the need for certification of embedded\nand real time software at the algorithmic level, mixed with concerns about cost and\ndevelopment time of that certified software justify the need for research in model-\nbased software validation and certified-by-design software.\n\nIn the context of CNS, we observe that the current FAA network has approx-\nimately 17,000 network devices, and keeps growing, and that in November 2009\nconfiguration errors brought current FAA network down and air traffic to crawl [67].\nIt is therefore necessary to come up with new methods to update, verify, and validate\nconfigurations on the fly. Moreover, advances in network configuration management\ntechnology and techniques are needed, which require the development of a disci-\npline of complex system configuration, verification of system architectures, robust\nand fault-tolerant systems design.\n\n4.3.3 Large-Scale, Real-Time Optimization Algorithms\n\nThis research topic covers theNextGen topics of safety, airspacemanagement, airport\nand terminal-area operations, new vehicles, and traffic flow management strategies.\n\nThere are currently over 35,000 commercial flights a day in the US, and a simi-\nlar number of military and general aviation flights. Scheduling airport and airspace\nresources in such a system needs the development of large-scale optimization algo-\nrithms, and the incorporation of weather uncertainties motivates the development of\nrobust or stochastic approaches. Safety constraints increase the complexity of the\nproblem. There are a range of ways in which the system can be modeled, ranging\nfrom discrete models, which require the solution of large integer programs [8, 9],\n\n\n\n114 H. Balakrishnan et al.\n\nto continuous, flow-based, Eulerian models, which can often be solved using lin-\near programs, but lose individual, flight-scale characteristics [7, 51, 62, 90]. Both\napproaches hold promise at different time-scales, and research into the tradeoffs\nbetween the approaches for tactical and strategic decision-making is needed.\n\n4.3.4 Multi-Objective, Multi-Stakeholder, Optimization\nFrameworks\n\nThe presence of multiple stakeholders and competing interests in the air transporta-\ntion system also poses an interesting research challenge. The objectives themselves\nmay differ among stakeholders; for example, on a weather-impacted day at a con-\ngested airport, air traffic control may be interested in maximizing the rate at which\naircraft arrive and depart (the throughput), the airlines may be interested in min-\nimizing either fuel costs, crew costs, or the total delays incurred by them, or the\ndelay incurred by high-priority flights, while travelers may care about the delay per\npassenger or the number of missed connections, or, simply, the possibility of arriv-\ning home today rather than tomorrow. These objectives are not necessarily aligned;\nfor example, the schedule that maximizes throughput may not be the fuel-optimal\nor delay-optimal schedule. It is necessary to develop techniques that determine the\ntrade-offs among the different objectives to support traffic managers and airport\noperators in their decision-making [52, 66]. Similarly, the study of the incentive\nproperties of resource allocation mechanisms is an important step to handling such\na multi-stakeholder environment.\n\n4.4 Domain-Specific Research Challenges\n\nIn addition to the overarching issuesmentioned above, the design and implementation\nof domain-specific solutions also pose important research challenges. A few such\nproblems are discussed below.\n\n4.4.1 Airport Arrival Management\n\nArrival management consists mainly of making sure that the flow of arriving aircraft\nis timely and orderly. In this process, the primary consideration is runway capacity.\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 115\n\n4.4.1.1 Ground Delay Programs\n\nSometimes, optimizing arrival flows occurs before the arriving aircraft has even taken\noff from its origin airport. Under these conditions, for a given set of aircraft bound\nto an airport, it has been observed that an excessive number of flights at departure\nresults, a few hours later, into excess arrival demand at the destination airport and\ndelays. Given the lower fuel and crew costs associated with waiting on the ground at\nthe departure location, rather than waiting in the air at destination, ground delay pro-\ngrams aim at delaying aircraft departures sufficiently so as to avoid traffic saturation\nat arrival [6, 94]. For completely saturated airports, such as London Heathrow inter-\nnational airport, such ground delay programsmust be very carefullyweighted against\nthe extreme, round-the-clock demand for landings, which cannot tolerate any missed\nlanding opportunity. In this case, residual airborne delay is deliberately maintained\nclose to arrival so as for arrival traffic to always be available to meet the landing\nrunway capacity. The key progress in ground delay programs has been, unchal-\nlenged, the introduction of Collaborative Decision Making (CDM) [96], whereby\nairlines recover some independent decision-making ability despite temporary capac-\nity limitations. This success can be equally attributed to the phenomenal evolution\nin communication technology, and to the strong spirit of collaboration among all\nairspace operators, most notably air traffic flow managers and airline dispatchers.\n\nRecently, the collaborative principles of ground-delay programs have been ten-\ntatively extended to handle airborne capacity limits. The Collaborative Trajectory\nOptions Program (CTOP) aimed at formalizing the already existing collaboration\nbetween airline dispatchers, pilots, and air traffic flowmanagers when desired routes\nand enroute capacity drop. Although similar in spirit to CDM, the foundations of\nthe problem addressed are very different, adding a strong spatial dimension to the\ntemporal dimension successfully handled by CDM.\n\n4.4.1.2 Green Arrivals\n\nTraditional arrival procedures are built upon the availability of 1950\u2019s navigation\nand control technology. Such arrival procedures are very inefficient as far as fuel\nand noise go, as they include several descent and power-on level flight segments,\nwhereas, in principle, environmentally friendlier, less noisy, power-off descents are\npossible. The main challenge associated with power-off, green descents is the partial\nloss of controllability over the aircraft trajectory timing. Consider for example the\nstandard approach shown in Fig. 4.3 together with a green approach. The standard\napproach is staged with many leveled-off segments allowing air traffic control and\npilots to tightly control their 4D position. The green approach, in comparison, offers\nlittle control over the trajectory timing, having been already carefully optimized to\nbe performed with idle, or near idle, engines. The challenge of green descents is\ntherefore to meet the stringent timing requirements allowing the arrival runway to\nperform at full capacity, despite the more limited control action. In recent work [74],\nit was shown that, given essential information, such as aircraft type, aircraft mass,\n\n\n\n116 H. Balakrishnan et al.\n\nFig. 4.3 Conventional versus continuous approaches (from [64])\n\nand the aircraft time of arrival at the top of descent point, it is possible to estimate the\ntime of arrival at the final approach fix with sufficient precision and therefore reduce\nenvironmental impact without impacting airport capacity. Today, green arrivals are\nimplemented at many airports around the world.\n\n4.4.2 Airport Departure Processes\n\nAircraft taxiing on the surface contribute significantly to the fuel burn and emissions\nat airports. This observation has motivated several efforts to identify opportunities to\nreduce airport congestion, design and field-test surface management strategies, and\nestimate the benefits of these strategies [24, 63, 71, 84, 89].\n\n4.4.2.1 Modeling\n\nThe modeling of airport operations is essential for understanding the underlying\nchallenges, and for the development of mitigation strategies. To this end several\nmodels have been developed, ranging from queuing models [38, 49, 56, 72, 83], to\nvarious attempts to characterize airport capacity [31, 73]. These models have been\nfurther used to predict taxi-out times at a specific airport [36, 37, 81, 82], and on\noccasion, as part of NAS-wide modeling efforts [17, 55, 99].\n\nA third body of related work involves the microscopic modeling of all airport\ncomponents. These tools model the layout of an airport, the operating rules for every\naircraft type, and the dynamics of every gate, taxiway and runway with high fidelity.\nAswould be expected, there are tradeoffs among the level of modeling fidelity, effort,\nand computational times [18, 34, 53].\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 117\n\n4.4.2.2 Congestion Mitigation Strategies\n\nThe simplest form of airport congestion mitigation mechanism is to create a virtual\nqueue, whereby aircraft ready for pushback wait for favorable conditions to do so\n[24]. A state-dependent pushback policy, such as the N-Control strategy [12, 15, 16,\n71], is based on the typical variation of departure throughput with the number of\ndepartures on the surface (denoted N ): As more aircraft pushback from their gates\nonto the taxiways, the throughput of the departure runway initially increases, as\nseen in Fig. 4.4 and first observed by Shumsky [82]. This curve is the fundamental\ndiagram of airport traffic and is the exact counterpart to the fundamental diagram\nof networked ground traffic, extensively discussed by Daganzo [30], and shown in\nFig. 4.5. As the number of taxiing departures exceeds a given threshold, denoted N?,\nthe departure runway capacity becomes the limiting factor, and there is no additional\nincrease in throughput. Any additional aircraft that pushback simply incur taxi-out\ndelays [63]. A similar heuristic, based on the concept of an Acceptable Level of\nTraffic (ALOT), has been observed to be employed by Air Traffic Controllers at BOS\nduring extreme congested situations [19]. TheN-Control policy is also closely related\nto the constant work-in-process (CONWIP) policy used in manufacturing systems.\nThe main benefits of CONWIP systems are their simplicity, implementability and\ncontrollability [88]. They present an efficient way to control congestion by accepting\nan adjustable risk of capacity loss. Such congestion control strategies are the direct\ncounterpart of road access control strategies implemented in many highways around\n\nFig. 4.4 Airport throughput versus traffic density\n\n\n\n118 H. Balakrishnan et al.\n\nthe world. It is worth mentioning that airports are usually not subject to the type\nof instabilities resulting from the unimodal geometry of the \u2018fundamental curve of\nground traffic\u2019 (cite appropriate people here) that makes road traffic congestion so\nchallenging to address, although evidence of gridlock can be observed experimentally\nat certain exceptionally busy airports, such as Newark Airport, see Fig. 4.6.\n\nFig. 4.5 Fundamental diagram of single or networked traffic [93]\n\n0 5 10 15 20 25 30\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n14\n\nNumber of aircraft taxiing out\n\nD\nep\n\nar\ntu\n\nre\n th\n\nro\nug\n\nhp\nut\n\n \n(a\n\nirc\nra\n\nft \n/1\n\n5 \nm\n\nin\n)\n\nFig. 4.6 Fundamental diagram of airport traffic at NewYork International Airport; when the airport\nis very highly loaded (in excess of 20 aircraft taxiing at the same time), the airport throughput goes\ndown, showing evidence of a growing gridlock\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 119\n\n4.4.2.3 Implementation\n\nThe N-Control strategy can be adapted to the human environment in the air traffic\ncontrol tower to obtain a rate-based control strategy by predicting the throughput in\na future time period, and deciding on the number of pushbacks in that time period\nneeded to maintain a certain level of ground traffic. Indeed, it was found that a\nrate-based control strategy is much better accepted by human operators than a pure\nthreshold strategy. Generalized versions of pushback control policies, based on full-\nstate feedback using surface surveillance, have also been considered for surface\ntraffic management [13, 14]. Recently, a refined Pushback Rate Control strategy has\nbeen developed, which uses the transient analysis of D(t)/Ek(t)/1 queuing systems\nto determine the optimal rate of pushbacks in a given time period, based on the\noperating environment, the number of aircraft taxiing out, and the length of the\ndeparture runway queue [84].\n\nSeveral approaches to departure metering have been field-tested, including the\nGround Metering Program at New York\u2019s JFK airport [63, 89], the field-tests of the\nCollaborative Departure Queue Management concept at Memphis (MEM) airport\n[11], the human-in-the-loop simulations of the Spot and Runway Departure Advisor\n(SARDA) concept atDallas FortWorth (DFW) airport [41], the trials of theDeparture\nManager (DMAN) concept [10] in Athens International airport (ATH) [80], and the\nfield-tests of Pushback Rate Control at Boston\u2019s Logan International airport (BOS)\n[85, 86].\n\nPushback control can also be formulated as a network congestion control problem\nand solved efficiently using approximate dynamic programming techniques [92].\nThis approach has been shown to effectively address practical resource constraints,\nsuch as limited gate availability [43, 44].\n\n4.4.2.4 Metrics to Characterize Airport Operational Performance\n\nThe availability of detailed surface surveillance datasets from sources such as theAir-\nport Surface Detection Equipment, Model-X (ASDE-X) have the potential to be used\nfor assessing airport performance, in addition to their primary purpose of enhancing\nsafety [23]. In particular, the data can be used to characterize surface flows, includ-\ning identification of congestion hotspots, queue dynamics and departure throughput,\nand to develop metrics to evaluate the daily and long-term operational performance\nof an airport under different operating conditions. These metrics can provide useful\nfeedback on operational performance to airport operators, and therefore have the\npotential to improve the efficiency of surface operations at airports [42, 45].\n\n\n\n120 H. Balakrishnan et al.\n\n4.4.3 The Trip is Not Over: Passenger Management\nin the Terminals\n\nThe passenger perspective on airports resource management differs noticeably from\nthat of the aircraft operator: While aircraft operations happen within the airside, the\npassenger experience, which includes part of the airside, is also considerably influ-\nenced by landside activities. Aircraft and passengers meet at the interface between\nthe two spaces, which consists of the boarding gate.\n\nPassenger traffic is driven by trajectory optimization, system capacity and queuing\nbehaviors, just like airspace dynamics or, for that purpose, any transportation system.\n\nThere are several steps that may be undertaken to mitigate long transit times and\nexcessive queuing for passengers: Both phenomena result in lost time, which may be\neither reduced, or reused to improve passenger experience and airport earnings alike:\nFor example, passengers may use excess transit time to either engage in shopping,\nor enjoy the services of a restaurant, all activities also beneficial to retailers and the\nairport authority.\n\n4.4.3.1 Minimizing Passenger Unimpeded Transit Times\n\nPassenger transit times within a given terminal usually grow with the distance sep-\narating the passenger point of entry to his destination. Three cases arise: Either the\npassenger checked in at the airport, or the passenger reached his destination, or the\npassenger is connecting from one flight to the next. In all cases, gate assignment is\nkey to influencing passenger transit time, since a gate close to the airport terminal\nresults in reduced transit time for checking-in and exiting passengers. On the other\nhand, two aircraft close to each other will see passengers connecting from either\naircraft to the other enjoy a lower gate-to-gate transit time. Placement of aircraft at\ngates is therefore very important and can be very dynamic.\n\n4.4.3.2 Queuing Effects\n\nQueuing effects arise in two contexts:\nFirst, couplings and trade-offs exist between the competing goals of minimizing\n\npassenger unimpeded transit time and \u2018queuing at the gate\u2019, a common phenomenon,\nwhereby an arriving aircraft finds its arrival gate to still be occupied by a departing\naircraft. Figure4.7 shows how expected wait time due to occupied gate decays as a\nfunction of scheduled gate idle time between occupancies.\n\nA strategy aimed at optimizing passenger transit tends naturally to cluster aircraft\nwithin a small, convenient set of gates, and a density increase in scheduled occupancy\ntimes for a given gate will result in increased \u2018gate queuing\u2019. Casual observations\nshow that \u2018gate queuing\u2019 is badly tolerated by passengers. We can explore the pareto\nfront showing passenger transit time from gate to gate (or from gate to exit) vs.\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 121\n\nFig. 4.7 Evolution of average gate delay as a function of planned idle time between occupancies\n[48]\n\npassenger time waiting for the gate to be free by optimizing\n\nJ (?) = ? \u00d7 (passenger transit cost) + (1 ? ?) \u00d7 (waiting for gate to free up).\n\nfor various values of ? between 0 and 1 [47]. The resulting tradeoff curve is given\nin Fig. 4.8. It shows that indeed transit costs and \u2018wait for gate\u2019 costs must be traded\nagainst each other. It is up to the airline to adjust what is the equivalent of a \u2018cost\nindex\u2019 to obtain acceptable trade-offs.\n\nSecond, queuing occurs at key locations in the airport terminal: Entering passen-\ngers experience queuing first at check-in, especially if they need to check in luggage.\nThen, the same passengers experience queuing at security gates. Last, these pas-\nsengers experience queuing upon boarding the aircraft. Exiting passengers usually\nexperience delays at customs and border control. Just as for ground delay programs\nand congested departure operations, intelligent queue management techniques can\nalleviate queueing problems arising in the terminal. Unlike airport arrival and depar-\nture capacity, however, passenger serve capacity at bottlenecks can be adjusted very\nfast via intelligent staffing policies. One of the keys to matching demand against\ncapacity is appropriate demand monitoring. The recent work by Nikoue and Clarke\n[48] shows that smart phone positioning techniques using triangulation or other sig-\nnal localization techniques can be used to anticipate demand at border control and\nsupport appropriate booth staffing policies. To support this task, there also exists a\nfundamental diagram of single or networked pedestrian traffic inside airport termi-\nnals. The one shown in Fig. 4.9 reflects that of Sydney airport, based on triangulated\nsignals from cell phones carried by passengers.\n\n\n\n122 H. Balakrishnan et al.\n\nFig. 4.8 Trade-off between time spent transiting from gate to gate/exit and time spent waiting for\narrival gate to be free. All units are in minutes\n\nFig. 4.9 Fundamental curve of airport pedestrian traffic approaching passport control at Sydney\nInternational Airport (courtesy Harold Nikoue). Red Average flow. Green 90% confidence interval.\nWhen the facility is highly loaded (in excess of 300 passengers present in the passport control area\nat the same time), the passenger throughput saturates\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 123\n\nFocusing on Sydney international airport, Nikoue and Clarke, have demonstrated\nthe significant improvements that can be obtained by properly managing passenger\nqueuing in real time and feeding back anticipated passenger demand (which is cor-\nrelated with flights expected flight landing times). Figures4.10 and 4.11 shows the\nradically different evolutions of queuing delays, depending on whether feedback is\nprovided and acted upon by the immigration staffing unit.\n\nThe effect of feedback is to limit the length of queuing at any time, and eliminate,\nfor example, the massive queuing peak occurring near 11:30 when the nominal\nstaffing profile is applied without feedback.\n\n4.4.4 Domain-Specific Contributions: Abstract Modeling\nApproaches\n\nThe combination of physical aviation infrastructure and automation in NextGen\npresents a variety of opportunities and challenges related to systems and control the-\nory. The context of traffic control can be the source of many new abstract problems\nto solicit the curiosity of mathematically inclined researchers in the decision and\ncontrol sciences. The value of these abstract problems is not only for intellectual\namusement: Microscopic simulations project are essential to the validation of the\nunderlying models by confronting their output against the opinion of system opera-\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\nW\nai\n\nt t\nim\n\ne \n(m\n\nin\n)\n\nTime of day(hour)\n\n0\n0 5 10 15 20\n\nmean\nupper bound\n\nFig. 4.10 Actual passenger delay generated by mismatched immigration staffing and actual flight\narrivals times\n\n\n\n124 H. Balakrishnan et al.\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\nW\nai\n\nt t\nim\n\ne \n(m\n\nin\n)\n\n0\n\nTime of day(hour)\n0 5 10 15 20\n\nmean\nupper bound\n\nFig. 4.11 Simulated passenger delay generated by mismatched immigration staffing and actual\nflight arrivals times\n\ntors. But proper abstract models of traffic can make preliminary analyses of air traffic\noperations much faster and cost-effective, allowing the investigator to quickly turn\nseveral design options around.\n\n4.4.4.1 Models of Air Traffic Based on Statistical Mechanics\n\nPerhaps the greatest success of abstract thinking applied to air traffic control is the\ngeneration of closed form analytical models inspired by gas particle dynamics to\ncharacterize airspace conflicts arising from properties such as structure, directional-\nity, or density. Some of the earliest published work featuring the gas particle collision\nmodel dates to the early 1960\u2019s. In a report to the Federal Aviation Administration,\nArad et al. [3] proposed a mathematical approach to model air traffic control with\nthe primary purpose of quantifying possible en-route airspace conflicts as a proxy of\ncontroller load to guide better sector design. The model relates the control function\nload to the expected number of conflicts C arising in a sector over a unit of time. C\nis estimated as\n\nC = 2a?V? N\n2\n\ng0S\n(4.1)\n\nwhere a? is a linear measure of separation minima, V is the average traffic speed, g0\nis a non-dimensional flow organization factor, and S is the (top-view) 2-D area of the\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 125\n\nairspace sector. As would be done in most subsequent developments of the particle\ncollision model, expressions for cases interest (e.g. airway crossings or overtaking)\nare derived fromageneralizedmodel form, and the 2Dmodel is extended to formulate\none for the 3D case.\n\nIn two subsequent studies [25, 32] the same model was applied to the terminal\narea environment, explicitly incorporating the concept of uniformly distributed ran-\ndom traffic position and heading. As shown by Graham and Orr [33] expressions for\nthe expected number of conflicts can be derived from a few fundamental concepts\nincluding the average relative velocity, the conflict volume swept by the moving air-\ncraft, and traffic density. Alexander [1] is perhaps one of the first authors to explicitly\nrefer to this type of model as a gas model, arguing that it is a reasonable analogue for\nair traffic phenomena given the quadratic relationship of conflict rate to traffic den-\nsity as supported by empirical airspace observations. The model assumes a random\ndistribution of aircraft and flight directions to estimate the probability that an aircraft\nwill not come within a distance r of another aircraft having already traveled a dis-\ntance L as a function of the average traffic density ? and number of non-interacting\naltitude layers n. The corresponding mean-free path L2 and frequency F2 of 2-body\ninteractions at a distance r with aircraft velocity V are estimated accordingly. The\nresulting interaction frequency per unit surface area is\n\nC2 = 1\n2\n\nF2? = r?\n2V\n\nn\n(4.2)\n\nUsing representative values for airspace density ? , aircraft speed V , and aircraft\nseparation minima r , Alexander draws meaningful conclusions regarding inherent\nconflict risk as a function of density.\n\nIn a similar way May [59] builds upon the technique originally suggested by\nMarks [58] to estimate the probability of conflict with a random particle collision\nmodel. The relative velocity VR between two aircraft can be used for one so that\nthe other can be assumed immovable. A NMAC cylindrical volume, defined with\nhorizontal separation distance MH and a vertical separation distance MV , sweeps a\ntotal NMAC volume as the aircraft moves on a straight line in time interval t:\n\nRNMAC = 4MH MV VRt (4.3)\n\nThe probability of aNMAC is estimated as the the probability that a second aircraft\nwill be in the swept volume RNMAC. Assuming a uniform time-invariant distribution\nof traffic, the estimate is reduced to be directly proportional to the swept NMAC\nvolume. Following the work by Graham and Orr [33] May estimates the average\nrelative velocity as:\n\nV?R = 1\n?\n\n? ?\n0\n\n?\nV 21 + V 22 ? 2V1V2cos(?)d? (4.4)\n\n\n\n126 H. Balakrishnan et al.\n\nMay applies this general technique to yield analytical estimates for the expected\nnumber of NMACs in a number of particular cases of interest, for instance for an\naircraft with velocity V1 intruding airspace where aircraft fly at V2, in once case with\nrandom headings and in another organized as a traffic stream.\n\nOther seminal work focused on extensions and generalizations of the theory,\ntreatment of special cases, and cross-examination against empirical air traffic con-\nflict data. For instance, Anno [2] compared midair collisions from the standpoint of\nrandom collision theory with midair collision data to estimate the effectiveness of\nATC control.\n\nEndoh\u2019s (1982) generalization and extension of the gas model constitutes one\nof the most significant contributions to the modeling paradigm. For instance, the\nestimate of the expected relative velocity considers the probability distribution of the\nvelocity values and the vector angle, resulting in the expression below for independent\ndistributions.\n\nE(Vr ) =\n?\n\nV1\n\n?\nV2\n\n? 2?\n0\n\n?\nV 21 + V 22 ? 2V1V2cos(?)?(?)?(V2)?(V1)d?dV2dV1\n\n(4.5)\n\nEndoh [21] also examines the implications of the above definition of expected\nrelative velocity against definitions in statistical mechanics and prior midair collision\nmodels. The special cases that Endoh derives from the generalized model are also\nnoteworthy because they account for important airspace features that are often not\ncaptured in earlier work by virtue of oversimplifying assumptions. For instance, the\nnon-uniform distribution of flight headings as observed in large airspace volumes,\nan IFR airway immersed in unstructured VFR airspace.\n\nMuchof thework byEndohwas later incorporated and expandedupon in reference\nmaterials byProfessorRobert Simpson [87] for theEngineering ofAir TrafficControl\nSystems course at MIT, contributing to the growing popularity and adoption of the\ngeneralized method throughout the 1990s. In this course material Simpson revisits\nthe generalized 2D formulation and provides closed form solutions of the horizontal\nencounter rate for special cases including a multi-directional (unstructured) traffic\nflow, unstructured unidirectional flow with varying speeds, airways with overtaking,\nunidirectional airway in multidirectional flow (IFR airway in VFR airspace), and\ntwo-airway intersection. He also examines multi-direction 3-D traffic at constant\nspeed, and the case where traffic is assigned to fly nominal paths, not necessarily\nstraight, in 3 dimensions. Building upon concepts treated by Alexander [1], he also\nexamines the collision rate for traffic assigned to different altitudes.\n\nToday the published literature features a wealth of applications and variations of\nthe gas model for midair collisions, in many cases to study novel airspace concepts\nand technologies. For instance, the integration of unmanned aircraft systems (UAS)\ninto the national airspace and the midair collision risks it presents have been studied\nextensively with the gas collision model [4, 20, 60, 61, 95, 97].\n\nOver the last few decades considerable effort has been dedicated to the develop-\nment of solutions to environmental impact of continued growth of aviation activity.\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 127\n\nTechnical solutions have been proposed in many forms, the vast majority comprised\nby advanced concepts and technologies for both aircraft/vehicles and airspace oper-\nations. While most efforts will typically address only one or the other, in recent years\nthere has been increasing emphasis on integrated analyses bridging both perspectives.\nMany advance aircraft concepts are fundamentally predicated on unconventional\nvehicle configurations for which mission profile and overall performance character-\nistics are considerably different frommore traditional aircraft. These differences have\nprofound implications for airspace operations, particularly when considering the rich\nvariety of aircraft in a mixed global fleet. Rather than examining the implications\nthat unique flight characteristics have on airspace operations as an afterthought, as\nhad occurred often in the past, recent advances have leveraged on the simplicity and\npower of the gas model to incorporate airspace safety and operational considerations\ninto the core analysis effort for advanced vehicle concepts.\n\nIn recent efforts by Feron, Jimenez, and Clarke the impact on airspace conflict\nresulting from the introduction of advanced aircraft concepts into the operating fleet\nwas examined. This characterizationwas conducted through encounter rate estimates\ngiven the same interpretation of seminal work reviewed earlier in this section, namely\na measure of the latent risk providing an upper bound on potential conflicts, or as\na measure of the required control load inferred from the level of air traffic activity\nand associated conflict phenomena. Assessments are made over a 2010 to 2050 time\nperiod while incorporating considerations of changing fleet and operations growth\nforecasts with appropriate fleet-level models [26, 39, 70]. Encounter rate estimates\nacross two fleet scenarios capture the impact of advanced vehicle concept introduc-\ntions. The reference scenario offers a baseline fleet technology level and assumes no\nadditional improvements beyond the current generation (e.g. A320NEO, B737MAX,\nB787, A350). The alternate scenario assumes performance improvements for tube\nand wing aircraft beyond the current generation, single aisle aircraft with open rotor\npropulsion starting in 2030, and hybrid wing body aircraft for the replacing the\ntraditional wide-body/twin aisle conventional starting in the mid 2030s.\n\nAn implementation of the gas particle model as reported by Simpson is used\nto produce encounter rate estimates. Flight speeds for different flight phases for all\naircraft obtained fromvehicle performance analyses, in combinationwith sufficiently\ndetailed sets of operations, are explicitly captured in this implementation of the\nmodel via numerical integration of the underlyingweighted distributions of speed and\nheading. The assessment is conducted at three levels of airspace system abstraction.\n\nFirst, the entire national airspace system is considered only for cruise conditions\nusing the corresponding speed distribution and uniformly random headings. Results\npredict an increasing rate of conflicts over time that is most directly attributed to the\ncorresponding increase in airspace density.However, there is no significant difference\nbetween scenarios suggesting that at an aggregate level for cruise conditions the\nintroduction of advance concepts does not significantly impact air traffic conflict\nphenomena.\n\nA second examination considers structured IFR airspace at the center level. The\nCleveland center (ZOB), one of the busiest in the nation,was selected for this purpose.\nA simplified representation of the center airspace structure containing its dominant\n\n\n\n128 H. Balakrishnan et al.\n\nFig. 4.12 Encounter rate for airway overtaking and crossing, increase trend for traffic projection\ngrowth and differences due to fleet mix scenarios\n\ncharacteristics was developed using a large set of radar track data (for FL350) to\nidentify turning points, cluster them into waypoints, and map each flight into a\ncorresponding sequence of segments [28]. Overtaking conflicts within the busiest\nairway segment, and crossing segments in the busiest airway segment intersection\nwere evaluated with the model, all the while utilizing the fleet mix for operations\nconducted in these segments. Results, shown in Fig.4.12, indicate an increase of\nthe encounter rate over time following the increase in airspace density. Only a very\nsmall increase in the encounter rate is observed for the scenariowith advanced vehicle\nconcepts past the year 2040. This effect, however modest, is attributed to the fleet\ncomposition observed for the segments of interest, which is notably different form\nthat for the entire NAS.\n\nThe third assessment considers the highly structured and coordinated airspace of\na class B airport arrival stream. With about 30% of all arrivals the FLCON stan-\ndard arrival is the busiest for Atlanta airport, itself the busiest in the world. The\nstudy looked at the arrival peak of the Atlanta 2013 statistical design day, which\ncorresponds to some 95 arrivals per hour. In this busy stream altitude and speed are\nstrictly controlled at the arrival fixwhich offers an ideal reference point beyondwhich\nthe encounter rate gas model may be exercised. All aircraft are reasonably assumed\nto follow the same linear altitude descent profile, as well as a linear velocity deceler-\nation profile, between the arrival fix (12,000 ft, 250kts CAS) and the final approach\nfix (1,000 ft, VApp) consistent with highly-coordinated Next-Gen operations. In this\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 129\n\nFig. 4.13 Encounter rate for arrival stream, increase trend for traffic projection growth and differ-\nences due to fleet mix scenarios\n\nmanner traffic coordination upstream of the arrival fix is implicitly captured without\ncompromising the fundamental modeling approach of the gas model; at the same\ntime it isolates conflict phenomena associated with differences in approach speed for\nthe fleet mix under study within a linear deceleration profile, as would be captured\nby the model. A 3 NM separation distance is used in this case given that it takes place\nwithin the TRACON. Because velocity varies with position, separation minima at\nthe metering fix is not guaranteed for the remainder of the approach path. In the past\ngas model implementations have assumed a constant speed for aircraft, often times\nusing some average of the arrival speed profile; alternatively the average of the speed\ndifferential between consecutive aircraft can be used, for example estimating it as\n\nE(VDiff(h)) = E(Vtrailing(h) ? Vleading(h)). (4.6)\n\nThis approach does not capture traffic compression and consequently significantly\nunderestimates the encounter rate. A novel modification to the encounter rate model\nwas implemented to account for the compression effect by calculating the conflict\nrange in consideration of the speed change. This modification to the model remains\nchiefly analytical, and shows good agreement against direct numerical simulation\nwith Monte Carlo sampling for a Poisson process. Results for the arrival stream,\nshown in Fig. 4.13, confirm that prior modeling approaches greatly underestimate\n\n\n\n130 H. Balakrishnan et al.\n\nFig. 4.14 Sensitivity of arrival stream encounter rate to advanced vehicle percent speed\nperturbations\n\nthe encounter rate, and suggest that introduction of advanced vehicle concepts mod-\nestly increases the encounter rate over the midterm and then decreases it in the longer\nterm, past the year 2045. This trend reversal is attributed to two effects: the compo-\nsition of the fleet at any given time, and the approach velocity values of the aircraft\nin said fleet mix. In the midterm the fleet composition has comparable proportions\nof conventional tube and wing aircraft with higher approach speeds and unconven-\ntional HWB configuration aircraft with much lower approach speeds, resulting in the\ngreatest average speed differentials and higher encounter rate. In the long term the\nspeed differential decreases with the unconventional aircraft comprising a greater\nproportion of the fleet. The modest magnitude of the impact can itself be attributed\nto the small proportion of wide-body capacity aircraft operations relative to more\ndominant narrow-body aircraft operations.\n\nWith the encounter rate model for the arrival stream sensitivity analyses can be\nconducted to examine the extent to which more pronounced velocity discrepancies\nof advanced vehicles relative to conventional ones result in changes to the encounter\nrate. Representative results are illustrated in Fig. 4.14.\n\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 131\n\n4.4.4.2 Geometric Analyses of Conflict Detection and Resolution\nAlgorithms\n\nConflict detection and resolution has rapidly become the canonical problem through\nwhich the research community enters the field air transportation. This fact is amply\njustified by the fact that conflict detection and resolution is the core task and main\nreason why air traffic management came to be in the first place (cite papers about\n1958 grand canyon accident). While there is a great deal of accumulated knowledge\nabout conflict detection and resolution algorithms, the very idea of proving that these\nalgorithms do, in fact, eliminate all possible conflicts, is far from exhaustion. Going\nas far as the development of TCAS in 1992, there has always been a desire to build\nassurance about collision and conflict avoidance problems (here, cite Lincoln Lab\nefforts), even though the most common practice has been, up until recently, to rely\non exhaustive simulations to slowly build evidence of proper system behavior, and\nconfidence that this behavior will remain so in the future. The very concept of prov-\ning the correctness of conflict resolution algorithms can be traced back as far back as\n[65], and possibly further back if one embeds the conflict/collision avoidance prob-\nlem within the corresponding mobile robotics subject [46, 50, 91], and the concept\nhas slowly gained momentum in the research community, relying on increasingly\nsophisticated computer-aided verification tools [27].\n\nBringing a solid mathematical basis to prove the absence of collision/conflict\namong aircraft (under properly stated assumptions) gives the researcher the oppor-\ntunity to build a complete axiomatic theory of air traffic control, whereby proven\nelementary conflict management blocks can be combined to form a complete engi-\nneered system. For example, the initial construct by Mao, Bilimoria and Feron [57],\nwhereby pairs of aircraft flows can be proven to intersect without loss of separation\nunder stated control laws, can be used to build a \u2018correct-by-design\u2019 air transportation\nnetwork, where conflicts are guaranteed to always be solved. Of course, the experi-\nenced air trafficmanagement specialistwill immediately recognizemanyweaknesses\nin the initial assumptions supporting these constructs. However, such an axiomatic\napproach can come as a useful complement to operational control procedures tomea-\nsure the gap that exists between today\u2019s system, which originates from a long legacy\nof pragmatic and incremental improvements, and a more elusive, \u2018mathematically\ncorrect\u2019 model built from scratch.\n\n4.4.4.3 Design of Control/Communications Protocols and Architectures\n\nAutomatic Dependent Surveillance\u2014Broadcast (ADS-B) is a NextGen surveillance\nand communication technology by which aircraft can broadcast onboard flight infor-\nmation via datalink to ground stations or other aircraft within range [75, 77, 78]. The\nposition estimates from ADS-B are will be more accurate and have lower latency\nthan traditional ground radar systems [54].\n\nA fundamental systems design decision is the level of decentralization that bal-\nances safety and efficiency. While ADS-B can be used to shift air traffic control\n\n\n\n132 H. Balakrishnan et al.\n\nto a more distributed architecture, channel variations and interference with existing\nsecondary radar replies can affect ADS-B transmissions. These observations have\nmotivated the development of hybrid control-communication protocols that account\nfor interactions between new and legacy infrastructure, and balance the tradeoffs\nbetween safety and efficiency [69].\n\nAlong with the increase in efficiency, there is a concern that decentralization\nmay make malicious behavior easier [79, 98]. Erroneous information introduced by\nmalicious entities may be retransmitted by other aircraft, and infect the rest of the\nsystem. With an increase in automation in all levels of the system, cybersecurity\nbecomes critical. These challenges also present opportunities to use innovative data\nfusion techniques to detect errors in broadcast data, build redundancy into the system,\nand improve overall performance [68].\n\nAcknowledgments This work was performed under partial support from the Federal Aviation\nAdministration under the NEXTOR II program task 0025, the National Aeronautics and Space\nAdministration under Contract No. NNL12AA14C, and Soci\u00e9t\u00e9 Internationale de T\u00e9l\u00e9communica-\ntions A\u00e9riennes.\n\nReferences\n\n1. Alexander, B.: Aircraft density andmidair collision. In: Proceedings of the IEEE, vol. 58 (1970)\n2. Anno, J.: Estimate of human control over mid-air collisions. J. Aircr. 19, 86\u201388 (1982)\n3. Arad, B.A., Golden, B., Grambard, J., Mayfield, C., Saun, H.V.: Control load, control capacity\n\nand optimal sector design. Technical Report No. RD64-16, Federal Aviation Administration,\nWilliam J. Hughes Technical Center, Atlantic city, NJ (1963)\n\n4. Awad, A.I.: An analysis of the risk fromUASmissions in the national airspace. Master\u2019s thesis,\nUniversity of Washington (2013)\n\n5. Balakrishnan, H., Feron, E.: (a sample of the) US academic community\u2019s views on research\ncontributions to NextGen. http://cps-vo.org/content/nitrdpresentationpptx (2015). Accessed\nFeb 2015\n\n6. Ball, M., Lulli, G.: Ground delay programs: optimizing over the included flight set based on\ndistance. Air traffic control. Q. (2004)\n\n7. Bayen, A., Raffard, R., Tomlin, C.: Adjoint-based control of a new eulerian network model of\nair traffic flow. IEEE Trans. Control. Syst. Technol. 14(5), 804\u2013818 (2006)\n\n8. Bertsimas, D., Lulli, G., Odoni, A.: The air traffic flow management problem: an integer\noptimization approach. In: Integer Programming and Combinatorial Optimization, pp. 34\u201346\n(2008)\n\n9. Bertsimas, D., Stock Patterson, S.: The air traffic flow management problem with enroute\ncapacities. Oper. Res. 46(3), 406\u2013422 (1998)\n\n10. B\u00f6hme, D.: Tactical departure management with the Eurocontrol/DLR DMAN. In: 6th\nUSA/Europe Air Traffic Management Research and Development Seminar, Baltimore, MD\n(2005)\n\n11. Brinton, C., Provan, C., Lent, S., Prevost, T., Passmore, S.: Collaborative departure queue man-\nagement: an example of collaborative decisionmaking in theUnited States. In: 9thUSA/Europe\nAir Traffic Management Research and Development Seminar (ATM2011), Berlin, Germany\n(2011)\n\n12. Burgain, P., Feron, E., Clarke, J., Darrasse, A.: Collaborative Virtual Queue: Fair Management\nof Congested Departure Operations and Benefit Analysis. Arxiv preprint arXiv:0807.0661\n(2008)\n\nhttp://cps-vo.org/content/nitrdpresentationpptx\nhttp://arxiv.org/abs/0807.0661\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 133\n\n13. Burgain, P., Kim, S.H., Feron, E.: Valuating surface surveillance technology for collaborative\nmultiple-spot control of airport departure operations. IEEE Trans. Intell. Trans. Syst. 15(2),\n710\u2013722 (2014)\n\n14. Burgain, P., Pinon, O.J., Feron, E., Clarke, J.P.,Mavris, D.N.: Optimizing pushback decisions to\nvaluate airport surface surveillance information. IEEETrans. Intell. Trans. Syst. 13(1), 180\u2013192\n(2012)\n\n15. Carr, F.: Stochastic modeling and control of airport surface traffic. Master\u2019s thesis, Massa-\nchusetts Institute of Technology (2001)\n\n16. Carr, F., Evans, A., Feron, E., Clarke, J.: Software tools to support researchon airport departure\nplanning. In: Digital Avionics Systems Conference. IEEE, Irvine CA (2002)\n\n17. Clarke, J., Melconian, T., Bly, E., Rabbani, F.: MEANSMIT extensible air network simulation.\nSimulation 83(5), 385 (2007)\n\n18. Clarke, J.P., Li, L., Balakrishnan, H., Feron, E., Griffin, K., Kim, B., Kim, S., Lee, H., Robeson,\nI.J., Solveling, G., Yu, P., Brooks, J.: Surface traffic optimization in the presence of uncertainties\n(2010). Final report, NASA Project NNX07AU34A\n\n19. Clewlow,R.,Michalek,D.: LoganControlTower:Controller Positions, Processes, andDecision\nSupport Systems. Technical report, Massachusetts Institute of Technology (2010)\n\n20. Dalamagkidis, K., Valavanis, K., L.A., Piegl: Evaluating the risk of unmanned aircraft ground\nimpacts. In: 16th IEEE Mediterranean Conference in Control and Automation, pp. 709\u2013716\n(2008)\n\n21. Endoh, S.: Aircraft collision models, Technical report, FTL Report R82\u20132, Massachusetts\nInstitute of Technology, Flight Transportation Laboratory (1982)\n\n22. EUROCONTROL: SESAR website. http://www.eurocontrol.int/sesar/\n23. Federal Aviation Administration: Fact Sheet of Airport Surface Detection Equipment, Model\n\nX (ASDE-X). http://www.faa.gov/news/fact_sheets/news_story.cfm?newsId=6296 (2010)\n24. Feron, E.R., Hansman, R.J., Odoni, A.R., Cots, R.B., Delcaire, B., Hall, W.D., Idris, H.R.,\n\nMuharremoglu,A., Pujet, N.: TheDeparture Planner: a conceptual discussion. Technical report,\nMassachusetts Institute of Technology (1997)\n\n25. Flanagan, P.: Chapter frequency of airspace conflicts in themixed terminal environment. Report\nof the Department of Transportation Air Traffic Control Advisory Committee, vol. 2, pp. 137\u2013\n144. Federal Aviation Administration, Oklahoma (1969)\n\n26. Frank, C., Jimenez, H., Pfaender, H., Mavris, D.: Scenario development to evaluate system-\nwide environmental benefits of aircraft technologies and concepts. In: Proceedings of the\n2013 Aviation Technology, Integration, and Operations Conference. American Institute of\nAeronautics and Astronautics (2013)\n\n27. Galdino, A., Munoz, C., Ayala-Rinc\u00f3n, M.: Formal verification of an optimal air traffic conflict\nresolution and recovery algorithm. Log. Lang. Inf. Comput. 177\u2013188 (2007)\n\n28. Gariel, M.: Toward a graceful degradation of air traffic management systems. Ph.D. thesis,\nGeorgia Institute of Technology (2010)\n\n29. Gariel, M., Feron, E.: Graceful degradation of air traffic operations: airspace sensitivity to\ndegraded surveillance systems. Proceedings of the IEEE, special issue on aviation information\nsystems (2009)\n\n30. Geroliminis, N., Daganzo, C.: Existence of urban-scale macroscopic fundamental diagrams:\nsome experimental findings. Trans. Res. Part B 42(9), 759\u2013770 (2008)\n\n31. Gilbo, E.: Airport capacity: representation, estimation, optimization. IEEE Trans. Control.\nSyst. Technol. 1(3), 144\u2013154 (1993)\n\n32. Graham, W., Orr, R.: Chapter terminal air traffic model with near midair collison and midair\ncollison comparison. Report of the Department of Transportation Air Traffic Control Advisory\nCommittee, vol. 2, pp. 151\u2013164. Federal Aviation Administraiton, Oklahoma (1969)\n\n33. Graham, W., Orr, R.: Terminal air traffic flow and collison exposure. In: Proceedings of the\nIEEE, vol. 58 (1970)\n\n34. Griffin, K.J., Yu, P., Rappaport, D.B.: Evaluating surface optimization techniques using a fast-\ntime airport surface simulation. In: AIAA Aviation Technology, Integration and Operations\n(ATIO) Conference. Fort Worth, TX (2010)\n\nhttp://www.eurocontrol.int/sesar/\nhttp://www.faa.gov/news/fact_sheets/news_story.cfm?newsId=6296\n\n\n134 H. Balakrishnan et al.\n\n35. How, J., Glaese, R., Grocott, S., Miller, D.: Finite element model-based robust controllers for\nthe middeck active control experiment (mace). Control. Syst. Technol. 5(1) (1995)\n\n36. Idris, H., Clarke, J.P., Bhuva, R., Kang, L.: Queuing model for taxi-out time estimation. Air\nTraffic Control. Q. (2001)\n\n37. Idris, H.R.: Observation and analysis of departure operations at Boston Logan International\nAirport. Ph.D. thesis, Massachusetts Institute of Technology (2001)\n\n38. Jacquillat, A., Odoni, A.R.: A Study of Airport Congestion at JFK and EWR. In: 5th Interna-\ntional Conference on Research in Air Transportation (2012)\n\n39. Jimenez, H., Pfaender, H., Mavris, D.: System-wide assessment of nasa era concept vehicles\nand technologies for fuelburn and co2. J. Aircr. Am. Inst. Aeronaut. Astronaut. 49, 1913\u20131930\n(2012)\n\n40. Joint Planning and Development Office: Concept of Operations for the Next Generation Air\nTransportation System (2007)\n\n41. Jung, Y., Hoang, T., Montoya, J., Gupta, G., Malik, W., Tobias, L.: Performance evaluation of a\nsurface traffic management tool for dallas/fort worth international airport. In: 9th USA/Europe\nAir Traffic Management Research and Development Seminar (ATM2011). Berlin, Germany\n(2011)\n\n42. Khadilkar, H., Balakrishnan, H.: A multi-modal Unscented Kalman filter for inference of\naircraft position and taxi mode from surface Surveillance data. In: AIAAAviation Technology,\nIntegration and Operations (ATIO) Conference. Virginia Beach, VA (2011)\n\n43. Khadilkar, H., Balakrishnan, H.: Optimal control of airport operations with gate capacity con-\nstraints. In: European Control Conference. Zurich, Switzerland (2012)\n\n44. Khadilkar, H., Balakrishnan, H.: Network congestion control of airport surface operations. J.\nGuid. Control. Dyn. (2014). To appear\n\n45. Khadilkar, H., Balakrishnan, H., Reilly, B.: Analysis of airport performance using surface sur-\nveillance data:A case study ofBOS. In:AIAAAviationTechnology, Integration andOperations\n(ATIO) Conference. Virginia Beach, VA (2011)\n\n46. Khatib, O.: Real-time obstacle avoidance for manipulators and mobile robots. Int. J. Robot.\nRes. 5(1), 90\u201398 (1986)\n\n47. Kim, S.: Airport control through intelligent gate assignment. Ph.D. thesis, Georgia Inst. Tech-\nnology (2013)\n\n48. Nikoue H., Marzuoli, A., Clarke, J.-P., Feron, E., Peters, J.: Passenger flow predictions at\nsydney international airport: a data-driven queuing approach. arXiv:1508.04839v1 (2015)\n\n49. Kivestu, P.A.: Alternative methods of investigating the time dependent M/G/k queue. Master\u2019s\nthesis, Massachusetts Institute of Technology (1976)\n\n50. Latombe, J.: Robot Motion Planning. Kluwer, Dordrecht (1995)\n51. LeNy, J., Balakrishnan,H.: Feedback control of theNationalAirspaceSystem. J.Guid.Control.\n\nDyn. 34(3) (2011)\n52. Lee, H., Balakrishnan, H.: A study of tradeoffs in scheduling terminal-area operations. Proc.\n\nIEEE 96(12) (2008)\n53. Lee, H., Balakrishnan, H.: Fast-time simulations of Detroit airport operations for evaluating\n\nperformance in the presence of uncertainties. In:DigitalAvionics SystemsConference (DASC).\nIEEE (2012)\n\n54. Lester, E.A., Hansman, R.J.: Benefits and Incentives for ADS-B Equipage in the National\nAirspace System. Technical report, MIT (2007)\n\n55. Long, D., Lee, D., Johnson, J., Gaier, E., Kostiuk, P.: Modeling Air Traffic Management Tech-\nnologies with a Queuing Network Model of the National Airspace System. Technical report,\nNASA Langley Research Center, Hampton, VA. Technical Report NASA/CR-1999-208988\n(1999)\n\n56. Malone,K.M.:Dynamic queueing systems : behavior and approximations for individual queues\nand for networks. Ph.D. thesis, Massachusetts Institute of Technology (1995)\n\n57. Mao, Z.H., Feron, E., Bilimoria, K.: Stability and performance of intersecting aircraft flows\nunder sequential conflict resolution. IEEE Trans. Intell. Trans. Syst. (2001)\n\nhttp://arXiv.org/abs/1508.04839v1\n\n\n4 Challenges in Aerospace Decision and Control: Air Transportation Systems 135\n\n58. Marks, B.L.: Air traffic control separation standards and collision risk. Technical Note 91,\nRoyal Aircraft Establishment (1963)\n\n59. May, G.: A method for predicting the number of near mid-air collisions in a defined airspace.\nOper. Res. Q. 22, 237\u2013251 (1971)\n\n60. Melnyk, R., Schrage, D., Volovoi, V., Jimenez, H.: Sense and avoid requirements for unmanned\naircraft systems using a target level of safety approach. Risk Anal. 34, 1894\u20131906 (2014)\n\n61. Melnyk, R., Schrage, D., Volovoi, V., Jimenez, H.: A third-party casualty risk model for UAS\noperations. In: Reliability Engineering and System Safety, vol. 124, pp. 105\u2013116. Elsevier\n(2014)\n\n62. Menon, P.K., Sweriduk, G.D., Bilimoria, K.D.: New approach for modeling, analysis, and\ncontrol of air traffic flow. J. Guid. Control. Dyn. 27(5), 737\u2013744 (2004)\n\n63. Nakahara, A., Reynolds, T., White, T., Dunsky, R.: Analysis of a surface congestion manage-\nment technique at New York JFK Airport. In: AIAA Aviation Technology, Integration and\nOperations (ATIO) Conference. Virginia Beach, VA (2011)\n\n64. University of New South Wales, C.: Air traffic simulation\u2014atoms. http://www.cs.adfa.edu.au/\nresearch/details2.php?page_id=543 (2015). Accessed Feb 2015\n\n65. Oh, J., Feron, E.: Safety certification of air traffic conflict resolution algorithms involving more\nthan two aircraft. In: American Control Conference, vol. 5, pp. 2807\u20132811. Philadelphia, PA\n(1998)\n\n66. O\u2019Neill, M.G., Dumont, J., Hansman, R.: Use of hyperspace trade analyses to evaluate envi-\nronmental and performance tradeoffs for cruise and approach operations. In: AIAA Aviation\nTechnology, Integration and Operations (ATIO) Conference. IEEE (2012)\n\n67. Federal AviationAdministration telecommunication infrastructure review panel: Report on nov\n19, 2009 outage. http://www.faa.gov/air_traffic/publications/media/FTI_Phase1.pdf (2015).\nAccessed Feb 2015\n\n68. Park, P., Khadilkar, H., Balakrishnan, H., Tomlin, C.: High confidence networked control for\nnext generation air transportation systems. IEEE Trans. Autom. Control. (2014). To appear\n\n69. Park, P., Khadilkar, H., Balakrishnan, H., Tomlin, C.: Hybrid communication protocols and\ncontrol algorithms for NextGen aircraft arrivals. IEEE Trans. Intell. Trans. Syst. (2014). To\nappear\n\n70. Pfaender, H., Jimenez, H., Mavris, D.: Effects of technology R&D investments on system level\nperformance. In: Proceedings of the 2013 Aviation Technology, Integration, and Operations\nConference. American Institute of Aeronautics and Astronautics (2013)\n\n71. Pujet, N., Delcaire, B., Feron, E.: Input-output modeling and control of the departure process\nof congested airports. In: AIAA Guidance, Navigation, and Control Conference and Exhibit,\nPortland, OR pp. 1835\u20131852 (1999)\n\n72. Pyrgiotis, N., Malone, K., Odoni, A.: Modelling delay propagation within an airport network.\nTrans. Res. Part C: Emerg. Technol. (2011)\n\n73. Ramanujam, V., Balakrishnan, H.: Estimation of Arrival-Departure Capacity Tradeoffs in\nMulti-Airport Systems. In: Proceedings of the 48th IEEE Conference on Decision Control\n(2009)\n\n74. Ren, L., Clarke, J.P., Ho, N.T.: Achieving low approach noise without sacrificing capacity. In:\nDigital Avionics Systems Conference, 2003. DASC\u201903. The 22nd, vol. 1, pp. 1-E. IEEE (2003)\n\n75. RTCA: Minimum Aviation System Performance Standard for Automatic Dependent Surveil-\nlance Broadcast (ADS-B) (2002). DO-242A\n\n76. Samad, T., Balas, G. (eds.): Software-Enabled Control: Information Technology for Dynamical\nSystems. Wiley, Hoboken (2003)\n\n77. Sampigethaya, K., Poovendran, R., Bushnell, L.: Secure operation, control and maintenance of\nfuture e-enabled airplanes. In: Proceedings of the IEEE, Special issue on Aviation Information\nSystems, vol. 96(12), pp. 1992\u20132007 (2008)\n\n78. Sampigethaya, K., Poovendran, R., Bushnell, L.: A framework for securing future e-enabled\naircraft navigation and surveillance. In: AIAA Infotech at Aerospace Conference. Seattle, WA\n(2009)\n\nhttp://www.cs.adfa.edu.au/research/details2.php?page_id=543\nhttp://www.cs.adfa.edu.au/research/details2.php?page_id=543\nhttp://www.faa.gov/air_traffic/publications/media/FTI_Phase1.pdf\n\n\n136 H. Balakrishnan et al.\n\n79. Sampigethaya, K., Poovendran, R., Shetty, S., Davis, T., Royalty, C.: Future e-enabled aircraft\ncommunications and security: the next 20 years and beyond. Proc. IEEE 99(11), 2040\u20132055\n(2011)\n\n80. Schaper, M., Tsoukala, G., Stavrati, R., Papadopoulos, N.: Departure flow control through\ntakeoff sequence optimisation: Setup and results of trials atAthens airport. In: 2011 IEEE/AIAA\n30th Digital Avionics Systems Conference (DASC), pp. 2B2-1. IEEE (2011)\n\n81. Shumsky, R.: Real-time forecasts of aircraft departure queues. Air Traffic Control. Q. 5(4)\n(1997)\n\n82. Shumsky, R.A.: Dynamic statistical models for the prediction of aircraft take-off times. Ph.D.\nthesis, Massachusetts Institute of Technology (1995)\n\n83. Simaiakis, I.: Analysis, Modeling and Control of the Airport Departure Process. Ph.D. thesis,\nMassachusetts Institute of Technology (2013)\n\n84. Simaiakis, I., Balakrishnan, H.: Dynamic control of airport departures: Algorithm development\nand field evaluation. In: American Control Conference (2012)\n\n85. Simaiakis, I., Khadilkar, H., Balakrishnan, H., Reynolds, T.G., Hansman, R.J.: Demonstration\nof reduced airport congestion through pushback rate control. Trans. Res. Part A: Policy and\nPract. 66, 251\u2013267 (2014)\n\n86. Simaiakis, I., Sandberg,M., Balakrishnan,H.: Dynamic control of airport departures: algorithm\ndevelopment and field evaluation. IEEE Trans. Intell. Trans. Syst. 15(1), 285\u2013295 (2014)\n\n87. Simpson, R.: Engineering of air traffic control systems. Technical report, Massachusetts Insti-\ntute of Technology, Flight Transportation Laboratory (1993)\n\n88. Spearman, M., Zazanis, M.: Push and pull production systems: Issues and comparisons. Oper.\nRes. 521\u2013532 (1992)\n\n89. Stroiney, S., Levy, B., Khadilkar, H., Balakrishnan, H.: Assessing the impacts of the JFK\nGround Metering Program. In: IEEE Digital Avionic Systems Conference (DASC) (2013)\n\n90. Sun, D., Bayen, A.: Multicommodity Eulerian-Lagrangian large-capacity cell transmission\nmodel for en route traffic. J. Guid. Control. Dyn. 31(3) (2008)\n\n91. Lozano-P\u00e9rez, T.: T., Wesley, M.: An algorithm for planning collision- free paths among poly-\nhedral obstacles. Commun. ACM 22(10), 560\u2013570 (1979)\n\n92. Tsitsiklis, J.: Neuro-Dynamic Programming. Athena Scientific, Cambridge (1996)\n93. Delft, T.U., Planning, D.T.: Why traffic management works. http://www.citg.tudelft.nl/\n\nen/about-faculty/departments/transport-and-planning/traffic-management-and-traffic-flow-\ntheory/challenges/why-traffic-management-works/ (2015). Accessed Feb 2015\n\n94. Vranas, P., Bertsimas, D., Odoni, A.: The multi-airport ground-holding problem in air traffic\ncontrol. Oper. Res. (1994)\n\n95. Waggoner, B.: Developing a risk assessment tool for unmanned aircraft system operations.\nPh.D. thesis, University of Washington (2010)\n\n96. Wambsganss, M.: Collaborative decision making through dynamic information transfer. Air\ntraffic Control. Q. (1996)\n\n97. Weibel, R., Hansman, R.: An integrated approach to evaluating risk mitigation measures for\nUAV operational concepts in the nas. In: Proceedings of InfoTech at Aerospace: advancing\ncontemporary aerospace technologies and their integration, pp. 509\u2013519 (2005)\n\n98. Weiss, J.: Protecting Industrial Control Systems From Electronic Threats. Momentum Press,\nNew York (2010)\n\n99. Wieland, F.: The detailed policy assessment tool (DPAT). In: Proceedings of the Spring\nINFORMS Conference (1997)\n\nhttp://www.citg.tudelft.nl/en/about-faculty/departments/transport-and-planning/traffic-management-and-traffic-flow-theory/challenges/why-traffic-management-works/\nhttp://www.citg.tudelft.nl/en/about-faculty/departments/transport-and-planning/traffic-management-and-traffic-flow-theory/challenges/why-traffic-management-works/\nhttp://www.citg.tudelft.nl/en/about-faculty/departments/transport-and-planning/traffic-management-and-traffic-flow-theory/challenges/why-traffic-management-works/\n\n\nChapter 5\nFrom Design to Implementation: An\nAutomated, Credible Autocoding Chain\nfor Control Systems\n\nTimothy Wang, Romain Jobredeaux, Heber Herencia,\nPierre-Lo\u00efc Garoche, Arnaud Dieumegard, \u00c9ric Feron\nand Marc Pantel\n\n5.1 Introduction\n\nA wide range of today\u2019s real-time embedded systems, especially their most critical\nparts, relies on a control-command computation core. The control-command of an\naircraft, a satellite, a car engine, is processed into a global loop repeated during the\nactivity of the controlled device. This loop models the acquisition of new input val-\nues via sensors, either from environment mesures (wind speed, acceleration, engine\nRPM, \u2026) or from human feedback through, for example, the brakes, the accelerator,\nthe stick or wheel control.\n\nT. Wang (B) \u00b7 R. Jobredeaux \u00b7 \u00c9. Feron\nGeorgia Institute of Technology, Atlanta, GA, USA\ne-mail: timothy.wang@gatech.edu\n\nR. Jobredeaux\ne-mail: romain.jobredeaux@gatech.edu\n\n\u00c9. Feron\ne-mail: feron@gatech.edu\n\nH. Herencia\nGeneral Electric Global Research, Clifton Park, NY, USA\ne-mail: heber.herencia-zapana@ge.com\n\nP.-L. Garoche\nONERA\u2014The French Aerospace Lab, Toulouse, France\ne-mail: pierre-loic.garoche@onera.fr\n\nA. Dieumegard \u00b7 M. Pantel\nENSEEIHT, Toulouse, France\ne-mail: arnaud.dieumegard@enseeiht.fr\n\nM. Pantel\ne-mail: marc.pantel@enseeiht.fr\n\n\u00a9 Springer-Verlag Berlin Heidelberg 2016\nE. Feron (ed.), Advances in Control System Technology\nfor Aerospace Applications, Lecture Notes in Control\nand Information Sciences 460, DOI 10.1007/978-3-662-47694-9_5\n\n137\n\n\n\n138 T. Wang et al.\n\nThe cost of failure of such systems is significant, and examples of such failures are\nnumerous, in spite of increasingly high certification requirements. In addition, as the\nFederal Aviation Administration (FAA) works on defining the proper frame to open\nthe airspace to Unmanned Aerial Systems (UAS), a major market is about to bloom\nand will benefit from automated and simple tools to facilitate product certification.\nCurrent analysis tools focus mainly on simulations. One obvious shortcoming is\nthe impossibility to simulate all the possible scenarios the system will be subject\nto. More advanced tools include static analysis modules, which derive properties\nof the system by formally analyzing its semantics. However, in the specific case of\ncontrol systems, analyzing the computational core can prove arduous for these tools,\nwhereas the engineers who designed the controller have a variety of mathematical\nresults that can greatly facilite this analysis, and evince more subtle properties of the\nimplemented controller.\n\nThere are many modern techniques to analyse software. Model checking is one\nthat endeavors to automatically prove safety-properties of finite-state systems [1].\nIt is widely used in industry as recent developments have made SAT solvers and\nSMT solvers much more efficient and scalable [2, 3]. Unfortunately, control software\nremains subject to an explosion of the state-space, making the use of these techniques\ndifficult for this research.\n\nAbstract interpretation has proven to be a powerful, scalable technique to prove\nlow-level properties of code. It was successfully applied on the Airbus A380 code to\nprove the absence of runtime errors caused by buffer overflow or index out-of-bound\nfailures [4]. The choice of a proper abstract domain and good widening/narrowing\nheuristics remains a difficult one. In particular, there is no good lattice structure on\nthe domain of ellipsoids, crucial to many results of control theory. Finally, some\ncontrol systems require highly non-linear Lyapunov functions in their proof of sta-\nbility, involving transcendental functions that no current domain encompasses, to our\nknowledge. Feret\u2019s work [5, 6] is a practical approach to the problem of extracting\nquadratic invariants in an abstract interpretation framework. Its goal is to address the\nneed by Astr\u00e9e [7] to handle the linear filters present in Airbus\u2019 real time software.\nPrevious work [8] by Monniaux addressed the same class of systems but not on actual\ncode. Both of these efforts address a strict subset of the systems we consider in this\nwork.\n\nThis chapter, following previous efforts aimed at demonstrating how control-\nsystemic domain knowledge can be leveraged for code analysis [9, 10], describes a\npractical implementation of a fully automated framework, which enables a control\ntheorist to use familiar tools to generate credible code, that is, code delivered with\ncertificates ensuring certain properties will hold for all executions.\n\nThe focus is on a specific class of controllers and properties, in order to achieve\nfull automation; it also explores various possible extensions.\n\nThe chapter is structured as follows: We first present a high level view of the\ngeneral framework in Sect. 5.2. We then proceed to describe how control semantics\ncan be expressed at different levels of design, in Sect. 5.3. Section 5.4 describes\nthe translation process by which graphical synchronous languages familiar to the\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 139\n\ncontrol theorist can be turned into credible code. Section 5.12 demonstrates how a\nproof of correctness can be automatically extracted from the generated code and its\nannotations.\n\n5.2 Credible Autocoding Framework\n\nAutocoding is an automated programming process that transforms a system expressed\nin a high-level modeling language such as Simulink or SCADE into a low-level imple-\nmentation language such as C. In credible autocoding, the code is generated along\nwith mathematically verifiable guarantees of functional correctness. The concept of\ncredible autocoding is analogous to credible compilation in [11]. Both processes\ngenerate formally verifiable evidences that the output correctly preserves certain\nsemantics of the input. The evidences can be independently checked for correctness\nby the certification authorities. Unlike credible compilation of Rinard, the formally\nverifiable evidences of interest in this research are the high-level functional properties\nof control systems which include stability, robustness and performance. An alternate\napproach towards producing guarantees for autocoder is building a formally verified\nautocoder. In a formally verified autocoder, each block transformations are mathe-\nmatically proved to be correct. This approach is technically challenging and has yet\nto be demonstrated to be feasible.\n\nData-flow modeling languages such as Simulink or SCADE are the default indus-\ntry choice for Model-based development of safety-critical control systems. Within\nthis framework of software development, systems are build using a language of high-\nlevel abstraction in order to facilitate rapid design and prototyping. The source code\nis then generated automatically from the input model using an automated code gener-\nation tool or an autocoder. The trustworthiness of the autocoder has often been ques-\ntioned in the industry [12]. In a data-flow language environment such as Simulink,\nthere are two major elements: \u201cblocks\u201d, and \u201clines.\u201d The blocks are functions that\nperform some operations on its input(s) and then output the result(s). The lines are\ndirected edges that flow from an origin block\u2019s output to a destination block\u2019s input.\nThis type of connectivity specifies that the origin output is equivalent to the destina-\ntion input. The blocks are organized into sets of blocks, forming a library of blocks.\nSome of the blocks have unpredictable variations in their semantics. For example,\nthe precise semantics of the Simulink product block depends on its input types, input\ndimensions, number of input/output, product operator selected, etc. The variations in\nSimulink block semantics, and the lack of formal documentation about them, present\nan obstacle in its wide adoption for safety-critical production. A related work [13],\nwhich is complementary to this research used a model-based approach, to assign\nprovably correct semantics to a set of Simulink blocks. The result of that research is\na library of trustworthy blocks\u2014the BlockLibrary language\u2014with precise semantics,\nthat can be reasoned about formally.\n\nIn the framework of credible autocoding, instead of proving that individual block\ntransformations are correct i.e. building the library of trustworthy blocks, the goal is to\n\n\n\n140 T. Wang et al.\n\nbe able to show that the output code also satisfies the high-level functional properties\nof the input model. The functional properties of the input model is dependent on the\ndomain of the input model. In the domain of control systems, a strong functional\nproperty is an exponential stability of the closed-loop system with a global domain of\nattraction, and a weaker functional property is simply the boundedness of the system.\nIn the domain of convex optimization, an example property is the linear convergence\nof the duality gap function to zero. The verification of the code against high-level\nfunctional property imparts an additional layer of guarantee on the correctness of\nthe code. For example, if a gain in a Simulink model was inverted accidentally\nbefore autocoding, the output code while correct in the sense of each individual\nblock transformations, is not likely to satisfy a pre-computed property such as the\nLyapunov stability of the system.\n\nThe complete credible autocoding process from Simulink model to verified code,\nfor the domain of control systems, is illustrated in Fig. 5.1. In this process, the credible\nautocoding portion (left half of Fig. 5.1) is performed by the code producers, who\ngenerate the code and provide evidence that the generated code is correct. The proof-\nchecking portion (right half of Fig. 5.1) are performed by the certification authorities\nwho are independent from the code producers. The only shared knowledge between\nthese two parties is a common language used to express the mathematical proofs on\nthe code. The control semantics include stability property of the system and the plant\nmodels used in the stability analysis for the closed-loop cases. The framework adds,\non top of a classic model-based development cycle, another layer of translations,\nthat converts quadratic invariant sets, computed using Lyapunov-based methods,\ninto code annotations on the code, which form a proof of the correctness of the\noutput code.\n\nFor credible autocoding of control software, compared against the traditional\nmodel-based development, the only additional requirement on control engineers is\n\nFig. 5.1 Automated credible autocoding/compilation chain for control systems\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 141\n\nthat they provide the Lyapunov function. The procedure for generating Lyapunov-\ntype certificate of stability and performance properties of control systems can be\nautomated using Linear Matrix Inequalities [14] (LMIs) and the Integral Quadratic\nConstraint [15] (IQC) framework. Each of the stability and performance properties\ngenerated can be encoded using an ellipsoid invariant, which can then be transformed\ninto an invariant for the code.\n\nThe advantages of the framework developed in this chapter can be summarized\nas follows:\n\n1. All the advantages of model-based development are inherited.\n2. The correctness of the autocoder is more or less guaranteed by the correctness\n\nof its output code. This is based on the idea of credible compilation in [11]. This\nreduces the need to formally verify the autocoder.\n\n3. The framework provides guarantees are of high-level functional properties, which\nprovides a potentially more useful characterization of the correctness of the system\nto the certification authorities.\n\n4. The framework can provide feedback information to the domain expert so errors\nin the construction of the model could be diagnosed more rapidly.\n\n5. In the context of certification, credible autocoding could potentially reduce the\nnumber of tests required for certification of the control software. In traditional\nunit testing, a piece of code, such as the control software is tested repeatedly for\nmany possible different inputs and scenarios. This is extremely time consuming.\nThe credible autocoding framework enables a meta-testing procedures, in which\nthe software, are tested for all possible inputs and scenarios, in one iteration.\n\n5.2.1 Input and Output Languages of the Framework\n\nThe input language of the framework should be a graphical data-flow modeling\nlanguage such as Simulink that is familiar to control engineers. The exact choice\nfor the input language is up to the domain users\u2019 preference and does not affect the\nutility of the framework as it can be eventually adapted to other modeling languages\nsuch as SCADE [16]. For the prototype tool-chain developed in this research, the\nchoice of the input language is a discrete-time subset of Simulink blocks. The subset\nof Simulink language include basic blocks: unit delays, gain, input, output, plus,\nminus, multiplication, divide, min, and max.\n\nLikewise, for the output language, the choice is likely to depend on the prefer-\nences of the industry and the certification authority. For the experimental prototype\ndescribed in this chapter, the output language was chosen to be C because of its\nindustrial popularity and the wide availability of static analyzers tailored for C code.\n\nThe set of annotations in the output source code contains both the functional\nproperties inserted by the domain expert and the proofs, which can be used to auto-\nmatically prove these properties. For the analysis of the annotated output, a prototype\nannotation checker that is based on the static analyzer frama-C and the theorem prover\n\n\n\n142 T. Wang et al.\n\nFig. 5.2 Test platforms. a Quanser helicopter (\u00a9 Quanser), b DGEN 380 lightweight turbofan\nengine (\u00a9 Price Induction)\n\nPVS is built. For automating the proof-checking of the annotated output, a set of lin-\near algebra definitions and theories were integrated into the standard NASA PVS\nlibrary [10].\n\nIn this chapter, the fully automated process from the input model to the verified\noutput is showcased for the property of close-loop stability. At this point, we restrict\nthe input space to only linear controllers with possible saturations in the loop. The\nrunning example that we use in this paper is described by the state-space difference\nequation in Example 5.1. This example is chosen because it has enough complexity\nto be representative of many controllers used in the industry, and is simple enough\nsuch that we can show in this paper, the output annotated code. The example system\nis consisted of states x ? R2, input y ? R, output u ? R, the state-transition function\nin (5.1), and the output function in (5.2).\n\nExample 5.1\n\nx+ =\n[\n\n0.4990 ?0.05\n0.01 1\n\n]\nx +\n[\n\n0\n0.01\n\n]\ny (5.1)\n\nu = [564.48 0] x + [1280] y. (5.2)\nIn addition to the two dimensional example used in this chapter, we have worked\nwith several larger systems shown in Fig. 5.2, which include the Quanser 3-degree-\nof-freedom Helicopter, and a FADEC control system of a small twin jet turbofan\nengine [17]. The state-space size of the engine FADEC controller is 11.\n\n5.3 Control Semantics\n\nThe set of control semantics that we can express on the model includes stability and\nboundedness.\n\nRemark 5.1 The types of systems in which we can express closed-loop stability\nproperties for are not just limited to simple linear systems like Example 5.1. They\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 143\n\nalso include nonlinear systems that can be modeled as linear systems with bounded\nnonlinearities in the feedback loops.\n\n5.3.1 Control System Stability and Boundedness\n\nA simple linear system such as Example 5.1 is commonly represented using the\nfollowing state-space formalism. For matrices A ? Rn\u00d7n, B ? Rn\u00d7m, C ? Rk\u00d7n, and\nD ? Rk\u00d7m, we have\n\nx+ = Ax + By\nu = Cx + Dy (5.3)\n\nThis state-space system has the state-transition function ? : (x, y) ? Ax + By and\nthe output function ? : (x, y) ? Cx + Dy. We also consider linear systems with\nbounded nonlinearities in their feedback interconnections. This model is a closer\nrepresentation of the real control systems when there are saturations, time-delays,\nanti-windup mechanisms, hysteresis, or noise in the loop. For y? = ? (t, y) with the\ntime-varying nonlinear function ?(t, y), in which y?i ? Miy for Mi > 0, we have\n\nx+ = Ax + By?\nu = Cx + Dy? (5.4)\n\nAnalogous to system (5.3), the state-transition function for (5.4) is ? : x, y ?\nAx + B?(t, y), and the output function is ? : (x, y) ? Cx + D?(t, y). For any\nsystems described by (5.3) and (5.4), we can compute efficiently the answer to the\nfollowing problem.\n\nProblem 5.1 1. Does there exist a symmetric matrix P ? Rn\u00d7n such that the\nquadratic function q : x ? xTPx is non-increasing along the system trajectories\nas t ? +??\n\nGenerally speaking such a problem can be transformed into a linear matrix\ninequality (LMI). The details of these transformations are skipped here as they are\nwell-established in the control literature [14, 18]. The algorithms used to solve LMIs\nare based on semi-definite programming, which is tractable up to large sizes [19].\n\n5.3.2 Prototype Tool-Chain\n\nIn this chapter, we describe a prototype tool-chain, which has been developed for\nthe demonstration of credible autocoding. The prototype tool-chain is split into a\ncredible autocoder front-end and a proof-checker back-end. The credible autocoder\nfront-end translates the model into annotated code. The proof-checking back-end\n\n\n\n144 T. Wang et al.\n\nanalyzes the annotated code produce by the front-end and decides whether or not the\nproof is coherent.\n\nGene-Auto [20\u201323] is an existing, open-source, autocoding prototype for embed-\nded systems. The front-end prototype in our tool-chain, which we dubbed Gene-\nAuto+, is based on Gene-Auto. For the front-end, we have several extensions to the\nlanguage or language environments Simulink, Gene-Auto and ACSL. ACSL [24] is\na formal specification language for C programs. More details on ACSL is described\nin Sect. 5.3.7. The language extensions are summarized as follows:\n\n1. A library of Annotation blocks in Simulink and Gene-Auto.\n2. An ACSL-like language within Gene-Auto.\n3. Abstract types and their operators in ACSL: matrix, vector and quadratic predi-\n\ncates.\n\nThe language extensions in Simulink and Gene-Auto are described in Sect. 5.3.3.\nThe language extensions in ACSL are described in Sect. 5.3.7.\n\n5.3.3 Control Semantics in Simulink and Gene-Auto\n\nAn observer (see [25]) in Simulink takes an input signal and returns an output of 1\nif the input satisfies a specific property, and 0 if otherwise. Both boundedness and\nstability can be expressed, for example, using an observer with inputs xi, i = 1, . . . , n,\nand the boolean-valued function\n\nx ?\n?\n\ni,j=1,...,n\nxiPijxj ? 1. (5.5)\n\nTo express the types of observers in (5.5) as annotations on the Simulink model,\nwe extended the Simulink language and the Gene-Auto environment with a set of\nannotation blocks.\n\nAnnotation blocks are structurally the same as any other Simulink blocks. The\nkey difference is that they do not translate into code. Our prototype annotation block\nlibrary has been built to contain a minimal set of blocks needed to express the\nproperties of control systems that are currently verifiable from Simulink to C code.\n\nThe prototype annotation block library contains four symbols: vamux, constant,\nquadratic, and system. Each annotation symbol denotes an annotation block type, To\nillustrate the annotations blocks, we have Fig. 5.3, which shows a Simulink model\nof an engine controller, along with 6 annotation blocks. The annotation blocks are\nhighlighted in red for the purpose of clarity.\n\nIn Simulink, the vamux block type takes n scalar or vector inputs xi, and outputs\n\na concatenated signal y = [xT1 , . . . , xTn\n]T\n\n. In Fig. 5.3, there are three vamux blocks,\nlabeled as nh, xc(t) and yd(t). The vamux block type only accepts one parameter,\nwhich determines the number of inputs to the block type. The vamux block does not\nexpress any property of the system. In Gene-Auto+, the main functionality of the\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 145\n\nFig. 5.3 Simulink model with annotation blocks\n\nvamux block is to establish equivalence relations between its inputs and the ith entry\nof its output. i.e. xi == yi. This enables the prototype to replace the pseudo-variables\nin the templates within the other annotation blocks with the actual variables from the\ncode.\n\nThe constant block type accepts one scalar, vector, or matrix input x, and a constant\nmatrix parameter [c1] or [c1, . . . , cn] for n ? N. The type of the constants ci are\nconstrained to be the same type as the input x. The output of the block is the boolean\nvalue x == c1 or?ni=1 (x == ci), which implies n sets of behaviors for the code.\nDefinition 5.1 A behavior is a set of unique assumptions on the parameters and\ninput, and output of the model.\n\nThis block type is useful for expressing the semantics of parameter varying sys-\ntems such as a gain-scheduled controller. For example, the scheduling parameter\nof the controller in Fig. 5.3 is the input NH, which is annotated with a constant\nblock labeled sampled_nh. In Gene-Auto+, the constant block type generates a set\nof assumption(s) {x == ci}, i = 1, . . . , n.\n\nThe quadratic block type accepts one input vector of n variables x, a matrix\nparameter P ? Sn\u00d7n, a logic connective symbol ? ? {<=,<,>,==}, a level-set\nconstant c ? R, and outputs the boolean value of xTPx ? c. The quadratic block type\ncan be used, for example, to express ellipsoidal invariant sets, sector-bound inequal-\nities, 2-norm squared, sum of squares polynomial sets, etc. The quadratic block\nalso accepts a positive scalar parameter mu. This is used to indicate the multiplier\ncomputed in stability analysis. The quadratic block type behaves like an ellipsoid\nobserver from (5.5) in Simulink. In Gene-Auto+, the quadratic block type generates\na predicate defined on its inputs: ?x.xTPx ? c. For example, in Fig. 5.3, the quadratic\nblock labeled stability represents a claim that xc(t) does not violate a quadratic con-\nstraint. The other quadratic block bounded_input is used to express a bound on the\ninput yd(t) to the controller.\n\n\n\n146 T. Wang et al.\n\nThe system block type is parameterized by 4 matrices A, B, C, and D. An example\nof a Simulink model annotated with the system block can be found in Sect. 5.3.5.\nThe system block type accepts two vector inputs u and y. The output of the system\nblock type is the state x of the dynamical system\n\nx+ = Ax + Bu, x(0) = x0\ny = Cx + Du. (5.6)\n\nThe semantics of the system block in Gene-Auto include the semantics of the discrete-\ntime linear state-space system in (5.6), and a set of relations {y?i == yi, ui = u?i} that\nestablish equivalence between the annotation variables y and u and their correspond-\ning variables y? and u? from the controller model. The system block type can be used, for\nexample, to express a model of the plant the controller is expected to interact with.\nThe same controller model can be annotated with multiple system blocks, which\nresults in multiple sets of predicates for the code, which can be annotated using the\nbehavior keyword from ACSL.\n\n5.3.4 Annotation Blocks and Behaviors in the Model\n\nIn a model, multiple system blocks s1, . . . , sn can be connected to the same set of\nvamux blocks. This results in a set of n behaviors expressed by the formula\n\n?n\ni si. If\n\nthere are n system blocks connected to the controller model, then there are n behaviors\nin the model.\n\nIf there are also k constant blocks in the model, each connected to a different\nvamux block, and each with m behaviors, then we have a total of mk behaviors\nresulting from the constant blocks:\n\n?k\ni\n\n(?m\ni ci\n)\n. The complete set of behaviors in\n\nthe model resulting from both the system and constant blocks is described by the\nformula (\n\nk?\ni\n\n(\nm?\ni\n\nci\n\n))\n?\n(\n\nn?\ni\n\nsi\n\n)\n(5.7)\n\nor a total of nmk possible behaviors.\nLastly, if there are w quadratic blocks in the model as well, and all of them are\n\nconnected to the same set of vamux block, then we have w number of behaviors ?wi qi\ndue to the quadratic blocks. Combining this set of behaviors conjunctively with the\nset of behaviors generated by the system and constant blocks results in\n\n(\nk?\ni\n\n(\nm?\ni\n\nci\n\n))\n?\n(\n\nn?\ni\n\nsi\n\n)\n?\n(\n\nw?\ni\n\nqi\n\n)\n(5.8)\n\nfor a possible total of wnmk behaviors in the model. However, each of the quadratic\nblocks that encode an inductive property such as stability are typically assigned a\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 147\n\nbehavior generated by a system block. This is true for many examples, in which the\nquadratic invariant is computed based on some plant model, using independent LMI-\nbased tools. For example, if there are n quadratic invariants and each is assigned a\nbehavior from a system block, then there are only n behaviors in the model:\n\nn?\ni\n\n(si ? qi) . (5.9)\n\nThis is far less than the explosion in the number of of behaviors predicted by (5.8).\nNext, some annotated examples are given. Each example contains a different\n\npossible set of control semantics.\n\n5.3.5 Closed-Loop Stability with Bounded Input\n\nFor the running example, the closed-loop stability of the system with bounded input\nis expressed with a set of the system and quadratic blocks. For example, as displayed\nin Fig. 5.4, the close-loop stability of the Simulink model of the control systems is\nexpressed using:\n\n1. a quadratic block stability to express the ellipsoidal invariant set that encodes the\nclosed-loop stability of the system.\n\n2. another quadratic block bounded_input to express a 2-norm bound on the input,\n3. a system block plant, which expresses the discrete-time linear state-space system\n\nused in the closed-loop stability analysis\n\nFig. 5.4 Control system model annotated with control semantics\n\n\n\n148 T. Wang et al.\n\n5.3.6 Expressing the Observer-Based Fault-Detection\nSemantics\n\nIn an observer-based fault-detection system, the dynamics of the observer are\ndesigned such that the output of the observer changes due to specific faults in the\nplant. Once the change exceeds a certain pre-defined threshold, the system is said\nto be in the faulty mode. To express the faulty and nominal behavior of a fault-\ndetection system, one can use two different system blocks. One system block is the\nmodel of the faulty plant that is predicted to trigger the faulty mode and the other\nis the nominal plant. This is displayed in Fig. 5.5. The quadratic blocks connected\nto the vamux blocks xf (t) and xn(t) express the closed-loop stability of the system.\nThey are assigned behaviors based on their physical connections to the system block.\nFor example, as displayed in Fig. 5.5, the block cl_faulty is connected to the sys-\ntem block quanser_faulty using the vamux block xf (t). The two quadratic blocks\n\nFig. 5.5 Expressing multiple behaviors: fault-detection system\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 149\n\nconnected to the vamux block xo(t) are used to express the stability of the observer\ndynamics. They are assigned the behaviors faulty and nominal, based on the labels\nin their names.\n\n5.3.7 Control Semantics at the Level of the C Code\n\nFor the specific problem of open loop stability, the expressiveness needed at the C\ncode level is twofold. On the one hand, one needs to express that a vector composed\nof program variables belongs to an ellipsoid. This entails a number of underlying\nlinear algebra concepts. On the other hand, one needs to provide the static analysis\ntools with indications on how to proceed with the proof of correctness.\n\nThe ANSI/ISO C Specification Language (ACSL), is an annotation language for\nC [24]. It is expressive enough to fulfill our needs, and its associated verification\ntool, Frama-C [26], offers a wide variety of back-end provers that can be used to\nestablish the correctness of the annotated code.\n\n5.3.7.1 Linear Algebra in ACSL\n\nA library of ACSL symbols has been developed to express concepts and proper-\nties pertaining to linear algebra. In particular, types have been defined for matrices\nand vectors, and predicates expressing that a vector of variables is a member of\nthe ellipsoid EP defined by {x ? Rn : xTPx ? 1}, or the ellipsoid GX defined by{\n\nx ? Rn :\n[\n\n1 xT\n\nx X\n\n]\n? 0\n}\n\n. For example, expressing that the vector composed of pro-\n\ngram variables v1 and v2 is in the set EP where P =\n(\n\n1.53 10.0\n10.0 507\n\n)\n, can be done with\n\nour ACSL extensions using the annotations in Fig. 5.6.\nThe invariance of ellipsoidEP throughout any program execution can be expressed\n\nby the loop invariant in Fig. 5.7. This annotation expresses that before and after every\nexecution of the loop, the property\n\n[\nv1 v2\n]T ? EP will hold. In terms of expressive-\n\nness, it is all that is required to express open loop stability of a linear controller.\nHowever, in order to facilitate the proof, intermediate annotations are added within\nthe loop to propagate the ellipsoid through the different variable assignments, as\nsuggested in [9] and expanded on in Sect. 5.4. For this reason, a loop body instruc-\ntion can be annotated with a local contract, as in Fig. 5.8.\n\nFig. 5.6 Asserting that a vector with components v1 and v2 belongs to ellipsoid EP in ACSL\n\n\n\n150 T. Wang et al.\n\nFig. 5.7 Expressing the invariance of EP on a loop in ACSL\n\nFig. 5.8 A local contract to assist the proof process\n\nFig. 5.9 Adding proof tactics to a contract to guide the proof back-end\n\n5.3.7.2 Including Proof Elements\n\nAn extension to ACSL, as well as a plugin to Frama-C, have been developed. They\nmake it possible to indicate the proof steps needed to show the correctness of a\ncontract, by adding extra annotations. For example, the syntax in Fig. 5.9 signals\nFrama-C to use the strategy AffineEllipsoid to prove the correctness of the\nlocal contract considered. Section 5.12 expands on this topic.\n\n5.3.8 Closed Loop Semantics\n\nIn order to express properties pertaining to the closed loop behavior of the system,\none needs to introduce a model for the plant, to be able to refer to the plant variables.\nThe most accurate way to do so would require a hybrid system representation, given\nthat the plant is commonly a continuous system, while the digital controller is a\ndiscrete one. A large body of work is devoted to proving meaningful properties of\nhybrid systems. In order to obtain actionable results, on which proof can be carried\nout, we made the choice of representing the plant as a linear system, discretized at\nthe same period as the controller. To achieve this, we use ACSL\u2019s ghost code feature.\n\nGhost code is a way to introduce variables and operations on these variables\nwithout affecting the semantics of the code. Any valid C code can be written in ghost\ncode as long it does not introduce a change in the actual variables.\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 151\n\nAt the end of the control loop, we use these variables to express the state update\nof the plant that results from the computed control signal value. We also enforce\naxiomatically the fact that the input read from the sensors equals the output of the\nplant.\n\nFor each state variable in the plant, we introduce a global ghost variable. Within\nthe update function of the controller, we introduce ghost code describing the state\nupdate resulting from the control output. A template of the structure of the code is\ngiven in Fig. 5.10.\n\n5.3.9 Control Semantics in PVS\n\nThrough a process described in Sect. 5.12, verifying the correctness of the annotated\nC code is done with the help of the interactive theorem prover PVS. This type of\nprover normally relies on a human in the loop to provide the basic steps required to\nprove a theorem. In order to reason about control systems, linear algebra theories\nhave been developed. General properties of vectors and matrices, as well as theorems\nspecific to this endeavor have been written and proven manually within the PVS\nenvironment [10].\n\n5.3.9.1 Basic Types and Theories\n\nIntroduced in [10] and available online1 as part of the larger NASA PVS library, the\nPVS linear algebra library allows one to reason about matrix and vector quantities,\nby defining relevant types, operators and predicates, and proving major properties.\nTo name a few, we have defined:\n\n\u2022 A vector type.\n\u2022 A matrix type, along with all operations relative to the algebra of matrices.\n\u2022 Various matrix subtypes such as square, symmetric and positive definite matrices.\n\u2022 Block matrices\n\u2022 Determinants\n\u2022 High level results such as the link between Schur\u2019s complement and positive def-\n\niniteness\n\n5.3.9.2 Theorems Specific to Control Theory\n\nIn [10], a theorem was introduced, named the ellipsoid theorem. A stronger version\nof this theorem, along with a couple other useful results in proving open loop stability\nof a controller, have been added to the library. The theorem in Fig. 5.11 expresses in\n\n1http://shemesh.larc.nasa.gov/fm/ftp/larc/PVS-library/.\n\nhttp://shemesh.larc.nasa.gov/fm/ftp/larc/PVS-library/\n\n\n152 T. Wang et al.\n\nFig. 5.10 Template of the update function with added plant semantics in ghost code. Note that\noften, the ghost code and the annotations are much larger than the code actually executed\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 153\n\nFig. 5.11 Affine ellipsoid transformation theorem in PVS\n\nFig. 5.12 Ellipsoid combination through S procedure theorem in PVS\n\nthe PVS syntax how a generic ellipsoid GQ is transformed into GMQMT by the linear\nmapping x ?? Mx.\n\nThe theorem in Fig. 5.12: expresses how, given 2 vectors x and y in 2 ellipsoids\nGQ1 and GQ2 , and multipliers ?1, ?2 > 0, such that ?1 + ?2 ? 1, it can always be\nsaid that\n\n(\nx\ny\n\n)\n? GQ, where Q =\n\n(\nQ1\n?1\n\n0\n\n0 Q2\n?2\n\n)\n\nThese 2 theorems are used heavily in Sect. 5.12 to prove the correctness of a given\nHoare triple. While they are not particularly novel, their proof in PVS was no trivial\nprocess and required close to 10000 manual proof steps from the authors.\n\n5.4 Autocoding with Control Semantics\n\nThe translation process in the credible autocoding prototype Gene-Auto+, is now\ndescribed in more details with a demonstration on the running example. From the\ninput model to the verified output, the property of open-loop and closed-loop stability\nfor a linear system with a nonlinear, but bounded input is expressed.\n\n5.5 Building the Input Model\n\nThe model with the closed-loop stability semantics is already displayed in Fig. 5.4.\nThe model expressing open-loop stability is displayed in Fig. 5.13.\n\n\n\n154 T. Wang et al.\n\nFig. 5.13 Open-loop stability\n\nIn either case, an assumption of boundedness is made on the input to the model and\nit is expressed by the quadratic block bounded_input. For the closed-loop case, the\nassumption of boundedness is made on the signal yd (see Fig. 5.4). For the open-loop\ncase, a similar boundedness assumption is made on the signal y ? yd (see Fig. 5.13).\nThe closed-loop quadratic invariant, expressing stability, is defined by the multiplier\nmu = 0.991, and P ? 0,\n\nP =\n\n?\n???\n\n0.1878 0.1258 ?0.0813 0.0149\n0.1258 0.3757 ?0.0220 0.0100\n\n?0.0813 ?0.0220 0.0660 ?0.0063\n0.0149 0.0100 ?0.0063 0.0012\n\n?\n??? . (5.10)\n\nLikewise, the stability analysis is also done for the open-loop case. The quadratic\ninvariants are inserted into their respective Simulink model using quadratic blocks.\nBoth of them are labeled as stability.\n\n5.6 Basics of Program Verification\n\nIn the translation process, we use several notions from formal program verification.\nFirst we have the following predicate notations for the annotations expressed in this\nsection. The ellipsoid sets are denoted using one of the following symbols:\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 155\n\np(P, x, c) ?\n{\nx ? Rn | xTPx ? c}\n\nq(Q, x, c) ?\n{\n\nx ? Rn |\n[\n\nc xT\n\nx Q\n\n]\n? 0\n}\n\n.\n(5.11)\n\nWithout loss of generality, the sublevel set parameter c is set to 1 unless described\notherwise.\n\nThe control semantics are translated into axiomatic semantics on the code.\nAxiomatic semantics is one of several approaches in theoretical computer science to\nassign mathematical meanings to a program [27]. In axiomatic semantics, the seman-\ntics or mathematical meanings of a program are defined using the logic predicates\nthat hold before the execution of the code and the ones that hold the execution of the\ncode. The main structure of axiomatic semantics is a Hoare triple [28].\n\nDefinition 5.2 A Hoare triple is the 3-tuple ({P} , C, {Q}), in which P is a predicate\nor a set defined by a formula in some logic, and Q is also another predicate, and C\ndenotes a block of code.\n\nThe symbol P denotes a post-condition and the symbol Q denotes a pre-condition.\n\nDefinition 5.3 A Hoare triple {P} , C, {Q} is interpreted to be partially correct, if P\nholds before the execution of C, and Q holds after the execution of C.\n\nRemark 1 The termination of C needs to be proved for correctness. For the rest of\nthis chapter, correctness refers to the notion of partial correctness.\n\nThe pre and post-conditions are expressed on the code as comments before and\nafter the block of code. For example, given the simple while program in Fig. 5.14,\nIf the statement |x| ? 1 holds before the execution of the loop, then it should hold\nfor all executions of the loop.\n\nDefinition 5.4 An invariant is a predicate that holds for all executions of the loop.\n\nThe statement |x| ? 1 is an invariant. It can be inserted into the code as both the pre-\ncondition and the post-condition, see the ACSL comments in Fig. 5.14. The Hoare\ntriple in Fig. 5.14, therefore is {|x| ? 1}while a do C end {|x| ? 1}.\n\nHere we give an illustration of Hoare triples on a Matlab implementation of x+ =\nAx+By (see Fig. 5.15). A Matlab example is used in this section and further on only for\nthe sake of brevity and clarity. In practice, a language like C is the typical choice for the\nimplementation of real-time control systems. We assume the Matlab example satisfies\n\nFig. 5.14 A while program in C\n\n\n\n156 T. Wang et al.\n\nFig. 5.15 Annotated lead/lag compensator in matlab\n\nsome ellipsoidal invariant p(P, x, 1), computed from a stability analysis [14]. The\ninvariance of p(P, x, 1), which is the property of interest, is translated into axiomatic\nsemantics for the Matlab code. This is done by translating the set q(P, x, 1), using\ntype matching, into the Matlab formula x*P*x<=1 and then inserting that formula\nas pre and post-condition for the program. The result is the annotated Matlab program\nin Fig. 5.15. Next, the basics of deductive program verification are described.\n\n5.6.1 Hoare Logic and Deductive Verification\n\nHoare logic is a formal proof system that comes with a set of axioms and infer-\nence rules for reasoning about the correctness of Hoare triples on various structures\nof an imperative programming language i.e. if-else statements, assignment\nstatements, while statements, for statements, empty statements, etc.\n\nFor example, an axiom in Hoare logic for the while program construct is\n\n{P ? a} C; {P}\n{P}while a do C end {\u00aca ? P} . (5.12)\n\nSyntactically speaking, the axioms and inference rules can be interpreted as follows:\nthe formula above the horizontal line implies the formula below that line. In the\nwhile axiom in (5.12), note that pre and post-conditions of the loop has to be\nsame formula. This means to verify program loops, an invariant is necessary. Some\nof the basic inferences rules for reasoning about imperative programs using Hoare\nlogic are listed in Table 5.1. The consequence rule in (5.13) is useful whenever a\nstronger pre-condition or weaker post-condition is needed. The term stronger here\nmeans the set defined by the predicate is smaller. The term weaker means precisely\nthe opposite. The substitution rule in (5.16) are used when the code is an assignment\nstatement. The weakest pre-condition expression P[x/expr] in (5.16) means P with\nall free occurrences of the expression expr replaced by x. For example, given a post-\ncondition y<=1 for the line of code y=x+1, one can deduct that x+1<=1 is a\nweakest pre-condition using the backward substitution rule in (5.16). The skip rule\nin (5.15) can be used when the executing piece of code does not change any variables\nin the pre and post-conditions.\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 157\n\nTable 5.1 Hoare logic inference rules for a imperative language\n\n{P1 =? P2}C{Q1 =? Q2}{P1}C{Q2} (5.13)\n{P}C1{R};{R}C2{Q}{P}C1;C2{Q} (5.14)\n\n{P}SKIP{P} (5.15) {P[e/x]}x:=expr{P} (5.16)\n\n1. {p(P,x,1)} a do C end{p(P,x,1)}.\n2. {p(P,x,1)}C{p(P,x,1)} by the axiom in (5.12).\n3. {p(P,A? x+B? y,1)}x = A?x+B?y{p(P,x,1)} by the backward substitution rule in (5.16).\n4. {p(P,A? x+B? y,1)}u=C ? x+B? y{p(P,Ax+By,1)} by the skip rule in (5.15).\n5. {p(P,x,1), p(P,A? x+B? y,1)}C{p(P,x,1)} by the composition rule in (5.14).\n6. if p(P,x,1) =? p(P,A?x+B?y,1), then {p(P,x,1)}C{p(P,x,1)} by the consequent rule in\n\n(5.13).\n\nFig. 5.16 Correctness of the program using Hoare logic deduction\n\nTo verify the Hoare triple in Fig. 5.15, use the inference rules from Table 5.1\non the code, starting from the post-condition x*P*x<=1.The process produces\nan alternate pre-condition q(P, A ? x + B ? y, 1) for the loop body. By the conse-\nquent rule, the correctness of the initial Hoare triple can be checked by checking if\np(P, x, 1) =? p(P, A ? x + B ? y, 1). The process in Fig. 5.16 is deductive. An\nalgorithmic reformulation of it is Dijstra\u2019s work on Predicate transformers [29]. By\nusing the Predicate transformers, the deductive process of Fig. 5.16 is reduced to a\ncomputational process that checks the correctness of first order formulas.\n\n5.6.2 Predicate Transformers\n\nThe Hoare triples on the code are computed using a form of the weakest pre-condition\ncalculus. The weakest pre-condition of C is a function wp that maps any post-\ncondition Q to a pre-condition. The output of the weakest pre-condition function\nwp(C, Q) is the largest set such that, after the execution of C, Q holds. For example,\nthe correctness of a Hoare triple, for a set of variables x in the code C, is determined\nby checking if the logic formula ?x, P =? wp(C, Q) holds. The wp function\ncan be applied to various constructs in an imperative programming language. Some\nexamples are given in Table 5.2. The sequence of Ii in (5.20) can be replaced by a\nsingle I if I is an invariant of the loop. Denote the while program as P , in the\ncase of partial correctness, wp(P, Q) = I is the weakest literal pre-condition if\nI =? wp(C, I). In the case of total correctness, wp(P, I) = I is the weakest\npre-condition, if I =? Q and the loop terminates. Recall the control program\nin Matlab from 5.15, which is comprised of a while loop and satisfies the invariant\np(P, x, 1), Apply wp-calculus to that program i.e. wp(P, p(P, x, 1)) = p(P, x, 1)\nleads to two logic formulas:\n\n\n\n158 T. Wang et al.\n\nTable 5.2 Weakest Pre-condition Calculus\nwp(C1; , ..., CN , Q) = wp(C1, wp(C2, wp(C3, ..., wp(CN , Q)) . . .) (5.17)\nwp(skip, Q) = Q (5.18)\nwp(x := e, Q) = Q[e/x] (5.19)\nwp(while a do C end, Q) = ?i ? N, Ii\nI0 = true (5.20)\nIi+1 = (\u00aca =? Q) ? (a =? wp(C, Ii))\n\n1. I =? Q and the loop terminates. The loop in 5.15 terminates after a finite\namount of iterations and clearly p(P, x, 1) =? p(P, x, 1) is true.\n\n2. I =? wp(C, I) i.e. p(P, x, 1) =? wp(C, p(P, x, 1)).\nThe second condition is harder to verify since the set wp(c, p(P, x, 1)) need to be\n\ncomputed. Notice the formula p(P, x, 1) =? wp(C, p(P, x, 1)) is equivalent to the\nHoare triple\n\n{p(P, x, 1), wp(C, p(P, x, 1)) C; {p(P, x, 1)} , (5.21)\n\nwhich means that p(P, x, 1) can be inserted as the pre and post-conditions of the\nloop body C in Fig. 5.15. Applied additional wp-calculus on the loop body results\nin the annotated code in 5.17. The set of pre-conditions generated by wp-calculus\ni.e. the displayed Matlab comments inside the loop in Fig. 5.17, along with the Mat-\nlab code itself, forms the translated proof of stability. Verifying this proof implies\nthat q(P, x, 1) is an invariant of the program, which is a strong evidence that the\nimplementation is good.\n\nFig. 5.17 Annotated lead/lag compensator in matlab\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 159\n\n5.6.3 Strongest Post-condition\n\nThe dual of weakest pre-condition is the strongest post-condition. The strongest post-\ncondition of C is a function that maps any pre-condition P to a post-condition. The\noutput of the strongest post-condition function sp(C, P) is the smallest set that holds\nafter the execution of C, given that P holds before the execution of C. To verify a\nHoare triple {P} C {Q} using sp-calculus, first compute sp(C, P) and then check that\nsp(C, P) ? Q.\n\n5.7 Translation Process for a Simple Dynamical System\n\nThis section describes the credible autocoding process for a simple dynamical system,\nusing a mixture of mathematics, C and ACSL.\n\nThe process starts with computing a quadratic invariant set for the system. Given\na dynamical system G defined by x+ = Ax, the ellipsoid set p(P, x, 1), constructed\nby solving ATPA ? P ? 0 for P ? 0, is also invariant w.r.t to G . The invariant\nproperty of p(P, x, 1) is the key that allows us to know a priori that the Hoare\nTriple {p(P, x, 1)}P2 {p(P, x, 1)}, in which P2 is a code implementation of G in\nFig. 5.18, is correct. Since P is invertible, then q(Q, x, 1) with Q = P?1 is equivalent\nto p(P, x, 1). The credible autocoder inserts q(Q, x, 1) as the pre and post-conditions\nof the program.\n\nUsing the weakest pre-condition function from (5.20) on q(Q, x, 1), one obtains\nq(Q, x, 1) as the pre and post-conditions of the loop body in P2. Note that the set\nq(Q, x, 1) is inserted into the code as pre and post-condition of the loop body. This is\ndisplayed in lines 7 and 8 of Fig. 5.18, with the loop body enclosed in curly braces.\n\nFig. 5.18 P2: code implementation of G\n\n\n\n160 T. Wang et al.\n\nNext, given the pre-condition q(Q, x, 1) on the loop body, the strongest post-\ncondition computations i.e. sp-calculus is performed on the code. Denote the body of\nthe while loop inP2 as B, the credible autocoding process computes sp(B, q(Q, x, 1))\nand then checks that sp(B, q(Q, x, 1)) ? q(Q, x, 1) to ensures the correctness of\n{q(Q, x, 1)} B {q(Q, x, 1)}.\n\nThe sp-calculus process uses ellipsoidal calculus. One of the techniques from\nellipsoidal calculus is the following regarding linear transformation of ellipsoidal\nsets.\n\nLemma 5.1 Given a set q(Q, x, 1), and given a linear transformation T, the image\nT(q(Q, x, 1)) is the set q(TQTT, x, 1).\n\nUsing the formula TQTT, we can compute a strongest post-condition for every\nline of code in B. Define Ci as the ith line of code in B. Denote xi as the state\n\nvector after the execution of Ci. For example, the state vector starts with x =\n[\n\nx1\nx2\n\n]\n\nbefore the execution of C1. The 2 lines of code C1 and C2 respectively assigns some\nvalues to the variable y1 and y2. The state vector\u2019s dimension increases and becomes\n\nx2 =\n\n?\n???\n\nx1\nx2\ny1\ny2\n\n?\n??? after the execution of C2. The state vector is x again after the execution\n\nof C4. Because the variables y1 and y2 are discarded from the state vector when they\nare not used in the code again. Next, given state vectors xi?1 and xi, and given the line\nof code Ci, the affine semantics of Ci is computed and then used in the construction\nof a linear transformation Ti from xi?1 to xi. For example, for C1, the code computes\nthe expression 0.4990 ? x1 + 0.1 ? x2 and assigns it to the variable y2. The affine\nsemantics of C1 is therefore y1 = Lx, in which L =\n\n[\n0.4990 0.1\n\n]\n. The state vector\n\nx0 is x and the state vector x1 is x1 =\n?\n?x1x2\n\ny1\n\n?\n?. Hence T1 =\n\n[\nI\nL\n\n]\n. Applying Lemma 5.1,\n\nthe strongest post-condition for Cm is\n\nq(\n1?\n\ni=m\nTiQ\n\nm?\ni=1\n\nTTi , xm, 1). (5.22)\n\nHence the strongest-post condition for B i.e. sp(B, q(Q, x, 1)) is q(Q4, x, 1), in which\n\nQ4 = T4T3T2T1QTT1 TT2 TT3 TT4 (5.23)\n\nThe computed post-conditions are inserted into P2 (see Fig. 5.19) as the neces-\nsary evidence for the proof-checking of P2. To verify that sp(B, q(Q, x, 1)) =?\nq(Q, x, 1), the inclusion condition q(Q4, x, 1) ? q(Q, x, 1) is checked. This can be\ndone using a Cholesky decomposition algorithm to check that Q ? Q4 ? 0.\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 161\n\nFig. 5.19 P2 annotated\n\n5.8 Gene-Auto+: A Prototype Credible Autocoder\n\nIn this section, some details of the prototype credible autocoder are given. The current\nprototype is capable of translating control semantics, described in Sect. 5.3.3 into\nverifiable ACSL annotations on the code.\n\n5.8.1 Gene-Auto: Translation\n\nGene-Auto\u2019s translation architecture is comprised of sequences of independent model\ntransformation stages. This classical, modular approach to code generator design has\nthe advantage of allowing relatively easy insertion of additional transformation and\nformal analysis stages, such as the annotation generation stage in the prototype.\nThe translation process goes through two layers of intermediate languages. The first\none, called the GASystemModel, is a data-flow language that is similar to Simulink.\n\n\n\n162 T. Wang et al.\n\nFig. 5.20 Translation in gene-auto+ versus gene-auto\n\nThe input Simulink model, after being imported, is first transformed into the system\nmodel. The system model, which is expressed in the GASystemModel language,\nis then transformed into the code model. The code model is in the GACodeModel\nlanguage representation, which has many similarities with imperative programming\nlanguages, such as C or Ada. The main translation modules within Gene-Auto, are\nthe importer, the block sequencer and typer, the GACodeModel generator, and the C\nprinter. For the prototype, we have recycled much of the transformation modules up to\nthe GACodeModel generator. For the translation of the control semantics, we added\na sub-module, dubbed the GAVAModel generator, to the GACodeModel generator.\nThe GAVAModel is the ACSL-like language extension in Gene-Auto+. For more\ndetails about it, including its meta-model, please see [30]. The GAVAModel language\nenables common ASCL constructs such as: behavior, assumes-statement, function\ncontract, require-statement, ensure-statement, and ghost code to be expressed within\nan intermediate representation in Gene-Auto+.\n\nFigure 5.20 summarizes the key differences between the translation process of\nGene-Auto and Gene-Auto+. The upper half of the figure shows the process in\nterms of languages and intermediate representations while the bottom part of the\nfigure shows the translation modules. Of the four language representations in the\ntranslation process, only the GASystemModel representation remains unchanged.\nThis is because, structurally speaking, the annotation blocks are identical to the\nnon-annotation blocks.\n\n5.8.2 Translation of Annotative Blocks\n\nThe annotation blocks are also first transformed into a GASystemModel represen-\ntation. This transformation step is unchanged from the original Gene-Auto as the\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 163\n\nFig. 5.21 Transformation of control semantics from GASystemModel to GAVAModel\n\nsame language is used to express both regular blocks and annotation blocks. In the\nGACodeModel generation stage, the blocks that express the control semantics are\nskipped since they are categorized as annotations. They are imported into the GAVA-\nModel generation sub-module. This sub-module first translates the annotative blocks\ninto a set of Hoare triple objects on the code model, and then translates the Hoare\ntriple objects into a GAVAModel representation. This new representation of the code\nmodel with axiomatic semantics is dubbed the annotated model.\n\nA high-level overview of the GAVAModel generator sub-module is summarized\nin Fig. 5.21. Following Gene-Auto\u2019s modular transformation architecture, the GAVA-\nModel sub-module is added as an independent stage within the GACodeModel gen-\neration module. The major stages in the translation of the annotation blocks into the\nannotated model are the following:\n\n1. The code model is converted into a control-flow graph structure X .\n2. The constant blocks are inserted into X .\n3. Constant propagation is executed with the definitions provided by the constant\n\nblocks.\n4. The system block is translated into two plant objects. A plant object is comprised\n\nof an affine transformations and a set of ghost code templates expressed in GAVA-\nModel. The plant objects are inserted into the beginning of X and the end of X .\nThe first plant object corresponds to the output function of the state-space sys-\ntem y = Cx. The second plant object corresponds to the state-transition function\nx+ = Ax + Bu.\n\n5. The quadratic blocks are grouped based on their inputs as either inductive or\nassertive. They are translated into ellipsoid objects and inserted into appropriate\nlocations within X .\n\n\n\n164 T. Wang et al.\n\n6. The strongest post-condition is computed using sp-calculus. In this process, ellip-\nsoid objects are generated for almost every line of code and then inserted into the\ncode model.\n\n7. The ellipsoid and plant objects in the annotation model are translated into anno-\ntations expressed in GAVAModel.\n\n5.9 Translation and Insertion of the System Block\n\nThe system block, which represents the model of the plant, is split into two plant\nobjects representing two linear transformations: y = Cx and x+ = Ax + Bu. One\nobject is inserted into the beginning of the compute function and the other part\nis inserted afterwards. The compute function is the function that implements the\ncontroller loop body. The two linear transformations are used in the sp-calculus to be\ndescribed later. The GAVAModel templates, contained within the two plant objects,\nare translated into a set of ACSL ghost code statements. The set of ACSL ghost code\nstatements, generated from the closed-loop example, is displayed in Fig. 5.22.\n\nFig. 5.22 Ghost code representation of the plant dynamics\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 165\n\n5.10 Translation of the Quadratic Blocks\n\nA short description of the typing of the quadratic blocks and their translations is\ngiven here. The semantics of closed-loop stability are structured in such way that\nthere is one inductive ellipsoid set (the Lyapunov function), on the model with another\nellipsoid set on the input (bounded input).\n\n5.10.1 Types of Quadratic Blocks\n\nThe quadratic blocks are separated into two main groups. The first group include\nthe blocks that are inductive. These encode the stability property of the system.\nTo determine if a quadratic block is inductive, the following properties must be\ncomputed:\n\n1. Every one of the quadratic block\u2019s input ports must be connected to a port of an\nunit delay block or to an output port of a system block.\n\n2. Given a setU that contains all unit delay blocks connected to the quadratic block.\nFor every unit delay blocks in U , there exists a path from its output node to its\ninput node on the system model.\n\nThe second group contains the assertive blocks. These blocks are used to either\nexpress boundedness of inputs or sector-bound conditions. Any quadratic blocks\nwith one or more input connected to a block that is neither unit delay nor system is\ncategorized as an assertive block. The sector-bound blocks are detected by checking\nto see if the level-set parameter c in the block is set to 0.\n\nAfter the quadratic blocks have been categorized, the bounded-input and inductive\nblocks are translated into ellipsoid objects containing the Schur form of p(P, x, 1)\ni.e. q(Q, x, 1) such that Q = P?1. This conversion is necessary as all subsequent\nsp-calculus are done in the Schur form due to the possibility of Qi in q(Qi, xi, 1)\nbeing singular.\n\n5.10.2 Insertion of Ellipsoid Objects\n\nAn assertive ellipsoid invariant q(Q, x, 1) is inserted into a location that is dependent\non x. If any of the variable in x is an input argument of the compute function,\nthen algorithm will back propagate using wp-calculus until x only contains either\nvariables that are input arguments of the compute function, or affine expressions of\nthe variables that are input arguments of the compute function.\n\nThe wp-calculus starts, if needed, after the assertive ellipsoid q(Q, x, 1) has been\ninserted as a post-condition for the last line of code, in which, a variable belonging\nto x is assigned. For example, consider the annotation block bounded_input in the\nopen-loop case, which expresses a boundedness assumption on the signal y ? yd .\n\n\n\n166 T. Wang et al.\n\nFig. 5.23 wp-calculus on an ellipsoids expressed in ACSL\n\nThe signal y ? yd also corresponds to the variable Sum4 in Fig. 5.23. The annotation\nblock is translated into an assertive ellipsoid object and is inserted into the code as a\npost-condition of Sum4=simple_olg_y-simple_olg_y_input. This post-\ncondition is displayed in the last ACSL contract of Fig. 5.23. Since the variableSum4\nis not an argument of the compute function, the insertion algorithm starts the wp-\ncalculus, until x?n in Q(Q, x?n, 1) only contains variables that are input arguments of\nthe compute function. For this case, the wp-calculus terminated when the ellipsoid\nin line 2 of Fig. 5.23 is generated.\n\nThe insertion of an inductive ellipsoid is more straightforward. The inductive\nellipsoid is duplicated three times and inserted as pre and post-conditions respectively\nat the beginning and end of the compute function body. It is also inserted as a pre\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 167\n\nFig. 5.24 Inductive ellipsoids in ACSL\n\nand post-conditions on the function itself. These ellipsoids are the ones defined by\nthe matrix variable QMat_1 in Fig. 5.24.\n\n5.11 Computing the Strongest Post-condition\n\nThe sp-calculus has been automated in Gene-Auto+ using a set of transformation\nrules from ellipsoidal calculus, which are used to compute sp(q(Q, x, 1), C) or its\n\n\n\n168 T. Wang et al.\n\nover-approximation for various block of code C. The set of transformation rules can\nbe divided into two categories: affine transformations, and S-Procedure transforma-\ntions.\n\n5.11.1 Affine Transformation\n\nThe basics of affine transformation have been described using the example x+ = Ax in\nSect. 5.7 and proven in PVS (see Fig. 5.11). For automating the proof-checking of the\naffine transformations of ellipsoids, we define a proof tactic denoted AffineEllipsoid,\nwhich corresponds to a proof strategy of the same name defined in PVS. This rule\nis applied whenever a linear abstraction of the code can be computed. Recall from\nSect. 5.7, given the pre-condition q(Qi, xi, 1) and the code z = Lxi, then the linear\ntransformation from xi to xi+1 is Ti =\n\n[\nI\nL\n\n]\n. The strongest post-condition is therefore\n\nq(TiQiTTi , xi+1, 1).\nIn the more general case, let the affine semantic of a block of code be z := Ly,\n\nwhere y ? Rm is vector of program states and L ? R1\u00d7m. Let Qi(x) := q(Qi, x, 1),\nthen the AffineEllipsoid tactic is\n\n{Qn(x)} z := a {Qn+1(x ? z)} , Qn+1 = F (Qn, ?(L, y, x), ?(z, x)) , (5.24)\n\nand the function F is defined as follows: given the functions ? : (L, y, x) ? R1\u00d7n\nand ? : (z, x) ? Z, we have\n\nF : (Qn, ?(L, y, x), ?(z, x)) ? T (?(L, y, x), ?(z, x))T QnT (?(L, y, x), ?(z, x))\n\nT\n(\n?(L, y, x), ?(z, x)i,j\n\n) :=\n??\n?\n\n1, 0 ? i, j ? n ? i = j ? i ?= ?(z, x)\n0, 0 ? i, j ? n ? i ?= j ? i ?= ?(z, x)\n?(y, x)1,j, i = ?(z, x) ? 0 ? j ? n\n\n?(L, y, x)1,j :=\n{\n\nL(1, k), 0 ? j, k ? n ? xj ? y ? yk = xj\n0, 0 ? j ? n ? xj /? y\n\n?(z, x) :=\n{\n\ni, z ? x ? z = xi\nn + 1, z /? x\n\n(5.25)\n\nThe ReduceEllipsoid tactic is used, when the state xi of the program is reduced in\ndimensions from the previous state xi?1. Let Q(x) := q(Q, x, 1), then the ReduceEl-\nlipsoid tactic is\n\n{Qn(x)} SKIP {Qn+1(x \\ {z})} , Qn+1 = G (Qn, ?(z, x)) , (5.26)\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 169\n\nand the function G is defined as the following: given the function ? : (z, x) ? Z,\nwe have\n\nG : (Qn, ?(z, x)) ? T (?(z, x))T QnT (?(z, x))\nT\n(\n?(z, x)i,j\n\n) :=\n{\n\n1, 0 ? i, j ? n ? 1 ? ((i < ?(z, x) ? i = j) ? (i ? ?(z, x) ? j = i + 1))\n0, 0 ? i, j ? n ? 1 ? ((i < ?(z, x) ? i ?= j) ? (i ? ?(z, x) ? j ?= i + 1))\n\n?(z, x) := { i, z = xi\n(5.27)\n\nBefore the insertion of the Ellipsoid objects into the code model, each line of code\nis analyzed for its affine semantics. A linear transformation matrix L is extracted from\nthe abstract semantics and stored in the control flow graph. For example, if we have\nx = y + 2z, then the affine algorithm returns a linear function represented by the\nmatrix L = [1 2]. For the plant objects, their affine semantics are computed from\nthe templates stored in the semantics of the system blocks.\n\nFigure 5.25 shows an example of the AffineEllipsoid usage in the open-loop exam-\nple. In this example, the pre-condition is the ellipsoid defined by the matrix variable\nQMat_21, and the ensuing line of code assigns the expression dt_+x1 to the vari-\nable Sum2. The affine transformation matrix is L = [1 1], and by applying the\nAffineEllipsoid rule, the ellipsoid transformation matrix T is\n\nT =\n{\n\nTij = 1.0, (i ? 4 ? i = j) ? (i = 6 ? (j = 6 ? i = 6)) ? (i = 5 ? j = 6)\nTij = 0.0, otherwise. (5.28)\n\n5.11.2 S-Procedure\n\nThe S-Procedure tactic, proven in PVS (see Fig. 5.12), is used to compute an over-\napproximation of the strongest post-condition for the nonlinear portion of the code.\nIt is based on the well-known principle of Lagrangian relaxation for quadratic\nforms [31]. For the bounded input stability problem, the LMI solution also yields\na small positive multiplier 1 >> ? > 0 that is associated with the bounded input\nquadratic form. This small multiplier proves to be useful in the sp-calculus in the\nfollowing sense. Consider the line of code yc=yd-z with two pre-conditions. One\nof the two pre-conditions is q(Qb, yd, 1), which is translated from the quadratic\nblock bounded_input in the closed-loop model. The other pre-condition q(Qi, xi, 1)\ny ? xi, is generated from the sp-calculus. The multiplier ? > 0 enables us to combine\nin a convex fashion the two pre-conditions q(Qb, yd, 1) and (Qi, xi, 1) into a single\npost-condition q(Qi+1, xi+1, 1), xi+1 = xi ? {yd}, in which\n\nQi+1 =\n[ 1\n\n1??Qi 0\n0 1\n\n?\nQb\n\n]\n(5.29)\n\n\n\n170 T. Wang et al.\n\nFig. 5.25 Application of AffineEllipsoid\n\nLet Qn(xi) := q(Qn, xi, 1), the S-Procedure tactic is\n\n{Q1(x1) ? Q2(x2) ? . . . ? QN (xN )} SKIP {Qn+1(x0 ? x1 ? . . . ? xn)}\nQn+1 =\n\nN?\ni=1\n\n?iH (Qi) ,\n(5.30)\n\nand H : Rni\u00d7ni ? RNn\u00d7Nn is defined as follows: given the function dim : Rn\u00d7n ?\nn, and the function ? : n ? Z+ ??ni=1 dim (Qi), we have\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 171\n\nH (Qi)(n, m) =\n{\n\nQi(n ? ? (i ? 1) , m ? ? (i ? 1)), ? (i ? 1) ? n, m ? ? (i)\n0.0, otherwise\n\n(5.31)\n\nGiven the pre-condition {Qi(xi)} and code C such that ?C? ? (y := Lz), the\nSProcedure rule is activated only when all the following conditions are satisfied:\n\n1. For each Qi (xi), the AffineEllipsoid rule does not apply.\n\n2. For the set {Qi (xi)} , i = 1, . . . , N , z ?\nN?\n\ni=1\nxi.\n\n3. For Qi (xi) , i = 1, . . . , N , z ? xi ? z ? xi ?= {?}.\nThe multipliers are computed beforehand using the S-Procedure theory to ensure\n\nthat the sp-calculus, which uses the S-Procedure rule at some point, does not result in\na strongest post-condition that violates the initial pre-condition. For the closed-loop\nexample in Fig. 5.26, there is one ellipsoid pre-condition defined by the matrix vari-\nableQMat_12. This ellipsoid is translated from the quadratic block bounded_input.\nThe other ellipsoid pre-condition, is defined by the matrix variable QMat_13. This\nellipsoid is computed by the sp-calculus. These two ellipsoids are combined to form\na post-condition ellipsoid using the S-Procedure. The matrix variable QMat_14,\nwhich defines the post-condition ellipsoid, is expressed using the pre-defined ACSL\nblock matrices function block_m.\n\nFig. 5.26 Application of the S-Procedure tactic\n\n\n\n172 T. Wang et al.\n\nFig. 5.27 Verifying the strongest post-condition\n\n5.11.3 Verification of the Strongest Post-condition\n\nAfter application of the sp-calculus, the alternative post-condition generated must\nbe checked against the initial pre-condition. For the closed-loop example displayed\nin Fig. 5.27, this means checking if Q_1 is a \u201cbigger\u201d matrix than Q_32. If this\nverification condition can be discharged, then one can claim the code satisfies the\nstability property. For the closed-loop example, because of a subtle error introduced\ninto the model that went unnoticed until this point, the last verification condition\ncould not be discharged until the sign error was corrected in the Simulink model.\n\n5.12 Automatic Verification of Control Semantics\n\nAs part of the credible autocoding process, the annotated C code which generation\nprocess we described in Sect. 5.4, must be independently verifiable. Indeed, we now\ndescribe and implement a tool that can be used by the certification authority in order\nautomatically check that the annotations are correct with respect to the code. This\nis achieved by checking that each of the individual Hoare triples hold. Figure 5.28\npresents an overview of the checking process. First, the WP plugin of Frama-C gen-\nerates verification conditions for each Hoare triple, and discharges the trivial ones\nwith its internal prover QeD. Then, the remaining conditions are translated into PVS\ntheorems for further processing, as described in Sect. 5.12.1. It is then necessary to\nmatch the types and predicates introduced in ACSL to their equivalent representation\nin PVS. This is done through theory interpretation [32] and explained in Sect. 5.12.2.\nOnce interpreted, the theorems can be generically proven thanks to custom PVS\nstrategies, as described in Sect. 5.12.3. In order to automatize these various tasks\nand integrate our framework within the Frama-C platform, which provides graphical\nsupport to display the status of a verification condition (proved/unproved), we wrote\na Frama-C plugin named pvs-ellipsoid, described in Sect. 5.12.4. Finally, one verifi-\ncation condition does not fall under either AffineEllipsoid of SProcedure\nstrategies. It is discussed in Sect. 5.12.5.\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 173\n\nAnnotated code\n\nC Code\n\n+ ACSL\n+ Proof tactics\n\nA CSL linear algebra library\n\nFrama-C\n\nVerification Conditions\n\nPVS Theorems\n\nPVS\nInterpreted Theorems\n\n+ Proof tactics\n\nPVS linear algebra library\n\nPVS strategies\n\nPVS proof\n\nGo / No Go\n\nFig. 5.28 General view of the automated verification process described and implemented in this\nsection\n\n5.12.1 From C Code to PVS Theorems\n\nThe autocoder described in the previous Section generates two C functions. One of\nthem is an initialization function, the other implements one execution of the loop\nthat acquires inputs and updates the state variables and the outputs. It is left to the\nimplementer to write the main function combining the two, putting the latter into\na loop, and interfacing with sensors and actuators to provide inputs and deliver\noutputs. Nevertheless, the properties of open and closed loop stability, as well as\nstate-boundedness, can be established by solely considering the update function,\nwhich this section now focuses on. The generated function essentially follows the\ntemplate shown in Fig. 5.29.\n\nFrama-C is a collaborative platform designed to analyze the source code of soft-\nware written in C. The WP plugin enables deductive verification of C programs\nannotated with ACSL. For each Hoare tripe {prei}insti{posti}, it generates a first\norder logic formula expressing prei =? wp(insti, posti).2 Through the Why3 plat-\nform, these formulas can be expressed as theorems in PVS, so that, for example, the\nACSL/C triple shown in Fig. 5.30, taken directly from our running example, becomes\nthe theorem shown in Fig. 5.31.\n\n2Given a program statement S and a postcondition Q, wp(S, Q) is the weakest precondition on the\ninitial state ensuring that execution of S terminates in a state satisfying Q.\n\n\n\n174 T. Wang et al.\n\nFig. 5.29 Template of the generated loop update function\n\nFig. 5.30 Typical example of an ACSL Hoare triple\n\nNote that, for the sake of readability, part of the hypotheses of this theorem,\nincluding hypotheses on the nature of variables, as well as hypotheses stemming\nfrom Hoare triples present earlier in the code, are ommitted here. Note also that in\nthe translation process, functions like malloc_0 or mflt_1 have appeared. They\ndescribe the memory state of the program at different execution points.\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 175\n\nFig. 5.31 Excerpt of the PVS translation of the triple shown in Fig. 5.30\n\n5.12.2 Theory Interpretation\n\nAt the ACSL level, a minimal set of linear algebra symbols has been introduced,\nalong with axioms defining their semantics. Section 5.3 describes a few of them.\nEach generated PVS theorem is written within a theory that contains a translation \u2019as\nis\u2019 of these definitions and axioms, along with some constructs specific to handling\nthe semantics of C programs. For example, the ACSL axiom expressing the number\nof rows of a 2 by 2 matrix (in Fig. 5.32) becomes the axiom shown in Fig. 5.33 after\ntranslation to PVS.\n\nIn order to leverage the existing results on matrices and ellipsoids in PVS, theory\ninterpretation is used. It is a logical technique used to relate one axiomatic theory\nto another. It is used here to map types introduced in ACSL, such as vectors and\nmatrices, to their counterparts in PVS, as well as the operations and predicates on\nthese types. To ensure soundness, PVS requires that what was written as axioms in\nthe ACSL library be proven in the interpreted PVS formalism.\n\nFig. 5.32 ACSL axiomatization of 2 by 2 matrix row-size\n\n\n\n176 T. Wang et al.\n\nFig. 5.33 Translation of the ACSL axiom from Fig. 5.32 into PVS\n\nThe interpreted symbols and soundness checks are the same for each proof objec-\ntive, facilitating the mechanization of the process. Syntactically, a new theory is\ncreated, in which the theory interpretation is carried out, and the theorem to be\nproven is automatically rewritten by PVS in terms of its own linear algebra symbols.\nThese manipulations on the generated PVS code are carried out by a frama-C plugin\ncalled pvs-ellipsoid, which is described below.\n\n5.12.3 Generically Discharging the Proofs in PVS\n\nOnce the theorem is in its interpreted form, all that remains to do is to apply the\nproper lemma to the proper arguments. Section 5.4 describes two different types of\nHoare triples that can be generated in ACSL. Two PVS strategies were written to\nhandle these possible cases. A PVS proof strategy is a generic function describing a\nset of basic steps communicated to the interactive theorem prover in order to facilitate\nor even fully discharge the proof of a lemma. The AffineEllipsoid strategy\nhandles any ellipsoid update stemming from a linear assignment of the variables.\nRecall ellipsoid_general, a theorem introduced in Sect. 5.3:\n\nTo apply this theorem properly, the first step of the strategy consists of parsing the\nobjectives and hypotheses of the theorem to acquire the name and the dimensions\nof the relevant variables, and to isolate the necessary hypotheses. The second step\nconsists of a case splitting on the dimensions of the variable: they are given to\nthe prover in order to complete the main proof, and then established separately\nusing the proper interpreted axioms. Next, it is established that y = Mx through\n\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 177\n\na case decomposition and numerous calls to relevant interpreted axioms. All the\nhypotheses are then present for a direct application of the theorem. The difficulties\nin proof strategy design lie in intercepting and anticipating the typecheck constraints\n(tccs) that PVS introduces throughout the proof. A third strategy was specifically\nwritten to handle them.\n\nThe S-Procedure strategy follows a very similar pattern, somewhat simpler since\nthe associated instruction in the Hoare triple is a skip, using ellipsoid_\ncombination, the other main theorem presented in Sect. 5.3.\n\n5.12.4 The pvs-ellipsoid Plugin to Frama-C\n\nThe pvs-ellipsoid plugin to Frama-C automatizes the steps mentionned in the previ-\nous subsections. It calls the WP plugin on the provided C file, then, whenever QeD\nfails to prove a step, it creates the PVS theorem for the verification condition through\nWhy3 and modifies the generated code to apply theory interpretation. It extracts the\nproof tactic to be used on this specific verification condition, and uses it to signify to\nthe next tool in the chain, proveit [33], what strategy to use to prove the theorem\nat hand. proveit is a command line tool that can be called on a PVS file and\nattempts to prove all the theories in it, possibly using user guidance such as the one\njust discussed. When the execution of proveit terminates, a report is produced,\nenabling the plugin to decide whether the verification condition is discharged or not.\nIf it is, a proof file is generated, making it possible for the proof to be replayed in\nPVS.\n\n5.12.5 Checking Inclusion of the Propagated Ellipsoid\n\nOne final verification condition falls under neither the AffineEllipsoid nor the\nS-Procedure categories. It expresses that the state remains in the initial ellipsoid\nGP. Through a number of transformations, we have proof that the state lies in some\nellipsoid G ?P. The conclusion of the verification lies in the final test P ? P? ? 0. The\ncurrent state of the linear algebra library in PVS does not permit to make such a test,\nhowever a number of very reliable external tools, like the INTLAB package of the\nMATLAB software suite, can operate this check. In the case of our framework, the\npvs-ellipsoid plugin intercepts this final verification condition before translating it to\nPVS, and uses custom code from [34] to ensure positive definiteness of the matrix,\nwith the added benefit of soundness with respect to floating point computations.\n\n\n\n178 T. Wang et al.\n\n5.13 Related Works\n\nAlthough the efforts described in this chapter explore a new intersection between\ncontrol theory and computer science, a few notable earlier works are mentioned here.\nUrsula Martin and her team developed a limited Hoare logic framework to reason on\nfrequency domain properties of linear controllers at the Simulink level [35]. Jerome\nFerret was the first to focus on the static analysis of digital filters in [5]. It was this\nwork that initiated the connections made between the control-theoretic techniques\nand software analysis methods in [9]. Parallel work by Roux et al. [34] uses policy\ninteration to generate and refine ellipsoid invariants. We would like to thank Eric\nGoubault and Sylvie Putot for the useful discussions, and mention their work on\nzonotopal domain for static analyzers [36].\n\n5.14 Conclusion\n\nThe prototype tools and various examples described in this chapter can be found\nonline.3 We have demonstrated in this chapter a set of prototype tools that is capable\nof migrating high-level functional properties of control systems down to the code\nlevel. In addition we have developed a tool which can independantly verify the\ncorrectness of those properties for the code, in an automatic manner. While the nature\nof controllers and properties supported is relatively restricted, this effort demonstrates\nthe feasability of a paradigm where domain specific knowledge is leveraged and\nautomatically assists code analysis. This opens the way for numerous directions\nof research. As the mathematical breadth of theorem provers increase, increasingly\ncomplex code invariants can theoretically be handled, and thus increasingly complex\ncontrollers. In particular, generating verifiable optimization algorithms, e.g. for the\npurpose of path planning, is a promising direction. Soundness of the results with\nrespect to floating point computations is another issue that requires attention.\n\nThe toolchain had been applied not only to the running example, but also on\nindustry size systems, such as the Quanser 3 degree-of-freedom helicopter, and a\nvery light jet turbofan engine controller from Price Induction.\n\nAcknowledgments The authors would like to thank Pierre Roux for his contribution to the PVS-\nellipsoid plugin, Gilberto Perez and Pablo Ascariz for their invaluable help on the PVS linear algebra\nlibrary.\n\nThis chapter was prepared under support from NSF Grant CPS Medium 1135955 (CrAVES),\nCPS Synergy 1446758 (SORTIES), the Army Research Office under MURI W911NF-11-1-\n0046, the National Aeronautics and Space Administration under NASA Cooperative Agreement\nNNL09AA00A, activity 2736, the French Fond Unique Interministeriel 2011 project P, ITEA2\nOPES, FNRAE project CAVALE, ANR INS project CAFEIN and ANR ASTRID project VORACE.\n\n3http://www.feron.org/Eric/Credible.\n\nhttp://www.feron.org/Eric/Credible\n\n\n5 From Design to Implementation: An Automated, Credible Autocoding \u2026 179\n\nReferences\n\n1. Clarke Jr, E.M., Grumberg, O., Peled, D.A.: Model Checking. MIT Press, Cambridge, MA,\nUSA (1999)\n\n2. De Moura, L.: Bj\u00f8rner, N.: Z3: An efficient SMT solver. In: Proceedings of the Theory and Prac-\ntice of Software, 14th International Conference on Tools and Algorithms for the Construction\nand Analysis of Systems, TACAS\u201908/ETAPS\u201908, pp. 337\u2013340. Springer, Berlin, Heidelberg\n(2008)\n\n3. Moskewicz, M.W., Madigan, C.F., Zhao, Y., Zhang, L., Malik, S.: Chaff: Engineering an\nefficient SAT solver. In: Proceedings of the 38th Annual Design Automation Conference. DAC\n\u201901, pp. 530\u2013535. ACM, New York, NY, USA (2001)\n\n4. Souyris, J.: Industrial experience of abstract interpretation-based static analyzers. In: Jacquart,\nR. (ed.) Building the Information Society, IFIP International Federation for Information\nProcessing, vol. 156, pp. 393\u2013400. Springer, US (2004). doi:10.1007/978-1-4020-8157-6_\n31\n\n5. Feret, J.: Static analysis of digital filters. In: European Symposium on Programming (ESOP\u201904),\nno. 2986 in LNCS, pp. 33\u201348. Springer, Berlin (2004)\n\n6. Feret, J.: Numerical abstract domains for digital filters. In: International workshop on Numerical\nand Symbolic Abstract Domains (NSAD) (2005)\n\n7. Cousot, P., Cousot, R., Feret, J., Mauborgne, L., Min\u00e9, A., Monniaux, D., Rival, X.: The\nASTR\u00c9E analyzer. In: Proceedings of the 14th European Symposium on Programming, Lecture\nNotes in Computer Science, vol. 3444 (2005)\n\n8. Monniaux, D.: Compositional analysis of floating-point linear numerical filters. In: CAV (2005)\n9. Feron, E.: From control systems to control software. IEEE Control Syst. 30(6), 50\u201371 (2010)\n\n10. Herencia-Zapana, H., Jobredeaux, R., Owre, S., Garoche, P.L., Feron, E., Perez, G., Ascariz, P.:\nPvs linear algebra libraries for verification of control software algorithms in c/acsl. In: NASA\nFormal Methods, pp. 147\u2013161 (2012)\n\n11. Rinard, M.: Credible compilation. Techincal report, In: Proceedings of CC 2001: International\nConference on Compiler Construction (1999)\n\n12. Denney, E.: Certifying auto-generated flight code. http://shemesh.larc.nasa.gov/LFM2008/\nslides/Session3/Denney.ppt (2008)\n\n13. Dieumegard, A.: Formal guarantees for safety critical code generation: the case of highly\nvariable languages. Ph.D. thesis, INP Toulouse (2015)\n\n14. Boyd, S., El Ghaoui, L., Feron, E., Balakrishnan, V.: Linear Matrix Inequalities in System and\nControl Theory, Studies in Applied Mathematics, vol. 15. SIAM, Philadelphia, PA (1994)\n\n15. Megretski, A., Rantzer, A.: System analysis via integral quadratic constraints. IEEE Trans.\nAutom. Control 42(6), 819\u2013830 (1997)\n\n16. Berry, G., Gonthier, G., Gonthier, A.B.G., Laltte, P.S.: The esterel synchronous programming\nlanguage: Design, semantics, implementation (1992)\n\n17. Pakmehr, M., Wang, T., Jobredeaux, R., Vivies, M., Feron, E.: Verifiable control system devel-\nopment for gas turbine engines. CoRR abs/1311.1885 (2013)\n\n18. Yakubovich, V.A.: The solution of certain matrix inequalities in automatic control theory. Soviet\nMath. Dokl 3, 620\u2013623 (1962)\n\n19. Nesterov, Y., Nemirovskii, A., Ye, Y.: Interior-point polynomial algorithms in convex program-\nming, In: SIAM, vol. 13. (1994)\n\n20. Bordin, M., Naks, T., Toom, A., Pantel, M.: Compilation of heterogeneous models: Motivations\nand challenges. In: ERTS. Soci\u00e9t\u00e9 des Ing\u00e9nieurs de l\u2019Automobile, http://www.sia.fr (2012)\n\n21. Izerrouken, N., Pantel, M., Thirioux, X.: Ssi Yan Kai, O.: Integrated formal approach for\nqualified critical embedded code generator. Formal Methods for Industrial Critical Systems.\nLecture Notes in Computer Science, vol. 5825, pp. 199\u2013201. Springer, Berlin (2009)\n\n22. Toom, A., Izerrouken, N., Naks, T., Pantel, M., Ssi-Yan-Kai, O.: Towards reliable code gener-\nation with an open tool: Evolutions of the gene-auto toolset. In: ERTS. Soci\u00e9t\u00e9 des Ing\u00e9nieurs\nde l\u2019Automobile, http://www.sia.fr (2010)\n\nhttp://dx.doi.org/10.1007/978-1-4020-8157-6_31\nhttp://dx.doi.org/10.1007/978-1-4020-8157-6_31\nhttp://shemesh.larc.nasa.gov/LFM2008/slides/Session3/Denney.ppt\nhttp://shemesh.larc.nasa.gov/LFM2008/slides/Session3/Denney.ppt\nhttp://www.sia.fr\nhttp://www.sia.fr\n\n\n180 T. Wang et al.\n\n23. Toom, A., Naks, T., Pantel, M., Gandriau, M., Wati, I.: Gene-auto\u2013an automatic code gener-\nator for a safe subset of simulink-stateflow and Scicos. In: ERTS. Soci\u00e9t\u00e9 des Ing\u00e9nieurs de\nl\u2019Automobile, http://www.sia.fr (2008)\n\n24. Baudin, P., Filli\u00e2tre, J.C., March\u00e9, C., Monate, B., Moy, Y., Prevosto, V.: ACSL: ANSI/ISO C\nSpecification Language. http://frama-c.cea.fr/acsl.html (2008)\n\n25. Whalen, M.W., Murugesan, A., Rayadurgam, S., Heimdahl, M.P.: Structuring simulink models\nfor verification and reuse. In: Proceedings of the 6th International Workshop on Modeling in\nSoftware Engineering, pp. 19\u201324. ACM (2014)\n\n26. Cuoq, P., Kirchner, F., Kosmatov, N., Prevosto, V., Signoles, J., Yakobowski, B.: Frama-c: A\nsoftware analysis perspective. In: Proceedings of the 10th International Conference on Software\nEngineering and Formal Methods. SEFM\u201912, pp. 233\u2013247. Springer, Berlin, Heidelberg (2012)\n\n27. Scott, M.L.: Programming Language Pragmatics. Morgan Kaufmann Publishers Inc., San Fran-\ncisco, CA, USA (2000)\n\n28. Hoare, C.A.R.: An axiomatic basis for computer programming. Commun. ACM 12, 576\u2013580\n(1969)\n\n29. Dijkstra, E.W.: Guarded commands, nondeterminacy and formal derivation of programs. Com-\nmun. ACM 18(8), 453\u2013457 (1975)\n\n30. Geneauto metamodel with verification annotations documentation. http://block-library.\nenseeiht.fr/html/Progress/geneautoAnnot.html\n\n31. J\u00f6nsson, U.T.: A Lecture on the S-Procedure. Lecture Note at the Royal Institute of technology,\nSweden (2001)\n\n32. Owre, S., Shankar, N.: Theory interpretation in pvs. Techincal report, SRI International (2001)\n33. Munoz, C.: Batch proving and proof scripting in pvs. NIA-NASA Langley. National Institute\n\nof Aerospace, Hampton, VA, Report NIA Report (2007)\n34. Roux, P., Jobredeaux, R., Garoche, P.L., Feron, E.: A generic ellipsoid abstract domain for\n\nlinear time invariant systems. In: HSCC, pp. 105\u2013114 (2012)\n35. Arthan, R., Martin, U., Oliva, P.: A hoare logic for linear systems. Formal Aspects Comput.\n\n25(3), 345\u2013363 (2013)\n36. Goubault, E., Putot, S.: A zonotopic framework for functional abstractions. CoRR\n\nabs/0910.1763 (2009)\n37. dof helicopter: http://www.quanser.com/Products/3dof_helicopter\n38. Price Induction: DGEN 380 turbofan engine. http://www.price-induction.com/en (2013)\n\nhttp://www.sia.fr\nhttp://frama-c.cea.fr/acsl.html\nhttp://block-library.enseeiht.fr/html/Progress/geneautoAnnot.html\nhttp://block-library.enseeiht.fr/html/Progress/geneautoAnnot.html\nhttp://www.quanser.com/Products/3dof_helicopter\nhttp://www.price-induction.com/en\n\n\tPreface\n\tContents\n\tContributors\n\t1 Spacecraft Autonomy Challenges  for Next-Generation Space Missions\n\t1.1 Introduction\n\t1.1.1 High-Level Challenges and High-Priority Technologies for Space Autonomous Systems\n\n\t1.2 Relative Guidance Algorithmic Challenges  for Autonomous Spacecraft\n\t1.2.1 Scope\n\t1.2.2 Need\n\t1.2.3 State of the Art\n\t1.2.4 Challenges and Future Directions\n\n\t1.3 Extreme Mobility\n\t1.3.1 Scope\n\t1.3.2 Need\n\t1.3.3 State of the Art\n\t1.3.4 Challenges and Future Directions\n\n\t1.4 Microgravity Mobility\n\t1.4.1 Scope\n\t1.4.2 Need\n\t1.4.3 State of the Art\n\t1.4.4 Challenges and Future Directions\n\n\t1.5 Conclusions\n\tReferences\n\n\t2 New Guidance, Navigation, and Control Technologies for Formation Flying Spacecraft and Planetary Landing\n\t2.1 Introduction\n\t2.2 GN&C Technologies for Planetary Landing  in Hazardous Terrain\n\t2.2.1 Introduction\n\t2.2.2 Design Considerations\n\t2.2.3 Case Study 1: Mars Robotic System\n\t2.2.4 Case Study 2: Crewed Lunar System\n\t2.2.5 System Comparison\n\n\t2.3 Phase Synchronization Control of Spacecraft Swarms\n\t2.3.1 Problem Statement---Controlling the Phase Differences in Periodic Orbits\n\t2.3.2 Phase Synchronization Control Law with Adaptive Graphs\n\t2.3.3 Main Stability Theorems and Simulation Results\n\n\t2.4 Application of Probabilistic Guidance to Swarms  of Spacecraft Operating in Earth Orbit\n\t2.4.1 Introduction\n\t2.4.2 Probabilistic Guidance Problem\n\t2.4.3 Probabilistic Guidance Algorithm (PGA)\n\t2.4.4 Adaptation of PGA to Earth Orbiting Swarms\n\n\t2.5 Nonlinear State Estimation And Sensor Optimization Problems for Detection of Space Collision Events\n\t2.5.1 LEO Sensor Constellation Design and Collision Event Testbed\n\t2.5.2 Satellite Collision Modeling and Estimation\n\n\t2.6 Conclusion\n\tReferences\n\n\t3 Aircraft Autonomy\n\t3.1 Introduction\n\t3.1.1 Challenges to the Safe Integration of UAVs  in the National Airspace\n\t3.1.2 Technical Enhancements for Safe Insertion of UAVs  in the NAS\n\n\t3.2 On-Board Air Autonomy Systems Needs\n\t3.2.1 Challenges to Integration of UAVs in the NAS\n\t3.2.2 Technical Enhancements for Improved In-Air  autonomy---Key Technologies\n\t3.2.3 Conclusions: A Road-Map to Address the Technical Challenges\n\n\t3.3 Human-Automation Collaboration\n\t3.3.1 Challenges in the Collaborative Human-Automation Scheduling Process\n\t3.3.2 Candidate Methods in Human-Automation Collaborative Scheduling\n\t3.3.3 Technical Enhancements needed for Humans Interactions with Scheduling Algorithms\n\t3.3.4 Conclusions\n\n\t3.4 Autonomy Evolution for Air Traffic Control\n\t3.4.1 Challenges and Limitations of Current Air Traffic Management System\n\t3.4.2 Enhancements Made Within ATC System\n\t3.4.3 Technical Enhancements needed in the Evolution  of Airborne and Ground-Based Technologies\n\t3.4.4 Conclusions and Proposed Road-Map\n\n\tReferences\n\n\t4 Challenges in Aerospace Decision and Control: Air Transportation Systems\n\t4.1 Introduction\n\t4.2 Key NextGen Topics\n\t4.3 Supporting Technology Research Challenges\n\t4.3.1 Design of Automation with Graceful Degradation Modes\n\t4.3.2 System Verification and Validation (V&V)\n\t4.3.3 Large-Scale, Real-Time Optimization Algorithms\n\t4.3.4 Multi-Objective, Multi-Stakeholder, Optimization Frameworks\n\n\t4.4 Domain-Specific Research Challenges\n\t4.4.1 Airport Arrival Management\n\t4.4.2 Airport Departure Processes\n\t4.4.3 The Trip is Not Over: Passenger Management  in the Terminals\n\t4.4.4 Domain-Specific Contributions: Abstract Modeling Approaches\n\n\tReferences\n\n\t5 From Design to Implementation: An Automated, Credible Autocoding Chain  for Control Systems\n\t5.1 Introduction\n\t5.2 Credible Autocoding Framework\n\t5.2.1 Input and Output Languages of the Framework\n\n\t5.3 Control Semantics\n\t5.3.1 Control System Stability and Boundedness\n\t5.3.2 Prototype Tool-Chain\n\t5.3.3 Control Semantics in Simulink and Gene-Auto\n\t5.3.4 Annotation Blocks and Behaviors in the Model\n\t5.3.5 Closed-Loop Stability with Bounded Input\n\t5.3.6 Expressing the Observer-Based Fault-Detection Semantics\n\t5.3.7 Control Semantics at the Level of the C Code\n\t5.3.8 Closed Loop Semantics\n\t5.3.9 Control Semantics in PVS\n\n\t5.4 Autocoding with Control Semantics\n\t5.5 Building the Input Model\n\t5.6 Basics of Program Verification\n\t5.6.1 Hoare Logic and Deductive Verification\n\t5.6.2 Predicate Transformers\n\t5.6.3 Strongest Post-condition\n\n\t5.7 Translation Process for a Simple Dynamical System\n\t5.8 Gene-Auto+: A Prototype Credible Autocoder\n\t5.8.1 Gene-Auto: Translation\n\t5.8.2 Translation of Annotative Blocks\n\n\t5.9 Translation and Insertion of the System Block\n\t5.10 Translation of the Quadratic Blocks\n\t5.10.1 Types of Quadratic Blocks\n\t5.10.2 Insertion of Ellipsoid Objects\n\n\t5.11 Computing the Strongest Post-condition\n\t5.11.1 Affine Transformation\n\t5.11.2 S-Procedure\n\t5.11.3 Verification of the Strongest Post-condition\n\n\t5.12 Automatic Verification of Control Semantics\n\t5.12.1 From C Code to PVS Theorems\n\t5.12.2 Theory Interpretation\n\t5.12.3 Generically Discharging the Proofs in PVS\n\t5.12.4 The pvs-ellipsoid Plugin to Frama-C\n\t5.12.5 Checking Inclusion of the Propagated Ellipsoid\n\n\t5.13 Related Works\n\t5.14 Conclusion\n\tReferences\n\n\n\n\n"}